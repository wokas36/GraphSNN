{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import argparse\n",
    "import heapq as hp\n",
    "\n",
    "from graph_data import GraphData\n",
    "from data_reader import DataReader\n",
    "from models import GNN\n",
    "\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=117, type=<class 'int'>, choices=None, help='Random seed.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment parameters\n",
    "'''\n",
    "----------------------------\n",
    "Dataset  |   batchnorm_dim\n",
    "----------------------------\n",
    "MUTAG    |     28\n",
    "PTC_MR   |     64\n",
    "BZR      |     57\n",
    "COX2     |     56\n",
    "COX2_MD  |     36\n",
    "BZR-MD   |     33\n",
    "PROTEINS |    620\n",
    "D&D      |   5748\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--device', default='cpu', help='Select CPU/CUDA for training.')\n",
    "parser.add_argument('--dataset', default='MUTAG', help='Dataset name.')\n",
    "parser.add_argument('--epochs', type=int, default=500, help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.009, help='Initial learning rate.') \n",
    "parser.add_argument('--wdecay', type=float, default=9e-3, help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Batch size.')\n",
    "parser.add_argument('--hidden_dim', type=int, default=64, help='Number of hidden units.')\n",
    "parser.add_argument('--n_layers', type=int, default=2, help='Number of MLP layers for GraphSN.')\n",
    "parser.add_argument('--batchnorm_dim', type=int, default=28, help='Batchnormalization dimension for GraphSN layer.')\n",
    "parser.add_argument('--dropout_1', type=float, default=0.5, help='Dropout rate for concatenation the outputs.') \n",
    "parser.add_argument('--dropout_2', type=float, default=0.6, help='Dropout rate for MLP layers in GraphSN.')\n",
    "parser.add_argument('--n_folds', type=int, default=10, help='Number of folds in cross validation.')\n",
    "parser.add_argument('--threads', type=int, default=0, help='Number of threads.')\n",
    "parser.add_argument('--log_interval', type=int, default=10 , help='Log interval for visualizing outputs.')\n",
    "parser.add_argument('--seed', type=int, default=117, help='Random seed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "making labels sequential, otherwise pytorch might crash\n",
      "N nodes avg/std/min/max: \t17.93/4.58/10/28\n",
      "N edges avg/std/min/max: \t19.79/5.68/10/33\n",
      "Node degree avg/std/min/max: \t2.21/0.74/1/4\n",
      "Node features dim: \t\t7\n",
      "N classes: \t\t\t2\n",
      "Classes: \t\t\t[0 1]\n",
      "Class 0: \t\t\t63 samples\n",
      "Class 1: \t\t\t125 samples\n",
      "feature 0, count 2395/3371\n",
      "feature 1, count 345/3371\n",
      "feature 2, count 593/3371\n",
      "feature 3, count 12/3371\n",
      "feature 4, count 1/3371\n",
      "feature 5, count 23/3371\n",
      "feature 6, count 2/3371\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "# dataset_fold_idx_path = './data/%s/' % args.dataset.upper() + 'fold_idx/'\n",
    "# datareader = DataReader(data_dir='./data/%s/' % args.dataset.upper(),\n",
    "#                         fold_dir=dataset_fold_idx_path,\n",
    "#                         rnd_state=np.random.RandomState(args.seed),\n",
    "#                         folds=args.n_folds,                    \n",
    "#                         use_cont_node_attr=False)\n",
    "\n",
    "datareader = DataReader(data_dir='./data/%s/' % args.dataset.upper(),\n",
    "                        fold_dir=None,\n",
    "                        rnd_state=np.random.RandomState(args.seed),\n",
    "                        folds=args.n_folds,                    \n",
    "                        use_cont_node_attr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(datareader.data['adj_list'])\n",
    "for itr in np.arange(dataset_length):\n",
    "    A_array = datareader.data['adj_list'][itr]\n",
    "    G = nx.from_numpy_matrix(A_array)\n",
    "    \n",
    "    sub_graphs = []\n",
    "    subgraph_nodes_list = []\n",
    "    sub_graphs_adj = []\n",
    "    sub_graph_edges = []\n",
    "    new_adj = torch.zeros(A_array.shape[0], A_array.shape[0])\n",
    "\n",
    "    for i in np.arange(len(A_array)):\n",
    "        s_indexes = []\n",
    "        for j in np.arange(len(A_array)):\n",
    "            s_indexes.append(i)\n",
    "            if(A_array[i][j]==1):\n",
    "                s_indexes.append(j)\n",
    "        sub_graphs.append(G.subgraph(s_indexes))\n",
    "\n",
    "    for i in np.arange(len(sub_graphs)):\n",
    "        subgraph_nodes_list.append(list(sub_graphs[i].nodes))\n",
    "        \n",
    "    for index in np.arange(len(sub_graphs)):\n",
    "        sub_graphs_adj.append(nx.adjacency_matrix(sub_graphs[index]).toarray())\n",
    "        \n",
    "    for index in np.arange(len(sub_graphs)):\n",
    "        sub_graph_edges.append(sub_graphs[index].number_of_edges())\n",
    "\n",
    "    for node in np.arange(len(subgraph_nodes_list)):\n",
    "        sub_adj = sub_graphs_adj[node]\n",
    "        for neighbors in np.arange(len(subgraph_nodes_list[node])):\n",
    "            index = subgraph_nodes_list[node][neighbors]\n",
    "            count = torch.tensor(0).float()\n",
    "            if(index==node):\n",
    "                continue\n",
    "            else:\n",
    "                c_neighbors = set(subgraph_nodes_list[node]).intersection(subgraph_nodes_list[index])\n",
    "                if index in c_neighbors:\n",
    "                    nodes_list = subgraph_nodes_list[node]\n",
    "                    sub_graph_index = nodes_list.index(index)\n",
    "                    c_neighbors_list = list(c_neighbors)\n",
    "                    for i, item1 in enumerate(nodes_list):\n",
    "                        if(item1 in c_neighbors):\n",
    "                            for item2 in c_neighbors_list:\n",
    "                                j = nodes_list.index(item2)\n",
    "                                count += sub_adj[i][j]\n",
    "\n",
    "                new_adj[node][index] = count/2\n",
    "                new_adj[node][index] = new_adj[node][index]/(len(c_neighbors)*(len(c_neighbors)-1))\n",
    "                new_adj[node][index] = new_adj[node][index] * (len(c_neighbors)**2)\n",
    "\n",
    "    weight = torch.FloatTensor(new_adj)\n",
    "    weight = weight / weight.sum(1, keepdim=True)\n",
    "    \n",
    "    weight = weight + torch.FloatTensor(A_array)\n",
    "\n",
    "    coeff = weight.sum(1, keepdim=True)\n",
    "    coeff = torch.diag((coeff.T)[0])\n",
    "    \n",
    "    weight = weight + coeff\n",
    "\n",
    "    weight = weight.detach().numpy()\n",
    "    weight = np.nan_to_num(weight, nan=0)\n",
    "\n",
    "    datareader.data['adj_list'][itr] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 0\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.026660 (avg: 1.026660) \tsec/iter: 0.4535\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 0.785703 (avg: 2.348863) \tsec/iter: 0.1794\n",
      "Test set (epoch 0): Average loss: 0.5136, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 0.713191 (avg: 0.713191) \tsec/iter: 0.0419\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.908705 (avg: 0.687991) \tsec/iter: 0.0402\n",
      "Test set (epoch 1): Average loss: 0.4876, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.924100 (avg: 0.924100) \tsec/iter: 0.0449\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.548007 (avg: 0.798769) \tsec/iter: 0.0339\n",
      "Test set (epoch 2): Average loss: 0.9649, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 1.264370 (avg: 1.264370) \tsec/iter: 0.0359\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.417559 (avg: 1.057758) \tsec/iter: 0.0336\n",
      "Test set (epoch 3): Average loss: 0.6234, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.890945 (avg: 0.890945) \tsec/iter: 0.0369\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.312020 (avg: 0.609259) \tsec/iter: 0.0332\n",
      "Test set (epoch 4): Average loss: 0.5820, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.536825 (avg: 0.536825) \tsec/iter: 0.0359\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.351997 (avg: 0.565564) \tsec/iter: 0.0346\n",
      "Test set (epoch 5): Average loss: 0.5909, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.372813 (avg: 0.372813) \tsec/iter: 0.0359\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.574622 (avg: 0.443358) \tsec/iter: 0.0319\n",
      "Test set (epoch 6): Average loss: 1.0698, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.387963 (avg: 0.387963) \tsec/iter: 0.0339\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.392722 (avg: 0.467918) \tsec/iter: 0.0329\n",
      "Test set (epoch 7): Average loss: 0.8652, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.462294 (avg: 0.462294) \tsec/iter: 0.0399\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.582963 (avg: 0.528088) \tsec/iter: 0.0319\n",
      "Test set (epoch 8): Average loss: 0.8825, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.420057 (avg: 0.420057) \tsec/iter: 0.0339\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.451164 (avg: 0.371372) \tsec/iter: 0.0339\n",
      "Test set (epoch 9): Average loss: 0.8259, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.480018 (avg: 0.480018) \tsec/iter: 0.0389\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.625024 (avg: 0.457905) \tsec/iter: 0.0359\n",
      "Test set (epoch 10): Average loss: 0.7557, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.316354 (avg: 0.316354) \tsec/iter: 0.0429\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.332411 (avg: 0.456066) \tsec/iter: 0.0352\n",
      "Test set (epoch 11): Average loss: 1.8123, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.599148 (avg: 0.599148) \tsec/iter: 0.0329\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.507186 (avg: 0.520615) \tsec/iter: 0.0326\n",
      "Test set (epoch 12): Average loss: 1.5781, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.403892 (avg: 0.403892) \tsec/iter: 0.0379\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.336349 (avg: 0.384493) \tsec/iter: 0.0329\n",
      "Test set (epoch 13): Average loss: 0.9234, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.283192 (avg: 0.283192) \tsec/iter: 0.0359\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.459500 (avg: 0.363119) \tsec/iter: 0.0372\n",
      "Test set (epoch 14): Average loss: 1.3944, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.538227 (avg: 0.538227) \tsec/iter: 0.0379\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.339086 (avg: 0.426275) \tsec/iter: 0.0322\n",
      "Test set (epoch 15): Average loss: 1.3707, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.405401 (avg: 0.405401) \tsec/iter: 0.0349\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.297192 (avg: 0.386507) \tsec/iter: 0.0312\n",
      "Test set (epoch 16): Average loss: 0.6224, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.485687 (avg: 0.485687) \tsec/iter: 0.0379\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.448669 (avg: 0.440435) \tsec/iter: 0.0332\n",
      "Test set (epoch 17): Average loss: 0.5914, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.397806 (avg: 0.397806) \tsec/iter: 0.0359\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.270724 (avg: 0.430244) \tsec/iter: 0.0329\n",
      "Test set (epoch 18): Average loss: 1.0651, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.343157 (avg: 0.343157) \tsec/iter: 0.0369\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.338616 (avg: 0.339441) \tsec/iter: 0.0366\n",
      "Test set (epoch 19): Average loss: 0.6990, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.523973 (avg: 0.523973) \tsec/iter: 0.0369\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.280389 (avg: 0.381439) \tsec/iter: 0.0326\n",
      "Test set (epoch 20): Average loss: 0.7712, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.377826 (avg: 0.377826) \tsec/iter: 0.0359\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.387240 (avg: 0.350337) \tsec/iter: 0.0309\n",
      "Test set (epoch 21): Average loss: 0.6516, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.381403 (avg: 0.381403) \tsec/iter: 0.0359\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.308350 (avg: 0.349202) \tsec/iter: 0.0306\n",
      "Test set (epoch 22): Average loss: 0.6867, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.313372 (avg: 0.313372) \tsec/iter: 0.0359\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.393768 (avg: 0.340795) \tsec/iter: 0.0346\n",
      "Test set (epoch 23): Average loss: 0.8398, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.386368 (avg: 0.386368) \tsec/iter: 0.0369\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.514661 (avg: 0.383190) \tsec/iter: 0.0312\n",
      "Test set (epoch 24): Average loss: 0.7176, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.351241 (avg: 0.351241) \tsec/iter: 0.0359\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.436397 (avg: 0.374688) \tsec/iter: 0.0306\n",
      "Test set (epoch 25): Average loss: 0.8063, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.388383 (avg: 0.388383) \tsec/iter: 0.0329\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.359552 (avg: 0.349569) \tsec/iter: 0.0316\n",
      "Test set (epoch 26): Average loss: 0.7409, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.321560 (avg: 0.321560) \tsec/iter: 0.0339\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.377141 (avg: 0.350918) \tsec/iter: 0.0329\n",
      "Test set (epoch 27): Average loss: 0.6393, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.351207 (avg: 0.351207) \tsec/iter: 0.0409\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.315153 (avg: 0.331716) \tsec/iter: 0.0382\n",
      "Test set (epoch 28): Average loss: 0.6349, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.339858 (avg: 0.339858) \tsec/iter: 0.0429\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.307423 (avg: 0.313245) \tsec/iter: 0.0386\n",
      "Test set (epoch 29): Average loss: 0.6158, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.379109 (avg: 0.379109) \tsec/iter: 0.0359\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.365381 (avg: 0.323484) \tsec/iter: 0.0309\n",
      "Test set (epoch 30): Average loss: 0.6641, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.287784 (avg: 0.287784) \tsec/iter: 0.0359\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.383996 (avg: 0.326193) \tsec/iter: 0.0332\n",
      "Test set (epoch 31): Average loss: 0.6271, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.326512 (avg: 0.326512) \tsec/iter: 0.0389\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.293521 (avg: 0.353083) \tsec/iter: 0.0316\n",
      "Test set (epoch 32): Average loss: 0.6539, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.290111 (avg: 0.290111) \tsec/iter: 0.0359\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.249738 (avg: 0.351746) \tsec/iter: 0.0342\n",
      "Test set (epoch 33): Average loss: 0.6828, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.421544 (avg: 0.421544) \tsec/iter: 0.0379\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.252589 (avg: 0.349828) \tsec/iter: 0.0332\n",
      "Test set (epoch 34): Average loss: 0.7170, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.283066 (avg: 0.283066) \tsec/iter: 0.0409\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.537322 (avg: 0.363184) \tsec/iter: 0.0372\n",
      "Test set (epoch 35): Average loss: 0.7293, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.319215 (avg: 0.319215) \tsec/iter: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.340149 (avg: 0.310048) \tsec/iter: 0.0682\n",
      "Test set (epoch 36): Average loss: 0.6843, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.364295 (avg: 0.364295) \tsec/iter: 0.0559\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.318966 (avg: 0.325667) \tsec/iter: 0.0502\n",
      "Test set (epoch 37): Average loss: 0.6636, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.331955 (avg: 0.331955) \tsec/iter: 0.0379\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.287038 (avg: 0.329589) \tsec/iter: 0.0342\n",
      "Test set (epoch 38): Average loss: 0.6725, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.265453 (avg: 0.265453) \tsec/iter: 0.0339\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.367839 (avg: 0.353775) \tsec/iter: 0.0342\n",
      "Test set (epoch 39): Average loss: 0.6822, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.450091 (avg: 0.450091) \tsec/iter: 0.0419\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.292721 (avg: 0.348297) \tsec/iter: 0.0339\n",
      "Test set (epoch 40): Average loss: 0.6605, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.300306 (avg: 0.300306) \tsec/iter: 0.0369\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.434261 (avg: 0.333755) \tsec/iter: 0.0322\n",
      "Test set (epoch 41): Average loss: 0.5730, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.409300 (avg: 0.409300) \tsec/iter: 0.0349\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.214478 (avg: 0.326950) \tsec/iter: 0.0306\n",
      "Test set (epoch 42): Average loss: 0.6655, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.321672 (avg: 0.321672) \tsec/iter: 0.0339\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.247939 (avg: 0.310526) \tsec/iter: 0.0316\n",
      "Test set (epoch 43): Average loss: 0.5564, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.315717 (avg: 0.315717) \tsec/iter: 0.0369\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.308649 (avg: 0.289921) \tsec/iter: 0.0319\n",
      "Test set (epoch 44): Average loss: 0.5309, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.291039 (avg: 0.291039) \tsec/iter: 0.0339\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.359379 (avg: 0.329210) \tsec/iter: 0.0332\n",
      "Test set (epoch 45): Average loss: 0.5867, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.405941 (avg: 0.405941) \tsec/iter: 0.0349\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.269352 (avg: 0.336782) \tsec/iter: 0.0312\n",
      "Test set (epoch 46): Average loss: 0.6002, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.348399 (avg: 0.348399) \tsec/iter: 0.0369\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.319538 (avg: 0.321714) \tsec/iter: 0.0319\n",
      "Test set (epoch 47): Average loss: 0.5858, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.450398 (avg: 0.450398) \tsec/iter: 0.0329\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.282457 (avg: 0.345136) \tsec/iter: 0.0286\n",
      "Test set (epoch 48): Average loss: 0.6669, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.304173 (avg: 0.304173) \tsec/iter: 0.0359\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.217377 (avg: 0.302436) \tsec/iter: 0.0296\n",
      "Test set (epoch 49): Average loss: 0.6070, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.397307 (avg: 0.397307) \tsec/iter: 0.0319\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.260281 (avg: 0.336398) \tsec/iter: 0.0296\n",
      "Test set (epoch 50): Average loss: 0.5699, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.326937 (avg: 0.326937) \tsec/iter: 0.0329\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.321436 (avg: 0.329347) \tsec/iter: 0.0279\n",
      "Test set (epoch 51): Average loss: 0.5514, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.299838 (avg: 0.299838) \tsec/iter: 0.0349\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.465669 (avg: 0.305219) \tsec/iter: 0.0306\n",
      "Test set (epoch 52): Average loss: 0.5403, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.305407 (avg: 0.305407) \tsec/iter: 0.0299\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.367996 (avg: 0.327270) \tsec/iter: 0.0309\n",
      "Test set (epoch 53): Average loss: 0.5992, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.310839 (avg: 0.310839) \tsec/iter: 0.0339\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.371083 (avg: 0.309164) \tsec/iter: 0.0309\n",
      "Test set (epoch 54): Average loss: 0.6438, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.266577 (avg: 0.266577) \tsec/iter: 0.0289\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.427718 (avg: 0.303804) \tsec/iter: 0.0309\n",
      "Test set (epoch 55): Average loss: 0.6677, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.311949 (avg: 0.311949) \tsec/iter: 0.0369\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.239109 (avg: 0.313654) \tsec/iter: 0.0322\n",
      "Test set (epoch 56): Average loss: 0.6416, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.295257 (avg: 0.295257) \tsec/iter: 0.0469\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.364025 (avg: 0.311003) \tsec/iter: 0.0389\n",
      "Test set (epoch 57): Average loss: 0.7062, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.253418 (avg: 0.253418) \tsec/iter: 0.0369\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.234546 (avg: 0.337867) \tsec/iter: 0.0326\n",
      "Test set (epoch 58): Average loss: 0.6415, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.357201 (avg: 0.357201) \tsec/iter: 0.0369\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.222499 (avg: 0.320366) \tsec/iter: 0.0329\n",
      "Test set (epoch 59): Average loss: 0.6911, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.419730 (avg: 0.419730) \tsec/iter: 0.0339\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.212831 (avg: 0.320782) \tsec/iter: 0.0306\n",
      "Test set (epoch 60): Average loss: 0.6567, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.334880 (avg: 0.334880) \tsec/iter: 0.0329\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.326932 (avg: 0.315777) \tsec/iter: 0.0299\n",
      "Test set (epoch 61): Average loss: 0.6178, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.356580 (avg: 0.356580) \tsec/iter: 0.0429\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.319302 (avg: 0.321795) \tsec/iter: 0.0359\n",
      "Test set (epoch 62): Average loss: 0.6387, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.351652 (avg: 0.351652) \tsec/iter: 0.0319\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.341430 (avg: 0.323330) \tsec/iter: 0.0326\n",
      "Test set (epoch 63): Average loss: 0.6095, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.365509 (avg: 0.365509) \tsec/iter: 0.0339\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.294549 (avg: 0.312475) \tsec/iter: 0.0326\n",
      "Test set (epoch 64): Average loss: 0.6184, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.243605 (avg: 0.243605) \tsec/iter: 0.0399\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.372173 (avg: 0.302140) \tsec/iter: 0.0362\n",
      "Test set (epoch 65): Average loss: 0.5886, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.356332 (avg: 0.356332) \tsec/iter: 0.0379\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.313606 (avg: 0.334059) \tsec/iter: 0.0359\n",
      "Test set (epoch 66): Average loss: 0.6379, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.339765 (avg: 0.339765) \tsec/iter: 0.0399\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.324518 (avg: 0.317426) \tsec/iter: 0.0326\n",
      "Test set (epoch 67): Average loss: 0.6241, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.267476 (avg: 0.267476) \tsec/iter: 0.0329\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.454912 (avg: 0.332329) \tsec/iter: 0.0326\n",
      "Test set (epoch 68): Average loss: 0.6740, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.301698 (avg: 0.301698) \tsec/iter: 0.0319\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.265271 (avg: 0.297741) \tsec/iter: 0.0316\n",
      "Test set (epoch 69): Average loss: 0.7186, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.318999 (avg: 0.318999) \tsec/iter: 0.0299\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.296236 (avg: 0.319427) \tsec/iter: 0.0299\n",
      "Test set (epoch 70): Average loss: 0.6350, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.250768 (avg: 0.250768) \tsec/iter: 0.0409\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.323178 (avg: 0.298198) \tsec/iter: 0.0336\n",
      "Test set (epoch 71): Average loss: 0.5789, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.254378 (avg: 0.254378) \tsec/iter: 0.0319\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.429612 (avg: 0.294088) \tsec/iter: 0.0319\n",
      "Test set (epoch 72): Average loss: 0.5984, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.301634 (avg: 0.301634) \tsec/iter: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.553352 (avg: 0.328157) \tsec/iter: 0.0332\n",
      "Test set (epoch 73): Average loss: 0.5331, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.277287 (avg: 0.277287) \tsec/iter: 0.0409\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.243449 (avg: 0.304500) \tsec/iter: 0.0352\n",
      "Test set (epoch 74): Average loss: 0.5360, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.328104 (avg: 0.328104) \tsec/iter: 0.0359\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.598002 (avg: 0.387726) \tsec/iter: 0.0322\n",
      "Test set (epoch 75): Average loss: 0.6537, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.343690 (avg: 0.343690) \tsec/iter: 0.0379\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.343017 (avg: 0.314441) \tsec/iter: 0.0306\n",
      "Test set (epoch 76): Average loss: 0.5350, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.331460 (avg: 0.331460) \tsec/iter: 0.0349\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.374012 (avg: 0.314138) \tsec/iter: 0.0293\n",
      "Test set (epoch 77): Average loss: 0.4994, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.282281 (avg: 0.282281) \tsec/iter: 0.0319\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.236143 (avg: 0.311426) \tsec/iter: 0.0289\n",
      "Test set (epoch 78): Average loss: 0.5551, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.276654 (avg: 0.276654) \tsec/iter: 0.0309\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.289480 (avg: 0.291976) \tsec/iter: 0.0293\n",
      "Test set (epoch 79): Average loss: 0.5033, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.303355 (avg: 0.303355) \tsec/iter: 0.0359\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.402019 (avg: 0.311252) \tsec/iter: 0.0339\n",
      "Test set (epoch 80): Average loss: 0.6335, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.362817 (avg: 0.362817) \tsec/iter: 0.0339\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.306603 (avg: 0.307313) \tsec/iter: 0.0322\n",
      "Test set (epoch 81): Average loss: 0.4927, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.389698 (avg: 0.389698) \tsec/iter: 0.0349\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.258507 (avg: 0.317418) \tsec/iter: 0.0309\n",
      "Test set (epoch 82): Average loss: 0.4450, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.330980 (avg: 0.330980) \tsec/iter: 0.0349\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.435980 (avg: 0.352065) \tsec/iter: 0.0356\n",
      "Test set (epoch 83): Average loss: 0.4655, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.325095 (avg: 0.325095) \tsec/iter: 0.0409\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.412117 (avg: 0.332405) \tsec/iter: 0.0359\n",
      "Test set (epoch 84): Average loss: 0.4896, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.311774 (avg: 0.311774) \tsec/iter: 0.0329\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.348062 (avg: 0.279947) \tsec/iter: 0.0296\n",
      "Test set (epoch 85): Average loss: 0.4892, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.317098 (avg: 0.317098) \tsec/iter: 0.0359\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.597561 (avg: 0.332436) \tsec/iter: 0.0309\n",
      "Test set (epoch 86): Average loss: 0.5842, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.339346 (avg: 0.339346) \tsec/iter: 0.0329\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.340205 (avg: 0.338438) \tsec/iter: 0.0382\n",
      "Test set (epoch 87): Average loss: 0.4707, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.407473 (avg: 0.407473) \tsec/iter: 0.0379\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.393729 (avg: 0.324545) \tsec/iter: 0.0422\n",
      "Test set (epoch 88): Average loss: 0.5358, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.273549 (avg: 0.273549) \tsec/iter: 0.0369\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.284577 (avg: 0.292232) \tsec/iter: 0.0329\n",
      "Test set (epoch 89): Average loss: 0.5097, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.279665 (avg: 0.279665) \tsec/iter: 0.0359\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.353688 (avg: 0.281674) \tsec/iter: 0.0322\n",
      "Test set (epoch 90): Average loss: 0.5356, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.239541 (avg: 0.239541) \tsec/iter: 0.0389\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.459473 (avg: 0.346209) \tsec/iter: 0.0336\n",
      "Test set (epoch 91): Average loss: 0.5340, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.239916 (avg: 0.239916) \tsec/iter: 0.0359\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.386289 (avg: 0.301763) \tsec/iter: 0.0346\n",
      "Test set (epoch 92): Average loss: 0.4921, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.313729 (avg: 0.313729) \tsec/iter: 0.0389\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.194960 (avg: 0.285663) \tsec/iter: 0.0369\n",
      "Test set (epoch 93): Average loss: 0.5748, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.347044 (avg: 0.347044) \tsec/iter: 0.0389\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.226893 (avg: 0.289723) \tsec/iter: 0.0319\n",
      "Test set (epoch 94): Average loss: 0.4873, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.324687 (avg: 0.324687) \tsec/iter: 0.0339\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.344585 (avg: 0.283295) \tsec/iter: 0.0303\n",
      "Test set (epoch 95): Average loss: 0.4936, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.277770 (avg: 0.277770) \tsec/iter: 0.0319\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.273069 (avg: 0.271127) \tsec/iter: 0.0319\n",
      "Test set (epoch 96): Average loss: 0.4820, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.230947 (avg: 0.230947) \tsec/iter: 0.0359\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.360455 (avg: 0.271439) \tsec/iter: 0.0309\n",
      "Test set (epoch 97): Average loss: 0.4422, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.220752 (avg: 0.220752) \tsec/iter: 0.0399\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.261790 (avg: 0.303216) \tsec/iter: 0.0329\n",
      "Test set (epoch 98): Average loss: 0.5380, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.224850 (avg: 0.224850) \tsec/iter: 0.0309\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.331496 (avg: 0.321790) \tsec/iter: 0.0316\n",
      "Test set (epoch 99): Average loss: 0.4625, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.220470 (avg: 0.220470) \tsec/iter: 0.0339\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.277977 (avg: 0.313442) \tsec/iter: 0.0303\n",
      "Test set (epoch 100): Average loss: 0.5396, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.270969 (avg: 0.270969) \tsec/iter: 0.0289\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.281369 (avg: 0.267305) \tsec/iter: 0.0299\n",
      "Test set (epoch 101): Average loss: 0.3818, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.255540 (avg: 0.255540) \tsec/iter: 0.0389\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.257260 (avg: 0.300006) \tsec/iter: 0.0356\n",
      "Test set (epoch 102): Average loss: 0.4646, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.286524 (avg: 0.286524) \tsec/iter: 0.0339\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.337506 (avg: 0.298551) \tsec/iter: 0.0329\n",
      "Test set (epoch 103): Average loss: 0.5694, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.368184 (avg: 0.368184) \tsec/iter: 0.0399\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.268134 (avg: 0.312826) \tsec/iter: 0.0332\n",
      "Test set (epoch 104): Average loss: 0.4710, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.297638 (avg: 0.297638) \tsec/iter: 0.0359\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.341206 (avg: 0.305765) \tsec/iter: 0.0322\n",
      "Test set (epoch 105): Average loss: 0.4436, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.348817 (avg: 0.348817) \tsec/iter: 0.0329\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.189832 (avg: 0.293933) \tsec/iter: 0.0289\n",
      "Test set (epoch 106): Average loss: 0.6334, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.321768 (avg: 0.321768) \tsec/iter: 0.0299\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.260432 (avg: 0.290881) \tsec/iter: 0.0293\n",
      "Test set (epoch 107): Average loss: 0.4784, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.305750 (avg: 0.305750) \tsec/iter: 0.0349\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.318798 (avg: 0.296413) \tsec/iter: 0.0309\n",
      "Test set (epoch 108): Average loss: 0.5620, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.131546 (avg: 0.131546) \tsec/iter: 0.0319\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.524472 (avg: 0.294037) \tsec/iter: 0.0322\n",
      "Test set (epoch 109): Average loss: 0.5246, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.383955 (avg: 0.383955) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.300016 (avg: 0.302405) \tsec/iter: 0.0309\n",
      "Test set (epoch 110): Average loss: 0.5431, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.263191 (avg: 0.263191) \tsec/iter: 0.0319\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.309627 (avg: 0.294272) \tsec/iter: 0.0316\n",
      "Test set (epoch 111): Average loss: 0.5392, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.327535 (avg: 0.327535) \tsec/iter: 0.0389\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.183225 (avg: 0.271053) \tsec/iter: 0.0379\n",
      "Test set (epoch 112): Average loss: 0.5299, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.264457 (avg: 0.264457) \tsec/iter: 0.0299\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.263071 (avg: 0.235210) \tsec/iter: 0.0279\n",
      "Test set (epoch 113): Average loss: 0.5172, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.261693 (avg: 0.261693) \tsec/iter: 0.0319\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.227484 (avg: 0.268996) \tsec/iter: 0.0289\n",
      "Test set (epoch 114): Average loss: 0.5266, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.352104 (avg: 0.352104) \tsec/iter: 0.0329\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.288069 (avg: 0.290586) \tsec/iter: 0.0296\n",
      "Test set (epoch 115): Average loss: 0.4942, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.154399 (avg: 0.154399) \tsec/iter: 0.0349\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.412674 (avg: 0.267532) \tsec/iter: 0.0299\n",
      "Test set (epoch 116): Average loss: 0.4499, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.229660 (avg: 0.229660) \tsec/iter: 0.0339\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.236455 (avg: 0.291783) \tsec/iter: 0.0336\n",
      "Test set (epoch 117): Average loss: 0.4927, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.268791 (avg: 0.268791) \tsec/iter: 0.0409\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.187334 (avg: 0.238730) \tsec/iter: 0.0349\n",
      "Test set (epoch 118): Average loss: 0.4418, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.245721 (avg: 0.245721) \tsec/iter: 0.0359\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.065106 (avg: 0.231602) \tsec/iter: 0.0312\n",
      "Test set (epoch 119): Average loss: 0.5022, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.260431 (avg: 0.260431) \tsec/iter: 0.0399\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.256696 (avg: 0.264157) \tsec/iter: 0.0326\n",
      "Test set (epoch 120): Average loss: 0.5537, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.275726 (avg: 0.275726) \tsec/iter: 0.0349\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.288252 (avg: 0.299719) \tsec/iter: 0.0399\n",
      "Test set (epoch 121): Average loss: 0.4997, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.198156 (avg: 0.198156) \tsec/iter: 0.1566\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.428816 (avg: 0.274449) \tsec/iter: 0.0775\n",
      "Test set (epoch 122): Average loss: 0.4535, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.214762 (avg: 0.214762) \tsec/iter: 0.0509\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.306963 (avg: 0.259723) \tsec/iter: 0.0429\n",
      "Test set (epoch 123): Average loss: 0.5657, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.186956 (avg: 0.186956) \tsec/iter: 0.0369\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.342549 (avg: 0.279709) \tsec/iter: 0.0326\n",
      "Test set (epoch 124): Average loss: 0.3863, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.171709 (avg: 0.171709) \tsec/iter: 0.0319\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.418342 (avg: 0.283832) \tsec/iter: 0.0312\n",
      "Test set (epoch 125): Average loss: 0.4074, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.225342 (avg: 0.225342) \tsec/iter: 0.0359\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.306777 (avg: 0.274195) \tsec/iter: 0.0326\n",
      "Test set (epoch 126): Average loss: 0.4904, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.223913 (avg: 0.223913) \tsec/iter: 0.0349\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.254669 (avg: 0.255819) \tsec/iter: 0.0303\n",
      "Test set (epoch 127): Average loss: 0.4151, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.249539 (avg: 0.249539) \tsec/iter: 0.0289\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.256111 (avg: 0.242886) \tsec/iter: 0.0296\n",
      "Test set (epoch 128): Average loss: 0.4303, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.226454 (avg: 0.226454) \tsec/iter: 0.0349\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.243948 (avg: 0.272506) \tsec/iter: 0.0362\n",
      "Test set (epoch 129): Average loss: 0.3856, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.129695 (avg: 0.129695) \tsec/iter: 0.0419\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.285544 (avg: 0.250089) \tsec/iter: 0.0319\n",
      "Test set (epoch 130): Average loss: 0.4679, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.271662 (avg: 0.271662) \tsec/iter: 0.0299\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.348608 (avg: 0.249477) \tsec/iter: 0.0346\n",
      "Test set (epoch 131): Average loss: 0.4789, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.248735 (avg: 0.248735) \tsec/iter: 0.0419\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.286442 (avg: 0.268911) \tsec/iter: 0.0329\n",
      "Test set (epoch 132): Average loss: 0.4236, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.326021 (avg: 0.326021) \tsec/iter: 0.0309\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.296081 (avg: 0.302194) \tsec/iter: 0.0273\n",
      "Test set (epoch 133): Average loss: 0.4842, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.316947 (avg: 0.316947) \tsec/iter: 0.0359\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.357083 (avg: 0.263947) \tsec/iter: 0.0293\n",
      "Test set (epoch 134): Average loss: 0.5179, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.315356 (avg: 0.315356) \tsec/iter: 0.0369\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.191072 (avg: 0.253845) \tsec/iter: 0.0336\n",
      "Test set (epoch 135): Average loss: 0.3494, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.319191 (avg: 0.319191) \tsec/iter: 0.0299\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.308636 (avg: 0.309177) \tsec/iter: 0.0293\n",
      "Test set (epoch 136): Average loss: 0.5128, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.282385 (avg: 0.282385) \tsec/iter: 0.0299\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.236291 (avg: 0.339433) \tsec/iter: 0.0309\n",
      "Test set (epoch 137): Average loss: 0.4434, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.279585 (avg: 0.279585) \tsec/iter: 0.0289\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.195590 (avg: 0.250546) \tsec/iter: 0.0289\n",
      "Test set (epoch 138): Average loss: 0.4432, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.286431 (avg: 0.286431) \tsec/iter: 0.0399\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.387953 (avg: 0.286813) \tsec/iter: 0.0356\n",
      "Test set (epoch 139): Average loss: 0.4484, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.248913 (avg: 0.248913) \tsec/iter: 0.0399\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.238130 (avg: 0.218928) \tsec/iter: 0.0366\n",
      "Test set (epoch 140): Average loss: 0.4564, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.206957 (avg: 0.206957) \tsec/iter: 0.0339\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.300059 (avg: 0.248900) \tsec/iter: 0.0312\n",
      "Test set (epoch 141): Average loss: 0.5231, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.260444 (avg: 0.260444) \tsec/iter: 0.0319\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.334574 (avg: 0.278758) \tsec/iter: 0.0296\n",
      "Test set (epoch 142): Average loss: 0.5289, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.232326 (avg: 0.232326) \tsec/iter: 0.0319\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.240857 (avg: 0.260205) \tsec/iter: 0.0283\n",
      "Test set (epoch 143): Average loss: 0.3819, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.200771 (avg: 0.200771) \tsec/iter: 0.0309\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.269886 (avg: 0.257713) \tsec/iter: 0.0299\n",
      "Test set (epoch 144): Average loss: 0.3685, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.240621 (avg: 0.240621) \tsec/iter: 0.0339\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.295617 (avg: 0.236445) \tsec/iter: 0.0329\n",
      "Test set (epoch 145): Average loss: 0.4535, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.340494 (avg: 0.340494) \tsec/iter: 0.0339\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.331217 (avg: 0.299961) \tsec/iter: 0.0293\n",
      "Test set (epoch 146): Average loss: 0.4708, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.342869 (avg: 0.342869) \tsec/iter: 0.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.241893 (avg: 0.297816) \tsec/iter: 0.0299\n",
      "Test set (epoch 147): Average loss: 0.4537, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.222670 (avg: 0.222670) \tsec/iter: 0.0339\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.348123 (avg: 0.264715) \tsec/iter: 0.0332\n",
      "Test set (epoch 148): Average loss: 0.4464, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.259225 (avg: 0.259225) \tsec/iter: 0.0419\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.288713 (avg: 0.247422) \tsec/iter: 0.0362\n",
      "Test set (epoch 149): Average loss: 0.3731, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.255673 (avg: 0.255673) \tsec/iter: 0.0339\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.129867 (avg: 0.228927) \tsec/iter: 0.0303\n",
      "Test set (epoch 150): Average loss: 0.4148, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.224242 (avg: 0.224242) \tsec/iter: 0.0339\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.385794 (avg: 0.250994) \tsec/iter: 0.0289\n",
      "Test set (epoch 151): Average loss: 0.3772, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.278370 (avg: 0.278370) \tsec/iter: 0.0379\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.335276 (avg: 0.264544) \tsec/iter: 0.0299\n",
      "Test set (epoch 152): Average loss: 0.4879, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.237340 (avg: 0.237340) \tsec/iter: 0.0349\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.336487 (avg: 0.270408) \tsec/iter: 0.0322\n",
      "Test set (epoch 153): Average loss: 0.4792, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.247936 (avg: 0.247936) \tsec/iter: 0.0389\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.290717 (avg: 0.270413) \tsec/iter: 0.0329\n",
      "Test set (epoch 154): Average loss: 0.4978, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.275191 (avg: 0.275191) \tsec/iter: 0.0329\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.229682 (avg: 0.259240) \tsec/iter: 0.0289\n",
      "Test set (epoch 155): Average loss: 0.4687, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.293668 (avg: 0.293668) \tsec/iter: 0.0359\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.224744 (avg: 0.245800) \tsec/iter: 0.0299\n",
      "Test set (epoch 156): Average loss: 0.4822, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.324772 (avg: 0.324772) \tsec/iter: 0.0349\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.190768 (avg: 0.350168) \tsec/iter: 0.0313\n",
      "Test set (epoch 157): Average loss: 0.4234, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.319584 (avg: 0.319584) \tsec/iter: 0.0379\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.261310 (avg: 0.274864) \tsec/iter: 0.0386\n",
      "Test set (epoch 158): Average loss: 0.4567, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.302341 (avg: 0.302341) \tsec/iter: 0.0419\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.287520 (avg: 0.265044) \tsec/iter: 0.0352\n",
      "Test set (epoch 159): Average loss: 0.4762, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.236730 (avg: 0.236730) \tsec/iter: 0.0359\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.348192 (avg: 0.262274) \tsec/iter: 0.0309\n",
      "Test set (epoch 160): Average loss: 0.4851, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.313616 (avg: 0.313616) \tsec/iter: 0.0319\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.282340 (avg: 0.280656) \tsec/iter: 0.0296\n",
      "Test set (epoch 161): Average loss: 0.4585, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.264839 (avg: 0.264839) \tsec/iter: 0.0369\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.281177 (avg: 0.261101) \tsec/iter: 0.0306\n",
      "Test set (epoch 162): Average loss: 0.4692, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.246908 (avg: 0.246908) \tsec/iter: 0.0339\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.173279 (avg: 0.265564) \tsec/iter: 0.0286\n",
      "Test set (epoch 163): Average loss: 0.4408, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.241134 (avg: 0.241134) \tsec/iter: 0.0309\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.271621 (avg: 0.246861) \tsec/iter: 0.0306\n",
      "Test set (epoch 164): Average loss: 0.4472, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.291603 (avg: 0.291603) \tsec/iter: 0.0329\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.314175 (avg: 0.241830) \tsec/iter: 0.0289\n",
      "Test set (epoch 165): Average loss: 0.4553, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.251090 (avg: 0.251090) \tsec/iter: 0.0339\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.208594 (avg: 0.239917) \tsec/iter: 0.0299\n",
      "Test set (epoch 166): Average loss: 0.4456, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.283488 (avg: 0.283488) \tsec/iter: 0.0339\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.255456 (avg: 0.235714) \tsec/iter: 0.0293\n",
      "Test set (epoch 167): Average loss: 0.4399, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.268351 (avg: 0.268351) \tsec/iter: 0.0449\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.280766 (avg: 0.299973) \tsec/iter: 0.0382\n",
      "Test set (epoch 168): Average loss: 0.5122, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.327751 (avg: 0.327751) \tsec/iter: 0.0389\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.178017 (avg: 0.266222) \tsec/iter: 0.0326\n",
      "Test set (epoch 169): Average loss: 0.3739, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.153353 (avg: 0.153353) \tsec/iter: 0.0349\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.283247 (avg: 0.273360) \tsec/iter: 0.0306\n",
      "Test set (epoch 170): Average loss: 0.4423, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.244369 (avg: 0.244369) \tsec/iter: 0.0329\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.409452 (avg: 0.272217) \tsec/iter: 0.0279\n",
      "Test set (epoch 171): Average loss: 0.4104, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.184794 (avg: 0.184794) \tsec/iter: 0.0309\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.303482 (avg: 0.248274) \tsec/iter: 0.0303\n",
      "Test set (epoch 172): Average loss: 0.4477, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.207030 (avg: 0.207030) \tsec/iter: 0.0349\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.273738 (avg: 0.222188) \tsec/iter: 0.0316\n",
      "Test set (epoch 173): Average loss: 0.3772, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.220661 (avg: 0.220661) \tsec/iter: 0.0329\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.467960 (avg: 0.270066) \tsec/iter: 0.0303\n",
      "Test set (epoch 174): Average loss: 0.4771, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.287352 (avg: 0.287352) \tsec/iter: 0.0339\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.215686 (avg: 0.272557) \tsec/iter: 0.0319\n",
      "Test set (epoch 175): Average loss: 0.3994, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.225223 (avg: 0.225223) \tsec/iter: 0.0369\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.189962 (avg: 0.233482) \tsec/iter: 0.0293\n",
      "Test set (epoch 176): Average loss: 0.4532, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.278140 (avg: 0.278140) \tsec/iter: 0.0329\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.207455 (avg: 0.273268) \tsec/iter: 0.0332\n",
      "Test set (epoch 177): Average loss: 0.4039, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.234249 (avg: 0.234249) \tsec/iter: 0.0359\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.248910 (avg: 0.214823) \tsec/iter: 0.0356\n",
      "Test set (epoch 178): Average loss: 0.4946, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.227679 (avg: 0.227679) \tsec/iter: 0.0349\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.212402 (avg: 0.238577) \tsec/iter: 0.0293\n",
      "Test set (epoch 179): Average loss: 0.5212, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.218769 (avg: 0.218769) \tsec/iter: 0.0329\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.196313 (avg: 0.217071) \tsec/iter: 0.0293\n",
      "Test set (epoch 180): Average loss: 0.5433, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.229794 (avg: 0.229794) \tsec/iter: 0.0329\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.398148 (avg: 0.273167) \tsec/iter: 0.0283\n",
      "Test set (epoch 181): Average loss: 0.4517, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.313110 (avg: 0.313110) \tsec/iter: 0.0329\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.256328 (avg: 0.319169) \tsec/iter: 0.0299\n",
      "Test set (epoch 182): Average loss: 0.4669, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.322159 (avg: 0.322159) \tsec/iter: 0.0319\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.241030 (avg: 0.288725) \tsec/iter: 0.0289\n",
      "Test set (epoch 183): Average loss: 0.4190, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.218876 (avg: 0.218876) \tsec/iter: 0.0349\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.391991 (avg: 0.295601) \tsec/iter: 0.0332\n",
      "Test set (epoch 184): Average loss: 0.4438, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.277650 (avg: 0.277650) \tsec/iter: 0.0359\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.156535 (avg: 0.254116) \tsec/iter: 0.0326\n",
      "Test set (epoch 185): Average loss: 0.4570, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.189518 (avg: 0.189518) \tsec/iter: 0.0349\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.303323 (avg: 0.244862) \tsec/iter: 0.0309\n",
      "Test set (epoch 186): Average loss: 0.4183, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.207869 (avg: 0.207869) \tsec/iter: 0.0359\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.276156 (avg: 0.243964) \tsec/iter: 0.0346\n",
      "Test set (epoch 187): Average loss: 0.4293, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.230421 (avg: 0.230421) \tsec/iter: 0.0399\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.242666 (avg: 0.250009) \tsec/iter: 0.0366\n",
      "Test set (epoch 188): Average loss: 0.4654, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.178458 (avg: 0.178458) \tsec/iter: 0.0359\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.269054 (avg: 0.231236) \tsec/iter: 0.0336\n",
      "Test set (epoch 189): Average loss: 0.4267, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.315973 (avg: 0.315973) \tsec/iter: 0.0369\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.285256 (avg: 0.267213) \tsec/iter: 0.0312\n",
      "Test set (epoch 190): Average loss: 0.3394, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.154805 (avg: 0.154805) \tsec/iter: 0.0319\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.251723 (avg: 0.250922) \tsec/iter: 0.0376\n",
      "Test set (epoch 191): Average loss: 0.4255, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.259879 (avg: 0.259879) \tsec/iter: 0.0588\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.263163 (avg: 0.267679) \tsec/iter: 0.0452\n",
      "Test set (epoch 192): Average loss: 0.3991, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.286560 (avg: 0.286560) \tsec/iter: 0.0319\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.305643 (avg: 0.255710) \tsec/iter: 0.0299\n",
      "Test set (epoch 193): Average loss: 0.4407, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.168540 (avg: 0.168540) \tsec/iter: 0.0349\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.297432 (avg: 0.282471) \tsec/iter: 0.0322\n",
      "Test set (epoch 194): Average loss: 0.4380, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.320231 (avg: 0.320231) \tsec/iter: 0.0369\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.286296 (avg: 0.298792) \tsec/iter: 0.0326\n",
      "Test set (epoch 195): Average loss: 0.3662, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.203014 (avg: 0.203014) \tsec/iter: 0.0319\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.411655 (avg: 0.255480) \tsec/iter: 0.0336\n",
      "Test set (epoch 196): Average loss: 0.4080, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.209857 (avg: 0.209857) \tsec/iter: 0.0419\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.240466 (avg: 0.264475) \tsec/iter: 0.0359\n",
      "Test set (epoch 197): Average loss: 0.3403, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.301113 (avg: 0.301113) \tsec/iter: 0.0349\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.314350 (avg: 0.285192) \tsec/iter: 0.0299\n",
      "Test set (epoch 198): Average loss: 0.4279, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.206582 (avg: 0.206582) \tsec/iter: 0.0329\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.135813 (avg: 0.222588) \tsec/iter: 0.0306\n",
      "Test set (epoch 199): Average loss: 0.3188, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.241750 (avg: 0.241750) \tsec/iter: 0.0329\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.218628 (avg: 0.226011) \tsec/iter: 0.0303\n",
      "Test set (epoch 200): Average loss: 0.4035, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.296246 (avg: 0.296246) \tsec/iter: 0.0379\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.294416 (avg: 0.249890) \tsec/iter: 0.0326\n",
      "Test set (epoch 201): Average loss: 0.3813, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.285800 (avg: 0.285800) \tsec/iter: 0.0309\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.125253 (avg: 0.201173) \tsec/iter: 0.0289\n",
      "Test set (epoch 202): Average loss: 0.4863, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.186619 (avg: 0.186619) \tsec/iter: 0.0339\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.249022 (avg: 0.229063) \tsec/iter: 0.0316\n",
      "Test set (epoch 203): Average loss: 0.4024, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.300326 (avg: 0.300326) \tsec/iter: 0.0299\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.349389 (avg: 0.289536) \tsec/iter: 0.0279\n",
      "Test set (epoch 204): Average loss: 0.3307, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.174554 (avg: 0.174554) \tsec/iter: 0.0329\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.323207 (avg: 0.226916) \tsec/iter: 0.0296\n",
      "Test set (epoch 205): Average loss: 0.4333, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.267266 (avg: 0.267266) \tsec/iter: 0.0349\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.192901 (avg: 0.246831) \tsec/iter: 0.0366\n",
      "Test set (epoch 206): Average loss: 0.3523, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.183468 (avg: 0.183468) \tsec/iter: 0.0379\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.261267 (avg: 0.262160) \tsec/iter: 0.0356\n",
      "Test set (epoch 207): Average loss: 0.3829, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.218699 (avg: 0.218699) \tsec/iter: 0.0329\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.165861 (avg: 0.212913) \tsec/iter: 0.0289\n",
      "Test set (epoch 208): Average loss: 0.3044, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.202045 (avg: 0.202045) \tsec/iter: 0.0329\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.138970 (avg: 0.245598) \tsec/iter: 0.0313\n",
      "Test set (epoch 209): Average loss: 0.3918, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.229740 (avg: 0.229740) \tsec/iter: 0.0339\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.266874 (avg: 0.240469) \tsec/iter: 0.0329\n",
      "Test set (epoch 210): Average loss: 0.3556, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.207355 (avg: 0.207355) \tsec/iter: 0.0399\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.314658 (avg: 0.255395) \tsec/iter: 0.0322\n",
      "Test set (epoch 211): Average loss: 0.4813, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.205002 (avg: 0.205002) \tsec/iter: 0.0339\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.119099 (avg: 0.221088) \tsec/iter: 0.0332\n",
      "Test set (epoch 212): Average loss: 0.3643, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.256309 (avg: 0.256309) \tsec/iter: 0.0359\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.272787 (avg: 0.248572) \tsec/iter: 0.0306\n",
      "Test set (epoch 213): Average loss: 0.3314, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.257169 (avg: 0.257169) \tsec/iter: 0.0329\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.209381 (avg: 0.248611) \tsec/iter: 0.0319\n",
      "Test set (epoch 214): Average loss: 0.4055, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.209885 (avg: 0.209885) \tsec/iter: 0.0369\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.244523 (avg: 0.235732) \tsec/iter: 0.0319\n",
      "Test set (epoch 215): Average loss: 0.3799, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.214512 (avg: 0.214512) \tsec/iter: 0.0399\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.388512 (avg: 0.255822) \tsec/iter: 0.0339\n",
      "Test set (epoch 216): Average loss: 0.3790, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.249988 (avg: 0.249988) \tsec/iter: 0.0389\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.190160 (avg: 0.223639) \tsec/iter: 0.0326\n",
      "Test set (epoch 217): Average loss: 0.3928, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.258887 (avg: 0.258887) \tsec/iter: 0.0299\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.251436 (avg: 0.231705) \tsec/iter: 0.0283\n",
      "Test set (epoch 218): Average loss: 0.3523, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.193503 (avg: 0.193503) \tsec/iter: 0.0339\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.245128 (avg: 0.225796) \tsec/iter: 0.0306\n",
      "Test set (epoch 219): Average loss: 0.4115, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.240298 (avg: 0.240298) \tsec/iter: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.170207 (avg: 0.190799) \tsec/iter: 0.0336\n",
      "Test set (epoch 220): Average loss: 0.3786, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.172799 (avg: 0.172799) \tsec/iter: 0.0319\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.389368 (avg: 0.223060) \tsec/iter: 0.0286\n",
      "Test set (epoch 221): Average loss: 0.3510, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.201809 (avg: 0.201809) \tsec/iter: 0.0319\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.219934 (avg: 0.207570) \tsec/iter: 0.0299\n",
      "Test set (epoch 222): Average loss: 0.3165, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.165955 (avg: 0.165955) \tsec/iter: 0.0369\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.294728 (avg: 0.214834) \tsec/iter: 0.0336\n",
      "Test set (epoch 223): Average loss: 0.4230, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.218106 (avg: 0.218106) \tsec/iter: 0.0319\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.336926 (avg: 0.229718) \tsec/iter: 0.0296\n",
      "Test set (epoch 224): Average loss: 0.3891, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.178703 (avg: 0.178703) \tsec/iter: 0.0369\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.286981 (avg: 0.218547) \tsec/iter: 0.0326\n",
      "Test set (epoch 225): Average loss: 0.3443, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.243225 (avg: 0.243225) \tsec/iter: 0.0399\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.391707 (avg: 0.247544) \tsec/iter: 0.0356\n",
      "Test set (epoch 226): Average loss: 0.4376, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.188838 (avg: 0.188838) \tsec/iter: 0.0339\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.304891 (avg: 0.236776) \tsec/iter: 0.0293\n",
      "Test set (epoch 227): Average loss: 0.3568, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.224842 (avg: 0.224842) \tsec/iter: 0.0339\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.343120 (avg: 0.220093) \tsec/iter: 0.0293\n",
      "Test set (epoch 228): Average loss: 0.3766, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.209217 (avg: 0.209217) \tsec/iter: 0.0349\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.134729 (avg: 0.204680) \tsec/iter: 0.0312\n",
      "Test set (epoch 229): Average loss: 0.4231, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.181624 (avg: 0.181624) \tsec/iter: 0.0359\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.309002 (avg: 0.226123) \tsec/iter: 0.0372\n",
      "Test set (epoch 230): Average loss: 0.4348, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.315974 (avg: 0.315974) \tsec/iter: 0.0349\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.344118 (avg: 0.277334) \tsec/iter: 0.0312\n",
      "Test set (epoch 231): Average loss: 0.4380, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.314903 (avg: 0.314903) \tsec/iter: 0.0339\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.318056 (avg: 0.266202) \tsec/iter: 0.0312\n",
      "Test set (epoch 232): Average loss: 0.3394, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.195471 (avg: 0.195471) \tsec/iter: 0.0339\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.410837 (avg: 0.262324) \tsec/iter: 0.0316\n",
      "Test set (epoch 233): Average loss: 0.3932, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.238947 (avg: 0.238947) \tsec/iter: 0.0309\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.297526 (avg: 0.221897) \tsec/iter: 0.0299\n",
      "Test set (epoch 234): Average loss: 0.4180, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.212945 (avg: 0.212945) \tsec/iter: 0.0329\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.263573 (avg: 0.229217) \tsec/iter: 0.0342\n",
      "Test set (epoch 235): Average loss: 0.4313, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.176483 (avg: 0.176483) \tsec/iter: 0.0399\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.192492 (avg: 0.206284) \tsec/iter: 0.0336\n",
      "Test set (epoch 236): Average loss: 0.4587, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.187573 (avg: 0.187573) \tsec/iter: 0.0339\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.238050 (avg: 0.210833) \tsec/iter: 0.0299\n",
      "Test set (epoch 237): Average loss: 0.3325, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.182698 (avg: 0.182698) \tsec/iter: 0.0329\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.285743 (avg: 0.237515) \tsec/iter: 0.0296\n",
      "Test set (epoch 238): Average loss: 0.3869, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.186317 (avg: 0.186317) \tsec/iter: 0.0389\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.396422 (avg: 0.228621) \tsec/iter: 0.0336\n",
      "Test set (epoch 239): Average loss: 0.4284, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.130995 (avg: 0.130995) \tsec/iter: 0.0339\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.299073 (avg: 0.231376) \tsec/iter: 0.0316\n",
      "Test set (epoch 240): Average loss: 0.3950, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.206212 (avg: 0.206212) \tsec/iter: 0.0329\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.225158 (avg: 0.241486) \tsec/iter: 0.0535\n",
      "Test set (epoch 241): Average loss: 0.4314, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.167394 (avg: 0.167394) \tsec/iter: 0.0559\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.158725 (avg: 0.216942) \tsec/iter: 0.0489\n",
      "Test set (epoch 242): Average loss: 0.3533, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.196583 (avg: 0.196583) \tsec/iter: 0.0549\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.165585 (avg: 0.199251) \tsec/iter: 0.0459\n",
      "Test set (epoch 243): Average loss: 0.3309, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.202925 (avg: 0.202925) \tsec/iter: 0.0419\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.247652 (avg: 0.218494) \tsec/iter: 0.0336\n",
      "Test set (epoch 244): Average loss: 0.4993, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.185625 (avg: 0.185625) \tsec/iter: 0.0349\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.381433 (avg: 0.275296) \tsec/iter: 0.0303\n",
      "Test set (epoch 245): Average loss: 0.4121, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.227660 (avg: 0.227660) \tsec/iter: 0.0349\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.308981 (avg: 0.261220) \tsec/iter: 0.0306\n",
      "Test set (epoch 246): Average loss: 0.3209, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.204148 (avg: 0.204148) \tsec/iter: 0.0389\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.254560 (avg: 0.256756) \tsec/iter: 0.0316\n",
      "Test set (epoch 247): Average loss: 0.4304, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.288332 (avg: 0.288332) \tsec/iter: 0.0329\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.140132 (avg: 0.234379) \tsec/iter: 0.0309\n",
      "Test set (epoch 248): Average loss: 0.4131, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.198125 (avg: 0.198125) \tsec/iter: 0.0329\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.271343 (avg: 0.222540) \tsec/iter: 0.0296\n",
      "Test set (epoch 249): Average loss: 0.4131, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.171178 (avg: 0.171178) \tsec/iter: 0.0369\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.155347 (avg: 0.218463) \tsec/iter: 0.0303\n",
      "Test set (epoch 250): Average loss: 0.4319, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.243416 (avg: 0.243416) \tsec/iter: 0.0339\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.126286 (avg: 0.194163) \tsec/iter: 0.0293\n",
      "Test set (epoch 251): Average loss: 0.3941, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.147237 (avg: 0.147237) \tsec/iter: 0.0329\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.313395 (avg: 0.231288) \tsec/iter: 0.0309\n",
      "Test set (epoch 252): Average loss: 0.4289, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.262407 (avg: 0.262407) \tsec/iter: 0.0379\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.122616 (avg: 0.231090) \tsec/iter: 0.0406\n",
      "Test set (epoch 253): Average loss: 0.3753, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.182314 (avg: 0.182314) \tsec/iter: 0.0409\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.191083 (avg: 0.234470) \tsec/iter: 0.0392\n",
      "Test set (epoch 254): Average loss: 0.3668, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.135488 (avg: 0.135488) \tsec/iter: 0.0359\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.203381 (avg: 0.239860) \tsec/iter: 0.0346\n",
      "Test set (epoch 255): Average loss: 0.3730, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.369857 (avg: 0.369857) \tsec/iter: 0.0588\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.252003 (avg: 0.281101) \tsec/iter: 0.0495\n",
      "Test set (epoch 256): Average loss: 0.3948, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.157519 (avg: 0.157519) \tsec/iter: 0.0389\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.219606 (avg: 0.219353) \tsec/iter: 0.0449\n",
      "Test set (epoch 257): Average loss: 0.3502, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.148719 (avg: 0.148719) \tsec/iter: 0.0479\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.236939 (avg: 0.226854) \tsec/iter: 0.0429\n",
      "Test set (epoch 258): Average loss: 0.4614, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.234107 (avg: 0.234107) \tsec/iter: 0.0539\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.163414 (avg: 0.233528) \tsec/iter: 0.0465\n",
      "Test set (epoch 259): Average loss: 0.4880, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.182285 (avg: 0.182285) \tsec/iter: 0.0449\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.232549 (avg: 0.181870) \tsec/iter: 0.0452\n",
      "Test set (epoch 260): Average loss: 0.4778, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.212034 (avg: 0.212034) \tsec/iter: 0.0459\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.224033 (avg: 0.230288) \tsec/iter: 0.0399\n",
      "Test set (epoch 261): Average loss: 0.4561, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.088478 (avg: 0.088478) \tsec/iter: 0.0489\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.129831 (avg: 0.187135) \tsec/iter: 0.0429\n",
      "Test set (epoch 262): Average loss: 0.4524, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.200353 (avg: 0.200353) \tsec/iter: 0.0409\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.130909 (avg: 0.169212) \tsec/iter: 0.0416\n",
      "Test set (epoch 263): Average loss: 0.4266, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.219002 (avg: 0.219002) \tsec/iter: 0.0449\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.195914 (avg: 0.214535) \tsec/iter: 0.0386\n",
      "Test set (epoch 264): Average loss: 0.4335, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.150366 (avg: 0.150366) \tsec/iter: 0.0359\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.231407 (avg: 0.213184) \tsec/iter: 0.0406\n",
      "Test set (epoch 265): Average loss: 0.4270, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.316774 (avg: 0.316774) \tsec/iter: 0.0429\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.254138 (avg: 0.246241) \tsec/iter: 0.0432\n",
      "Test set (epoch 266): Average loss: 0.3827, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.202143 (avg: 0.202143) \tsec/iter: 0.0469\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.176507 (avg: 0.202439) \tsec/iter: 0.0409\n",
      "Test set (epoch 267): Average loss: 0.4753, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.158500 (avg: 0.158500) \tsec/iter: 0.0479\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.239342 (avg: 0.262457) \tsec/iter: 0.0449\n",
      "Test set (epoch 268): Average loss: 0.3075, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.216964 (avg: 0.216964) \tsec/iter: 0.0399\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.221326 (avg: 0.242200) \tsec/iter: 0.0392\n",
      "Test set (epoch 269): Average loss: 0.3433, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.445295 (avg: 0.445295) \tsec/iter: 0.0479\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.175463 (avg: 0.265281) \tsec/iter: 0.0426\n",
      "Test set (epoch 270): Average loss: 0.3471, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.192382 (avg: 0.192382) \tsec/iter: 0.0499\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.145813 (avg: 0.214671) \tsec/iter: 0.0422\n",
      "Test set (epoch 271): Average loss: 0.2981, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.143527 (avg: 0.143527) \tsec/iter: 0.0459\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.312279 (avg: 0.221141) \tsec/iter: 0.0426\n",
      "Test set (epoch 272): Average loss: 0.4817, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.158838 (avg: 0.158838) \tsec/iter: 0.0429\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.215018 (avg: 0.253445) \tsec/iter: 0.0382\n",
      "Test set (epoch 273): Average loss: 0.4614, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.176607 (avg: 0.176607) \tsec/iter: 0.0469\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.165213 (avg: 0.167064) \tsec/iter: 0.0442\n",
      "Test set (epoch 274): Average loss: 0.3349, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.229112 (avg: 0.229112) \tsec/iter: 0.0539\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.159991 (avg: 0.200511) \tsec/iter: 0.0475\n",
      "Test set (epoch 275): Average loss: 0.4142, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.174291 (avg: 0.174291) \tsec/iter: 0.0409\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.273801 (avg: 0.223233) \tsec/iter: 0.0449\n",
      "Test set (epoch 276): Average loss: 0.3796, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.186128 (avg: 0.186128) \tsec/iter: 0.0548\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.265654 (avg: 0.251017) \tsec/iter: 0.0452\n",
      "Test set (epoch 277): Average loss: 0.2797, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.165466 (avg: 0.165466) \tsec/iter: 0.0459\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.242190 (avg: 0.231642) \tsec/iter: 0.0442\n",
      "Test set (epoch 278): Average loss: 0.2941, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.185843 (avg: 0.185843) \tsec/iter: 0.0479\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.166893 (avg: 0.199506) \tsec/iter: 0.0449\n",
      "Test set (epoch 279): Average loss: 0.3845, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.227480 (avg: 0.227480) \tsec/iter: 0.0558\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.176509 (avg: 0.182856) \tsec/iter: 0.0459\n",
      "Test set (epoch 280): Average loss: 0.3084, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.190006 (avg: 0.190006) \tsec/iter: 0.0568\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.256442 (avg: 0.196469) \tsec/iter: 0.0525\n",
      "Test set (epoch 281): Average loss: 0.3291, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.220344 (avg: 0.220344) \tsec/iter: 0.0598\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.260105 (avg: 0.213239) \tsec/iter: 0.0492\n",
      "Test set (epoch 282): Average loss: 0.3360, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.174072 (avg: 0.174072) \tsec/iter: 0.0459\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.183487 (avg: 0.207304) \tsec/iter: 0.0419\n",
      "Test set (epoch 283): Average loss: 0.2885, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.095936 (avg: 0.095936) \tsec/iter: 0.0479\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.111873 (avg: 0.237189) \tsec/iter: 0.0482\n",
      "Test set (epoch 284): Average loss: 0.2860, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.224087 (avg: 0.224087) \tsec/iter: 0.0499\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.117842 (avg: 0.215304) \tsec/iter: 0.0432\n",
      "Test set (epoch 285): Average loss: 0.3702, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.117510 (avg: 0.117510) \tsec/iter: 0.0389\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.200355 (avg: 0.175524) \tsec/iter: 0.0389\n",
      "Test set (epoch 286): Average loss: 0.3494, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.196209 (avg: 0.196209) \tsec/iter: 0.0459\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.363160 (avg: 0.237859) \tsec/iter: 0.0406\n",
      "Test set (epoch 287): Average loss: 0.4181, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.237258 (avg: 0.237258) \tsec/iter: 0.0409\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.161236 (avg: 0.220236) \tsec/iter: 0.0402\n",
      "Test set (epoch 288): Average loss: 0.3577, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.242399 (avg: 0.242399) \tsec/iter: 0.0539\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.210221 (avg: 0.201538) \tsec/iter: 0.0485\n",
      "Test set (epoch 289): Average loss: 0.3818, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.102873 (avg: 0.102873) \tsec/iter: 0.0419\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.216937 (avg: 0.158855) \tsec/iter: 0.0399\n",
      "Test set (epoch 290): Average loss: 0.3546, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.157292 (avg: 0.157292) \tsec/iter: 0.0479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.363049 (avg: 0.199259) \tsec/iter: 0.0419\n",
      "Test set (epoch 291): Average loss: 0.3896, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.161597 (avg: 0.161597) \tsec/iter: 0.0409\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.295850 (avg: 0.208464) \tsec/iter: 0.0399\n",
      "Test set (epoch 292): Average loss: 0.4072, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.203475 (avg: 0.203475) \tsec/iter: 0.0459\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.296396 (avg: 0.237218) \tsec/iter: 0.0422\n",
      "Test set (epoch 293): Average loss: 0.3503, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.196957 (avg: 0.196957) \tsec/iter: 0.0578\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.216106 (avg: 0.187394) \tsec/iter: 0.0459\n",
      "Test set (epoch 294): Average loss: 0.3252, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.131726 (avg: 0.131726) \tsec/iter: 0.0399\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.256764 (avg: 0.210845) \tsec/iter: 0.0382\n",
      "Test set (epoch 295): Average loss: 0.2697, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.154437 (avg: 0.154437) \tsec/iter: 0.0489\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.207215 (avg: 0.181095) \tsec/iter: 0.0455\n",
      "Test set (epoch 296): Average loss: 0.3948, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.185948 (avg: 0.185948) \tsec/iter: 0.0479\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.228981 (avg: 0.204143) \tsec/iter: 0.0429\n",
      "Test set (epoch 297): Average loss: 0.3243, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.199846 (avg: 0.199846) \tsec/iter: 0.0489\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.160737 (avg: 0.201119) \tsec/iter: 0.0396\n",
      "Test set (epoch 298): Average loss: 0.3389, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.128845 (avg: 0.128845) \tsec/iter: 0.0489\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.156149 (avg: 0.194773) \tsec/iter: 0.0422\n",
      "Test set (epoch 299): Average loss: 0.4231, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.217539 (avg: 0.217539) \tsec/iter: 0.0409\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.167521 (avg: 0.220320) \tsec/iter: 0.0406\n",
      "Test set (epoch 300): Average loss: 0.4243, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.160104 (avg: 0.160104) \tsec/iter: 0.0479\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.219149 (avg: 0.178566) \tsec/iter: 0.0416\n",
      "Test set (epoch 301): Average loss: 0.4244, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.115341 (avg: 0.115341) \tsec/iter: 0.0449\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.226291 (avg: 0.208033) \tsec/iter: 0.0402\n",
      "Test set (epoch 302): Average loss: 0.2459, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.193317 (avg: 0.193317) \tsec/iter: 0.0419\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.209061 (avg: 0.217639) \tsec/iter: 0.0392\n",
      "Test set (epoch 303): Average loss: 0.3398, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.233080 (avg: 0.233080) \tsec/iter: 0.0459\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.086502 (avg: 0.178119) \tsec/iter: 0.0449\n",
      "Test set (epoch 304): Average loss: 0.3203, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.164990 (avg: 0.164990) \tsec/iter: 0.0519\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.244986 (avg: 0.231658) \tsec/iter: 0.0449\n",
      "Test set (epoch 305): Average loss: 0.3642, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.277207 (avg: 0.277207) \tsec/iter: 0.0479\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.137732 (avg: 0.208443) \tsec/iter: 0.0439\n",
      "Test set (epoch 306): Average loss: 0.2901, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.160798 (avg: 0.160798) \tsec/iter: 0.0429\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.205195 (avg: 0.186202) \tsec/iter: 0.0416\n",
      "Test set (epoch 307): Average loss: 0.2653, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.204540 (avg: 0.204540) \tsec/iter: 0.0539\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.169280 (avg: 0.175786) \tsec/iter: 0.0482\n",
      "Test set (epoch 308): Average loss: 0.4030, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.132355 (avg: 0.132355) \tsec/iter: 0.0499\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.272418 (avg: 0.212845) \tsec/iter: 0.0412\n",
      "Test set (epoch 309): Average loss: 0.3243, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.277640 (avg: 0.277640) \tsec/iter: 0.0519\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.075037 (avg: 0.186104) \tsec/iter: 0.0436\n",
      "Test set (epoch 310): Average loss: 0.4425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.179814 (avg: 0.179814) \tsec/iter: 0.0479\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.094729 (avg: 0.167383) \tsec/iter: 0.0416\n",
      "Test set (epoch 311): Average loss: 0.4223, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.139023 (avg: 0.139023) \tsec/iter: 0.0549\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.138412 (avg: 0.200176) \tsec/iter: 0.0475\n",
      "Test set (epoch 312): Average loss: 0.4822, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.184447 (avg: 0.184447) \tsec/iter: 0.0419\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.221316 (avg: 0.200399) \tsec/iter: 0.0432\n",
      "Test set (epoch 313): Average loss: 0.4360, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.195704 (avg: 0.195704) \tsec/iter: 0.0439\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.220354 (avg: 0.203196) \tsec/iter: 0.0419\n",
      "Test set (epoch 314): Average loss: 0.3327, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.208815 (avg: 0.208815) \tsec/iter: 0.0469\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.265650 (avg: 0.190493) \tsec/iter: 0.0449\n",
      "Test set (epoch 315): Average loss: 0.3891, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.171808 (avg: 0.171808) \tsec/iter: 0.0489\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.292524 (avg: 0.198908) \tsec/iter: 0.0465\n",
      "Test set (epoch 316): Average loss: 0.3590, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.167654 (avg: 0.167654) \tsec/iter: 0.0578\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.207383 (avg: 0.175012) \tsec/iter: 0.0578\n",
      "Test set (epoch 317): Average loss: 0.5386, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.182084 (avg: 0.182084) \tsec/iter: 0.0578\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.097065 (avg: 0.201352) \tsec/iter: 0.0512\n",
      "Test set (epoch 318): Average loss: 0.3301, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.161792 (avg: 0.161792) \tsec/iter: 0.0529\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.229884 (avg: 0.183435) \tsec/iter: 0.0492\n",
      "Test set (epoch 319): Average loss: 0.4481, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.204259 (avg: 0.204259) \tsec/iter: 0.0549\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.196231 (avg: 0.200444) \tsec/iter: 0.0495\n",
      "Test set (epoch 320): Average loss: 0.2932, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.199637 (avg: 0.199637) \tsec/iter: 0.0608\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.206612 (avg: 0.219663) \tsec/iter: 0.0499\n",
      "Test set (epoch 321): Average loss: 0.3341, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.185524 (avg: 0.185524) \tsec/iter: 0.0449\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.123371 (avg: 0.179572) \tsec/iter: 0.0419\n",
      "Test set (epoch 322): Average loss: 0.4093, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.261609 (avg: 0.261609) \tsec/iter: 0.0429\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.190536 (avg: 0.205605) \tsec/iter: 0.0465\n",
      "Test set (epoch 323): Average loss: 0.4371, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.322186 (avg: 0.322186) \tsec/iter: 0.0559\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.147226 (avg: 0.216662) \tsec/iter: 0.0539\n",
      "Test set (epoch 324): Average loss: 0.4613, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.103353 (avg: 0.103353) \tsec/iter: 0.0469\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.209962 (avg: 0.155618) \tsec/iter: 0.0436\n",
      "Test set (epoch 325): Average loss: 0.3761, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.184842 (avg: 0.184842) \tsec/iter: 0.0499\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.202921 (avg: 0.187206) \tsec/iter: 0.0479\n",
      "Test set (epoch 326): Average loss: 0.4393, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.152377 (avg: 0.152377) \tsec/iter: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.201519 (avg: 0.196923) \tsec/iter: 0.0495\n",
      "Test set (epoch 327): Average loss: 0.4526, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.194404 (avg: 0.194404) \tsec/iter: 0.0529\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.243484 (avg: 0.201599) \tsec/iter: 0.0485\n",
      "Test set (epoch 328): Average loss: 0.4190, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.171284 (avg: 0.171284) \tsec/iter: 0.0568\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.247928 (avg: 0.162596) \tsec/iter: 0.0525\n",
      "Test set (epoch 329): Average loss: 0.4149, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.171661 (avg: 0.171661) \tsec/iter: 0.0588\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.255616 (avg: 0.191531) \tsec/iter: 0.0509\n",
      "Test set (epoch 330): Average loss: 0.3447, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.113494 (avg: 0.113494) \tsec/iter: 0.0489\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.185249 (avg: 0.165148) \tsec/iter: 0.0432\n",
      "Test set (epoch 331): Average loss: 0.4225, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.170849 (avg: 0.170849) \tsec/iter: 0.0479\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.244397 (avg: 0.173904) \tsec/iter: 0.0422\n",
      "Test set (epoch 332): Average loss: 0.3945, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.229977 (avg: 0.229977) \tsec/iter: 0.0459\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.082695 (avg: 0.179533) \tsec/iter: 0.0442\n",
      "Test set (epoch 333): Average loss: 0.3692, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.269926 (avg: 0.269926) \tsec/iter: 0.0429\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.255425 (avg: 0.217780) \tsec/iter: 0.0416\n",
      "Test set (epoch 334): Average loss: 0.4383, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.133618 (avg: 0.133618) \tsec/iter: 0.0548\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.172151 (avg: 0.179753) \tsec/iter: 0.0469\n",
      "Test set (epoch 335): Average loss: 0.3357, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.238889 (avg: 0.238889) \tsec/iter: 0.0509\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.151130 (avg: 0.187914) \tsec/iter: 0.0588\n",
      "Test set (epoch 336): Average loss: 0.4648, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.172283 (avg: 0.172283) \tsec/iter: 0.0539\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.188498 (avg: 0.170655) \tsec/iter: 0.0459\n",
      "Test set (epoch 337): Average loss: 0.4026, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.300303 (avg: 0.300303) \tsec/iter: 0.0549\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.246031 (avg: 0.218663) \tsec/iter: 0.0502\n",
      "Test set (epoch 338): Average loss: 0.4369, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.220569 (avg: 0.220569) \tsec/iter: 0.0529\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.161977 (avg: 0.187242) \tsec/iter: 0.0465\n",
      "Test set (epoch 339): Average loss: 0.3389, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.221395 (avg: 0.221395) \tsec/iter: 0.0419\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.133008 (avg: 0.158107) \tsec/iter: 0.0436\n",
      "Test set (epoch 340): Average loss: 0.3912, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.189857 (avg: 0.189857) \tsec/iter: 0.0519\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.259666 (avg: 0.197389) \tsec/iter: 0.0439\n",
      "Test set (epoch 341): Average loss: 0.4033, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.130593 (avg: 0.130593) \tsec/iter: 0.0419\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.116928 (avg: 0.137925) \tsec/iter: 0.0439\n",
      "Test set (epoch 342): Average loss: 0.4122, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.164691 (avg: 0.164691) \tsec/iter: 0.0578\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.279893 (avg: 0.190377) \tsec/iter: 0.0522\n",
      "Test set (epoch 343): Average loss: 0.3671, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.160264 (avg: 0.160264) \tsec/iter: 0.0489\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.221680 (avg: 0.178049) \tsec/iter: 0.0442\n",
      "Test set (epoch 344): Average loss: 0.3713, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.240029 (avg: 0.240029) \tsec/iter: 0.0549\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.187924 (avg: 0.209548) \tsec/iter: 0.0469\n",
      "Test set (epoch 345): Average loss: 0.5559, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.184330 (avg: 0.184330) \tsec/iter: 0.0519\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.128297 (avg: 0.178128) \tsec/iter: 0.0492\n",
      "Test set (epoch 346): Average loss: 0.4410, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.230802 (avg: 0.230802) \tsec/iter: 0.0558\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.130088 (avg: 0.240912) \tsec/iter: 0.0472\n",
      "Test set (epoch 347): Average loss: 0.4541, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.203661 (avg: 0.203661) \tsec/iter: 0.0459\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.073217 (avg: 0.175569) \tsec/iter: 0.0435\n",
      "Test set (epoch 348): Average loss: 0.4002, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.148923 (avg: 0.148923) \tsec/iter: 0.0479\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.115354 (avg: 0.163426) \tsec/iter: 0.0445\n",
      "Test set (epoch 349): Average loss: 0.3018, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.149913 (avg: 0.149913) \tsec/iter: 0.0549\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.285650 (avg: 0.169806) \tsec/iter: 0.0475\n",
      "Test set (epoch 350): Average loss: 0.3801, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.215195 (avg: 0.215195) \tsec/iter: 0.0568\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.148104 (avg: 0.178485) \tsec/iter: 0.0485\n",
      "Test set (epoch 351): Average loss: 0.4451, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.103411 (avg: 0.103411) \tsec/iter: 0.0549\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.317114 (avg: 0.166115) \tsec/iter: 0.0449\n",
      "Test set (epoch 352): Average loss: 0.3787, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.137643 (avg: 0.137643) \tsec/iter: 0.0499\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.226158 (avg: 0.239962) \tsec/iter: 0.0462\n",
      "Test set (epoch 353): Average loss: 0.3950, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.169288 (avg: 0.169288) \tsec/iter: 0.0469\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.166932 (avg: 0.179995) \tsec/iter: 0.0449\n",
      "Test set (epoch 354): Average loss: 0.4009, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.173498 (avg: 0.173498) \tsec/iter: 0.0489\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.155932 (avg: 0.195251) \tsec/iter: 0.0485\n",
      "Test set (epoch 355): Average loss: 0.4541, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.187380 (avg: 0.187380) \tsec/iter: 0.0578\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.337348 (avg: 0.226655) \tsec/iter: 0.0525\n",
      "Test set (epoch 356): Average loss: 0.5475, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.224892 (avg: 0.224892) \tsec/iter: 0.0568\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.167122 (avg: 0.198849) \tsec/iter: 0.0469\n",
      "Test set (epoch 357): Average loss: 0.3976, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.208411 (avg: 0.208411) \tsec/iter: 0.0529\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.183476 (avg: 0.155504) \tsec/iter: 0.0482\n",
      "Test set (epoch 358): Average loss: 0.4004, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.127931 (avg: 0.127931) \tsec/iter: 0.0489\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.212064 (avg: 0.238820) \tsec/iter: 0.0445\n",
      "Test set (epoch 359): Average loss: 0.4270, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.110315 (avg: 0.110315) \tsec/iter: 0.0429\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.167163 (avg: 0.182214) \tsec/iter: 0.0445\n",
      "Test set (epoch 360): Average loss: 0.4537, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.152667 (avg: 0.152667) \tsec/iter: 0.0469\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.162069 (avg: 0.201710) \tsec/iter: 0.0459\n",
      "Test set (epoch 361): Average loss: 0.3933, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.192668 (avg: 0.192668) \tsec/iter: 0.0429\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.105536 (avg: 0.164261) \tsec/iter: 0.0436\n",
      "Test set (epoch 362): Average loss: 0.4098, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.151436 (avg: 0.151436) \tsec/iter: 0.0559\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.183203 (avg: 0.155813) \tsec/iter: 0.0519\n",
      "Test set (epoch 363): Average loss: 0.4282, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.193009 (avg: 0.193009) \tsec/iter: 0.0568\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.190458 (avg: 0.189097) \tsec/iter: 0.0475\n",
      "Test set (epoch 364): Average loss: 0.4471, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.166038 (avg: 0.166038) \tsec/iter: 0.0568\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.139583 (avg: 0.140505) \tsec/iter: 0.0482\n",
      "Test set (epoch 365): Average loss: 0.4372, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.197088 (avg: 0.197088) \tsec/iter: 0.0549\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.198720 (avg: 0.159808) \tsec/iter: 0.0489\n",
      "Test set (epoch 366): Average loss: 0.4458, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.124078 (avg: 0.124078) \tsec/iter: 0.0479\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.155841 (avg: 0.149897) \tsec/iter: 0.0485\n",
      "Test set (epoch 367): Average loss: 0.4882, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.208312 (avg: 0.208312) \tsec/iter: 0.0469\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.151766 (avg: 0.170518) \tsec/iter: 0.0442\n",
      "Test set (epoch 368): Average loss: 0.4011, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.189889 (avg: 0.189889) \tsec/iter: 0.0479\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.138684 (avg: 0.158413) \tsec/iter: 0.0462\n",
      "Test set (epoch 369): Average loss: 0.3691, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.155506 (avg: 0.155506) \tsec/iter: 0.0529\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.168607 (avg: 0.193094) \tsec/iter: 0.0475\n",
      "Test set (epoch 370): Average loss: 0.4305, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.159312 (avg: 0.159312) \tsec/iter: 0.0549\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.310059 (avg: 0.201720) \tsec/iter: 0.0462\n",
      "Test set (epoch 371): Average loss: 0.3879, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.226265 (avg: 0.226265) \tsec/iter: 0.0509\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.153452 (avg: 0.186932) \tsec/iter: 0.0442\n",
      "Test set (epoch 372): Average loss: 0.4124, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.154837 (avg: 0.154837) \tsec/iter: 0.0429\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.200637 (avg: 0.164250) \tsec/iter: 0.0439\n",
      "Test set (epoch 373): Average loss: 0.3938, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.076164 (avg: 0.076164) \tsec/iter: 0.0509\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.258005 (avg: 0.135610) \tsec/iter: 0.0555\n",
      "Test set (epoch 374): Average loss: 0.4085, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.166587 (avg: 0.166587) \tsec/iter: 0.0539\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.193489 (avg: 0.198954) \tsec/iter: 0.0489\n",
      "Test set (epoch 375): Average loss: 0.4561, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.185581 (avg: 0.185581) \tsec/iter: 0.0578\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.153179 (avg: 0.200340) \tsec/iter: 0.0525\n",
      "Test set (epoch 376): Average loss: 0.4091, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.260420 (avg: 0.260420) \tsec/iter: 0.0588\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.131519 (avg: 0.199586) \tsec/iter: 0.0542\n",
      "Test set (epoch 377): Average loss: 0.3855, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.138246 (avg: 0.138246) \tsec/iter: 0.0539\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.220908 (avg: 0.188054) \tsec/iter: 0.0485\n",
      "Test set (epoch 378): Average loss: 0.3847, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.161890 (avg: 0.161890) \tsec/iter: 0.0489\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.289179 (avg: 0.202229) \tsec/iter: 0.0442\n",
      "Test set (epoch 379): Average loss: 0.4868, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.105448 (avg: 0.105448) \tsec/iter: 0.0509\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.085001 (avg: 0.156095) \tsec/iter: 0.0469\n",
      "Test set (epoch 380): Average loss: 0.4307, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.231990 (avg: 0.231990) \tsec/iter: 0.0549\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.173462 (avg: 0.200364) \tsec/iter: 0.0482\n",
      "Test set (epoch 381): Average loss: 0.3928, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.207424 (avg: 0.207424) \tsec/iter: 0.0588\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.134990 (avg: 0.170530) \tsec/iter: 0.0529\n",
      "Test set (epoch 382): Average loss: 0.4748, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.211571 (avg: 0.211571) \tsec/iter: 0.0489\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.103809 (avg: 0.198768) \tsec/iter: 0.0479\n",
      "Test set (epoch 383): Average loss: 0.3638, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.127152 (avg: 0.127152) \tsec/iter: 0.0489\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.263923 (avg: 0.184346) \tsec/iter: 0.0452\n",
      "Test set (epoch 384): Average loss: 0.4427, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.243044 (avg: 0.243044) \tsec/iter: 0.0539\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.142145 (avg: 0.164769) \tsec/iter: 0.0475\n",
      "Test set (epoch 385): Average loss: 0.5607, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.158540 (avg: 0.158540) \tsec/iter: 0.0429\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.111137 (avg: 0.205470) \tsec/iter: 0.0452\n",
      "Test set (epoch 386): Average loss: 0.3168, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.137535 (avg: 0.137535) \tsec/iter: 0.0439\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.181100 (avg: 0.169198) \tsec/iter: 0.0505\n",
      "Test set (epoch 387): Average loss: 0.4602, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.161094 (avg: 0.161094) \tsec/iter: 0.0618\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.154019 (avg: 0.171855) \tsec/iter: 0.0545\n",
      "Test set (epoch 388): Average loss: 0.4386, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.142486 (avg: 0.142486) \tsec/iter: 0.0578\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.230798 (avg: 0.173199) \tsec/iter: 0.0459\n",
      "Test set (epoch 389): Average loss: 0.4593, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.141793 (avg: 0.141793) \tsec/iter: 0.0489\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.222484 (avg: 0.213496) \tsec/iter: 0.0479\n",
      "Test set (epoch 390): Average loss: 0.3506, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.128087 (avg: 0.128087) \tsec/iter: 0.0469\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.202164 (avg: 0.182060) \tsec/iter: 0.0429\n",
      "Test set (epoch 391): Average loss: 0.4811, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.198360 (avg: 0.198360) \tsec/iter: 0.0489\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.183017 (avg: 0.213127) \tsec/iter: 0.0442\n",
      "Test set (epoch 392): Average loss: 0.4169, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.141858 (avg: 0.141858) \tsec/iter: 0.0509\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.269497 (avg: 0.175482) \tsec/iter: 0.0452\n",
      "Test set (epoch 393): Average loss: 0.3274, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.120764 (avg: 0.120764) \tsec/iter: 0.0529\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.223017 (avg: 0.180471) \tsec/iter: 0.0472\n",
      "Test set (epoch 394): Average loss: 0.4149, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.164780 (avg: 0.164780) \tsec/iter: 0.0529\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.128959 (avg: 0.152387) \tsec/iter: 0.0539\n",
      "Test set (epoch 395): Average loss: 0.4048, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.175469 (avg: 0.175469) \tsec/iter: 0.0519\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.168103 (avg: 0.185338) \tsec/iter: 0.0502\n",
      "Test set (epoch 396): Average loss: 0.3992, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.186598 (avg: 0.186598) \tsec/iter: 0.0499\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.118652 (avg: 0.180375) \tsec/iter: 0.0475\n",
      "Test set (epoch 397): Average loss: 0.3792, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.112974 (avg: 0.112974) \tsec/iter: 0.0449\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.171447 (avg: 0.176617) \tsec/iter: 0.0465\n",
      "Test set (epoch 398): Average loss: 0.3104, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.134887 (avg: 0.134887) \tsec/iter: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.187138 (avg: 0.146455) \tsec/iter: 0.0452\n",
      "Test set (epoch 399): Average loss: 0.4901, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.208126 (avg: 0.208126) \tsec/iter: 0.0568\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.165705 (avg: 0.180061) \tsec/iter: 0.0495\n",
      "Test set (epoch 400): Average loss: 0.4186, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.139622 (avg: 0.139622) \tsec/iter: 0.0568\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.136464 (avg: 0.165797) \tsec/iter: 0.0522\n",
      "Test set (epoch 401): Average loss: 0.4757, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.148366 (avg: 0.148366) \tsec/iter: 0.0539\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.076445 (avg: 0.146811) \tsec/iter: 0.0452\n",
      "Test set (epoch 402): Average loss: 0.4092, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.171644 (avg: 0.171644) \tsec/iter: 0.0479\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.068424 (avg: 0.177849) \tsec/iter: 0.0479\n",
      "Test set (epoch 403): Average loss: 0.3859, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.102240 (avg: 0.102240) \tsec/iter: 0.0509\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.193357 (avg: 0.155610) \tsec/iter: 0.0435\n",
      "Test set (epoch 404): Average loss: 0.4959, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.198527 (avg: 0.198527) \tsec/iter: 0.0469\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.207454 (avg: 0.162541) \tsec/iter: 0.0455\n",
      "Test set (epoch 405): Average loss: 0.6536, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.116978 (avg: 0.116978) \tsec/iter: 0.0479\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.096538 (avg: 0.150596) \tsec/iter: 0.0455\n",
      "Test set (epoch 406): Average loss: 0.4690, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.207907 (avg: 0.207907) \tsec/iter: 0.0489\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.085075 (avg: 0.148525) \tsec/iter: 0.0462\n",
      "Test set (epoch 407): Average loss: 0.4468, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.137105 (avg: 0.137105) \tsec/iter: 0.0539\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.158937 (avg: 0.154405) \tsec/iter: 0.0542\n",
      "Test set (epoch 408): Average loss: 0.6910, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.242234 (avg: 0.242234) \tsec/iter: 0.0588\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.111634 (avg: 0.179300) \tsec/iter: 0.0472\n",
      "Test set (epoch 409): Average loss: 0.5437, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.101993 (avg: 0.101993) \tsec/iter: 0.0549\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.273037 (avg: 0.178233) \tsec/iter: 0.0445\n",
      "Test set (epoch 410): Average loss: 0.5199, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.269731 (avg: 0.269731) \tsec/iter: 0.0529\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.251982 (avg: 0.204164) \tsec/iter: 0.0622\n",
      "Test set (epoch 411): Average loss: 0.5787, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.185972 (avg: 0.185972) \tsec/iter: 0.0549\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.169525 (avg: 0.240214) \tsec/iter: 0.0512\n",
      "Test set (epoch 412): Average loss: 0.5114, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.173246 (avg: 0.173246) \tsec/iter: 0.0568\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.200455 (avg: 0.186365) \tsec/iter: 0.0701\n",
      "Test set (epoch 413): Average loss: 0.4253, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.122433 (avg: 0.122433) \tsec/iter: 0.0798\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.180374 (avg: 0.153702) \tsec/iter: 0.0718\n",
      "Test set (epoch 414): Average loss: 0.5068, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.139336 (avg: 0.139336) \tsec/iter: 0.0549\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.118509 (avg: 0.169942) \tsec/iter: 0.0499\n",
      "Test set (epoch 415): Average loss: 0.4435, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.206559 (avg: 0.206559) \tsec/iter: 0.0608\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.212127 (avg: 0.200596) \tsec/iter: 0.0522\n",
      "Test set (epoch 416): Average loss: 0.3729, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.185258 (avg: 0.185258) \tsec/iter: 0.0578\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.149526 (avg: 0.152383) \tsec/iter: 0.0492\n",
      "Test set (epoch 417): Average loss: 0.5835, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.144403 (avg: 0.144403) \tsec/iter: 0.0449\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.166178 (avg: 0.135637) \tsec/iter: 0.0445\n",
      "Test set (epoch 418): Average loss: 0.2742, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.191117 (avg: 0.191117) \tsec/iter: 0.0598\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.090897 (avg: 0.146065) \tsec/iter: 0.0545\n",
      "Test set (epoch 419): Average loss: 0.4115, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.138129 (avg: 0.138129) \tsec/iter: 0.0678\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.125610 (avg: 0.128837) \tsec/iter: 0.0602\n",
      "Test set (epoch 420): Average loss: 0.4682, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.214480 (avg: 0.214480) \tsec/iter: 0.0668\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.302603 (avg: 0.205709) \tsec/iter: 0.0593\n",
      "Test set (epoch 421): Average loss: 0.4833, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.154431 (avg: 0.154431) \tsec/iter: 0.0678\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.176970 (avg: 0.135547) \tsec/iter: 0.0612\n",
      "Test set (epoch 422): Average loss: 0.4375, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.205336 (avg: 0.205336) \tsec/iter: 0.0598\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.181003 (avg: 0.157216) \tsec/iter: 0.0562\n",
      "Test set (epoch 423): Average loss: 0.4213, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.197113 (avg: 0.197113) \tsec/iter: 0.0529\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.197471 (avg: 0.227540) \tsec/iter: 0.0572\n",
      "Test set (epoch 424): Average loss: 0.4736, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.210427 (avg: 0.210427) \tsec/iter: 0.0668\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.216335 (avg: 0.185350) \tsec/iter: 0.0592\n",
      "Test set (epoch 425): Average loss: 0.3681, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.180390 (avg: 0.180390) \tsec/iter: 0.0608\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.144060 (avg: 0.150888) \tsec/iter: 0.0549\n",
      "Test set (epoch 426): Average loss: 0.2809, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.285601 (avg: 0.285601) \tsec/iter: 0.0568\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.197335 (avg: 0.240730) \tsec/iter: 0.0535\n",
      "Test set (epoch 427): Average loss: 0.3701, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.133366 (avg: 0.133366) \tsec/iter: 0.0628\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.268206 (avg: 0.195038) \tsec/iter: 0.0542\n",
      "Test set (epoch 428): Average loss: 0.4759, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.288772 (avg: 0.288772) \tsec/iter: 0.0559\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.148464 (avg: 0.207443) \tsec/iter: 0.0492\n",
      "Test set (epoch 429): Average loss: 0.3500, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.180856 (avg: 0.180856) \tsec/iter: 0.0598\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.150906 (avg: 0.180504) \tsec/iter: 0.0545\n",
      "Test set (epoch 430): Average loss: 0.4600, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.220017 (avg: 0.220017) \tsec/iter: 0.0499\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.189060 (avg: 0.192140) \tsec/iter: 0.0489\n",
      "Test set (epoch 431): Average loss: 0.4141, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.180246 (avg: 0.180246) \tsec/iter: 0.0519\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.148113 (avg: 0.148743) \tsec/iter: 0.0489\n",
      "Test set (epoch 432): Average loss: 0.5822, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.120285 (avg: 0.120285) \tsec/iter: 0.0539\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.110488 (avg: 0.141254) \tsec/iter: 0.0462\n",
      "Test set (epoch 433): Average loss: 0.4678, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.183537 (avg: 0.183537) \tsec/iter: 0.0489\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.264038 (avg: 0.204271) \tsec/iter: 0.0465\n",
      "Test set (epoch 434): Average loss: 0.5457, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.199683 (avg: 0.199683) \tsec/iter: 0.0598\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.125690 (avg: 0.173838) \tsec/iter: 0.0502\n",
      "Test set (epoch 435): Average loss: 0.5023, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.141070 (avg: 0.141070) \tsec/iter: 0.0549\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.188661 (avg: 0.180731) \tsec/iter: 0.0542\n",
      "Test set (epoch 436): Average loss: 0.4492, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.146267 (avg: 0.146267) \tsec/iter: 0.0808\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.225093 (avg: 0.138462) \tsec/iter: 0.0655\n",
      "Test set (epoch 437): Average loss: 0.5193, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.185622 (avg: 0.185622) \tsec/iter: 0.0509\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.167653 (avg: 0.159925) \tsec/iter: 0.0605\n",
      "Test set (epoch 438): Average loss: 0.4285, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.136188 (avg: 0.136188) \tsec/iter: 0.0698\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.222160 (avg: 0.172908) \tsec/iter: 0.0632\n",
      "Test set (epoch 439): Average loss: 0.5460, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.174393 (avg: 0.174393) \tsec/iter: 0.0658\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.278268 (avg: 0.182313) \tsec/iter: 0.0582\n",
      "Test set (epoch 440): Average loss: 0.4230, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.091392 (avg: 0.091392) \tsec/iter: 0.0529\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.046711 (avg: 0.136644) \tsec/iter: 0.0522\n",
      "Test set (epoch 441): Average loss: 0.4447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.153273 (avg: 0.153273) \tsec/iter: 0.0628\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.207372 (avg: 0.195886) \tsec/iter: 0.0575\n",
      "Test set (epoch 442): Average loss: 0.4027, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.189114 (avg: 0.189114) \tsec/iter: 0.0658\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.138609 (avg: 0.137764) \tsec/iter: 0.0618\n",
      "Test set (epoch 443): Average loss: 0.4039, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.091162 (avg: 0.091162) \tsec/iter: 0.0608\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.268236 (avg: 0.162516) \tsec/iter: 0.0522\n",
      "Test set (epoch 444): Average loss: 0.3446, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.126990 (avg: 0.126990) \tsec/iter: 0.0568\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.231700 (avg: 0.188880) \tsec/iter: 0.0529\n",
      "Test set (epoch 445): Average loss: 0.4408, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.171458 (avg: 0.171458) \tsec/iter: 0.0588\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.165473 (avg: 0.158492) \tsec/iter: 0.0485\n",
      "Test set (epoch 446): Average loss: 0.4829, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.173931 (avg: 0.173931) \tsec/iter: 0.0598\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.268663 (avg: 0.169157) \tsec/iter: 0.0612\n",
      "Test set (epoch 447): Average loss: 0.4106, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.075790 (avg: 0.075790) \tsec/iter: 0.0549\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.291700 (avg: 0.162576) \tsec/iter: 0.0499\n",
      "Test set (epoch 448): Average loss: 0.5029, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.157582 (avg: 0.157582) \tsec/iter: 0.0529\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.350346 (avg: 0.193773) \tsec/iter: 0.0505\n",
      "Test set (epoch 449): Average loss: 0.5302, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.228111 (avg: 0.228111) \tsec/iter: 0.0578\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.114531 (avg: 0.215764) \tsec/iter: 0.0522\n",
      "Test set (epoch 450): Average loss: 0.5635, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.148363 (avg: 0.148363) \tsec/iter: 0.0628\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.109648 (avg: 0.147123) \tsec/iter: 0.0525\n",
      "Test set (epoch 451): Average loss: 0.4531, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.222599 (avg: 0.222599) \tsec/iter: 0.0519\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.121118 (avg: 0.144800) \tsec/iter: 0.0499\n",
      "Test set (epoch 452): Average loss: 0.4859, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.096817 (avg: 0.096817) \tsec/iter: 0.0748\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.216194 (avg: 0.185587) \tsec/iter: 0.0592\n",
      "Test set (epoch 453): Average loss: 0.4172, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.167382 (avg: 0.167382) \tsec/iter: 0.0618\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.148329 (avg: 0.145610) \tsec/iter: 0.0535\n",
      "Test set (epoch 454): Average loss: 0.5142, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.151251 (avg: 0.151251) \tsec/iter: 0.0598\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.288972 (avg: 0.160230) \tsec/iter: 0.0519\n",
      "Test set (epoch 455): Average loss: 0.5083, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.222538 (avg: 0.222538) \tsec/iter: 0.0489\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.202878 (avg: 0.180280) \tsec/iter: 0.0472\n",
      "Test set (epoch 456): Average loss: 0.4207, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.124589 (avg: 0.124589) \tsec/iter: 0.0568\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.067524 (avg: 0.165380) \tsec/iter: 0.0512\n",
      "Test set (epoch 457): Average loss: 0.4754, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.206016 (avg: 0.206016) \tsec/iter: 0.0469\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.159704 (avg: 0.171492) \tsec/iter: 0.0492\n",
      "Test set (epoch 458): Average loss: 0.3687, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.238610 (avg: 0.238610) \tsec/iter: 0.0588\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.090217 (avg: 0.145968) \tsec/iter: 0.0575\n",
      "Test set (epoch 459): Average loss: 0.4325, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.202511 (avg: 0.202511) \tsec/iter: 0.0588\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.160202 (avg: 0.204134) \tsec/iter: 0.0628\n",
      "Test set (epoch 460): Average loss: 0.5534, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.195961 (avg: 0.195961) \tsec/iter: 0.0539\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.259978 (avg: 0.175191) \tsec/iter: 0.0522\n",
      "Test set (epoch 461): Average loss: 0.4413, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.192935 (avg: 0.192935) \tsec/iter: 0.0539\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.202473 (avg: 0.209908) \tsec/iter: 0.0502\n",
      "Test set (epoch 462): Average loss: 0.3833, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.173678 (avg: 0.173678) \tsec/iter: 0.0489\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.140797 (avg: 0.149331) \tsec/iter: 0.0449\n",
      "Test set (epoch 463): Average loss: 0.4867, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.097483 (avg: 0.097483) \tsec/iter: 0.0499\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.148198 (avg: 0.171992) \tsec/iter: 0.0565\n",
      "Test set (epoch 464): Average loss: 0.5297, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.178820 (avg: 0.178820) \tsec/iter: 0.0638\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.080984 (avg: 0.138114) \tsec/iter: 0.0568\n",
      "Test set (epoch 465): Average loss: 0.3593, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.167181 (avg: 0.167181) \tsec/iter: 0.0539\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.298529 (avg: 0.196649) \tsec/iter: 0.0502\n",
      "Test set (epoch 466): Average loss: 0.5505, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.199002 (avg: 0.199002) \tsec/iter: 0.0509\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.161784 (avg: 0.158287) \tsec/iter: 0.0459\n",
      "Test set (epoch 467): Average loss: 0.4848, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.104446 (avg: 0.104446) \tsec/iter: 0.0578\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.356144 (avg: 0.178277) \tsec/iter: 0.0582\n",
      "Test set (epoch 468): Average loss: 0.3641, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.139215 (avg: 0.139215) \tsec/iter: 0.0519\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.094809 (avg: 0.160598) \tsec/iter: 0.0479\n",
      "Test set (epoch 469): Average loss: 0.4496, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.162421 (avg: 0.162421) \tsec/iter: 0.0618\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.069857 (avg: 0.156056) \tsec/iter: 0.0525\n",
      "Test set (epoch 470): Average loss: 0.5192, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.190555 (avg: 0.190555) \tsec/iter: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.102576 (avg: 0.156037) \tsec/iter: 0.0588\n",
      "Test set (epoch 471): Average loss: 0.4538, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.119324 (avg: 0.119324) \tsec/iter: 0.0628\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.300666 (avg: 0.155344) \tsec/iter: 0.0555\n",
      "Test set (epoch 472): Average loss: 0.3595, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.134108 (avg: 0.134108) \tsec/iter: 0.0568\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.138921 (avg: 0.138019) \tsec/iter: 0.0502\n",
      "Test set (epoch 473): Average loss: 0.4051, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.157103 (avg: 0.157103) \tsec/iter: 0.0598\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.081550 (avg: 0.142224) \tsec/iter: 0.0515\n",
      "Test set (epoch 474): Average loss: 0.4519, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.168757 (avg: 0.168757) \tsec/iter: 0.0628\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.133166 (avg: 0.165368) \tsec/iter: 0.0559\n",
      "Test set (epoch 475): Average loss: 0.4920, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.163919 (avg: 0.163919) \tsec/iter: 0.0618\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.093799 (avg: 0.122293) \tsec/iter: 0.0552\n",
      "Test set (epoch 476): Average loss: 0.5057, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.309877 (avg: 0.309877) \tsec/iter: 0.0618\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.140128 (avg: 0.188169) \tsec/iter: 0.0509\n",
      "Test set (epoch 477): Average loss: 0.4975, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.177608 (avg: 0.177608) \tsec/iter: 0.0598\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.172309 (avg: 0.171589) \tsec/iter: 0.0529\n",
      "Test set (epoch 478): Average loss: 0.4430, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.196662 (avg: 0.196662) \tsec/iter: 0.0588\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.191948 (avg: 0.168508) \tsec/iter: 0.0525\n",
      "Test set (epoch 479): Average loss: 0.6118, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.185921 (avg: 0.185921) \tsec/iter: 0.0608\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.212951 (avg: 0.198559) \tsec/iter: 0.0529\n",
      "Test set (epoch 480): Average loss: 0.4579, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.307333 (avg: 0.307333) \tsec/iter: 0.0598\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.060583 (avg: 0.235344) \tsec/iter: 0.0648\n",
      "Test set (epoch 481): Average loss: 0.5000, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.170495 (avg: 0.170495) \tsec/iter: 0.0688\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.113615 (avg: 0.185849) \tsec/iter: 0.0632\n",
      "Test set (epoch 482): Average loss: 0.5472, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.131449 (avg: 0.131449) \tsec/iter: 0.0588\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.221145 (avg: 0.174240) \tsec/iter: 0.0512\n",
      "Test set (epoch 483): Average loss: 0.4534, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.182876 (avg: 0.182876) \tsec/iter: 0.0499\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.140698 (avg: 0.132538) \tsec/iter: 0.0509\n",
      "Test set (epoch 484): Average loss: 0.4597, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.225803 (avg: 0.225803) \tsec/iter: 0.0509\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.155702 (avg: 0.175261) \tsec/iter: 0.0479\n",
      "Test set (epoch 485): Average loss: 0.4019, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.103071 (avg: 0.103071) \tsec/iter: 0.0568\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.148233 (avg: 0.127226) \tsec/iter: 0.0542\n",
      "Test set (epoch 486): Average loss: 0.5240, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.152435 (avg: 0.152435) \tsec/iter: 0.0628\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.174563 (avg: 0.165758) \tsec/iter: 0.0555\n",
      "Test set (epoch 487): Average loss: 0.5408, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.109094 (avg: 0.109094) \tsec/iter: 0.0658\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.289725 (avg: 0.188120) \tsec/iter: 0.0509\n",
      "Test set (epoch 488): Average loss: 0.3982, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.209031 (avg: 0.209031) \tsec/iter: 0.0578\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.173783 (avg: 0.169760) \tsec/iter: 0.0499\n",
      "Test set (epoch 489): Average loss: 0.4138, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.166249 (avg: 0.166249) \tsec/iter: 0.0479\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.095467 (avg: 0.175051) \tsec/iter: 0.0455\n",
      "Test set (epoch 490): Average loss: 0.3960, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.175594 (avg: 0.175594) \tsec/iter: 0.0559\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.147773 (avg: 0.175089) \tsec/iter: 0.0492\n",
      "Test set (epoch 491): Average loss: 0.4885, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.096204 (avg: 0.096204) \tsec/iter: 0.0559\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.139163 (avg: 0.114878) \tsec/iter: 0.0519\n",
      "Test set (epoch 492): Average loss: 0.3576, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.165174 (avg: 0.165174) \tsec/iter: 0.0499\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.328258 (avg: 0.191026) \tsec/iter: 0.0535\n",
      "Test set (epoch 493): Average loss: 0.4534, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.099915 (avg: 0.099915) \tsec/iter: 0.0588\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.217770 (avg: 0.156266) \tsec/iter: 0.0519\n",
      "Test set (epoch 494): Average loss: 0.4101, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.088872 (avg: 0.088872) \tsec/iter: 0.0578\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.259185 (avg: 0.141807) \tsec/iter: 0.0519\n",
      "Test set (epoch 495): Average loss: 0.5216, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.159531 (avg: 0.159531) \tsec/iter: 0.0608\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.205012 (avg: 0.191337) \tsec/iter: 0.0539\n",
      "Test set (epoch 496): Average loss: 0.4796, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.105236 (avg: 0.105236) \tsec/iter: 0.0588\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.138792 (avg: 0.152525) \tsec/iter: 0.0562\n",
      "Test set (epoch 497): Average loss: 0.5425, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.081172 (avg: 0.081172) \tsec/iter: 0.0519\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.150578 (avg: 0.157112) \tsec/iter: 0.0499\n",
      "Test set (epoch 498): Average loss: 0.3944, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.166597 (avg: 0.166597) \tsec/iter: 0.0598\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.139372 (avg: 0.172354) \tsec/iter: 0.0562\n",
      "Test set (epoch 499): Average loss: 0.4364, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 1\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.272528 (avg: 1.272528) \tsec/iter: 0.0549\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 1.068616 (avg: 3.868427) \tsec/iter: 0.0485\n",
      "Test set (epoch 0): Average loss: 1.0671, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 1.878435 (avg: 1.878435) \tsec/iter: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.970562 (avg: 1.254828) \tsec/iter: 0.0442\n",
      "Test set (epoch 1): Average loss: 0.2360, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.755270 (avg: 0.755270) \tsec/iter: 0.0539\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.640116 (avg: 0.761707) \tsec/iter: 0.0472\n",
      "Test set (epoch 2): Average loss: 0.2672, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.490088 (avg: 0.490088) \tsec/iter: 0.0459\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.846741 (avg: 0.555377) \tsec/iter: 0.0445\n",
      "Test set (epoch 3): Average loss: 1.0896, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.727337 (avg: 0.727337) \tsec/iter: 0.0529\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.547845 (avg: 0.573715) \tsec/iter: 0.0449\n",
      "Test set (epoch 4): Average loss: 0.8215, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.516833 (avg: 0.516833) \tsec/iter: 0.0529\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.724915 (avg: 0.742495) \tsec/iter: 0.0505\n",
      "Test set (epoch 5): Average loss: 0.5067, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.455719 (avg: 0.455719) \tsec/iter: 0.0628\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.512719 (avg: 0.598602) \tsec/iter: 0.0532\n",
      "Test set (epoch 6): Average loss: 0.5549, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.415866 (avg: 0.415866) \tsec/iter: 0.0419\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.436952 (avg: 0.464211) \tsec/iter: 0.0419\n",
      "Test set (epoch 7): Average loss: 0.3541, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.562822 (avg: 0.562822) \tsec/iter: 0.0509\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.367148 (avg: 0.515161) \tsec/iter: 0.0442\n",
      "Test set (epoch 8): Average loss: 0.6804, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.585403 (avg: 0.585403) \tsec/iter: 0.0459\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.273668 (avg: 0.474702) \tsec/iter: 0.0495\n",
      "Test set (epoch 9): Average loss: 0.3869, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.401544 (avg: 0.401544) \tsec/iter: 0.0449\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.541545 (avg: 0.464897) \tsec/iter: 0.0442\n",
      "Test set (epoch 10): Average loss: 0.8020, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.434470 (avg: 0.434470) \tsec/iter: 0.0509\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.588503 (avg: 0.438244) \tsec/iter: 0.0459\n",
      "Test set (epoch 11): Average loss: 0.7218, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.466185 (avg: 0.466185) \tsec/iter: 0.0559\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.555069 (avg: 0.447556) \tsec/iter: 0.0612\n",
      "Test set (epoch 12): Average loss: 0.9332, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.610350 (avg: 0.610350) \tsec/iter: 0.0588\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.331486 (avg: 0.510711) \tsec/iter: 0.0509\n",
      "Test set (epoch 13): Average loss: 0.8075, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.422774 (avg: 0.422774) \tsec/iter: 0.0449\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.402439 (avg: 0.415959) \tsec/iter: 0.0442\n",
      "Test set (epoch 14): Average loss: 0.7995, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.475109 (avg: 0.475109) \tsec/iter: 0.0628\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.200852 (avg: 0.376281) \tsec/iter: 0.0515\n",
      "Test set (epoch 15): Average loss: 0.6502, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.472775 (avg: 0.472775) \tsec/iter: 0.0429\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.269494 (avg: 0.426843) \tsec/iter: 0.0386\n",
      "Test set (epoch 16): Average loss: 0.5324, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.375644 (avg: 0.375644) \tsec/iter: 0.0499\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.535810 (avg: 0.392855) \tsec/iter: 0.0465\n",
      "Test set (epoch 17): Average loss: 0.4726, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.739490 (avg: 0.739490) \tsec/iter: 0.0489\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.403134 (avg: 0.498769) \tsec/iter: 0.0539\n",
      "Test set (epoch 18): Average loss: 0.5008, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.375614 (avg: 0.375614) \tsec/iter: 0.0539\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.392617 (avg: 0.448834) \tsec/iter: 0.0499\n",
      "Test set (epoch 19): Average loss: 0.8849, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.399558 (avg: 0.399558) \tsec/iter: 0.0578\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.445552 (avg: 0.392224) \tsec/iter: 0.0509\n",
      "Test set (epoch 20): Average loss: 0.7359, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.432228 (avg: 0.432228) \tsec/iter: 0.0449\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.311963 (avg: 0.389888) \tsec/iter: 0.0422\n",
      "Test set (epoch 21): Average loss: 0.6401, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.473235 (avg: 0.473235) \tsec/iter: 0.0489\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.308100 (avg: 0.402350) \tsec/iter: 0.0452\n",
      "Test set (epoch 22): Average loss: 0.7164, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.320443 (avg: 0.320443) \tsec/iter: 0.0549\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.559238 (avg: 0.398137) \tsec/iter: 0.0459\n",
      "Test set (epoch 23): Average loss: 0.8113, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.333213 (avg: 0.333213) \tsec/iter: 0.0519\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.370451 (avg: 0.374173) \tsec/iter: 0.0489\n",
      "Test set (epoch 24): Average loss: 0.6963, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.481236 (avg: 0.481236) \tsec/iter: 0.0559\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.259617 (avg: 0.405514) \tsec/iter: 0.0505\n",
      "Test set (epoch 25): Average loss: 0.6663, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.406019 (avg: 0.406019) \tsec/iter: 0.0479\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.366301 (avg: 0.375332) \tsec/iter: 0.0462\n",
      "Test set (epoch 26): Average loss: 0.6684, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.393527 (avg: 0.393527) \tsec/iter: 0.0419\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.370088 (avg: 0.398393) \tsec/iter: 0.0419\n",
      "Test set (epoch 27): Average loss: 0.6993, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.327835 (avg: 0.327835) \tsec/iter: 0.0519\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.562515 (avg: 0.378353) \tsec/iter: 0.0455\n",
      "Test set (epoch 28): Average loss: 0.7285, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.331580 (avg: 0.331580) \tsec/iter: 0.0449\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.431836 (avg: 0.327422) \tsec/iter: 0.0462\n",
      "Test set (epoch 29): Average loss: 0.7160, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.342199 (avg: 0.342199) \tsec/iter: 0.0529\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.385622 (avg: 0.352486) \tsec/iter: 0.0479\n",
      "Test set (epoch 30): Average loss: 0.6475, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.402231 (avg: 0.402231) \tsec/iter: 0.0549\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.292429 (avg: 0.384835) \tsec/iter: 0.0632\n",
      "Test set (epoch 31): Average loss: 0.5986, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.426624 (avg: 0.426624) \tsec/iter: 0.0539\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.432445 (avg: 0.387806) \tsec/iter: 0.0489\n",
      "Test set (epoch 32): Average loss: 0.6987, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.377090 (avg: 0.377090) \tsec/iter: 0.0578\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.415625 (avg: 0.398998) \tsec/iter: 0.0469\n",
      "Test set (epoch 33): Average loss: 0.7391, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.337452 (avg: 0.337452) \tsec/iter: 0.0578\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.316485 (avg: 0.386355) \tsec/iter: 0.0482\n",
      "Test set (epoch 34): Average loss: 0.7235, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.316269 (avg: 0.316269) \tsec/iter: 0.0479\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.570021 (avg: 0.400316) \tsec/iter: 0.0439\n",
      "Test set (epoch 35): Average loss: 0.7374, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.404378 (avg: 0.404378) \tsec/iter: 0.0499\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.258847 (avg: 0.340454) \tsec/iter: 0.0482\n",
      "Test set (epoch 36): Average loss: 0.7180, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.381643 (avg: 0.381643) \tsec/iter: 0.0489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.321552 (avg: 0.355138) \tsec/iter: 0.0502\n",
      "Test set (epoch 37): Average loss: 0.6775, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.457693 (avg: 0.457693) \tsec/iter: 0.0559\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.412470 (avg: 0.388601) \tsec/iter: 0.0509\n",
      "Test set (epoch 38): Average loss: 0.5885, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.423743 (avg: 0.423743) \tsec/iter: 0.0568\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.316098 (avg: 0.360924) \tsec/iter: 0.0479\n",
      "Test set (epoch 39): Average loss: 0.6118, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.302593 (avg: 0.302593) \tsec/iter: 0.0519\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.409975 (avg: 0.363674) \tsec/iter: 0.0489\n",
      "Test set (epoch 40): Average loss: 0.6789, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.308180 (avg: 0.308180) \tsec/iter: 0.0529\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.467102 (avg: 0.372561) \tsec/iter: 0.0455\n",
      "Test set (epoch 41): Average loss: 0.6923, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.381380 (avg: 0.381380) \tsec/iter: 0.0459\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.379286 (avg: 0.364031) \tsec/iter: 0.0445\n",
      "Test set (epoch 42): Average loss: 0.6818, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.479765 (avg: 0.479765) \tsec/iter: 0.0519\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.359667 (avg: 0.386983) \tsec/iter: 0.0442\n",
      "Test set (epoch 43): Average loss: 0.6678, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.459589 (avg: 0.459589) \tsec/iter: 0.0618\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.275954 (avg: 0.357493) \tsec/iter: 0.0628\n",
      "Test set (epoch 44): Average loss: 0.7006, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.405722 (avg: 0.405722) \tsec/iter: 0.0539\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.395639 (avg: 0.374924) \tsec/iter: 0.0485\n",
      "Test set (epoch 45): Average loss: 0.6599, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.314191 (avg: 0.314191) \tsec/iter: 0.0558\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.442197 (avg: 0.371193) \tsec/iter: 0.0495\n",
      "Test set (epoch 46): Average loss: 0.6578, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.370910 (avg: 0.370910) \tsec/iter: 0.0469\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.460441 (avg: 0.381453) \tsec/iter: 0.0432\n",
      "Test set (epoch 47): Average loss: 0.7206, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.260213 (avg: 0.260213) \tsec/iter: 0.0509\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.383095 (avg: 0.369543) \tsec/iter: 0.0489\n",
      "Test set (epoch 48): Average loss: 0.8174, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.440657 (avg: 0.440657) \tsec/iter: 0.0489\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.333585 (avg: 0.390163) \tsec/iter: 0.0439\n",
      "Test set (epoch 49): Average loss: 0.6884, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.287484 (avg: 0.287484) \tsec/iter: 0.0509\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.454794 (avg: 0.337976) \tsec/iter: 0.0482\n",
      "Test set (epoch 50): Average loss: 0.6416, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.356488 (avg: 0.356488) \tsec/iter: 0.0549\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.355320 (avg: 0.356457) \tsec/iter: 0.0472\n",
      "Test set (epoch 51): Average loss: 0.6911, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.338761 (avg: 0.338761) \tsec/iter: 0.0549\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.280902 (avg: 0.364188) \tsec/iter: 0.0492\n",
      "Test set (epoch 52): Average loss: 0.7781, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.351865 (avg: 0.351865) \tsec/iter: 0.0469\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.343399 (avg: 0.364074) \tsec/iter: 0.0406\n",
      "Test set (epoch 53): Average loss: 0.6731, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.344756 (avg: 0.344756) \tsec/iter: 0.0459\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.406160 (avg: 0.390437) \tsec/iter: 0.0442\n",
      "Test set (epoch 54): Average loss: 0.6386, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.338221 (avg: 0.338221) \tsec/iter: 0.0429\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.377719 (avg: 0.367717) \tsec/iter: 0.0419\n",
      "Test set (epoch 55): Average loss: 0.6845, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.344729 (avg: 0.344729) \tsec/iter: 0.0519\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.473254 (avg: 0.344068) \tsec/iter: 0.0475\n",
      "Test set (epoch 56): Average loss: 0.7107, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.361006 (avg: 0.361006) \tsec/iter: 0.0469\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.400551 (avg: 0.349558) \tsec/iter: 0.0445\n",
      "Test set (epoch 57): Average loss: 0.6169, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.319636 (avg: 0.319636) \tsec/iter: 0.0529\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.374469 (avg: 0.343898) \tsec/iter: 0.0459\n",
      "Test set (epoch 58): Average loss: 0.6336, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.370798 (avg: 0.370798) \tsec/iter: 0.0429\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.259405 (avg: 0.346903) \tsec/iter: 0.0462\n",
      "Test set (epoch 59): Average loss: 0.6784, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.367932 (avg: 0.367932) \tsec/iter: 0.0539\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.366380 (avg: 0.339766) \tsec/iter: 0.0482\n",
      "Test set (epoch 60): Average loss: 0.6635, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.380850 (avg: 0.380850) \tsec/iter: 0.0529\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.324403 (avg: 0.371031) \tsec/iter: 0.0465\n",
      "Test set (epoch 61): Average loss: 0.6559, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.274079 (avg: 0.274079) \tsec/iter: 0.0549\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.425546 (avg: 0.338235) \tsec/iter: 0.0472\n",
      "Test set (epoch 62): Average loss: 0.6301, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.312001 (avg: 0.312001) \tsec/iter: 0.0559\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.283038 (avg: 0.353466) \tsec/iter: 0.0509\n",
      "Test set (epoch 63): Average loss: 0.5562, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.371680 (avg: 0.371680) \tsec/iter: 0.0549\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.298015 (avg: 0.341829) \tsec/iter: 0.0495\n",
      "Test set (epoch 64): Average loss: 0.6078, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.374075 (avg: 0.374075) \tsec/iter: 0.0419\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.385503 (avg: 0.342181) \tsec/iter: 0.0452\n",
      "Test set (epoch 65): Average loss: 0.5980, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.337772 (avg: 0.337772) \tsec/iter: 0.0519\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.314196 (avg: 0.329972) \tsec/iter: 0.0482\n",
      "Test set (epoch 66): Average loss: 0.5875, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.349825 (avg: 0.349825) \tsec/iter: 0.0459\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.284114 (avg: 0.363942) \tsec/iter: 0.0455\n",
      "Test set (epoch 67): Average loss: 0.4724, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.425897 (avg: 0.425897) \tsec/iter: 0.0499\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.465073 (avg: 0.360760) \tsec/iter: 0.0469\n",
      "Test set (epoch 68): Average loss: 0.6746, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.396749 (avg: 0.396749) \tsec/iter: 0.0559\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.288647 (avg: 0.352774) \tsec/iter: 0.0499\n",
      "Test set (epoch 69): Average loss: 0.5506, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.261681 (avg: 0.261681) \tsec/iter: 0.0588\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.399849 (avg: 0.325678) \tsec/iter: 0.0525\n",
      "Test set (epoch 70): Average loss: 0.5310, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.332366 (avg: 0.332366) \tsec/iter: 0.0529\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.317516 (avg: 0.349788) \tsec/iter: 0.0482\n",
      "Test set (epoch 71): Average loss: 0.5145, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.376095 (avg: 0.376095) \tsec/iter: 0.0509\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.366828 (avg: 0.356263) \tsec/iter: 0.0436\n",
      "Test set (epoch 72): Average loss: 0.4704, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.246505 (avg: 0.246505) \tsec/iter: 0.0529\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.321339 (avg: 0.331715) \tsec/iter: 0.0479\n",
      "Test set (epoch 73): Average loss: 0.5874, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.379553 (avg: 0.379553) \tsec/iter: 0.0539\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.303894 (avg: 0.358032) \tsec/iter: 0.0465\n",
      "Test set (epoch 74): Average loss: 0.4727, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.417744 (avg: 0.417744) \tsec/iter: 0.0489\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.469776 (avg: 0.358926) \tsec/iter: 0.0439\n",
      "Test set (epoch 75): Average loss: 0.4879, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.430130 (avg: 0.430130) \tsec/iter: 0.0509\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.321756 (avg: 0.323730) \tsec/iter: 0.0436\n",
      "Test set (epoch 76): Average loss: 0.5034, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.282200 (avg: 0.282200) \tsec/iter: 0.0499\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.476368 (avg: 0.338542) \tsec/iter: 0.0462\n",
      "Test set (epoch 77): Average loss: 0.5100, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.279453 (avg: 0.279453) \tsec/iter: 0.0539\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.385605 (avg: 0.330041) \tsec/iter: 0.0499\n",
      "Test set (epoch 78): Average loss: 0.5077, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.314197 (avg: 0.314197) \tsec/iter: 0.0489\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.378344 (avg: 0.337580) \tsec/iter: 0.0462\n",
      "Test set (epoch 79): Average loss: 0.4979, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.359802 (avg: 0.359802) \tsec/iter: 0.0389\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.479174 (avg: 0.361501) \tsec/iter: 0.0402\n",
      "Test set (epoch 80): Average loss: 0.4364, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.309045 (avg: 0.309045) \tsec/iter: 0.0429\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.420376 (avg: 0.320412) \tsec/iter: 0.0455\n",
      "Test set (epoch 81): Average loss: 0.5756, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.381615 (avg: 0.381615) \tsec/iter: 0.0529\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.334080 (avg: 0.361730) \tsec/iter: 0.0442\n",
      "Test set (epoch 82): Average loss: 0.4856, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.390469 (avg: 0.390469) \tsec/iter: 0.0449\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.388786 (avg: 0.343188) \tsec/iter: 0.0452\n",
      "Test set (epoch 83): Average loss: 0.4174, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.419415 (avg: 0.419415) \tsec/iter: 0.0559\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.374010 (avg: 0.353791) \tsec/iter: 0.0499\n",
      "Test set (epoch 84): Average loss: 0.4170, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.309336 (avg: 0.309336) \tsec/iter: 0.0489\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.368248 (avg: 0.346343) \tsec/iter: 0.0485\n",
      "Test set (epoch 85): Average loss: 0.4596, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.339265 (avg: 0.339265) \tsec/iter: 0.0559\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.272397 (avg: 0.296218) \tsec/iter: 0.0515\n",
      "Test set (epoch 86): Average loss: 0.4118, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.318878 (avg: 0.318878) \tsec/iter: 0.0479\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.373952 (avg: 0.344687) \tsec/iter: 0.0465\n",
      "Test set (epoch 87): Average loss: 0.4797, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.309830 (avg: 0.309830) \tsec/iter: 0.0409\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.293110 (avg: 0.320064) \tsec/iter: 0.0439\n",
      "Test set (epoch 88): Average loss: 0.3890, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.360281 (avg: 0.360281) \tsec/iter: 0.0499\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.379377 (avg: 0.343547) \tsec/iter: 0.0495\n",
      "Test set (epoch 89): Average loss: 0.4423, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.342986 (avg: 0.342986) \tsec/iter: 0.0529\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.388702 (avg: 0.332480) \tsec/iter: 0.0495\n",
      "Test set (epoch 90): Average loss: 0.4636, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.402925 (avg: 0.402925) \tsec/iter: 0.0429\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.250043 (avg: 0.321224) \tsec/iter: 0.0442\n",
      "Test set (epoch 91): Average loss: 0.4033, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.256126 (avg: 0.256126) \tsec/iter: 0.0429\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.380989 (avg: 0.347903) \tsec/iter: 0.0426\n",
      "Test set (epoch 92): Average loss: 0.4477, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.321679 (avg: 0.321679) \tsec/iter: 0.0559\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.280094 (avg: 0.343708) \tsec/iter: 0.0505\n",
      "Test set (epoch 93): Average loss: 0.6291, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.316040 (avg: 0.316040) \tsec/iter: 0.0529\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.478375 (avg: 0.351057) \tsec/iter: 0.0452\n",
      "Test set (epoch 94): Average loss: 0.4891, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.389960 (avg: 0.389960) \tsec/iter: 0.0539\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.289392 (avg: 0.341936) \tsec/iter: 0.0495\n",
      "Test set (epoch 95): Average loss: 0.4060, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.235926 (avg: 0.235926) \tsec/iter: 0.0469\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.340811 (avg: 0.296852) \tsec/iter: 0.0472\n",
      "Test set (epoch 96): Average loss: 0.4986, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.394894 (avg: 0.394894) \tsec/iter: 0.0598\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.364349 (avg: 0.347453) \tsec/iter: 0.0502\n",
      "Test set (epoch 97): Average loss: 0.4575, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.330811 (avg: 0.330811) \tsec/iter: 0.0549\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.274303 (avg: 0.318125) \tsec/iter: 0.0472\n",
      "Test set (epoch 98): Average loss: 0.4206, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.249535 (avg: 0.249535) \tsec/iter: 0.0429\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.456806 (avg: 0.335167) \tsec/iter: 0.0442\n",
      "Test set (epoch 99): Average loss: 0.5485, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.337720 (avg: 0.337720) \tsec/iter: 0.0469\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.326287 (avg: 0.346858) \tsec/iter: 0.0455\n",
      "Test set (epoch 100): Average loss: 0.3964, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.266652 (avg: 0.266652) \tsec/iter: 0.0539\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.323674 (avg: 0.315953) \tsec/iter: 0.0495\n",
      "Test set (epoch 101): Average loss: 0.5616, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.364647 (avg: 0.364647) \tsec/iter: 0.0519\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.296092 (avg: 0.326039) \tsec/iter: 0.0465\n",
      "Test set (epoch 102): Average loss: 0.4812, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.305136 (avg: 0.305136) \tsec/iter: 0.0598\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.314444 (avg: 0.322452) \tsec/iter: 0.0525\n",
      "Test set (epoch 103): Average loss: 0.4641, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.280223 (avg: 0.280223) \tsec/iter: 0.0568\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.431427 (avg: 0.340076) \tsec/iter: 0.0502\n",
      "Test set (epoch 104): Average loss: 0.4885, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.270109 (avg: 0.270109) \tsec/iter: 0.0409\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.273933 (avg: 0.327692) \tsec/iter: 0.0419\n",
      "Test set (epoch 105): Average loss: 0.4946, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.309643 (avg: 0.309643) \tsec/iter: 0.0429\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.558662 (avg: 0.354253) \tsec/iter: 0.0439\n",
      "Test set (epoch 106): Average loss: 0.6148, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.318252 (avg: 0.318252) \tsec/iter: 0.0499\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.270707 (avg: 0.310830) \tsec/iter: 0.0479\n",
      "Test set (epoch 107): Average loss: 0.3499, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.339656 (avg: 0.339656) \tsec/iter: 0.0509\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.294047 (avg: 0.317910) \tsec/iter: 0.0455\n",
      "Test set (epoch 108): Average loss: 0.4459, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.348821 (avg: 0.348821) \tsec/iter: 0.0489\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.431633 (avg: 0.328359) \tsec/iter: 0.0459\n",
      "Test set (epoch 109): Average loss: 0.4077, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.257148 (avg: 0.257148) \tsec/iter: 0.0559\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.476495 (avg: 0.341853) \tsec/iter: 0.0505\n",
      "Test set (epoch 110): Average loss: 0.4300, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.316942 (avg: 0.316942) \tsec/iter: 0.0489\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.369630 (avg: 0.332633) \tsec/iter: 0.0482\n",
      "Test set (epoch 111): Average loss: 0.4892, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.328564 (avg: 0.328564) \tsec/iter: 0.0598\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.326693 (avg: 0.318310) \tsec/iter: 0.0509\n",
      "Test set (epoch 112): Average loss: 0.5508, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.240145 (avg: 0.240145) \tsec/iter: 0.0489\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.427083 (avg: 0.308521) \tsec/iter: 0.0432\n",
      "Test set (epoch 113): Average loss: 0.5529, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.267354 (avg: 0.267354) \tsec/iter: 0.0529\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.345978 (avg: 0.315109) \tsec/iter: 0.0485\n",
      "Test set (epoch 114): Average loss: 0.3804, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.270840 (avg: 0.270840) \tsec/iter: 0.0529\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.329355 (avg: 0.319367) \tsec/iter: 0.0482\n",
      "Test set (epoch 115): Average loss: 0.5871, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.370110 (avg: 0.370110) \tsec/iter: 0.0539\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.340449 (avg: 0.334926) \tsec/iter: 0.0522\n",
      "Test set (epoch 116): Average loss: 0.4958, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.294616 (avg: 0.294616) \tsec/iter: 0.0539\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.210477 (avg: 0.288569) \tsec/iter: 0.0515\n",
      "Test set (epoch 117): Average loss: 0.5624, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.350407 (avg: 0.350407) \tsec/iter: 0.0469\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.218598 (avg: 0.340989) \tsec/iter: 0.0502\n",
      "Test set (epoch 118): Average loss: 0.5132, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.268289 (avg: 0.268289) \tsec/iter: 0.0479\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.366920 (avg: 0.326877) \tsec/iter: 0.0439\n",
      "Test set (epoch 119): Average loss: 0.4563, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.338238 (avg: 0.338238) \tsec/iter: 0.0549\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.274968 (avg: 0.336399) \tsec/iter: 0.0519\n",
      "Test set (epoch 120): Average loss: 0.3633, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.416261 (avg: 0.416261) \tsec/iter: 0.0538\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.383951 (avg: 0.337251) \tsec/iter: 0.0502\n",
      "Test set (epoch 121): Average loss: 0.5774, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.427731 (avg: 0.427731) \tsec/iter: 0.0509\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.263866 (avg: 0.343254) \tsec/iter: 0.0549\n",
      "Test set (epoch 122): Average loss: 0.4209, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.271640 (avg: 0.271640) \tsec/iter: 0.0578\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.355393 (avg: 0.316334) \tsec/iter: 0.0489\n",
      "Test set (epoch 123): Average loss: 0.4139, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.331243 (avg: 0.331243) \tsec/iter: 0.0409\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.249835 (avg: 0.301507) \tsec/iter: 0.0459\n",
      "Test set (epoch 124): Average loss: 0.4347, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.291114 (avg: 0.291114) \tsec/iter: 0.0479\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.316469 (avg: 0.314611) \tsec/iter: 0.0422\n",
      "Test set (epoch 125): Average loss: 0.3657, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.264655 (avg: 0.264655) \tsec/iter: 0.0469\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.402346 (avg: 0.328625) \tsec/iter: 0.0465\n",
      "Test set (epoch 126): Average loss: 0.4827, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.185262 (avg: 0.185262) \tsec/iter: 0.0539\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.288879 (avg: 0.284258) \tsec/iter: 0.0492\n",
      "Test set (epoch 127): Average loss: 0.3357, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.305328 (avg: 0.305328) \tsec/iter: 0.0479\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.390335 (avg: 0.318214) \tsec/iter: 0.0455\n",
      "Test set (epoch 128): Average loss: 0.3795, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.299925 (avg: 0.299925) \tsec/iter: 0.0509\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.373312 (avg: 0.295052) \tsec/iter: 0.0469\n",
      "Test set (epoch 129): Average loss: 0.4167, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.291499 (avg: 0.291499) \tsec/iter: 0.0469\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.390285 (avg: 0.295097) \tsec/iter: 0.0452\n",
      "Test set (epoch 130): Average loss: 0.3598, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.272831 (avg: 0.272831) \tsec/iter: 0.0499\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.364414 (avg: 0.332002) \tsec/iter: 0.0482\n",
      "Test set (epoch 131): Average loss: 0.3811, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.195999 (avg: 0.195999) \tsec/iter: 0.0509\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.431719 (avg: 0.349865) \tsec/iter: 0.0459\n",
      "Test set (epoch 132): Average loss: 0.5451, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.362593 (avg: 0.362593) \tsec/iter: 0.0469\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.231316 (avg: 0.308110) \tsec/iter: 0.0469\n",
      "Test set (epoch 133): Average loss: 0.2800, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.348908 (avg: 0.348908) \tsec/iter: 0.0529\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.291829 (avg: 0.313127) \tsec/iter: 0.0442\n",
      "Test set (epoch 134): Average loss: 0.5101, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.290301 (avg: 0.290301) \tsec/iter: 0.0568\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.304907 (avg: 0.272087) \tsec/iter: 0.0685\n",
      "Test set (epoch 135): Average loss: 0.4466, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.351558 (avg: 0.351558) \tsec/iter: 0.0648\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.250309 (avg: 0.293595) \tsec/iter: 0.0705\n",
      "Test set (epoch 136): Average loss: 0.3127, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.367992 (avg: 0.367992) \tsec/iter: 0.0648\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.277878 (avg: 0.325867) \tsec/iter: 0.0568\n",
      "Test set (epoch 137): Average loss: 0.2760, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.259408 (avg: 0.259408) \tsec/iter: 0.0558\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.405074 (avg: 0.298948) \tsec/iter: 0.0578\n",
      "Test set (epoch 138): Average loss: 0.3409, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.290548 (avg: 0.290548) \tsec/iter: 0.0559\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.420070 (avg: 0.321819) \tsec/iter: 0.0582\n",
      "Test set (epoch 139): Average loss: 0.4596, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.262842 (avg: 0.262842) \tsec/iter: 0.0888\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.287142 (avg: 0.299753) \tsec/iter: 0.0781\n",
      "Test set (epoch 140): Average loss: 0.3601, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.373773 (avg: 0.373773) \tsec/iter: 0.0588\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.268588 (avg: 0.309713) \tsec/iter: 0.0499\n",
      "Test set (epoch 141): Average loss: 0.3706, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.306545 (avg: 0.306545) \tsec/iter: 0.0549\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.373065 (avg: 0.322805) \tsec/iter: 0.0499\n",
      "Test set (epoch 142): Average loss: 0.3039, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.292395 (avg: 0.292395) \tsec/iter: 0.0558\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.206344 (avg: 0.297901) \tsec/iter: 0.0475\n",
      "Test set (epoch 143): Average loss: 0.4259, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.332498 (avg: 0.332498) \tsec/iter: 0.0439\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.204063 (avg: 0.294835) \tsec/iter: 0.0426\n",
      "Test set (epoch 144): Average loss: 0.2761, Accuracy: 17/18 (94.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.240807 (avg: 0.240807) \tsec/iter: 0.0429\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.322162 (avg: 0.343267) \tsec/iter: 0.0439\n",
      "Test set (epoch 145): Average loss: 0.4164, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.253281 (avg: 0.253281) \tsec/iter: 0.0588\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.306527 (avg: 0.288094) \tsec/iter: 0.0575\n",
      "Test set (epoch 146): Average loss: 0.3581, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.300680 (avg: 0.300680) \tsec/iter: 0.0539\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.304457 (avg: 0.306792) \tsec/iter: 0.0495\n",
      "Test set (epoch 147): Average loss: 0.4376, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.299818 (avg: 0.299818) \tsec/iter: 0.0519\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.299912 (avg: 0.293640) \tsec/iter: 0.0522\n",
      "Test set (epoch 148): Average loss: 0.3469, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.195411 (avg: 0.195411) \tsec/iter: 0.0479\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.372212 (avg: 0.255702) \tsec/iter: 0.0489\n",
      "Test set (epoch 149): Average loss: 0.3435, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.247068 (avg: 0.247068) \tsec/iter: 0.0509\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.353522 (avg: 0.307974) \tsec/iter: 0.0485\n",
      "Test set (epoch 150): Average loss: 0.3730, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.323381 (avg: 0.323381) \tsec/iter: 0.0499\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.318407 (avg: 0.269531) \tsec/iter: 0.0439\n",
      "Test set (epoch 151): Average loss: 0.4656, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.228291 (avg: 0.228291) \tsec/iter: 0.0549\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.257573 (avg: 0.270578) \tsec/iter: 0.0505\n",
      "Test set (epoch 152): Average loss: 0.3140, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.319941 (avg: 0.319941) \tsec/iter: 0.0519\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.192064 (avg: 0.292020) \tsec/iter: 0.0489\n",
      "Test set (epoch 153): Average loss: 0.2461, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.219836 (avg: 0.219836) \tsec/iter: 0.0578\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.233060 (avg: 0.248118) \tsec/iter: 0.0512\n",
      "Test set (epoch 154): Average loss: 0.3056, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.316873 (avg: 0.316873) \tsec/iter: 0.0598\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.159902 (avg: 0.291408) \tsec/iter: 0.0565\n",
      "Test set (epoch 155): Average loss: 0.2381, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.228292 (avg: 0.228292) \tsec/iter: 0.0539\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.453515 (avg: 0.306517) \tsec/iter: 0.0495\n",
      "Test set (epoch 156): Average loss: 0.3722, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.288563 (avg: 0.288563) \tsec/iter: 0.0479\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.363236 (avg: 0.302129) \tsec/iter: 0.0455\n",
      "Test set (epoch 157): Average loss: 0.2101, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.232755 (avg: 0.232755) \tsec/iter: 0.0489\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.415758 (avg: 0.302604) \tsec/iter: 0.0565\n",
      "Test set (epoch 158): Average loss: 0.5204, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.233746 (avg: 0.233746) \tsec/iter: 0.0558\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.422944 (avg: 0.334255) \tsec/iter: 0.0502\n",
      "Test set (epoch 159): Average loss: 0.2392, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.213060 (avg: 0.213060) \tsec/iter: 0.0558\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.346340 (avg: 0.280806) \tsec/iter: 0.0485\n",
      "Test set (epoch 160): Average loss: 0.2451, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.269764 (avg: 0.269764) \tsec/iter: 0.0509\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.184365 (avg: 0.278891) \tsec/iter: 0.0475\n",
      "Test set (epoch 161): Average loss: 0.3291, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.307160 (avg: 0.307160) \tsec/iter: 0.0519\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.315535 (avg: 0.285290) \tsec/iter: 0.0469\n",
      "Test set (epoch 162): Average loss: 0.1729, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.239079 (avg: 0.239079) \tsec/iter: 0.0479\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.216641 (avg: 0.275921) \tsec/iter: 0.0522\n",
      "Test set (epoch 163): Average loss: 0.2707, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.289246 (avg: 0.289246) \tsec/iter: 0.0559\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.288056 (avg: 0.273355) \tsec/iter: 0.0535\n",
      "Test set (epoch 164): Average loss: 0.2399, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.293226 (avg: 0.293226) \tsec/iter: 0.0568\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.235693 (avg: 0.277959) \tsec/iter: 0.0529\n",
      "Test set (epoch 165): Average loss: 0.2759, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.309251 (avg: 0.309251) \tsec/iter: 0.0628\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.373159 (avg: 0.374716) \tsec/iter: 0.0535\n",
      "Test set (epoch 166): Average loss: 0.1616, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.346550 (avg: 0.346550) \tsec/iter: 0.0559\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.254492 (avg: 0.310749) \tsec/iter: 0.0502\n",
      "Test set (epoch 167): Average loss: 0.2849, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.238774 (avg: 0.238774) \tsec/iter: 0.0449\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.297810 (avg: 0.327460) \tsec/iter: 0.0422\n",
      "Test set (epoch 168): Average loss: 0.2066, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.187929 (avg: 0.187929) \tsec/iter: 0.0539\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.233767 (avg: 0.271274) \tsec/iter: 0.0449\n",
      "Test set (epoch 169): Average loss: 0.3148, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.358096 (avg: 0.358096) \tsec/iter: 0.0519\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.256575 (avg: 0.254762) \tsec/iter: 0.0495\n",
      "Test set (epoch 170): Average loss: 0.2038, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.226826 (avg: 0.226826) \tsec/iter: 0.0529\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.278143 (avg: 0.269591) \tsec/iter: 0.0469\n",
      "Test set (epoch 171): Average loss: 0.1955, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.197789 (avg: 0.197789) \tsec/iter: 0.0499\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.341210 (avg: 0.270334) \tsec/iter: 0.0505\n",
      "Test set (epoch 172): Average loss: 0.2315, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.353757 (avg: 0.353757) \tsec/iter: 0.0449\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.347282 (avg: 0.324024) \tsec/iter: 0.0489\n",
      "Test set (epoch 173): Average loss: 0.1377, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.231160 (avg: 0.231160) \tsec/iter: 0.0558\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.415280 (avg: 0.350121) \tsec/iter: 0.0465\n",
      "Test set (epoch 174): Average loss: 0.1666, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.406350 (avg: 0.406350) \tsec/iter: 0.0439\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.211960 (avg: 0.310413) \tsec/iter: 0.0449\n",
      "Test set (epoch 175): Average loss: 0.2043, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.216564 (avg: 0.216564) \tsec/iter: 0.0558\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.403759 (avg: 0.299069) \tsec/iter: 0.0499\n",
      "Test set (epoch 176): Average loss: 0.2038, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.232980 (avg: 0.232980) \tsec/iter: 0.0489\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.395212 (avg: 0.286974) \tsec/iter: 0.0522\n",
      "Test set (epoch 177): Average loss: 0.2675, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.206235 (avg: 0.206235) \tsec/iter: 0.0628\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.208040 (avg: 0.259644) \tsec/iter: 0.0532\n",
      "Test set (epoch 178): Average loss: 0.2182, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.332021 (avg: 0.332021) \tsec/iter: 0.0539\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.266575 (avg: 0.271466) \tsec/iter: 0.0479\n",
      "Test set (epoch 179): Average loss: 0.2055, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.344415 (avg: 0.344415) \tsec/iter: 0.0509\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.407341 (avg: 0.302860) \tsec/iter: 0.0465\n",
      "Test set (epoch 180): Average loss: 0.4295, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.322530 (avg: 0.322530) \tsec/iter: 0.0479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.220935 (avg: 0.293092) \tsec/iter: 0.0469\n",
      "Test set (epoch 181): Average loss: 0.2021, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.319880 (avg: 0.319880) \tsec/iter: 0.0469\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.208692 (avg: 0.258533) \tsec/iter: 0.0439\n",
      "Test set (epoch 182): Average loss: 0.2867, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.371176 (avg: 0.371176) \tsec/iter: 0.0558\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.205547 (avg: 0.266018) \tsec/iter: 0.0499\n",
      "Test set (epoch 183): Average loss: 0.1726, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.291182 (avg: 0.291182) \tsec/iter: 0.0598\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.253668 (avg: 0.291068) \tsec/iter: 0.0539\n",
      "Test set (epoch 184): Average loss: 0.2287, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.189814 (avg: 0.189814) \tsec/iter: 0.0509\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.310520 (avg: 0.257901) \tsec/iter: 0.0502\n",
      "Test set (epoch 185): Average loss: 0.2869, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.280986 (avg: 0.280986) \tsec/iter: 0.0469\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.290538 (avg: 0.258773) \tsec/iter: 0.0416\n",
      "Test set (epoch 186): Average loss: 0.1788, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.365468 (avg: 0.365468) \tsec/iter: 0.0549\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.282150 (avg: 0.325357) \tsec/iter: 0.0429\n",
      "Test set (epoch 187): Average loss: 0.2104, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.197089 (avg: 0.197089) \tsec/iter: 0.0568\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.372143 (avg: 0.264500) \tsec/iter: 0.0529\n",
      "Test set (epoch 188): Average loss: 0.1784, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.243517 (avg: 0.243517) \tsec/iter: 0.0529\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.423834 (avg: 0.273858) \tsec/iter: 0.0489\n",
      "Test set (epoch 189): Average loss: 0.1653, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.229879 (avg: 0.229879) \tsec/iter: 0.0539\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.306259 (avg: 0.293243) \tsec/iter: 0.0472\n",
      "Test set (epoch 190): Average loss: 0.2025, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.306470 (avg: 0.306470) \tsec/iter: 0.0568\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.269550 (avg: 0.272864) \tsec/iter: 0.0485\n",
      "Test set (epoch 191): Average loss: 0.1514, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.265716 (avg: 0.265716) \tsec/iter: 0.0459\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.268620 (avg: 0.299093) \tsec/iter: 0.0485\n",
      "Test set (epoch 192): Average loss: 0.2710, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.295498 (avg: 0.295498) \tsec/iter: 0.0479\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.295398 (avg: 0.278472) \tsec/iter: 0.0442\n",
      "Test set (epoch 193): Average loss: 0.2017, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.314027 (avg: 0.314027) \tsec/iter: 0.0499\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.215097 (avg: 0.309798) \tsec/iter: 0.0432\n",
      "Test set (epoch 194): Average loss: 0.1589, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.294255 (avg: 0.294255) \tsec/iter: 0.0529\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.329059 (avg: 0.276847) \tsec/iter: 0.0485\n",
      "Test set (epoch 195): Average loss: 0.2232, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.193792 (avg: 0.193792) \tsec/iter: 0.0529\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.284497 (avg: 0.258686) \tsec/iter: 0.0475\n",
      "Test set (epoch 196): Average loss: 0.2634, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.277369 (avg: 0.277369) \tsec/iter: 0.0748\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.327153 (avg: 0.291687) \tsec/iter: 0.0628\n",
      "Test set (epoch 197): Average loss: 0.2188, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.241976 (avg: 0.241976) \tsec/iter: 0.0539\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.316760 (avg: 0.262140) \tsec/iter: 0.0509\n",
      "Test set (epoch 198): Average loss: 0.2043, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.317477 (avg: 0.317477) \tsec/iter: 0.0499\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.283196 (avg: 0.261556) \tsec/iter: 0.0426\n",
      "Test set (epoch 199): Average loss: 0.1407, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.221014 (avg: 0.221014) \tsec/iter: 0.0479\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.429989 (avg: 0.263723) \tsec/iter: 0.0426\n",
      "Test set (epoch 200): Average loss: 0.1618, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.234900 (avg: 0.234900) \tsec/iter: 0.0439\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.291359 (avg: 0.300508) \tsec/iter: 0.0452\n",
      "Test set (epoch 201): Average loss: 0.2458, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.198396 (avg: 0.198396) \tsec/iter: 0.0549\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.339219 (avg: 0.280090) \tsec/iter: 0.0475\n",
      "Test set (epoch 202): Average loss: 0.1758, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.201050 (avg: 0.201050) \tsec/iter: 0.0489\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.293905 (avg: 0.256301) \tsec/iter: 0.0469\n",
      "Test set (epoch 203): Average loss: 0.3258, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.352817 (avg: 0.352817) \tsec/iter: 0.0549\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.359043 (avg: 0.339805) \tsec/iter: 0.0492\n",
      "Test set (epoch 204): Average loss: 0.2783, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.201369 (avg: 0.201369) \tsec/iter: 0.0479\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.162930 (avg: 0.237569) \tsec/iter: 0.0452\n",
      "Test set (epoch 205): Average loss: 0.1399, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.199069 (avg: 0.199069) \tsec/iter: 0.0439\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.248418 (avg: 0.257189) \tsec/iter: 0.0452\n",
      "Test set (epoch 206): Average loss: 0.2433, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.179212 (avg: 0.179212) \tsec/iter: 0.0489\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.195968 (avg: 0.242350) \tsec/iter: 0.0409\n",
      "Test set (epoch 207): Average loss: 0.1240, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.305271 (avg: 0.305271) \tsec/iter: 0.0519\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.168510 (avg: 0.277039) \tsec/iter: 0.0489\n",
      "Test set (epoch 208): Average loss: 0.1733, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.280896 (avg: 0.280896) \tsec/iter: 0.0469\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.238662 (avg: 0.287253) \tsec/iter: 0.0455\n",
      "Test set (epoch 209): Average loss: 0.2317, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.351421 (avg: 0.351421) \tsec/iter: 0.0529\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.192483 (avg: 0.309698) \tsec/iter: 0.0462\n",
      "Test set (epoch 210): Average loss: 0.1476, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.355129 (avg: 0.355129) \tsec/iter: 0.0559\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.218428 (avg: 0.272388) \tsec/iter: 0.0465\n",
      "Test set (epoch 211): Average loss: 0.1703, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.252517 (avg: 0.252517) \tsec/iter: 0.0529\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.266621 (avg: 0.270203) \tsec/iter: 0.0452\n",
      "Test set (epoch 212): Average loss: 0.2043, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.352096 (avg: 0.352096) \tsec/iter: 0.0429\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.309052 (avg: 0.284959) \tsec/iter: 0.0426\n",
      "Test set (epoch 213): Average loss: 0.1857, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.225103 (avg: 0.225103) \tsec/iter: 0.0479\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.346633 (avg: 0.262201) \tsec/iter: 0.0445\n",
      "Test set (epoch 214): Average loss: 0.1767, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.204366 (avg: 0.204366) \tsec/iter: 0.0539\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.252005 (avg: 0.333636) \tsec/iter: 0.0485\n",
      "Test set (epoch 215): Average loss: 0.2575, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.351766 (avg: 0.351766) \tsec/iter: 0.0439\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.309987 (avg: 0.325966) \tsec/iter: 0.0475\n",
      "Test set (epoch 216): Average loss: 0.2598, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.271984 (avg: 0.271984) \tsec/iter: 0.0618\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.297921 (avg: 0.288703) \tsec/iter: 0.0525\n",
      "Test set (epoch 217): Average loss: 0.1897, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.320568 (avg: 0.320568) \tsec/iter: 0.0479\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.169324 (avg: 0.290564) \tsec/iter: 0.0449\n",
      "Test set (epoch 218): Average loss: 0.2278, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.218027 (avg: 0.218027) \tsec/iter: 0.0449\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.243397 (avg: 0.257662) \tsec/iter: 0.0422\n",
      "Test set (epoch 219): Average loss: 0.1468, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.312323 (avg: 0.312323) \tsec/iter: 0.0469\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.326513 (avg: 0.288338) \tsec/iter: 0.0459\n",
      "Test set (epoch 220): Average loss: 0.1691, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.333016 (avg: 0.333016) \tsec/iter: 0.0469\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.156503 (avg: 0.246608) \tsec/iter: 0.0509\n",
      "Test set (epoch 221): Average loss: 0.2362, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.225411 (avg: 0.225411) \tsec/iter: 0.0539\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.353797 (avg: 0.295619) \tsec/iter: 0.0485\n",
      "Test set (epoch 222): Average loss: 0.2651, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.304531 (avg: 0.304531) \tsec/iter: 0.0559\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.268646 (avg: 0.286540) \tsec/iter: 0.0625\n",
      "Test set (epoch 223): Average loss: 0.1753, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.285779 (avg: 0.285779) \tsec/iter: 0.0469\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.268575 (avg: 0.272925) \tsec/iter: 0.0459\n",
      "Test set (epoch 224): Average loss: 0.1425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.346894 (avg: 0.346894) \tsec/iter: 0.0539\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.225185 (avg: 0.274291) \tsec/iter: 0.0455\n",
      "Test set (epoch 225): Average loss: 0.1957, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.221844 (avg: 0.221844) \tsec/iter: 0.0549\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.285550 (avg: 0.278983) \tsec/iter: 0.0432\n",
      "Test set (epoch 226): Average loss: 0.2884, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.278997 (avg: 0.278997) \tsec/iter: 0.0519\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.275107 (avg: 0.256217) \tsec/iter: 0.0426\n",
      "Test set (epoch 227): Average loss: 0.2420, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.269660 (avg: 0.269660) \tsec/iter: 0.0499\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.237401 (avg: 0.265116) \tsec/iter: 0.0482\n",
      "Test set (epoch 228): Average loss: 0.1604, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.385186 (avg: 0.385186) \tsec/iter: 0.0728\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.212726 (avg: 0.302087) \tsec/iter: 0.0598\n",
      "Test set (epoch 229): Average loss: 0.1995, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.290466 (avg: 0.290466) \tsec/iter: 0.0489\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.276982 (avg: 0.261722) \tsec/iter: 0.0479\n",
      "Test set (epoch 230): Average loss: 0.1763, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.283447 (avg: 0.283447) \tsec/iter: 0.0558\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.309954 (avg: 0.298944) \tsec/iter: 0.0489\n",
      "Test set (epoch 231): Average loss: 0.2218, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.233761 (avg: 0.233761) \tsec/iter: 0.0489\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.250733 (avg: 0.237928) \tsec/iter: 0.0472\n",
      "Test set (epoch 232): Average loss: 0.1534, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.177338 (avg: 0.177338) \tsec/iter: 0.0519\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.382916 (avg: 0.272220) \tsec/iter: 0.0472\n",
      "Test set (epoch 233): Average loss: 0.1601, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.368143 (avg: 0.368143) \tsec/iter: 0.0499\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.166288 (avg: 0.287183) \tsec/iter: 0.0426\n",
      "Test set (epoch 234): Average loss: 0.2393, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.247365 (avg: 0.247365) \tsec/iter: 0.0519\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.262416 (avg: 0.244909) \tsec/iter: 0.0559\n",
      "Test set (epoch 235): Average loss: 0.1757, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.267506 (avg: 0.267506) \tsec/iter: 0.0559\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.333099 (avg: 0.302986) \tsec/iter: 0.0509\n",
      "Test set (epoch 236): Average loss: 0.2097, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.265627 (avg: 0.265627) \tsec/iter: 0.0549\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.275446 (avg: 0.267678) \tsec/iter: 0.0445\n",
      "Test set (epoch 237): Average loss: 0.1482, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.281728 (avg: 0.281728) \tsec/iter: 0.0509\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.227132 (avg: 0.259472) \tsec/iter: 0.0465\n",
      "Test set (epoch 238): Average loss: 0.2077, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.396642 (avg: 0.396642) \tsec/iter: 0.0509\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.402623 (avg: 0.302156) \tsec/iter: 0.0462\n",
      "Test set (epoch 239): Average loss: 0.1826, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.265251 (avg: 0.265251) \tsec/iter: 0.0479\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.240260 (avg: 0.244149) \tsec/iter: 0.0472\n",
      "Test set (epoch 240): Average loss: 0.1618, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.240607 (avg: 0.240607) \tsec/iter: 0.0489\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.224491 (avg: 0.249293) \tsec/iter: 0.0475\n",
      "Test set (epoch 241): Average loss: 0.1569, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.264609 (avg: 0.264609) \tsec/iter: 0.0738\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.377406 (avg: 0.243444) \tsec/iter: 0.0605\n",
      "Test set (epoch 242): Average loss: 0.1528, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.156829 (avg: 0.156829) \tsec/iter: 0.0489\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.200768 (avg: 0.213620) \tsec/iter: 0.0469\n",
      "Test set (epoch 243): Average loss: 0.1618, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.230831 (avg: 0.230831) \tsec/iter: 0.0449\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.381797 (avg: 0.260616) \tsec/iter: 0.0455\n",
      "Test set (epoch 244): Average loss: 0.2007, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.215536 (avg: 0.215536) \tsec/iter: 0.0539\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.257155 (avg: 0.284773) \tsec/iter: 0.0436\n",
      "Test set (epoch 245): Average loss: 0.1559, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.234935 (avg: 0.234935) \tsec/iter: 0.0429\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.284578 (avg: 0.275211) \tsec/iter: 0.0409\n",
      "Test set (epoch 246): Average loss: 0.1683, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.312928 (avg: 0.312928) \tsec/iter: 0.0519\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.197124 (avg: 0.253541) \tsec/iter: 0.0482\n",
      "Test set (epoch 247): Average loss: 0.1506, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.239799 (avg: 0.239799) \tsec/iter: 0.0429\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.163520 (avg: 0.269678) \tsec/iter: 0.0465\n",
      "Test set (epoch 248): Average loss: 0.1547, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.202547 (avg: 0.202547) \tsec/iter: 0.0568\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.216656 (avg: 0.231801) \tsec/iter: 0.0515\n",
      "Test set (epoch 249): Average loss: 0.1440, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.258287 (avg: 0.258287) \tsec/iter: 0.0519\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.181940 (avg: 0.267223) \tsec/iter: 0.0462\n",
      "Test set (epoch 250): Average loss: 0.1552, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.226037 (avg: 0.226037) \tsec/iter: 0.0578\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.245228 (avg: 0.250362) \tsec/iter: 0.0562\n",
      "Test set (epoch 251): Average loss: 0.1787, Accuracy: 17/18 (94.44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.275091 (avg: 0.275091) \tsec/iter: 0.0578\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.305009 (avg: 0.268744) \tsec/iter: 0.0512\n",
      "Test set (epoch 252): Average loss: 0.2932, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.314504 (avg: 0.314504) \tsec/iter: 0.0588\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.163681 (avg: 0.267050) \tsec/iter: 0.0475\n",
      "Test set (epoch 253): Average loss: 0.1475, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.300828 (avg: 0.300828) \tsec/iter: 0.0469\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.190914 (avg: 0.242443) \tsec/iter: 0.0485\n",
      "Test set (epoch 254): Average loss: 0.1400, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.252040 (avg: 0.252040) \tsec/iter: 0.0519\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.246271 (avg: 0.241898) \tsec/iter: 0.0509\n",
      "Test set (epoch 255): Average loss: 0.2552, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.204160 (avg: 0.204160) \tsec/iter: 0.0479\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.190370 (avg: 0.217081) \tsec/iter: 0.0472\n",
      "Test set (epoch 256): Average loss: 0.2248, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.160953 (avg: 0.160953) \tsec/iter: 0.0459\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.188222 (avg: 0.275849) \tsec/iter: 0.0482\n",
      "Test set (epoch 257): Average loss: 0.2464, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.252004 (avg: 0.252004) \tsec/iter: 0.0539\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.212866 (avg: 0.214649) \tsec/iter: 0.0482\n",
      "Test set (epoch 258): Average loss: 0.2459, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.181299 (avg: 0.181299) \tsec/iter: 0.0499\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.293827 (avg: 0.235177) \tsec/iter: 0.0442\n",
      "Test set (epoch 259): Average loss: 0.2244, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.253537 (avg: 0.253537) \tsec/iter: 0.0499\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.183490 (avg: 0.264899) \tsec/iter: 0.0489\n",
      "Test set (epoch 260): Average loss: 0.1128, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.199589 (avg: 0.199589) \tsec/iter: 0.0748\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.203663 (avg: 0.223940) \tsec/iter: 0.0585\n",
      "Test set (epoch 261): Average loss: 0.2386, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.223255 (avg: 0.223255) \tsec/iter: 0.0559\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.330885 (avg: 0.234344) \tsec/iter: 0.0509\n",
      "Test set (epoch 262): Average loss: 0.1626, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.271646 (avg: 0.271646) \tsec/iter: 0.0439\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.292188 (avg: 0.296982) \tsec/iter: 0.0426\n",
      "Test set (epoch 263): Average loss: 0.1387, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.387496 (avg: 0.387496) \tsec/iter: 0.0439\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.185914 (avg: 0.276830) \tsec/iter: 0.0442\n",
      "Test set (epoch 264): Average loss: 0.2565, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.242658 (avg: 0.242658) \tsec/iter: 0.0479\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.319838 (avg: 0.263844) \tsec/iter: 0.0465\n",
      "Test set (epoch 265): Average loss: 0.1652, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.252873 (avg: 0.252873) \tsec/iter: 0.0399\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.183654 (avg: 0.211987) \tsec/iter: 0.0412\n",
      "Test set (epoch 266): Average loss: 0.1384, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.285348 (avg: 0.285348) \tsec/iter: 0.0598\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.299567 (avg: 0.279990) \tsec/iter: 0.0539\n",
      "Test set (epoch 267): Average loss: 0.0862, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.274532 (avg: 0.274532) \tsec/iter: 0.0578\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.204647 (avg: 0.227316) \tsec/iter: 0.0532\n",
      "Test set (epoch 268): Average loss: 0.1689, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.278555 (avg: 0.278555) \tsec/iter: 0.0539\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.222558 (avg: 0.250033) \tsec/iter: 0.0489\n",
      "Test set (epoch 269): Average loss: 0.2144, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.187502 (avg: 0.187502) \tsec/iter: 0.0519\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.160490 (avg: 0.232629) \tsec/iter: 0.0479\n",
      "Test set (epoch 270): Average loss: 0.1017, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.192838 (avg: 0.192838) \tsec/iter: 0.0469\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.498399 (avg: 0.303352) \tsec/iter: 0.0442\n",
      "Test set (epoch 271): Average loss: 0.1541, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.241509 (avg: 0.241509) \tsec/iter: 0.0519\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.208956 (avg: 0.278406) \tsec/iter: 0.0482\n",
      "Test set (epoch 272): Average loss: 0.2602, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.254502 (avg: 0.254502) \tsec/iter: 0.0489\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.278525 (avg: 0.269472) \tsec/iter: 0.0485\n",
      "Test set (epoch 273): Average loss: 0.2276, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.213393 (avg: 0.213393) \tsec/iter: 0.0568\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.195614 (avg: 0.236383) \tsec/iter: 0.0545\n",
      "Test set (epoch 274): Average loss: 0.2245, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.376296 (avg: 0.376296) \tsec/iter: 0.0439\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.251099 (avg: 0.280933) \tsec/iter: 0.0422\n",
      "Test set (epoch 275): Average loss: 0.0941, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.266192 (avg: 0.266192) \tsec/iter: 0.0539\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.276909 (avg: 0.262666) \tsec/iter: 0.0479\n",
      "Test set (epoch 276): Average loss: 0.1370, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.234162 (avg: 0.234162) \tsec/iter: 0.0489\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.327476 (avg: 0.244794) \tsec/iter: 0.0452\n",
      "Test set (epoch 277): Average loss: 0.1629, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.187262 (avg: 0.187262) \tsec/iter: 0.0529\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.185898 (avg: 0.238122) \tsec/iter: 0.0452\n",
      "Test set (epoch 278): Average loss: 0.2038, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.259892 (avg: 0.259892) \tsec/iter: 0.0459\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.222552 (avg: 0.231600) \tsec/iter: 0.0442\n",
      "Test set (epoch 279): Average loss: 0.2225, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.301974 (avg: 0.301974) \tsec/iter: 0.0549\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.265520 (avg: 0.261354) \tsec/iter: 0.0645\n",
      "Test set (epoch 280): Average loss: 0.1539, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.373105 (avg: 0.373105) \tsec/iter: 0.0678\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.367462 (avg: 0.297276) \tsec/iter: 0.0512\n",
      "Test set (epoch 281): Average loss: 0.1586, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.204101 (avg: 0.204101) \tsec/iter: 0.0539\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.215045 (avg: 0.276447) \tsec/iter: 0.0482\n",
      "Test set (epoch 282): Average loss: 0.2714, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.247686 (avg: 0.247686) \tsec/iter: 0.0529\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.276698 (avg: 0.243979) \tsec/iter: 0.0435\n",
      "Test set (epoch 283): Average loss: 0.2264, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.294209 (avg: 0.294209) \tsec/iter: 0.0519\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.308553 (avg: 0.283880) \tsec/iter: 0.0479\n",
      "Test set (epoch 284): Average loss: 0.1410, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.256167 (avg: 0.256167) \tsec/iter: 0.0459\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.269649 (avg: 0.264006) \tsec/iter: 0.0449\n",
      "Test set (epoch 285): Average loss: 0.2044, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.276131 (avg: 0.276131) \tsec/iter: 0.0519\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.222552 (avg: 0.273159) \tsec/iter: 0.0482\n",
      "Test set (epoch 286): Average loss: 0.1670, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.312401 (avg: 0.312401) \tsec/iter: 0.0568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.317464 (avg: 0.286152) \tsec/iter: 0.0608\n",
      "Test set (epoch 287): Average loss: 0.2110, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.228565 (avg: 0.228565) \tsec/iter: 0.0568\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.274731 (avg: 0.227057) \tsec/iter: 0.0482\n",
      "Test set (epoch 288): Average loss: 0.2166, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.255137 (avg: 0.255137) \tsec/iter: 0.0499\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.399134 (avg: 0.286527) \tsec/iter: 0.0479\n",
      "Test set (epoch 289): Average loss: 0.1789, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.276692 (avg: 0.276692) \tsec/iter: 0.0469\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.290193 (avg: 0.251959) \tsec/iter: 0.0429\n",
      "Test set (epoch 290): Average loss: 0.1373, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.283866 (avg: 0.283866) \tsec/iter: 0.0549\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.274627 (avg: 0.279207) \tsec/iter: 0.0472\n",
      "Test set (epoch 291): Average loss: 0.2253, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.219428 (avg: 0.219428) \tsec/iter: 0.0429\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.307849 (avg: 0.237541) \tsec/iter: 0.0445\n",
      "Test set (epoch 292): Average loss: 0.2148, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.127540 (avg: 0.127540) \tsec/iter: 0.0529\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.228786 (avg: 0.210371) \tsec/iter: 0.0519\n",
      "Test set (epoch 293): Average loss: 0.2095, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.221932 (avg: 0.221932) \tsec/iter: 0.0549\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.360014 (avg: 0.236164) \tsec/iter: 0.0568\n",
      "Test set (epoch 294): Average loss: 0.2154, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.259135 (avg: 0.259135) \tsec/iter: 0.0549\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.207288 (avg: 0.237081) \tsec/iter: 0.0459\n",
      "Test set (epoch 295): Average loss: 0.1969, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.264007 (avg: 0.264007) \tsec/iter: 0.0519\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.122566 (avg: 0.268654) \tsec/iter: 0.0479\n",
      "Test set (epoch 296): Average loss: 0.1905, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.213849 (avg: 0.213849) \tsec/iter: 0.0529\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.230022 (avg: 0.235936) \tsec/iter: 0.0462\n",
      "Test set (epoch 297): Average loss: 0.2197, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.268299 (avg: 0.268299) \tsec/iter: 0.0459\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.305243 (avg: 0.242666) \tsec/iter: 0.0445\n",
      "Test set (epoch 298): Average loss: 0.1988, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.319845 (avg: 0.319845) \tsec/iter: 0.0549\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.250592 (avg: 0.253828) \tsec/iter: 0.0522\n",
      "Test set (epoch 299): Average loss: 0.1969, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.337639 (avg: 0.337639) \tsec/iter: 0.0549\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.323428 (avg: 0.265963) \tsec/iter: 0.0475\n",
      "Test set (epoch 300): Average loss: 0.1648, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.284167 (avg: 0.284167) \tsec/iter: 0.0499\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.321533 (avg: 0.238194) \tsec/iter: 0.0459\n",
      "Test set (epoch 301): Average loss: 0.1511, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.123498 (avg: 0.123498) \tsec/iter: 0.0409\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.386751 (avg: 0.252063) \tsec/iter: 0.0399\n",
      "Test set (epoch 302): Average loss: 0.1722, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.306212 (avg: 0.306212) \tsec/iter: 0.0489\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.186653 (avg: 0.250012) \tsec/iter: 0.0455\n",
      "Test set (epoch 303): Average loss: 0.2039, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.310745 (avg: 0.310745) \tsec/iter: 0.0449\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.256444 (avg: 0.282146) \tsec/iter: 0.0406\n",
      "Test set (epoch 304): Average loss: 0.1673, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.315622 (avg: 0.315622) \tsec/iter: 0.0399\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.254243 (avg: 0.255806) \tsec/iter: 0.0412\n",
      "Test set (epoch 305): Average loss: 0.1566, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.227690 (avg: 0.227690) \tsec/iter: 0.0598\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.215669 (avg: 0.248115) \tsec/iter: 0.0585\n",
      "Test set (epoch 306): Average loss: 0.1566, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.300488 (avg: 0.300488) \tsec/iter: 0.0519\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.195468 (avg: 0.238662) \tsec/iter: 0.0459\n",
      "Test set (epoch 307): Average loss: 0.1922, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.295270 (avg: 0.295270) \tsec/iter: 0.0529\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.141676 (avg: 0.242496) \tsec/iter: 0.0492\n",
      "Test set (epoch 308): Average loss: 0.1402, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.191854 (avg: 0.191854) \tsec/iter: 0.0539\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.288605 (avg: 0.248789) \tsec/iter: 0.0489\n",
      "Test set (epoch 309): Average loss: 0.1253, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.272920 (avg: 0.272920) \tsec/iter: 0.0549\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.307066 (avg: 0.250826) \tsec/iter: 0.0485\n",
      "Test set (epoch 310): Average loss: 0.1557, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.144505 (avg: 0.144505) \tsec/iter: 0.0529\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.265971 (avg: 0.246545) \tsec/iter: 0.0452\n",
      "Test set (epoch 311): Average loss: 0.3547, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.330389 (avg: 0.330389) \tsec/iter: 0.0549\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.198966 (avg: 0.264947) \tsec/iter: 0.0529\n",
      "Test set (epoch 312): Average loss: 0.1895, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.255809 (avg: 0.255809) \tsec/iter: 0.0608\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.198250 (avg: 0.247073) \tsec/iter: 0.0515\n",
      "Test set (epoch 313): Average loss: 0.2772, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.218362 (avg: 0.218362) \tsec/iter: 0.0519\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.266612 (avg: 0.278110) \tsec/iter: 0.0505\n",
      "Test set (epoch 314): Average loss: 0.1632, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.248420 (avg: 0.248420) \tsec/iter: 0.0489\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.295195 (avg: 0.251998) \tsec/iter: 0.0472\n",
      "Test set (epoch 315): Average loss: 0.1414, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.159825 (avg: 0.159825) \tsec/iter: 0.0489\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.298242 (avg: 0.245777) \tsec/iter: 0.0449\n",
      "Test set (epoch 316): Average loss: 0.3672, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.394180 (avg: 0.394180) \tsec/iter: 0.0598\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.388678 (avg: 0.316330) \tsec/iter: 0.0499\n",
      "Test set (epoch 317): Average loss: 0.2321, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.210276 (avg: 0.210276) \tsec/iter: 0.0479\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.320262 (avg: 0.310326) \tsec/iter: 0.0575\n",
      "Test set (epoch 318): Average loss: 0.2398, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.291549 (avg: 0.291549) \tsec/iter: 0.0568\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.252356 (avg: 0.238920) \tsec/iter: 0.0519\n",
      "Test set (epoch 319): Average loss: 0.1608, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.353489 (avg: 0.353489) \tsec/iter: 0.0539\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.258084 (avg: 0.280054) \tsec/iter: 0.0469\n",
      "Test set (epoch 320): Average loss: 0.1309, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.178854 (avg: 0.178854) \tsec/iter: 0.0499\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.310262 (avg: 0.233288) \tsec/iter: 0.0492\n",
      "Test set (epoch 321): Average loss: 0.1344, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.158062 (avg: 0.158062) \tsec/iter: 0.0559\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.224244 (avg: 0.245701) \tsec/iter: 0.0489\n",
      "Test set (epoch 322): Average loss: 0.1431, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.219519 (avg: 0.219519) \tsec/iter: 0.0439\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.378083 (avg: 0.248717) \tsec/iter: 0.0465\n",
      "Test set (epoch 323): Average loss: 0.1636, Accuracy: 18/18 (100.00%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.323526 (avg: 0.323526) \tsec/iter: 0.0469\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.221660 (avg: 0.275123) \tsec/iter: 0.0602\n",
      "Test set (epoch 324): Average loss: 0.1385, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.294318 (avg: 0.294318) \tsec/iter: 0.0628\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.191411 (avg: 0.237471) \tsec/iter: 0.0542\n",
      "Test set (epoch 325): Average loss: 0.1759, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.178757 (avg: 0.178757) \tsec/iter: 0.0559\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.240101 (avg: 0.231913) \tsec/iter: 0.0505\n",
      "Test set (epoch 326): Average loss: 0.1875, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.291281 (avg: 0.291281) \tsec/iter: 0.0529\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.134900 (avg: 0.236945) \tsec/iter: 0.0502\n",
      "Test set (epoch 327): Average loss: 0.2054, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.298968 (avg: 0.298968) \tsec/iter: 0.0568\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.227223 (avg: 0.271415) \tsec/iter: 0.0495\n",
      "Test set (epoch 328): Average loss: 0.2042, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.234158 (avg: 0.234158) \tsec/iter: 0.0559\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.221234 (avg: 0.236802) \tsec/iter: 0.0472\n",
      "Test set (epoch 329): Average loss: 0.1460, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.209480 (avg: 0.209480) \tsec/iter: 0.0449\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.218756 (avg: 0.200527) \tsec/iter: 0.0459\n",
      "Test set (epoch 330): Average loss: 0.1751, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.192697 (avg: 0.192697) \tsec/iter: 0.0578\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.298247 (avg: 0.220692) \tsec/iter: 0.0495\n",
      "Test set (epoch 331): Average loss: 0.1844, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.288594 (avg: 0.288594) \tsec/iter: 0.0449\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.286543 (avg: 0.251622) \tsec/iter: 0.0455\n",
      "Test set (epoch 332): Average loss: 0.2357, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.195557 (avg: 0.195557) \tsec/iter: 0.0519\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.284105 (avg: 0.243275) \tsec/iter: 0.0499\n",
      "Test set (epoch 333): Average loss: 0.2417, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.236357 (avg: 0.236357) \tsec/iter: 0.0539\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.305256 (avg: 0.246343) \tsec/iter: 0.0469\n",
      "Test set (epoch 334): Average loss: 0.1558, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.352486 (avg: 0.352486) \tsec/iter: 0.0499\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.221814 (avg: 0.292123) \tsec/iter: 0.0459\n",
      "Test set (epoch 335): Average loss: 0.2938, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.183816 (avg: 0.183816) \tsec/iter: 0.0738\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.278652 (avg: 0.224727) \tsec/iter: 0.0555\n",
      "Test set (epoch 336): Average loss: 0.2559, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.235859 (avg: 0.235859) \tsec/iter: 0.0539\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.247332 (avg: 0.238933) \tsec/iter: 0.0552\n",
      "Test set (epoch 337): Average loss: 0.1640, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.148708 (avg: 0.148708) \tsec/iter: 0.0499\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.249908 (avg: 0.235156) \tsec/iter: 0.0475\n",
      "Test set (epoch 338): Average loss: 0.2184, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.209580 (avg: 0.209580) \tsec/iter: 0.0559\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.248395 (avg: 0.235096) \tsec/iter: 0.0549\n",
      "Test set (epoch 339): Average loss: 0.1579, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.227353 (avg: 0.227353) \tsec/iter: 0.0588\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.242276 (avg: 0.206463) \tsec/iter: 0.0502\n",
      "Test set (epoch 340): Average loss: 0.2579, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.195886 (avg: 0.195886) \tsec/iter: 0.0419\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.147145 (avg: 0.222410) \tsec/iter: 0.0422\n",
      "Test set (epoch 341): Average loss: 0.2935, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.333863 (avg: 0.333863) \tsec/iter: 0.0449\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.250787 (avg: 0.253407) \tsec/iter: 0.0479\n",
      "Test set (epoch 342): Average loss: 0.1558, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.314137 (avg: 0.314137) \tsec/iter: 0.0608\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.253454 (avg: 0.252452) \tsec/iter: 0.0529\n",
      "Test set (epoch 343): Average loss: 0.1195, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.308476 (avg: 0.308476) \tsec/iter: 0.0539\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.300244 (avg: 0.273876) \tsec/iter: 0.0482\n",
      "Test set (epoch 344): Average loss: 0.1674, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.153629 (avg: 0.153629) \tsec/iter: 0.0529\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.315415 (avg: 0.223578) \tsec/iter: 0.0495\n",
      "Test set (epoch 345): Average loss: 0.1920, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.214903 (avg: 0.214903) \tsec/iter: 0.0549\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.315765 (avg: 0.213421) \tsec/iter: 0.0489\n",
      "Test set (epoch 346): Average loss: 0.1294, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.249200 (avg: 0.249200) \tsec/iter: 0.0558\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.150075 (avg: 0.248435) \tsec/iter: 0.0495\n",
      "Test set (epoch 347): Average loss: 0.2203, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.209510 (avg: 0.209510) \tsec/iter: 0.0449\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.243754 (avg: 0.229942) \tsec/iter: 0.0459\n",
      "Test set (epoch 348): Average loss: 0.1517, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.323989 (avg: 0.323989) \tsec/iter: 0.1007\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.137891 (avg: 0.230849) \tsec/iter: 0.0814\n",
      "Test set (epoch 349): Average loss: 0.2253, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.147059 (avg: 0.147059) \tsec/iter: 0.0479\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.221581 (avg: 0.214806) \tsec/iter: 0.0449\n",
      "Test set (epoch 350): Average loss: 0.1958, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.222817 (avg: 0.222817) \tsec/iter: 0.0549\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.244246 (avg: 0.269761) \tsec/iter: 0.0482\n",
      "Test set (epoch 351): Average loss: 0.2406, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.177196 (avg: 0.177196) \tsec/iter: 0.0529\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.324708 (avg: 0.207951) \tsec/iter: 0.0462\n",
      "Test set (epoch 352): Average loss: 0.2290, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.231694 (avg: 0.231694) \tsec/iter: 0.0479\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.212985 (avg: 0.198888) \tsec/iter: 0.0436\n",
      "Test set (epoch 353): Average loss: 0.1623, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.254704 (avg: 0.254704) \tsec/iter: 0.0539\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.149108 (avg: 0.292070) \tsec/iter: 0.0479\n",
      "Test set (epoch 354): Average loss: 0.2599, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.318861 (avg: 0.318861) \tsec/iter: 0.0449\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.197803 (avg: 0.230205) \tsec/iter: 0.0479\n",
      "Test set (epoch 355): Average loss: 0.2105, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.189820 (avg: 0.189820) \tsec/iter: 0.0539\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.219202 (avg: 0.202346) \tsec/iter: 0.0469\n",
      "Test set (epoch 356): Average loss: 0.1251, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.241526 (avg: 0.241526) \tsec/iter: 0.0499\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.264608 (avg: 0.266858) \tsec/iter: 0.0449\n",
      "Test set (epoch 357): Average loss: 0.1650, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.271932 (avg: 0.271932) \tsec/iter: 0.0469\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.330944 (avg: 0.232656) \tsec/iter: 0.0429\n",
      "Test set (epoch 358): Average loss: 0.2197, Accuracy: 17/18 (94.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.259180 (avg: 0.259180) \tsec/iter: 0.0469\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.200523 (avg: 0.231574) \tsec/iter: 0.0389\n",
      "Test set (epoch 359): Average loss: 0.2956, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.219823 (avg: 0.219823) \tsec/iter: 0.0459\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.225397 (avg: 0.236142) \tsec/iter: 0.0459\n",
      "Test set (epoch 360): Average loss: 0.2068, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.154195 (avg: 0.154195) \tsec/iter: 0.0539\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.292213 (avg: 0.221758) \tsec/iter: 0.0432\n",
      "Test set (epoch 361): Average loss: 0.1420, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.273169 (avg: 0.273169) \tsec/iter: 0.0479\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.154200 (avg: 0.260197) \tsec/iter: 0.0442\n",
      "Test set (epoch 362): Average loss: 0.2469, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.219453 (avg: 0.219453) \tsec/iter: 0.0499\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.327923 (avg: 0.250761) \tsec/iter: 0.0449\n",
      "Test set (epoch 363): Average loss: 0.2252, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.240442 (avg: 0.240442) \tsec/iter: 0.0419\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.176799 (avg: 0.217762) \tsec/iter: 0.0392\n",
      "Test set (epoch 364): Average loss: 0.2414, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.220976 (avg: 0.220976) \tsec/iter: 0.0419\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.122582 (avg: 0.206106) \tsec/iter: 0.0409\n",
      "Test set (epoch 365): Average loss: 0.1612, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.186902 (avg: 0.186902) \tsec/iter: 0.0409\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.228200 (avg: 0.210162) \tsec/iter: 0.0382\n",
      "Test set (epoch 366): Average loss: 0.3406, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.297255 (avg: 0.297255) \tsec/iter: 0.0429\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.287581 (avg: 0.258797) \tsec/iter: 0.0382\n",
      "Test set (epoch 367): Average loss: 0.1193, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.169444 (avg: 0.169444) \tsec/iter: 0.0409\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.308200 (avg: 0.179317) \tsec/iter: 0.0386\n",
      "Test set (epoch 368): Average loss: 0.2012, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.296627 (avg: 0.296627) \tsec/iter: 0.0379\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.257776 (avg: 0.262535) \tsec/iter: 0.0382\n",
      "Test set (epoch 369): Average loss: 0.2692, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.296108 (avg: 0.296108) \tsec/iter: 0.0499\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.110579 (avg: 0.259607) \tsec/iter: 0.0455\n",
      "Test set (epoch 370): Average loss: 0.1549, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.288890 (avg: 0.288890) \tsec/iter: 0.0479\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.521201 (avg: 0.290972) \tsec/iter: 0.0445\n",
      "Test set (epoch 371): Average loss: 0.2945, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.238454 (avg: 0.238454) \tsec/iter: 0.0439\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.402345 (avg: 0.255537) \tsec/iter: 0.0379\n",
      "Test set (epoch 372): Average loss: 0.1255, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.246076 (avg: 0.246076) \tsec/iter: 0.0469\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.356648 (avg: 0.268585) \tsec/iter: 0.0396\n",
      "Test set (epoch 373): Average loss: 0.2541, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.343290 (avg: 0.343290) \tsec/iter: 0.0379\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.150857 (avg: 0.258065) \tsec/iter: 0.0369\n",
      "Test set (epoch 374): Average loss: 0.1344, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.279164 (avg: 0.279164) \tsec/iter: 0.0429\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.278481 (avg: 0.251600) \tsec/iter: 0.0422\n",
      "Test set (epoch 375): Average loss: 0.2084, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.204613 (avg: 0.204613) \tsec/iter: 0.0459\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.240520 (avg: 0.226796) \tsec/iter: 0.0419\n",
      "Test set (epoch 376): Average loss: 0.3356, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.267601 (avg: 0.267601) \tsec/iter: 0.0399\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.182604 (avg: 0.228586) \tsec/iter: 0.0429\n",
      "Test set (epoch 377): Average loss: 0.3026, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.220995 (avg: 0.220995) \tsec/iter: 0.0559\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.259680 (avg: 0.215071) \tsec/iter: 0.0432\n",
      "Test set (epoch 378): Average loss: 0.4217, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.217464 (avg: 0.217464) \tsec/iter: 0.0369\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.278710 (avg: 0.233997) \tsec/iter: 0.0349\n",
      "Test set (epoch 379): Average loss: 0.1830, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.129166 (avg: 0.129166) \tsec/iter: 0.0319\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.300405 (avg: 0.215791) \tsec/iter: 0.0303\n",
      "Test set (epoch 380): Average loss: 0.2724, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.200241 (avg: 0.200241) \tsec/iter: 0.0329\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.208780 (avg: 0.233901) \tsec/iter: 0.0329\n",
      "Test set (epoch 381): Average loss: 0.1960, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.173720 (avg: 0.173720) \tsec/iter: 0.0359\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.168878 (avg: 0.201686) \tsec/iter: 0.0336\n",
      "Test set (epoch 382): Average loss: 0.2563, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.237158 (avg: 0.237158) \tsec/iter: 0.0429\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.313620 (avg: 0.236152) \tsec/iter: 0.0346\n",
      "Test set (epoch 383): Average loss: 0.1369, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.151416 (avg: 0.151416) \tsec/iter: 0.0309\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.325532 (avg: 0.241589) \tsec/iter: 0.0303\n",
      "Test set (epoch 384): Average loss: 0.2469, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.191451 (avg: 0.191451) \tsec/iter: 0.0359\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.170142 (avg: 0.223133) \tsec/iter: 0.0309\n",
      "Test set (epoch 385): Average loss: 0.3632, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.150526 (avg: 0.150526) \tsec/iter: 0.0409\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.206233 (avg: 0.220251) \tsec/iter: 0.0372\n",
      "Test set (epoch 386): Average loss: 0.3813, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.221993 (avg: 0.221993) \tsec/iter: 0.0389\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.346514 (avg: 0.251698) \tsec/iter: 0.0349\n",
      "Test set (epoch 387): Average loss: 0.5009, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.339189 (avg: 0.339189) \tsec/iter: 0.0389\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.258654 (avg: 0.250917) \tsec/iter: 0.0329\n",
      "Test set (epoch 388): Average loss: 0.2215, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.258064 (avg: 0.258064) \tsec/iter: 0.0349\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.262251 (avg: 0.228092) \tsec/iter: 0.0306\n",
      "Test set (epoch 389): Average loss: 0.2736, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.214639 (avg: 0.214639) \tsec/iter: 0.0349\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.207927 (avg: 0.234408) \tsec/iter: 0.0303\n",
      "Test set (epoch 390): Average loss: 0.2093, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.361431 (avg: 0.361431) \tsec/iter: 0.0329\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.226005 (avg: 0.246493) \tsec/iter: 0.0309\n",
      "Test set (epoch 391): Average loss: 0.2178, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.230605 (avg: 0.230605) \tsec/iter: 0.0319\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.246930 (avg: 0.218390) \tsec/iter: 0.0309\n",
      "Test set (epoch 392): Average loss: 0.3119, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.221309 (avg: 0.221309) \tsec/iter: 0.0359\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.073635 (avg: 0.207722) \tsec/iter: 0.0329\n",
      "Test set (epoch 393): Average loss: 0.1764, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.246111 (avg: 0.246111) \tsec/iter: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.185484 (avg: 0.204503) \tsec/iter: 0.0326\n",
      "Test set (epoch 394): Average loss: 0.2935, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.254309 (avg: 0.254309) \tsec/iter: 0.0309\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.200390 (avg: 0.215011) \tsec/iter: 0.0299\n",
      "Test set (epoch 395): Average loss: 0.2514, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.265666 (avg: 0.265666) \tsec/iter: 0.0389\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.261148 (avg: 0.285760) \tsec/iter: 0.0376\n",
      "Test set (epoch 396): Average loss: 0.2871, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.183951 (avg: 0.183951) \tsec/iter: 0.0419\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.111468 (avg: 0.212904) \tsec/iter: 0.0336\n",
      "Test set (epoch 397): Average loss: 0.2357, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.299365 (avg: 0.299365) \tsec/iter: 0.0399\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.170440 (avg: 0.217548) \tsec/iter: 0.0332\n",
      "Test set (epoch 398): Average loss: 0.3156, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.138673 (avg: 0.138673) \tsec/iter: 0.0379\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.303389 (avg: 0.205554) \tsec/iter: 0.0366\n",
      "Test set (epoch 399): Average loss: 0.2403, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.186449 (avg: 0.186449) \tsec/iter: 0.0389\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.151289 (avg: 0.220305) \tsec/iter: 0.0332\n",
      "Test set (epoch 400): Average loss: 0.2565, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.188751 (avg: 0.188751) \tsec/iter: 0.0359\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.190456 (avg: 0.230961) \tsec/iter: 0.0326\n",
      "Test set (epoch 401): Average loss: 0.2870, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.150694 (avg: 0.150694) \tsec/iter: 0.0339\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.351815 (avg: 0.230192) \tsec/iter: 0.0342\n",
      "Test set (epoch 402): Average loss: 0.2333, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.158149 (avg: 0.158149) \tsec/iter: 0.0319\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.238688 (avg: 0.193097) \tsec/iter: 0.0309\n",
      "Test set (epoch 403): Average loss: 0.4621, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.304896 (avg: 0.304896) \tsec/iter: 0.0359\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.349379 (avg: 0.242687) \tsec/iter: 0.0359\n",
      "Test set (epoch 404): Average loss: 0.1698, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.241592 (avg: 0.241592) \tsec/iter: 0.0429\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.228826 (avg: 0.198067) \tsec/iter: 0.0376\n",
      "Test set (epoch 405): Average loss: 0.4094, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.258757 (avg: 0.258757) \tsec/iter: 0.0309\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.129435 (avg: 0.211530) \tsec/iter: 0.0279\n",
      "Test set (epoch 406): Average loss: 0.3242, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.127496 (avg: 0.127496) \tsec/iter: 0.0349\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.283521 (avg: 0.195340) \tsec/iter: 0.0293\n",
      "Test set (epoch 407): Average loss: 0.3431, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.234495 (avg: 0.234495) \tsec/iter: 0.0359\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.153559 (avg: 0.224300) \tsec/iter: 0.0326\n",
      "Test set (epoch 408): Average loss: 0.2425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.196062 (avg: 0.196062) \tsec/iter: 0.0349\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.209138 (avg: 0.245787) \tsec/iter: 0.0319\n",
      "Test set (epoch 409): Average loss: 0.2316, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.219379 (avg: 0.219379) \tsec/iter: 0.0429\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.324415 (avg: 0.235112) \tsec/iter: 0.0342\n",
      "Test set (epoch 410): Average loss: 0.3326, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.199719 (avg: 0.199719) \tsec/iter: 0.0339\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.445005 (avg: 0.261042) \tsec/iter: 0.0296\n",
      "Test set (epoch 411): Average loss: 0.3237, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.175832 (avg: 0.175832) \tsec/iter: 0.0299\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.211086 (avg: 0.228133) \tsec/iter: 0.0283\n",
      "Test set (epoch 412): Average loss: 0.1664, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.213424 (avg: 0.213424) \tsec/iter: 0.0359\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.318199 (avg: 0.244382) \tsec/iter: 0.0309\n",
      "Test set (epoch 413): Average loss: 0.1684, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.209570 (avg: 0.209570) \tsec/iter: 0.0349\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.229117 (avg: 0.255580) \tsec/iter: 0.0339\n",
      "Test set (epoch 414): Average loss: 0.1886, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.222809 (avg: 0.222809) \tsec/iter: 0.0419\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.203554 (avg: 0.221784) \tsec/iter: 0.0352\n",
      "Test set (epoch 415): Average loss: 0.2158, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.168087 (avg: 0.168087) \tsec/iter: 0.0329\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.251324 (avg: 0.201412) \tsec/iter: 0.0319\n",
      "Test set (epoch 416): Average loss: 0.3072, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.230834 (avg: 0.230834) \tsec/iter: 0.0339\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.172980 (avg: 0.230062) \tsec/iter: 0.0312\n",
      "Test set (epoch 417): Average loss: 0.1627, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.185072 (avg: 0.185072) \tsec/iter: 0.0309\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.299971 (avg: 0.240198) \tsec/iter: 0.0306\n",
      "Test set (epoch 418): Average loss: 0.1502, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.196804 (avg: 0.196804) \tsec/iter: 0.0339\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.212776 (avg: 0.199871) \tsec/iter: 0.0303\n",
      "Test set (epoch 419): Average loss: 0.2284, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.242524 (avg: 0.242524) \tsec/iter: 0.0299\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.256185 (avg: 0.274431) \tsec/iter: 0.0286\n",
      "Test set (epoch 420): Average loss: 0.1500, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.243188 (avg: 0.243188) \tsec/iter: 0.0379\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.249049 (avg: 0.230828) \tsec/iter: 0.0379\n",
      "Test set (epoch 421): Average loss: 0.1539, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.248419 (avg: 0.248419) \tsec/iter: 0.0339\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.321304 (avg: 0.218975) \tsec/iter: 0.0309\n",
      "Test set (epoch 422): Average loss: 0.2354, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.230377 (avg: 0.230377) \tsec/iter: 0.0339\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.403856 (avg: 0.245478) \tsec/iter: 0.0349\n",
      "Test set (epoch 423): Average loss: 0.3798, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.132867 (avg: 0.132867) \tsec/iter: 0.0409\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.264562 (avg: 0.228080) \tsec/iter: 0.0376\n",
      "Test set (epoch 424): Average loss: 0.0967, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.106863 (avg: 0.106863) \tsec/iter: 0.0319\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.347991 (avg: 0.192717) \tsec/iter: 0.0309\n",
      "Test set (epoch 425): Average loss: 0.3717, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.183275 (avg: 0.183275) \tsec/iter: 0.0329\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.272095 (avg: 0.200421) \tsec/iter: 0.0332\n",
      "Test set (epoch 426): Average loss: 0.1392, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.224038 (avg: 0.224038) \tsec/iter: 0.0399\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.167362 (avg: 0.190374) \tsec/iter: 0.0319\n",
      "Test set (epoch 427): Average loss: 0.2411, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.281311 (avg: 0.281311) \tsec/iter: 0.0329\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.163929 (avg: 0.221302) \tsec/iter: 0.0306\n",
      "Test set (epoch 428): Average loss: 0.1141, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.189655 (avg: 0.189655) \tsec/iter: 0.0329\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.142190 (avg: 0.225920) \tsec/iter: 0.0316\n",
      "Test set (epoch 429): Average loss: 0.1372, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.191601 (avg: 0.191601) \tsec/iter: 0.0309\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.283243 (avg: 0.227393) \tsec/iter: 0.0283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 430): Average loss: 0.3612, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.168772 (avg: 0.168772) \tsec/iter: 0.0329\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.303670 (avg: 0.222651) \tsec/iter: 0.0303\n",
      "Test set (epoch 431): Average loss: 0.1844, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.281642 (avg: 0.281642) \tsec/iter: 0.0339\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.176639 (avg: 0.229625) \tsec/iter: 0.0319\n",
      "Test set (epoch 432): Average loss: 0.2218, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.134193 (avg: 0.134193) \tsec/iter: 0.0319\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.276595 (avg: 0.189504) \tsec/iter: 0.0339\n",
      "Test set (epoch 433): Average loss: 0.2745, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.201865 (avg: 0.201865) \tsec/iter: 0.0429\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.180379 (avg: 0.208584) \tsec/iter: 0.0362\n",
      "Test set (epoch 434): Average loss: 0.3519, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.206856 (avg: 0.206856) \tsec/iter: 0.0319\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.255819 (avg: 0.245765) \tsec/iter: 0.0312\n",
      "Test set (epoch 435): Average loss: 0.2455, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.154211 (avg: 0.154211) \tsec/iter: 0.0339\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.284323 (avg: 0.212889) \tsec/iter: 0.0322\n",
      "Test set (epoch 436): Average loss: 0.4142, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.280764 (avg: 0.280764) \tsec/iter: 0.0379\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.117064 (avg: 0.226757) \tsec/iter: 0.0352\n",
      "Test set (epoch 437): Average loss: 0.1833, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.242753 (avg: 0.242753) \tsec/iter: 0.0359\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.262034 (avg: 0.226048) \tsec/iter: 0.0329\n",
      "Test set (epoch 438): Average loss: 0.1599, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.229147 (avg: 0.229147) \tsec/iter: 0.0369\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.301419 (avg: 0.273731) \tsec/iter: 0.0319\n",
      "Test set (epoch 439): Average loss: 0.4310, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.309754 (avg: 0.309754) \tsec/iter: 0.0349\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.229467 (avg: 0.260848) \tsec/iter: 0.0342\n",
      "Test set (epoch 440): Average loss: 0.2776, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.210265 (avg: 0.210265) \tsec/iter: 0.0309\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.175036 (avg: 0.207749) \tsec/iter: 0.0309\n",
      "Test set (epoch 441): Average loss: 0.2395, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.214779 (avg: 0.214779) \tsec/iter: 0.0379\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.133597 (avg: 0.207368) \tsec/iter: 0.0366\n",
      "Test set (epoch 442): Average loss: 0.2465, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.271774 (avg: 0.271774) \tsec/iter: 0.0389\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.478985 (avg: 0.274701) \tsec/iter: 0.0376\n",
      "Test set (epoch 443): Average loss: 0.2926, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.199456 (avg: 0.199456) \tsec/iter: 0.0369\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.191437 (avg: 0.209340) \tsec/iter: 0.0316\n",
      "Test set (epoch 444): Average loss: 0.1842, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.172932 (avg: 0.172932) \tsec/iter: 0.0399\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.168877 (avg: 0.215696) \tsec/iter: 0.0332\n",
      "Test set (epoch 445): Average loss: 0.2584, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.179585 (avg: 0.179585) \tsec/iter: 0.0369\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.110997 (avg: 0.260106) \tsec/iter: 0.0322\n",
      "Test set (epoch 446): Average loss: 0.2410, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.263238 (avg: 0.263238) \tsec/iter: 0.0319\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.127995 (avg: 0.261601) \tsec/iter: 0.0303\n",
      "Test set (epoch 447): Average loss: 0.2412, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.212382 (avg: 0.212382) \tsec/iter: 0.0319\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.312021 (avg: 0.254760) \tsec/iter: 0.0293\n",
      "Test set (epoch 448): Average loss: 0.3625, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.187377 (avg: 0.187377) \tsec/iter: 0.0359\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.228994 (avg: 0.231874) \tsec/iter: 0.0329\n",
      "Test set (epoch 449): Average loss: 0.1782, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.280028 (avg: 0.280028) \tsec/iter: 0.0379\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.218522 (avg: 0.235850) \tsec/iter: 0.0336\n",
      "Test set (epoch 450): Average loss: 0.2285, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.113463 (avg: 0.113463) \tsec/iter: 0.0319\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.322831 (avg: 0.207487) \tsec/iter: 0.0336\n",
      "Test set (epoch 451): Average loss: 0.1515, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.219939 (avg: 0.219939) \tsec/iter: 0.0429\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.180607 (avg: 0.197673) \tsec/iter: 0.0386\n",
      "Test set (epoch 452): Average loss: 0.2852, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.155747 (avg: 0.155747) \tsec/iter: 0.0349\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.393561 (avg: 0.197013) \tsec/iter: 0.0326\n",
      "Test set (epoch 453): Average loss: 0.3430, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.343095 (avg: 0.343095) \tsec/iter: 0.0349\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.211705 (avg: 0.256281) \tsec/iter: 0.0303\n",
      "Test set (epoch 454): Average loss: 0.1880, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.236570 (avg: 0.236570) \tsec/iter: 0.0329\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.189708 (avg: 0.198488) \tsec/iter: 0.0299\n",
      "Test set (epoch 455): Average loss: 0.1698, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.291980 (avg: 0.291980) \tsec/iter: 0.0359\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.258361 (avg: 0.231920) \tsec/iter: 0.0326\n",
      "Test set (epoch 456): Average loss: 0.1516, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.228464 (avg: 0.228464) \tsec/iter: 0.0339\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.229999 (avg: 0.243196) \tsec/iter: 0.0309\n",
      "Test set (epoch 457): Average loss: 0.2278, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.212334 (avg: 0.212334) \tsec/iter: 0.0339\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.192216 (avg: 0.226027) \tsec/iter: 0.0296\n",
      "Test set (epoch 458): Average loss: 0.1516, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.249314 (avg: 0.249314) \tsec/iter: 0.0349\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.185332 (avg: 0.250327) \tsec/iter: 0.0309\n",
      "Test set (epoch 459): Average loss: 0.2437, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.160388 (avg: 0.160388) \tsec/iter: 0.0339\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.178592 (avg: 0.203191) \tsec/iter: 0.0306\n",
      "Test set (epoch 460): Average loss: 0.3084, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.160763 (avg: 0.160763) \tsec/iter: 0.0389\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.237878 (avg: 0.186835) \tsec/iter: 0.0359\n",
      "Test set (epoch 461): Average loss: 0.2566, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.195437 (avg: 0.195437) \tsec/iter: 0.0399\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.154427 (avg: 0.196368) \tsec/iter: 0.0372\n",
      "Test set (epoch 462): Average loss: 0.2105, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.184966 (avg: 0.184966) \tsec/iter: 0.0379\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.277992 (avg: 0.219577) \tsec/iter: 0.0349\n",
      "Test set (epoch 463): Average loss: 0.2670, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.155385 (avg: 0.155385) \tsec/iter: 0.0349\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.193685 (avg: 0.283039) \tsec/iter: 0.0316\n",
      "Test set (epoch 464): Average loss: 0.2161, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.155468 (avg: 0.155468) \tsec/iter: 0.0339\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.188057 (avg: 0.196649) \tsec/iter: 0.0329\n",
      "Test set (epoch 465): Average loss: 0.2048, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.211566 (avg: 0.211566) \tsec/iter: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.153049 (avg: 0.195785) \tsec/iter: 0.0322\n",
      "Test set (epoch 466): Average loss: 0.1886, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.247570 (avg: 0.247570) \tsec/iter: 0.0329\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.195822 (avg: 0.197656) \tsec/iter: 0.0313\n",
      "Test set (epoch 467): Average loss: 0.2201, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.274834 (avg: 0.274834) \tsec/iter: 0.0389\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.172406 (avg: 0.200877) \tsec/iter: 0.0312\n",
      "Test set (epoch 468): Average loss: 0.2335, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.169596 (avg: 0.169596) \tsec/iter: 0.0329\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.303946 (avg: 0.224668) \tsec/iter: 0.0319\n",
      "Test set (epoch 469): Average loss: 0.1310, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.269220 (avg: 0.269220) \tsec/iter: 0.0319\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.216203 (avg: 0.250649) \tsec/iter: 0.0322\n",
      "Test set (epoch 470): Average loss: 0.2050, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.303757 (avg: 0.303757) \tsec/iter: 0.0409\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.168732 (avg: 0.230552) \tsec/iter: 0.0382\n",
      "Test set (epoch 471): Average loss: 0.2936, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.163549 (avg: 0.163549) \tsec/iter: 0.0349\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.330861 (avg: 0.259025) \tsec/iter: 0.0312\n",
      "Test set (epoch 472): Average loss: 0.1425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.132787 (avg: 0.132787) \tsec/iter: 0.0349\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.328953 (avg: 0.285173) \tsec/iter: 0.0303\n",
      "Test set (epoch 473): Average loss: 0.2044, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.207593 (avg: 0.207593) \tsec/iter: 0.0419\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.206104 (avg: 0.220718) \tsec/iter: 0.0445\n",
      "Test set (epoch 474): Average loss: 0.2172, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.239992 (avg: 0.239992) \tsec/iter: 0.0369\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.265901 (avg: 0.232717) \tsec/iter: 0.0332\n",
      "Test set (epoch 475): Average loss: 0.2270, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.162872 (avg: 0.162872) \tsec/iter: 0.0339\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.208519 (avg: 0.218924) \tsec/iter: 0.0329\n",
      "Test set (epoch 476): Average loss: 0.2675, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.233688 (avg: 0.233688) \tsec/iter: 0.0319\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.285700 (avg: 0.272013) \tsec/iter: 0.0316\n",
      "Test set (epoch 477): Average loss: 0.3389, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.236174 (avg: 0.236174) \tsec/iter: 0.0329\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.193789 (avg: 0.249801) \tsec/iter: 0.0319\n",
      "Test set (epoch 478): Average loss: 0.1979, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.153120 (avg: 0.153120) \tsec/iter: 0.0329\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.265583 (avg: 0.229768) \tsec/iter: 0.0316\n",
      "Test set (epoch 479): Average loss: 0.2069, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.271009 (avg: 0.271009) \tsec/iter: 0.0389\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.189236 (avg: 0.240741) \tsec/iter: 0.0356\n",
      "Test set (epoch 480): Average loss: 0.1313, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.193119 (avg: 0.193119) \tsec/iter: 0.0399\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.246671 (avg: 0.191651) \tsec/iter: 0.0322\n",
      "Test set (epoch 481): Average loss: 0.2063, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.173986 (avg: 0.173986) \tsec/iter: 0.0439\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.202899 (avg: 0.203333) \tsec/iter: 0.0346\n",
      "Test set (epoch 482): Average loss: 0.2233, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.199520 (avg: 0.199520) \tsec/iter: 0.0349\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.269357 (avg: 0.235529) \tsec/iter: 0.0322\n",
      "Test set (epoch 483): Average loss: 0.2472, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.309399 (avg: 0.309399) \tsec/iter: 0.0339\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.315064 (avg: 0.267755) \tsec/iter: 0.0312\n",
      "Test set (epoch 484): Average loss: 0.4425, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.265012 (avg: 0.265012) \tsec/iter: 0.0319\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.195934 (avg: 0.250504) \tsec/iter: 0.0306\n",
      "Test set (epoch 485): Average loss: 0.2167, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.145634 (avg: 0.145634) \tsec/iter: 0.0319\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.269171 (avg: 0.203745) \tsec/iter: 0.0289\n",
      "Test set (epoch 486): Average loss: 0.1875, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.178881 (avg: 0.178881) \tsec/iter: 0.0359\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.204203 (avg: 0.209227) \tsec/iter: 0.0336\n",
      "Test set (epoch 487): Average loss: 0.2308, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.246330 (avg: 0.246330) \tsec/iter: 0.0429\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.182728 (avg: 0.233307) \tsec/iter: 0.0342\n",
      "Test set (epoch 488): Average loss: 0.2451, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.235603 (avg: 0.235603) \tsec/iter: 0.0359\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.149139 (avg: 0.235344) \tsec/iter: 0.0356\n",
      "Test set (epoch 489): Average loss: 0.1960, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.271066 (avg: 0.271066) \tsec/iter: 0.0429\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.143872 (avg: 0.217596) \tsec/iter: 0.0359\n",
      "Test set (epoch 490): Average loss: 0.2154, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.259292 (avg: 0.259292) \tsec/iter: 0.0349\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.205159 (avg: 0.223865) \tsec/iter: 0.0329\n",
      "Test set (epoch 491): Average loss: 0.1326, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.212027 (avg: 0.212027) \tsec/iter: 0.0339\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.218573 (avg: 0.202995) \tsec/iter: 0.0322\n",
      "Test set (epoch 492): Average loss: 0.1535, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.195053 (avg: 0.195053) \tsec/iter: 0.0339\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.198930 (avg: 0.253518) \tsec/iter: 0.0303\n",
      "Test set (epoch 493): Average loss: 0.2371, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.178902 (avg: 0.178902) \tsec/iter: 0.0389\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.346832 (avg: 0.222317) \tsec/iter: 0.0309\n",
      "Test set (epoch 494): Average loss: 0.1438, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.162206 (avg: 0.162206) \tsec/iter: 0.0369\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.147733 (avg: 0.188525) \tsec/iter: 0.0312\n",
      "Test set (epoch 495): Average loss: 0.1989, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.141881 (avg: 0.141881) \tsec/iter: 0.0379\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.188597 (avg: 0.210427) \tsec/iter: 0.0309\n",
      "Test set (epoch 496): Average loss: 0.1943, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.235026 (avg: 0.235026) \tsec/iter: 0.0309\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.180354 (avg: 0.197690) \tsec/iter: 0.0319\n",
      "Test set (epoch 497): Average loss: 0.2104, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.220867 (avg: 0.220867) \tsec/iter: 0.0329\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.310364 (avg: 0.236068) \tsec/iter: 0.0322\n",
      "Test set (epoch 498): Average loss: 0.2116, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.135877 (avg: 0.135877) \tsec/iter: 0.0419\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.367850 (avg: 0.221346) \tsec/iter: 0.0389\n",
      "Test set (epoch 499): Average loss: 0.3168, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "\n",
      "FOLD 2\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 2.918303 (avg: 2.918303) \tsec/iter: 0.0389\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 4.188375 (avg: 4.754787) \tsec/iter: 0.0359\n",
      "Test set (epoch 0): Average loss: 1.0275, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 1.300104 (avg: 1.300104) \tsec/iter: 0.0389\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.504709 (avg: 1.182301) \tsec/iter: 0.0326\n",
      "Test set (epoch 1): Average loss: 0.4115, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.821759 (avg: 0.821759) \tsec/iter: 0.0359\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.665247 (avg: 0.825589) \tsec/iter: 0.0329\n",
      "Test set (epoch 2): Average loss: 1.2375, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.766435 (avg: 0.766435) \tsec/iter: 0.0319\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.992114 (avg: 0.691107) \tsec/iter: 0.0286\n",
      "Test set (epoch 3): Average loss: 1.4093, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.503763 (avg: 0.503763) \tsec/iter: 0.0429\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.365193 (avg: 0.527587) \tsec/iter: 0.0346\n",
      "Test set (epoch 4): Average loss: 0.9575, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.424967 (avg: 0.424967) \tsec/iter: 0.0329\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.606678 (avg: 0.476367) \tsec/iter: 0.0309\n",
      "Test set (epoch 5): Average loss: 1.4543, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.597691 (avg: 0.597691) \tsec/iter: 0.0339\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.752597 (avg: 0.660734) \tsec/iter: 0.0319\n",
      "Test set (epoch 6): Average loss: 1.8769, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.745083 (avg: 0.745083) \tsec/iter: 0.0399\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.750238 (avg: 0.653254) \tsec/iter: 0.0332\n",
      "Test set (epoch 7): Average loss: 1.4304, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.384730 (avg: 0.384730) \tsec/iter: 0.0349\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.304905 (avg: 0.389396) \tsec/iter: 0.0356\n",
      "Test set (epoch 8): Average loss: 1.2315, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.409331 (avg: 0.409331) \tsec/iter: 0.0409\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.500666 (avg: 0.439800) \tsec/iter: 0.0326\n",
      "Test set (epoch 9): Average loss: 1.4588, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.530612 (avg: 0.530612) \tsec/iter: 0.0339\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.499709 (avg: 0.451872) \tsec/iter: 0.0319\n",
      "Test set (epoch 10): Average loss: 1.1374, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.554269 (avg: 0.554269) \tsec/iter: 0.0379\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.409344 (avg: 0.446905) \tsec/iter: 0.0322\n",
      "Test set (epoch 11): Average loss: 0.9893, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.463260 (avg: 0.463260) \tsec/iter: 0.0359\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.333432 (avg: 0.399663) \tsec/iter: 0.0306\n",
      "Test set (epoch 12): Average loss: 1.0570, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.425033 (avg: 0.425033) \tsec/iter: 0.0379\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.560495 (avg: 0.467775) \tsec/iter: 0.0326\n",
      "Test set (epoch 13): Average loss: 1.0448, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.375839 (avg: 0.375839) \tsec/iter: 0.0369\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.546408 (avg: 0.427059) \tsec/iter: 0.0342\n",
      "Test set (epoch 14): Average loss: 0.9306, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.423727 (avg: 0.423727) \tsec/iter: 0.0359\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.291935 (avg: 0.393672) \tsec/iter: 0.0309\n",
      "Test set (epoch 15): Average loss: 0.6369, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.616838 (avg: 0.616838) \tsec/iter: 0.0339\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.346977 (avg: 0.461180) \tsec/iter: 0.0299\n",
      "Test set (epoch 16): Average loss: 0.8845, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.318234 (avg: 0.318234) \tsec/iter: 0.0349\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.456181 (avg: 0.363306) \tsec/iter: 0.0356\n",
      "Test set (epoch 17): Average loss: 1.1580, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.478835 (avg: 0.478835) \tsec/iter: 0.0439\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.455584 (avg: 0.467220) \tsec/iter: 0.0379\n",
      "Test set (epoch 18): Average loss: 0.9399, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.453068 (avg: 0.453068) \tsec/iter: 0.0409\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.226515 (avg: 0.358625) \tsec/iter: 0.0359\n",
      "Test set (epoch 19): Average loss: 0.9144, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.413715 (avg: 0.413715) \tsec/iter: 0.0369\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.414202 (avg: 0.374555) \tsec/iter: 0.0303\n",
      "Test set (epoch 20): Average loss: 0.9072, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.378513 (avg: 0.378513) \tsec/iter: 0.0319\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.372033 (avg: 0.359114) \tsec/iter: 0.0306\n",
      "Test set (epoch 21): Average loss: 0.9883, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.458279 (avg: 0.458279) \tsec/iter: 0.0359\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.374651 (avg: 0.387869) \tsec/iter: 0.0319\n",
      "Test set (epoch 22): Average loss: 0.9759, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.340360 (avg: 0.340360) \tsec/iter: 0.0349\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.481751 (avg: 0.373893) \tsec/iter: 0.0319\n",
      "Test set (epoch 23): Average loss: 0.9356, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.344888 (avg: 0.344888) \tsec/iter: 0.0389\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.323583 (avg: 0.383691) \tsec/iter: 0.0342\n",
      "Test set (epoch 24): Average loss: 0.8994, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.359945 (avg: 0.359945) \tsec/iter: 0.0339\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.334365 (avg: 0.350317) \tsec/iter: 0.0296\n",
      "Test set (epoch 25): Average loss: 0.9216, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.329871 (avg: 0.329871) \tsec/iter: 0.0379\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.489432 (avg: 0.375280) \tsec/iter: 0.0342\n",
      "Test set (epoch 26): Average loss: 1.0788, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.410914 (avg: 0.410914) \tsec/iter: 0.0429\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.382993 (avg: 0.363262) \tsec/iter: 0.0359\n",
      "Test set (epoch 27): Average loss: 0.9191, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.311588 (avg: 0.311588) \tsec/iter: 0.0339\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.456702 (avg: 0.394450) \tsec/iter: 0.0322\n",
      "Test set (epoch 28): Average loss: 0.9837, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.510705 (avg: 0.510705) \tsec/iter: 0.0349\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.310610 (avg: 0.385817) \tsec/iter: 0.0312\n",
      "Test set (epoch 29): Average loss: 0.9643, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.410816 (avg: 0.410816) \tsec/iter: 0.0319\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.265428 (avg: 0.366443) \tsec/iter: 0.0289\n",
      "Test set (epoch 30): Average loss: 0.9500, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.398951 (avg: 0.398951) \tsec/iter: 0.0369\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.239144 (avg: 0.348846) \tsec/iter: 0.0319\n",
      "Test set (epoch 31): Average loss: 0.9097, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.411998 (avg: 0.411998) \tsec/iter: 0.0319\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.353576 (avg: 0.370636) \tsec/iter: 0.0303\n",
      "Test set (epoch 32): Average loss: 0.8946, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.379166 (avg: 0.379166) \tsec/iter: 0.0359\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.498032 (avg: 0.366403) \tsec/iter: 0.0319\n",
      "Test set (epoch 33): Average loss: 0.9159, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.441962 (avg: 0.441962) \tsec/iter: 0.0409\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.302925 (avg: 0.370110) \tsec/iter: 0.0342\n",
      "Test set (epoch 34): Average loss: 1.0431, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.313209 (avg: 0.313209) \tsec/iter: 0.0369\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.490448 (avg: 0.391986) \tsec/iter: 0.0309\n",
      "Test set (epoch 35): Average loss: 0.9931, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.339950 (avg: 0.339950) \tsec/iter: 0.0339\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.361320 (avg: 0.361271) \tsec/iter: 0.0346\n",
      "Test set (epoch 36): Average loss: 1.0004, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.356760 (avg: 0.356760) \tsec/iter: 0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.425044 (avg: 0.359331) \tsec/iter: 0.0372\n",
      "Test set (epoch 37): Average loss: 0.9503, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.497597 (avg: 0.497597) \tsec/iter: 0.0409\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.239211 (avg: 0.388363) \tsec/iter: 0.0336\n",
      "Test set (epoch 38): Average loss: 0.9126, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.320627 (avg: 0.320627) \tsec/iter: 0.0359\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.390194 (avg: 0.366099) \tsec/iter: 0.0349\n",
      "Test set (epoch 39): Average loss: 1.0356, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.324451 (avg: 0.324451) \tsec/iter: 0.0319\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.398293 (avg: 0.364021) \tsec/iter: 0.0299\n",
      "Test set (epoch 40): Average loss: 1.0024, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.381043 (avg: 0.381043) \tsec/iter: 0.0329\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.368564 (avg: 0.362566) \tsec/iter: 0.0296\n",
      "Test set (epoch 41): Average loss: 1.0110, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.405847 (avg: 0.405847) \tsec/iter: 0.0319\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.283915 (avg: 0.350568) \tsec/iter: 0.0332\n",
      "Test set (epoch 42): Average loss: 0.9585, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.384320 (avg: 0.384320) \tsec/iter: 0.0379\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.323296 (avg: 0.378441) \tsec/iter: 0.0322\n",
      "Test set (epoch 43): Average loss: 1.0014, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.338443 (avg: 0.338443) \tsec/iter: 0.0379\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.358091 (avg: 0.363212) \tsec/iter: 0.0299\n",
      "Test set (epoch 44): Average loss: 0.9834, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.371799 (avg: 0.371799) \tsec/iter: 0.0379\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.384463 (avg: 0.355054) \tsec/iter: 0.0332\n",
      "Test set (epoch 45): Average loss: 0.9622, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.279307 (avg: 0.279307) \tsec/iter: 0.0409\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.481832 (avg: 0.382052) \tsec/iter: 0.0366\n",
      "Test set (epoch 46): Average loss: 1.0730, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.393975 (avg: 0.393975) \tsec/iter: 0.0329\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.330644 (avg: 0.361941) \tsec/iter: 0.0322\n",
      "Test set (epoch 47): Average loss: 1.0936, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.312881 (avg: 0.312881) \tsec/iter: 0.0359\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.374551 (avg: 0.347042) \tsec/iter: 0.0319\n",
      "Test set (epoch 48): Average loss: 0.9821, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.366107 (avg: 0.366107) \tsec/iter: 0.0319\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.391141 (avg: 0.383661) \tsec/iter: 0.0296\n",
      "Test set (epoch 49): Average loss: 1.0536, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.308303 (avg: 0.308303) \tsec/iter: 0.0369\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.446722 (avg: 0.350941) \tsec/iter: 0.0319\n",
      "Test set (epoch 50): Average loss: 0.9999, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.351476 (avg: 0.351476) \tsec/iter: 0.0379\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.383658 (avg: 0.361674) \tsec/iter: 0.0372\n",
      "Test set (epoch 51): Average loss: 1.0457, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.287818 (avg: 0.287818) \tsec/iter: 0.0319\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.461194 (avg: 0.343318) \tsec/iter: 0.0306\n",
      "Test set (epoch 52): Average loss: 1.0706, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.323486 (avg: 0.323486) \tsec/iter: 0.0329\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.404108 (avg: 0.338001) \tsec/iter: 0.0329\n",
      "Test set (epoch 53): Average loss: 0.9403, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.357701 (avg: 0.357701) \tsec/iter: 0.0349\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.339267 (avg: 0.348784) \tsec/iter: 0.0322\n",
      "Test set (epoch 54): Average loss: 0.8747, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.398848 (avg: 0.398848) \tsec/iter: 0.0379\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.376962 (avg: 0.366539) \tsec/iter: 0.0356\n",
      "Test set (epoch 55): Average loss: 0.8622, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.336975 (avg: 0.336975) \tsec/iter: 0.0379\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.413588 (avg: 0.337175) \tsec/iter: 0.0312\n",
      "Test set (epoch 56): Average loss: 0.7861, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.322597 (avg: 0.322597) \tsec/iter: 0.0289\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.366832 (avg: 0.321285) \tsec/iter: 0.0306\n",
      "Test set (epoch 57): Average loss: 0.8695, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.292765 (avg: 0.292765) \tsec/iter: 0.0349\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.283147 (avg: 0.356315) \tsec/iter: 0.0319\n",
      "Test set (epoch 58): Average loss: 0.8955, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.356380 (avg: 0.356380) \tsec/iter: 0.0409\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.393045 (avg: 0.350754) \tsec/iter: 0.0336\n",
      "Test set (epoch 59): Average loss: 0.8956, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.359648 (avg: 0.359648) \tsec/iter: 0.0349\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.329117 (avg: 0.337138) \tsec/iter: 0.0312\n",
      "Test set (epoch 60): Average loss: 0.9602, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.315674 (avg: 0.315674) \tsec/iter: 0.0349\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.244862 (avg: 0.312453) \tsec/iter: 0.0309\n",
      "Test set (epoch 61): Average loss: 0.8548, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.396692 (avg: 0.396692) \tsec/iter: 0.0309\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.402762 (avg: 0.340526) \tsec/iter: 0.0293\n",
      "Test set (epoch 62): Average loss: 0.8352, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.313333 (avg: 0.313333) \tsec/iter: 0.0369\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.372108 (avg: 0.361609) \tsec/iter: 0.0319\n",
      "Test set (epoch 63): Average loss: 0.8900, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.252976 (avg: 0.252976) \tsec/iter: 0.0389\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.461988 (avg: 0.371798) \tsec/iter: 0.0372\n",
      "Test set (epoch 64): Average loss: 0.7748, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.409300 (avg: 0.409300) \tsec/iter: 0.0419\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.333877 (avg: 0.350816) \tsec/iter: 0.0366\n",
      "Test set (epoch 65): Average loss: 0.7772, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.438025 (avg: 0.438025) \tsec/iter: 0.0339\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.216185 (avg: 0.350617) \tsec/iter: 0.0316\n",
      "Test set (epoch 66): Average loss: 0.7511, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.276907 (avg: 0.276907) \tsec/iter: 0.0339\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.371454 (avg: 0.346760) \tsec/iter: 0.0309\n",
      "Test set (epoch 67): Average loss: 0.7994, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.269810 (avg: 0.269810) \tsec/iter: 0.0329\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.303127 (avg: 0.345472) \tsec/iter: 0.0312\n",
      "Test set (epoch 68): Average loss: 0.7589, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.385140 (avg: 0.385140) \tsec/iter: 0.0339\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.314913 (avg: 0.348395) \tsec/iter: 0.0322\n",
      "Test set (epoch 69): Average loss: 0.7613, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.411426 (avg: 0.411426) \tsec/iter: 0.0349\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.311501 (avg: 0.341107) \tsec/iter: 0.0309\n",
      "Test set (epoch 70): Average loss: 0.7916, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.382050 (avg: 0.382050) \tsec/iter: 0.0369\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.222091 (avg: 0.339858) \tsec/iter: 0.0299\n",
      "Test set (epoch 71): Average loss: 0.7253, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.356680 (avg: 0.356680) \tsec/iter: 0.0339\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.365922 (avg: 0.336617) \tsec/iter: 0.0309\n",
      "Test set (epoch 72): Average loss: 0.6969, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.372203 (avg: 0.372203) \tsec/iter: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.382416 (avg: 0.341981) \tsec/iter: 0.0316\n",
      "Test set (epoch 73): Average loss: 0.7371, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.317280 (avg: 0.317280) \tsec/iter: 0.0419\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.507432 (avg: 0.342805) \tsec/iter: 0.0359\n",
      "Test set (epoch 74): Average loss: 0.7158, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.308862 (avg: 0.308862) \tsec/iter: 0.0399\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.276577 (avg: 0.351353) \tsec/iter: 0.0332\n",
      "Test set (epoch 75): Average loss: 0.6786, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.386676 (avg: 0.386676) \tsec/iter: 0.0329\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.359984 (avg: 0.358822) \tsec/iter: 0.0299\n",
      "Test set (epoch 76): Average loss: 0.5880, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.345344 (avg: 0.345344) \tsec/iter: 0.0339\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.275394 (avg: 0.354243) \tsec/iter: 0.0319\n",
      "Test set (epoch 77): Average loss: 0.5666, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.364131 (avg: 0.364131) \tsec/iter: 0.0379\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.254715 (avg: 0.354761) \tsec/iter: 0.0346\n",
      "Test set (epoch 78): Average loss: 0.6254, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.417573 (avg: 0.417573) \tsec/iter: 0.0309\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.272649 (avg: 0.353872) \tsec/iter: 0.0303\n",
      "Test set (epoch 79): Average loss: 0.6188, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.386445 (avg: 0.386445) \tsec/iter: 0.0339\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.219227 (avg: 0.361185) \tsec/iter: 0.0326\n",
      "Test set (epoch 80): Average loss: 0.7195, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.315642 (avg: 0.315642) \tsec/iter: 0.0319\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.357875 (avg: 0.334463) \tsec/iter: 0.0326\n",
      "Test set (epoch 81): Average loss: 0.7134, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.313222 (avg: 0.313222) \tsec/iter: 0.0339\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.306975 (avg: 0.312225) \tsec/iter: 0.0319\n",
      "Test set (epoch 82): Average loss: 0.5931, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.284255 (avg: 0.284255) \tsec/iter: 0.0319\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.267761 (avg: 0.307699) \tsec/iter: 0.0349\n",
      "Test set (epoch 83): Average loss: 0.7147, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.271570 (avg: 0.271570) \tsec/iter: 0.0578\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.366533 (avg: 0.327790) \tsec/iter: 0.0452\n",
      "Test set (epoch 84): Average loss: 0.5819, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.272846 (avg: 0.272846) \tsec/iter: 0.0409\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.224117 (avg: 0.331727) \tsec/iter: 0.0376\n",
      "Test set (epoch 85): Average loss: 0.7048, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.303425 (avg: 0.303425) \tsec/iter: 0.0429\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.234190 (avg: 0.315786) \tsec/iter: 0.0386\n",
      "Test set (epoch 86): Average loss: 0.7397, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.382528 (avg: 0.382528) \tsec/iter: 0.0439\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.287679 (avg: 0.327998) \tsec/iter: 0.0409\n",
      "Test set (epoch 87): Average loss: 0.8090, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.377693 (avg: 0.377693) \tsec/iter: 0.0449\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.451432 (avg: 0.349418) \tsec/iter: 0.0419\n",
      "Test set (epoch 88): Average loss: 0.7539, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.404353 (avg: 0.404353) \tsec/iter: 0.0439\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.204499 (avg: 0.307949) \tsec/iter: 0.0399\n",
      "Test set (epoch 89): Average loss: 0.8145, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.235037 (avg: 0.235037) \tsec/iter: 0.0459\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.455961 (avg: 0.330739) \tsec/iter: 0.0386\n",
      "Test set (epoch 90): Average loss: 0.8424, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.346568 (avg: 0.346568) \tsec/iter: 0.0399\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.389561 (avg: 0.340608) \tsec/iter: 0.0366\n",
      "Test set (epoch 91): Average loss: 0.5984, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.374179 (avg: 0.374179) \tsec/iter: 0.0389\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.361791 (avg: 0.358609) \tsec/iter: 0.0349\n",
      "Test set (epoch 92): Average loss: 0.7980, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.307223 (avg: 0.307223) \tsec/iter: 0.0359\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.259792 (avg: 0.328509) \tsec/iter: 0.0319\n",
      "Test set (epoch 93): Average loss: 0.8035, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.368107 (avg: 0.368107) \tsec/iter: 0.0349\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.271755 (avg: 0.337591) \tsec/iter: 0.0319\n",
      "Test set (epoch 94): Average loss: 0.6425, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.361809 (avg: 0.361809) \tsec/iter: 0.0309\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.193789 (avg: 0.320900) \tsec/iter: 0.0319\n",
      "Test set (epoch 95): Average loss: 0.6483, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.353316 (avg: 0.353316) \tsec/iter: 0.0309\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.212878 (avg: 0.309778) \tsec/iter: 0.0306\n",
      "Test set (epoch 96): Average loss: 0.6018, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.464040 (avg: 0.464040) \tsec/iter: 0.0349\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.383629 (avg: 0.373297) \tsec/iter: 0.0303\n",
      "Test set (epoch 97): Average loss: 0.7407, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.320662 (avg: 0.320662) \tsec/iter: 0.0329\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.338002 (avg: 0.325380) \tsec/iter: 0.0306\n",
      "Test set (epoch 98): Average loss: 0.5614, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.418682 (avg: 0.418682) \tsec/iter: 0.0399\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.268471 (avg: 0.394422) \tsec/iter: 0.0329\n",
      "Test set (epoch 99): Average loss: 0.6257, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.297320 (avg: 0.297320) \tsec/iter: 0.0319\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.350024 (avg: 0.353369) \tsec/iter: 0.0319\n",
      "Test set (epoch 100): Average loss: 0.7046, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.269326 (avg: 0.269326) \tsec/iter: 0.0379\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.443484 (avg: 0.312347) \tsec/iter: 0.0339\n",
      "Test set (epoch 101): Average loss: 0.7178, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.342288 (avg: 0.342288) \tsec/iter: 0.0339\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.269209 (avg: 0.338596) \tsec/iter: 0.0299\n",
      "Test set (epoch 102): Average loss: 0.7126, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.266744 (avg: 0.266744) \tsec/iter: 0.0349\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.375877 (avg: 0.313852) \tsec/iter: 0.0359\n",
      "Test set (epoch 103): Average loss: 0.5684, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.332741 (avg: 0.332741) \tsec/iter: 0.0339\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.318525 (avg: 0.308546) \tsec/iter: 0.0303\n",
      "Test set (epoch 104): Average loss: 0.6499, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.345374 (avg: 0.345374) \tsec/iter: 0.0409\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.283827 (avg: 0.287085) \tsec/iter: 0.0332\n",
      "Test set (epoch 105): Average loss: 0.5137, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.232767 (avg: 0.232767) \tsec/iter: 0.0359\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.405108 (avg: 0.342004) \tsec/iter: 0.0303\n",
      "Test set (epoch 106): Average loss: 0.7326, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.297065 (avg: 0.297065) \tsec/iter: 0.0339\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.418839 (avg: 0.327609) \tsec/iter: 0.0299\n",
      "Test set (epoch 107): Average loss: 0.5146, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.357697 (avg: 0.357697) \tsec/iter: 0.0339\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.471569 (avg: 0.349208) \tsec/iter: 0.0306\n",
      "Test set (epoch 108): Average loss: 0.6625, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.312764 (avg: 0.312764) \tsec/iter: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.295771 (avg: 0.332704) \tsec/iter: 0.0296\n",
      "Test set (epoch 109): Average loss: 0.6384, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.330824 (avg: 0.330824) \tsec/iter: 0.0369\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.239057 (avg: 0.277456) \tsec/iter: 0.0359\n",
      "Test set (epoch 110): Average loss: 0.6636, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.287354 (avg: 0.287354) \tsec/iter: 0.0399\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.405238 (avg: 0.331170) \tsec/iter: 0.0342\n",
      "Test set (epoch 111): Average loss: 0.7137, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.287045 (avg: 0.287045) \tsec/iter: 0.0359\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.402628 (avg: 0.338232) \tsec/iter: 0.0326\n",
      "Test set (epoch 112): Average loss: 0.6768, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.332534 (avg: 0.332534) \tsec/iter: 0.0399\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.144620 (avg: 0.307344) \tsec/iter: 0.0322\n",
      "Test set (epoch 113): Average loss: 0.6448, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.428204 (avg: 0.428204) \tsec/iter: 0.0339\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.303909 (avg: 0.335651) \tsec/iter: 0.0312\n",
      "Test set (epoch 114): Average loss: 0.5162, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.307676 (avg: 0.307676) \tsec/iter: 0.0359\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.304680 (avg: 0.340570) \tsec/iter: 0.0326\n",
      "Test set (epoch 115): Average loss: 0.5420, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.265808 (avg: 0.265808) \tsec/iter: 0.0319\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.468886 (avg: 0.310578) \tsec/iter: 0.0293\n",
      "Test set (epoch 116): Average loss: 0.6208, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.303948 (avg: 0.303948) \tsec/iter: 0.0429\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.316388 (avg: 0.298784) \tsec/iter: 0.0362\n",
      "Test set (epoch 117): Average loss: 0.4879, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.414700 (avg: 0.414700) \tsec/iter: 0.0369\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.286252 (avg: 0.317990) \tsec/iter: 0.0329\n",
      "Test set (epoch 118): Average loss: 0.6073, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.300350 (avg: 0.300350) \tsec/iter: 0.0429\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.341773 (avg: 0.315495) \tsec/iter: 0.0396\n",
      "Test set (epoch 119): Average loss: 0.4660, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.273234 (avg: 0.273234) \tsec/iter: 0.0479\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.287314 (avg: 0.296160) \tsec/iter: 0.0549\n",
      "Test set (epoch 120): Average loss: 0.5814, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.302655 (avg: 0.302655) \tsec/iter: 0.0459\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.372627 (avg: 0.305744) \tsec/iter: 0.0462\n",
      "Test set (epoch 121): Average loss: 0.4631, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.334726 (avg: 0.334726) \tsec/iter: 0.0449\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.305376 (avg: 0.328254) \tsec/iter: 0.0455\n",
      "Test set (epoch 122): Average loss: 0.5769, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.341408 (avg: 0.341408) \tsec/iter: 0.0509\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.251577 (avg: 0.289144) \tsec/iter: 0.0432\n",
      "Test set (epoch 123): Average loss: 0.5598, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.246755 (avg: 0.246755) \tsec/iter: 0.0509\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.410629 (avg: 0.299328) \tsec/iter: 0.0482\n",
      "Test set (epoch 124): Average loss: 0.5607, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.329303 (avg: 0.329303) \tsec/iter: 0.0389\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.356139 (avg: 0.350396) \tsec/iter: 0.0372\n",
      "Test set (epoch 125): Average loss: 0.7021, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.349813 (avg: 0.349813) \tsec/iter: 0.0499\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.429282 (avg: 0.337127) \tsec/iter: 0.0445\n",
      "Test set (epoch 126): Average loss: 0.4842, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.260816 (avg: 0.260816) \tsec/iter: 0.0638\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.510870 (avg: 0.323405) \tsec/iter: 0.0489\n",
      "Test set (epoch 127): Average loss: 0.6607, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.268435 (avg: 0.268435) \tsec/iter: 0.0479\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.326169 (avg: 0.323834) \tsec/iter: 0.0462\n",
      "Test set (epoch 128): Average loss: 0.4541, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.370755 (avg: 0.370755) \tsec/iter: 0.0529\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.234846 (avg: 0.292891) \tsec/iter: 0.0479\n",
      "Test set (epoch 129): Average loss: 0.5454, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.201132 (avg: 0.201132) \tsec/iter: 0.0489\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.376946 (avg: 0.279074) \tsec/iter: 0.0426\n",
      "Test set (epoch 130): Average loss: 0.5775, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.348066 (avg: 0.348066) \tsec/iter: 0.0638\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.246868 (avg: 0.298144) \tsec/iter: 0.0495\n",
      "Test set (epoch 131): Average loss: 0.5869, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.434918 (avg: 0.434918) \tsec/iter: 0.0499\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.162345 (avg: 0.322735) \tsec/iter: 0.0472\n",
      "Test set (epoch 132): Average loss: 0.5127, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.224935 (avg: 0.224935) \tsec/iter: 0.0519\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.429814 (avg: 0.309844) \tsec/iter: 0.0502\n",
      "Test set (epoch 133): Average loss: 0.4559, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.290059 (avg: 0.290059) \tsec/iter: 0.0559\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.395138 (avg: 0.347745) \tsec/iter: 0.0499\n",
      "Test set (epoch 134): Average loss: 0.5727, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.350585 (avg: 0.350585) \tsec/iter: 0.0429\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.325237 (avg: 0.322441) \tsec/iter: 0.0439\n",
      "Test set (epoch 135): Average loss: 0.5557, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.308932 (avg: 0.308932) \tsec/iter: 0.0509\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.270296 (avg: 0.296786) \tsec/iter: 0.0452\n",
      "Test set (epoch 136): Average loss: 0.5054, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.355688 (avg: 0.355688) \tsec/iter: 0.0489\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.213919 (avg: 0.312161) \tsec/iter: 0.0452\n",
      "Test set (epoch 137): Average loss: 0.4128, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.328203 (avg: 0.328203) \tsec/iter: 0.0469\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.283897 (avg: 0.347000) \tsec/iter: 0.0462\n",
      "Test set (epoch 138): Average loss: 0.4528, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.246717 (avg: 0.246717) \tsec/iter: 0.0499\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.434406 (avg: 0.303999) \tsec/iter: 0.0449\n",
      "Test set (epoch 139): Average loss: 0.4760, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.284623 (avg: 0.284623) \tsec/iter: 0.0479\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.265943 (avg: 0.299839) \tsec/iter: 0.0465\n",
      "Test set (epoch 140): Average loss: 0.3456, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.356012 (avg: 0.356012) \tsec/iter: 0.0479\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.191979 (avg: 0.302649) \tsec/iter: 0.0445\n",
      "Test set (epoch 141): Average loss: 0.5646, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.301677 (avg: 0.301677) \tsec/iter: 0.0489\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.325045 (avg: 0.329732) \tsec/iter: 0.0489\n",
      "Test set (epoch 142): Average loss: 0.3734, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.234065 (avg: 0.234065) \tsec/iter: 0.0479\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.264722 (avg: 0.278671) \tsec/iter: 0.0376\n",
      "Test set (epoch 143): Average loss: 0.4392, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.305632 (avg: 0.305632) \tsec/iter: 0.0369\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.306115 (avg: 0.301885) \tsec/iter: 0.0389\n",
      "Test set (epoch 144): Average loss: 0.4029, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.280295 (avg: 0.280295) \tsec/iter: 0.0409\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.157281 (avg: 0.279902) \tsec/iter: 0.0399\n",
      "Test set (epoch 145): Average loss: 0.4672, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.230338 (avg: 0.230338) \tsec/iter: 0.0479\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.298302 (avg: 0.294293) \tsec/iter: 0.0436\n",
      "Test set (epoch 146): Average loss: 0.4511, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.235934 (avg: 0.235934) \tsec/iter: 0.0469\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.543481 (avg: 0.293771) \tsec/iter: 0.0412\n",
      "Test set (epoch 147): Average loss: 0.5154, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.269675 (avg: 0.269675) \tsec/iter: 0.0339\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.311234 (avg: 0.295701) \tsec/iter: 0.0326\n",
      "Test set (epoch 148): Average loss: 0.4807, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.256681 (avg: 0.256681) \tsec/iter: 0.0339\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.361335 (avg: 0.304413) \tsec/iter: 0.0309\n",
      "Test set (epoch 149): Average loss: 0.4304, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.262020 (avg: 0.262020) \tsec/iter: 0.0369\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.281208 (avg: 0.282131) \tsec/iter: 0.0309\n",
      "Test set (epoch 150): Average loss: 0.5446, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.248199 (avg: 0.248199) \tsec/iter: 0.0329\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.180776 (avg: 0.273551) \tsec/iter: 0.0316\n",
      "Test set (epoch 151): Average loss: 0.3404, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.379478 (avg: 0.379478) \tsec/iter: 0.0399\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.211011 (avg: 0.317022) \tsec/iter: 0.0329\n",
      "Test set (epoch 152): Average loss: 0.4418, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.224887 (avg: 0.224887) \tsec/iter: 0.0369\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.403992 (avg: 0.293564) \tsec/iter: 0.0322\n",
      "Test set (epoch 153): Average loss: 0.3712, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.200722 (avg: 0.200722) \tsec/iter: 0.0369\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.256076 (avg: 0.293665) \tsec/iter: 0.0322\n",
      "Test set (epoch 154): Average loss: 0.4644, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.307653 (avg: 0.307653) \tsec/iter: 0.0339\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.314615 (avg: 0.313898) \tsec/iter: 0.0319\n",
      "Test set (epoch 155): Average loss: 0.3889, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.314088 (avg: 0.314088) \tsec/iter: 0.0409\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.446574 (avg: 0.336306) \tsec/iter: 0.0369\n",
      "Test set (epoch 156): Average loss: 0.6277, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.259399 (avg: 0.259399) \tsec/iter: 0.0389\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.382146 (avg: 0.281593) \tsec/iter: 0.0322\n",
      "Test set (epoch 157): Average loss: 0.4345, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.320385 (avg: 0.320385) \tsec/iter: 0.0399\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.216621 (avg: 0.283966) \tsec/iter: 0.0332\n",
      "Test set (epoch 158): Average loss: 0.3961, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.206210 (avg: 0.206210) \tsec/iter: 0.0369\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.258278 (avg: 0.261680) \tsec/iter: 0.0336\n",
      "Test set (epoch 159): Average loss: 0.4859, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.257255 (avg: 0.257255) \tsec/iter: 0.0429\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.313633 (avg: 0.293371) \tsec/iter: 0.0372\n",
      "Test set (epoch 160): Average loss: 0.4413, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.351868 (avg: 0.351868) \tsec/iter: 0.0359\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.246211 (avg: 0.276181) \tsec/iter: 0.0296\n",
      "Test set (epoch 161): Average loss: 0.3378, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.420380 (avg: 0.420380) \tsec/iter: 0.0339\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.151099 (avg: 0.298529) \tsec/iter: 0.0309\n",
      "Test set (epoch 162): Average loss: 0.5084, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.299776 (avg: 0.299776) \tsec/iter: 0.0349\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.312075 (avg: 0.318861) \tsec/iter: 0.0322\n",
      "Test set (epoch 163): Average loss: 0.5074, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.362064 (avg: 0.362064) \tsec/iter: 0.0399\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.261346 (avg: 0.311191) \tsec/iter: 0.0329\n",
      "Test set (epoch 164): Average loss: 0.3769, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.271626 (avg: 0.271626) \tsec/iter: 0.0369\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.401913 (avg: 0.319262) \tsec/iter: 0.0349\n",
      "Test set (epoch 165): Average loss: 0.7016, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.368671 (avg: 0.368671) \tsec/iter: 0.0359\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.323425 (avg: 0.302792) \tsec/iter: 0.0312\n",
      "Test set (epoch 166): Average loss: 0.3698, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.222913 (avg: 0.222913) \tsec/iter: 0.0339\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.342321 (avg: 0.303788) \tsec/iter: 0.0316\n",
      "Test set (epoch 167): Average loss: 0.4604, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.346711 (avg: 0.346711) \tsec/iter: 0.0329\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.273135 (avg: 0.278143) \tsec/iter: 0.0332\n",
      "Test set (epoch 168): Average loss: 0.3073, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.331045 (avg: 0.331045) \tsec/iter: 0.0379\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.215271 (avg: 0.287800) \tsec/iter: 0.0336\n",
      "Test set (epoch 169): Average loss: 0.4110, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.229681 (avg: 0.229681) \tsec/iter: 0.0299\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.250456 (avg: 0.257805) \tsec/iter: 0.0283\n",
      "Test set (epoch 170): Average loss: 0.3522, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.235279 (avg: 0.235279) \tsec/iter: 0.0379\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.313224 (avg: 0.310138) \tsec/iter: 0.0326\n",
      "Test set (epoch 171): Average loss: 0.4314, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.224189 (avg: 0.224189) \tsec/iter: 0.0349\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.308997 (avg: 0.257904) \tsec/iter: 0.0309\n",
      "Test set (epoch 172): Average loss: 0.3954, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.251298 (avg: 0.251298) \tsec/iter: 0.0329\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.250782 (avg: 0.278239) \tsec/iter: 0.0342\n",
      "Test set (epoch 173): Average loss: 0.4142, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.280508 (avg: 0.280508) \tsec/iter: 0.0349\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.285317 (avg: 0.265406) \tsec/iter: 0.0336\n",
      "Test set (epoch 174): Average loss: 0.4241, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.238673 (avg: 0.238673) \tsec/iter: 0.0389\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.253773 (avg: 0.292219) \tsec/iter: 0.0359\n",
      "Test set (epoch 175): Average loss: 0.3722, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.289893 (avg: 0.289893) \tsec/iter: 0.0329\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.229850 (avg: 0.246883) \tsec/iter: 0.0296\n",
      "Test set (epoch 176): Average loss: 0.6201, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.271196 (avg: 0.271196) \tsec/iter: 0.0349\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.302679 (avg: 0.289059) \tsec/iter: 0.0349\n",
      "Test set (epoch 177): Average loss: 0.4308, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.219666 (avg: 0.219666) \tsec/iter: 0.0339\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.330762 (avg: 0.259352) \tsec/iter: 0.0329\n",
      "Test set (epoch 178): Average loss: 0.4481, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.258629 (avg: 0.258629) \tsec/iter: 0.0349\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.251795 (avg: 0.254914) \tsec/iter: 0.0336\n",
      "Test set (epoch 179): Average loss: 0.5266, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.151808 (avg: 0.151808) \tsec/iter: 0.0339\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.359364 (avg: 0.254769) \tsec/iter: 0.0316\n",
      "Test set (epoch 180): Average loss: 0.2988, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.285364 (avg: 0.285364) \tsec/iter: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.196312 (avg: 0.277982) \tsec/iter: 0.0336\n",
      "Test set (epoch 181): Average loss: 0.3772, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.278813 (avg: 0.278813) \tsec/iter: 0.0309\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.191366 (avg: 0.275978) \tsec/iter: 0.0326\n",
      "Test set (epoch 182): Average loss: 0.3333, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.294425 (avg: 0.294425) \tsec/iter: 0.0369\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.264561 (avg: 0.278204) \tsec/iter: 0.0359\n",
      "Test set (epoch 183): Average loss: 0.3352, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.231849 (avg: 0.231849) \tsec/iter: 0.0459\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.283634 (avg: 0.245747) \tsec/iter: 0.0396\n",
      "Test set (epoch 184): Average loss: 0.4094, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.192874 (avg: 0.192874) \tsec/iter: 0.0379\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.287753 (avg: 0.293747) \tsec/iter: 0.0329\n",
      "Test set (epoch 185): Average loss: 0.4293, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.329596 (avg: 0.329596) \tsec/iter: 0.0399\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.175734 (avg: 0.265204) \tsec/iter: 0.0366\n",
      "Test set (epoch 186): Average loss: 0.4297, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.230806 (avg: 0.230806) \tsec/iter: 0.0369\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.276370 (avg: 0.257526) \tsec/iter: 0.0319\n",
      "Test set (epoch 187): Average loss: 0.3785, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.256438 (avg: 0.256438) \tsec/iter: 0.0399\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.332762 (avg: 0.292425) \tsec/iter: 0.0339\n",
      "Test set (epoch 188): Average loss: 0.4204, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.253336 (avg: 0.253336) \tsec/iter: 0.0389\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.206005 (avg: 0.238230) \tsec/iter: 0.0339\n",
      "Test set (epoch 189): Average loss: 0.5985, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.266119 (avg: 0.266119) \tsec/iter: 0.0359\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.211722 (avg: 0.326282) \tsec/iter: 0.0336\n",
      "Test set (epoch 190): Average loss: 0.3865, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.193490 (avg: 0.193490) \tsec/iter: 0.0359\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.361920 (avg: 0.282842) \tsec/iter: 0.0359\n",
      "Test set (epoch 191): Average loss: 0.4476, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.272134 (avg: 0.272134) \tsec/iter: 0.0419\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.221914 (avg: 0.277629) \tsec/iter: 0.0396\n",
      "Test set (epoch 192): Average loss: 0.3088, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.231810 (avg: 0.231810) \tsec/iter: 0.0539\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.338074 (avg: 0.258942) \tsec/iter: 0.0432\n",
      "Test set (epoch 193): Average loss: 0.6017, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.300539 (avg: 0.300539) \tsec/iter: 0.0369\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.271655 (avg: 0.272898) \tsec/iter: 0.0322\n",
      "Test set (epoch 194): Average loss: 0.3447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.278163 (avg: 0.278163) \tsec/iter: 0.0359\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.357141 (avg: 0.306448) \tsec/iter: 0.0316\n",
      "Test set (epoch 195): Average loss: 0.4176, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.231847 (avg: 0.231847) \tsec/iter: 0.0379\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.237629 (avg: 0.247980) \tsec/iter: 0.0316\n",
      "Test set (epoch 196): Average loss: 0.2746, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.221905 (avg: 0.221905) \tsec/iter: 0.0319\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.302080 (avg: 0.272807) \tsec/iter: 0.0306\n",
      "Test set (epoch 197): Average loss: 0.3038, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.273228 (avg: 0.273228) \tsec/iter: 0.0309\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.229328 (avg: 0.250268) \tsec/iter: 0.0286\n",
      "Test set (epoch 198): Average loss: 0.3653, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.202230 (avg: 0.202230) \tsec/iter: 0.0399\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.280776 (avg: 0.232451) \tsec/iter: 0.0352\n",
      "Test set (epoch 199): Average loss: 0.3063, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.239071 (avg: 0.239071) \tsec/iter: 0.0319\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.213326 (avg: 0.263027) \tsec/iter: 0.0303\n",
      "Test set (epoch 200): Average loss: 0.3523, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.305019 (avg: 0.305019) \tsec/iter: 0.0309\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.272069 (avg: 0.280869) \tsec/iter: 0.0299\n",
      "Test set (epoch 201): Average loss: 0.3592, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.234792 (avg: 0.234792) \tsec/iter: 0.0389\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.259745 (avg: 0.245040) \tsec/iter: 0.0359\n",
      "Test set (epoch 202): Average loss: 0.2867, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.200326 (avg: 0.200326) \tsec/iter: 0.0359\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.276825 (avg: 0.307368) \tsec/iter: 0.0322\n",
      "Test set (epoch 203): Average loss: 0.3617, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.246851 (avg: 0.246851) \tsec/iter: 0.0319\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.271615 (avg: 0.256365) \tsec/iter: 0.0319\n",
      "Test set (epoch 204): Average loss: 0.3097, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.256600 (avg: 0.256600) \tsec/iter: 0.0309\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.390027 (avg: 0.271646) \tsec/iter: 0.0303\n",
      "Test set (epoch 205): Average loss: 0.4136, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.282725 (avg: 0.282725) \tsec/iter: 0.0309\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.239637 (avg: 0.292126) \tsec/iter: 0.0299\n",
      "Test set (epoch 206): Average loss: 0.3805, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.333943 (avg: 0.333943) \tsec/iter: 0.0389\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.284052 (avg: 0.294623) \tsec/iter: 0.0326\n",
      "Test set (epoch 207): Average loss: 0.3476, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.307070 (avg: 0.307070) \tsec/iter: 0.0299\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.333850 (avg: 0.282057) \tsec/iter: 0.0322\n",
      "Test set (epoch 208): Average loss: 0.3427, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.228757 (avg: 0.228757) \tsec/iter: 0.0309\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.314766 (avg: 0.256467) \tsec/iter: 0.0312\n",
      "Test set (epoch 209): Average loss: 0.3400, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.293373 (avg: 0.293373) \tsec/iter: 0.0289\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.270083 (avg: 0.257400) \tsec/iter: 0.0289\n",
      "Test set (epoch 210): Average loss: 0.2592, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.186201 (avg: 0.186201) \tsec/iter: 0.0389\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.254222 (avg: 0.234855) \tsec/iter: 0.0359\n",
      "Test set (epoch 211): Average loss: 0.3310, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.246715 (avg: 0.246715) \tsec/iter: 0.0389\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.347170 (avg: 0.275916) \tsec/iter: 0.0366\n",
      "Test set (epoch 212): Average loss: 0.3115, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.265899 (avg: 0.265899) \tsec/iter: 0.0379\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.337404 (avg: 0.261122) \tsec/iter: 0.0332\n",
      "Test set (epoch 213): Average loss: 0.4101, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.221327 (avg: 0.221327) \tsec/iter: 0.0329\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.225480 (avg: 0.240075) \tsec/iter: 0.0303\n",
      "Test set (epoch 214): Average loss: 0.3343, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.211115 (avg: 0.211115) \tsec/iter: 0.0329\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.197216 (avg: 0.233058) \tsec/iter: 0.0306\n",
      "Test set (epoch 215): Average loss: 0.3642, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.321821 (avg: 0.321821) \tsec/iter: 0.0369\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.230148 (avg: 0.233733) \tsec/iter: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 216): Average loss: 0.5006, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.220323 (avg: 0.220323) \tsec/iter: 0.0389\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.305936 (avg: 0.240837) \tsec/iter: 0.0316\n",
      "Test set (epoch 217): Average loss: 0.3012, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.205785 (avg: 0.205785) \tsec/iter: 0.0349\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.317491 (avg: 0.237055) \tsec/iter: 0.0322\n",
      "Test set (epoch 218): Average loss: 0.3002, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.363663 (avg: 0.363663) \tsec/iter: 0.0349\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.307172 (avg: 0.309637) \tsec/iter: 0.0312\n",
      "Test set (epoch 219): Average loss: 0.2881, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.201114 (avg: 0.201114) \tsec/iter: 0.0339\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.396411 (avg: 0.277897) \tsec/iter: 0.0296\n",
      "Test set (epoch 220): Average loss: 0.3301, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.307494 (avg: 0.307494) \tsec/iter: 0.0349\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.312508 (avg: 0.284098) \tsec/iter: 0.0342\n",
      "Test set (epoch 221): Average loss: 0.3200, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.234858 (avg: 0.234858) \tsec/iter: 0.0359\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.291068 (avg: 0.287620) \tsec/iter: 0.0316\n",
      "Test set (epoch 222): Average loss: 0.3914, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.156451 (avg: 0.156451) \tsec/iter: 0.0379\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.683789 (avg: 0.292898) \tsec/iter: 0.0326\n",
      "Test set (epoch 223): Average loss: 0.4336, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.278001 (avg: 0.278001) \tsec/iter: 0.0409\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.195218 (avg: 0.278713) \tsec/iter: 0.0359\n",
      "Test set (epoch 224): Average loss: 0.3655, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.328649 (avg: 0.328649) \tsec/iter: 0.0359\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.145726 (avg: 0.265881) \tsec/iter: 0.0299\n",
      "Test set (epoch 225): Average loss: 0.3621, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.274402 (avg: 0.274402) \tsec/iter: 0.0349\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.274901 (avg: 0.261048) \tsec/iter: 0.0336\n",
      "Test set (epoch 226): Average loss: 0.4453, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.286496 (avg: 0.286496) \tsec/iter: 0.0339\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.284691 (avg: 0.274005) \tsec/iter: 0.0303\n",
      "Test set (epoch 227): Average loss: 0.3783, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.183043 (avg: 0.183043) \tsec/iter: 0.0339\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.190681 (avg: 0.241840) \tsec/iter: 0.0296\n",
      "Test set (epoch 228): Average loss: 0.2780, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.251201 (avg: 0.251201) \tsec/iter: 0.0419\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.319612 (avg: 0.258400) \tsec/iter: 0.0366\n",
      "Test set (epoch 229): Average loss: 0.3467, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.290776 (avg: 0.290776) \tsec/iter: 0.0449\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.159895 (avg: 0.230632) \tsec/iter: 0.0419\n",
      "Test set (epoch 230): Average loss: 0.3241, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.287546 (avg: 0.287546) \tsec/iter: 0.0459\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.247342 (avg: 0.261447) \tsec/iter: 0.0382\n",
      "Test set (epoch 231): Average loss: 0.3015, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.288598 (avg: 0.288598) \tsec/iter: 0.0369\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.137405 (avg: 0.237609) \tsec/iter: 0.0329\n",
      "Test set (epoch 232): Average loss: 0.2683, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.263870 (avg: 0.263870) \tsec/iter: 0.0359\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.309616 (avg: 0.264710) \tsec/iter: 0.0322\n",
      "Test set (epoch 233): Average loss: 0.2588, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.225388 (avg: 0.225388) \tsec/iter: 0.0339\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.346158 (avg: 0.253728) \tsec/iter: 0.0306\n",
      "Test set (epoch 234): Average loss: 0.2580, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.262904 (avg: 0.262904) \tsec/iter: 0.0369\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.291801 (avg: 0.278336) \tsec/iter: 0.0316\n",
      "Test set (epoch 235): Average loss: 0.3962, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.201647 (avg: 0.201647) \tsec/iter: 0.0369\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.285179 (avg: 0.247524) \tsec/iter: 0.0309\n",
      "Test set (epoch 236): Average loss: 0.3370, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.228938 (avg: 0.228938) \tsec/iter: 0.0329\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.346842 (avg: 0.262648) \tsec/iter: 0.0296\n",
      "Test set (epoch 237): Average loss: 0.4190, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.300066 (avg: 0.300066) \tsec/iter: 0.0359\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.255213 (avg: 0.240891) \tsec/iter: 0.0309\n",
      "Test set (epoch 238): Average loss: 0.3325, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.220111 (avg: 0.220111) \tsec/iter: 0.0369\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.365604 (avg: 0.245369) \tsec/iter: 0.0382\n",
      "Test set (epoch 239): Average loss: 0.3086, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.294618 (avg: 0.294618) \tsec/iter: 0.0389\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.227247 (avg: 0.248525) \tsec/iter: 0.0352\n",
      "Test set (epoch 240): Average loss: 0.3315, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.198517 (avg: 0.198517) \tsec/iter: 0.0329\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.250415 (avg: 0.237906) \tsec/iter: 0.0299\n",
      "Test set (epoch 241): Average loss: 0.3401, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.221782 (avg: 0.221782) \tsec/iter: 0.0319\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.289465 (avg: 0.251153) \tsec/iter: 0.0283\n",
      "Test set (epoch 242): Average loss: 0.3172, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.218820 (avg: 0.218820) \tsec/iter: 0.0339\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.369574 (avg: 0.264725) \tsec/iter: 0.0309\n",
      "Test set (epoch 243): Average loss: 0.4634, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.346591 (avg: 0.346591) \tsec/iter: 0.0379\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.117303 (avg: 0.254402) \tsec/iter: 0.0319\n",
      "Test set (epoch 244): Average loss: 0.2189, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.222525 (avg: 0.222525) \tsec/iter: 0.0319\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.319260 (avg: 0.257674) \tsec/iter: 0.0286\n",
      "Test set (epoch 245): Average loss: 0.2957, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.266058 (avg: 0.266058) \tsec/iter: 0.0329\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.176251 (avg: 0.251459) \tsec/iter: 0.0293\n",
      "Test set (epoch 246): Average loss: 0.3651, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.220638 (avg: 0.220638) \tsec/iter: 0.0309\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.164495 (avg: 0.228203) \tsec/iter: 0.0306\n",
      "Test set (epoch 247): Average loss: 0.2656, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.259078 (avg: 0.259078) \tsec/iter: 0.0359\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.289685 (avg: 0.234009) \tsec/iter: 0.0329\n",
      "Test set (epoch 248): Average loss: 0.2755, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.214817 (avg: 0.214817) \tsec/iter: 0.0369\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.224410 (avg: 0.231811) \tsec/iter: 0.0352\n",
      "Test set (epoch 249): Average loss: 0.5131, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.148091 (avg: 0.148091) \tsec/iter: 0.0359\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.236668 (avg: 0.206185) \tsec/iter: 0.0342\n",
      "Test set (epoch 250): Average loss: 0.2414, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.317218 (avg: 0.317218) \tsec/iter: 0.0309\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.180706 (avg: 0.264667) \tsec/iter: 0.0299\n",
      "Test set (epoch 251): Average loss: 0.3066, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.211468 (avg: 0.211468) \tsec/iter: 0.0349\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.194804 (avg: 0.211734) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 252): Average loss: 0.3304, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.140994 (avg: 0.140994) \tsec/iter: 0.0379\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.448066 (avg: 0.282191) \tsec/iter: 0.0339\n",
      "Test set (epoch 253): Average loss: 0.3130, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.283557 (avg: 0.283557) \tsec/iter: 0.0329\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.251049 (avg: 0.269822) \tsec/iter: 0.0316\n",
      "Test set (epoch 254): Average loss: 0.3650, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.211543 (avg: 0.211543) \tsec/iter: 0.0329\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.219862 (avg: 0.237307) \tsec/iter: 0.0322\n",
      "Test set (epoch 255): Average loss: 0.2331, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.264280 (avg: 0.264280) \tsec/iter: 0.0329\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.234732 (avg: 0.214566) \tsec/iter: 0.0306\n",
      "Test set (epoch 256): Average loss: 0.2535, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.180257 (avg: 0.180257) \tsec/iter: 0.0359\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.424625 (avg: 0.302557) \tsec/iter: 0.0319\n",
      "Test set (epoch 257): Average loss: 0.2849, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.319376 (avg: 0.319376) \tsec/iter: 0.0339\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.240123 (avg: 0.260492) \tsec/iter: 0.0332\n",
      "Test set (epoch 258): Average loss: 0.3022, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.171624 (avg: 0.171624) \tsec/iter: 0.0419\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.293538 (avg: 0.212214) \tsec/iter: 0.0362\n",
      "Test set (epoch 259): Average loss: 0.4198, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.217279 (avg: 0.217279) \tsec/iter: 0.0349\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.205491 (avg: 0.260016) \tsec/iter: 0.0319\n",
      "Test set (epoch 260): Average loss: 0.3321, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.241918 (avg: 0.241918) \tsec/iter: 0.0349\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.281443 (avg: 0.271242) \tsec/iter: 0.0309\n",
      "Test set (epoch 261): Average loss: 0.3273, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.310878 (avg: 0.310878) \tsec/iter: 0.0319\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.295375 (avg: 0.279162) \tsec/iter: 0.0309\n",
      "Test set (epoch 262): Average loss: 0.3680, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.178040 (avg: 0.178040) \tsec/iter: 0.0329\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.208748 (avg: 0.259290) \tsec/iter: 0.0306\n",
      "Test set (epoch 263): Average loss: 0.3885, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.224281 (avg: 0.224281) \tsec/iter: 0.0369\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.301696 (avg: 0.249769) \tsec/iter: 0.0316\n",
      "Test set (epoch 264): Average loss: 0.3196, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.298820 (avg: 0.298820) \tsec/iter: 0.0309\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.207457 (avg: 0.267290) \tsec/iter: 0.0306\n",
      "Test set (epoch 265): Average loss: 0.2216, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.280369 (avg: 0.280369) \tsec/iter: 0.0309\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.098665 (avg: 0.219983) \tsec/iter: 0.0319\n",
      "Test set (epoch 266): Average loss: 0.3500, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.221838 (avg: 0.221838) \tsec/iter: 0.0389\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.237836 (avg: 0.246275) \tsec/iter: 0.0312\n",
      "Test set (epoch 267): Average loss: 0.2891, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.240418 (avg: 0.240418) \tsec/iter: 0.0349\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.248345 (avg: 0.239585) \tsec/iter: 0.0352\n",
      "Test set (epoch 268): Average loss: 0.3219, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.221301 (avg: 0.221301) \tsec/iter: 0.0389\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.222204 (avg: 0.239622) \tsec/iter: 0.0339\n",
      "Test set (epoch 269): Average loss: 0.3400, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.293728 (avg: 0.293728) \tsec/iter: 0.0369\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.226919 (avg: 0.290435) \tsec/iter: 0.0326\n",
      "Test set (epoch 270): Average loss: 0.2797, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.163832 (avg: 0.163832) \tsec/iter: 0.0349\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.304932 (avg: 0.227596) \tsec/iter: 0.0329\n",
      "Test set (epoch 271): Average loss: 0.2615, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.217448 (avg: 0.217448) \tsec/iter: 0.0369\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.306795 (avg: 0.251198) \tsec/iter: 0.0339\n",
      "Test set (epoch 272): Average loss: 0.3259, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.217233 (avg: 0.217233) \tsec/iter: 0.0329\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.276337 (avg: 0.245142) \tsec/iter: 0.0303\n",
      "Test set (epoch 273): Average loss: 0.3004, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.288063 (avg: 0.288063) \tsec/iter: 0.0309\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.285911 (avg: 0.282109) \tsec/iter: 0.0293\n",
      "Test set (epoch 274): Average loss: 0.3551, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.160052 (avg: 0.160052) \tsec/iter: 0.0359\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.203026 (avg: 0.219597) \tsec/iter: 0.0299\n",
      "Test set (epoch 275): Average loss: 0.3421, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.298886 (avg: 0.298886) \tsec/iter: 0.0349\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.204605 (avg: 0.245230) \tsec/iter: 0.0306\n",
      "Test set (epoch 276): Average loss: 0.3764, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.168502 (avg: 0.168502) \tsec/iter: 0.0409\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.224064 (avg: 0.235209) \tsec/iter: 0.0366\n",
      "Test set (epoch 277): Average loss: 0.3359, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.194199 (avg: 0.194199) \tsec/iter: 0.0379\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.293287 (avg: 0.213490) \tsec/iter: 0.0386\n",
      "Test set (epoch 278): Average loss: 0.2633, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.249473 (avg: 0.249473) \tsec/iter: 0.0399\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.186332 (avg: 0.239732) \tsec/iter: 0.0316\n",
      "Test set (epoch 279): Average loss: 0.2272, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.172017 (avg: 0.172017) \tsec/iter: 0.0309\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.462601 (avg: 0.281069) \tsec/iter: 0.0316\n",
      "Test set (epoch 280): Average loss: 0.3046, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.337106 (avg: 0.337106) \tsec/iter: 0.0329\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.367303 (avg: 0.299911) \tsec/iter: 0.0316\n",
      "Test set (epoch 281): Average loss: 0.3245, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.192870 (avg: 0.192870) \tsec/iter: 0.0369\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.229799 (avg: 0.280740) \tsec/iter: 0.0329\n",
      "Test set (epoch 282): Average loss: 0.4114, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.245917 (avg: 0.245917) \tsec/iter: 0.0289\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.257578 (avg: 0.257596) \tsec/iter: 0.0273\n",
      "Test set (epoch 283): Average loss: 0.3914, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.161633 (avg: 0.161633) \tsec/iter: 0.0309\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.273298 (avg: 0.188663) \tsec/iter: 0.0279\n",
      "Test set (epoch 284): Average loss: 0.3257, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.239534 (avg: 0.239534) \tsec/iter: 0.0349\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.250998 (avg: 0.229773) \tsec/iter: 0.0296\n",
      "Test set (epoch 285): Average loss: 0.3105, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.155239 (avg: 0.155239) \tsec/iter: 0.0389\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.151480 (avg: 0.224493) \tsec/iter: 0.0309\n",
      "Test set (epoch 286): Average loss: 0.4029, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.181220 (avg: 0.181220) \tsec/iter: 0.0359\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.227737 (avg: 0.195520) \tsec/iter: 0.0346\n",
      "Test set (epoch 287): Average loss: 0.3107, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.220431 (avg: 0.220431) \tsec/iter: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.213332 (avg: 0.229580) \tsec/iter: 0.0336\n",
      "Test set (epoch 288): Average loss: 0.2562, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.209445 (avg: 0.209445) \tsec/iter: 0.0309\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.307677 (avg: 0.241050) \tsec/iter: 0.0289\n",
      "Test set (epoch 289): Average loss: 0.2345, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.170776 (avg: 0.170776) \tsec/iter: 0.0359\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.271539 (avg: 0.247937) \tsec/iter: 0.0326\n",
      "Test set (epoch 290): Average loss: 0.3164, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.155238 (avg: 0.155238) \tsec/iter: 0.0349\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.269902 (avg: 0.216313) \tsec/iter: 0.0322\n",
      "Test set (epoch 291): Average loss: 0.2505, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.316691 (avg: 0.316691) \tsec/iter: 0.0359\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.270940 (avg: 0.248486) \tsec/iter: 0.0316\n",
      "Test set (epoch 292): Average loss: 0.2756, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.271399 (avg: 0.271399) \tsec/iter: 0.0339\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.355529 (avg: 0.279874) \tsec/iter: 0.0329\n",
      "Test set (epoch 293): Average loss: 0.2941, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.158702 (avg: 0.158702) \tsec/iter: 0.0309\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.148832 (avg: 0.216969) \tsec/iter: 0.0306\n",
      "Test set (epoch 294): Average loss: 0.3475, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.183127 (avg: 0.183127) \tsec/iter: 0.0319\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.185474 (avg: 0.221308) \tsec/iter: 0.0303\n",
      "Test set (epoch 295): Average loss: 0.2337, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.218039 (avg: 0.218039) \tsec/iter: 0.0309\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.190662 (avg: 0.226446) \tsec/iter: 0.0306\n",
      "Test set (epoch 296): Average loss: 0.3082, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.173764 (avg: 0.173764) \tsec/iter: 0.0389\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.376573 (avg: 0.245109) \tsec/iter: 0.0356\n",
      "Test set (epoch 297): Average loss: 0.4693, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.334580 (avg: 0.334580) \tsec/iter: 0.0409\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.166011 (avg: 0.243013) \tsec/iter: 0.0329\n",
      "Test set (epoch 298): Average loss: 0.2917, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.258150 (avg: 0.258150) \tsec/iter: 0.0319\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.306659 (avg: 0.279523) \tsec/iter: 0.0293\n",
      "Test set (epoch 299): Average loss: 0.3218, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.236687 (avg: 0.236687) \tsec/iter: 0.0329\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.208041 (avg: 0.236583) \tsec/iter: 0.0306\n",
      "Test set (epoch 300): Average loss: 0.2648, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.222993 (avg: 0.222993) \tsec/iter: 0.0339\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.191179 (avg: 0.217038) \tsec/iter: 0.0322\n",
      "Test set (epoch 301): Average loss: 0.3719, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.218302 (avg: 0.218302) \tsec/iter: 0.0349\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.209865 (avg: 0.221070) \tsec/iter: 0.0326\n",
      "Test set (epoch 302): Average loss: 0.3923, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.199855 (avg: 0.199855) \tsec/iter: 0.0319\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.328388 (avg: 0.214658) \tsec/iter: 0.0303\n",
      "Test set (epoch 303): Average loss: 0.3273, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.268668 (avg: 0.268668) \tsec/iter: 0.0319\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.211838 (avg: 0.215733) \tsec/iter: 0.0329\n",
      "Test set (epoch 304): Average loss: 0.3207, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.219430 (avg: 0.219430) \tsec/iter: 0.0339\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.167077 (avg: 0.212899) \tsec/iter: 0.0306\n",
      "Test set (epoch 305): Average loss: 0.4603, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.274995 (avg: 0.274995) \tsec/iter: 0.0349\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.184443 (avg: 0.236523) \tsec/iter: 0.0359\n",
      "Test set (epoch 306): Average loss: 0.3486, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.190392 (avg: 0.190392) \tsec/iter: 0.0389\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.416094 (avg: 0.271601) \tsec/iter: 0.0372\n",
      "Test set (epoch 307): Average loss: 0.3249, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.276719 (avg: 0.276719) \tsec/iter: 0.0319\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.324043 (avg: 0.243826) \tsec/iter: 0.0299\n",
      "Test set (epoch 308): Average loss: 0.3176, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.200957 (avg: 0.200957) \tsec/iter: 0.0319\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.158330 (avg: 0.197888) \tsec/iter: 0.0303\n",
      "Test set (epoch 309): Average loss: 0.2495, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.190041 (avg: 0.190041) \tsec/iter: 0.0349\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.258078 (avg: 0.212016) \tsec/iter: 0.0316\n",
      "Test set (epoch 310): Average loss: 0.2571, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.159809 (avg: 0.159809) \tsec/iter: 0.0339\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.199104 (avg: 0.210793) \tsec/iter: 0.0329\n",
      "Test set (epoch 311): Average loss: 0.3299, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.189338 (avg: 0.189338) \tsec/iter: 0.0319\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.250553 (avg: 0.221057) \tsec/iter: 0.0296\n",
      "Test set (epoch 312): Average loss: 0.2276, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.225915 (avg: 0.225915) \tsec/iter: 0.0319\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.198543 (avg: 0.209520) \tsec/iter: 0.0293\n",
      "Test set (epoch 313): Average loss: 0.2511, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.172183 (avg: 0.172183) \tsec/iter: 0.0329\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.225617 (avg: 0.255166) \tsec/iter: 0.0309\n",
      "Test set (epoch 314): Average loss: 0.4982, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.307971 (avg: 0.307971) \tsec/iter: 0.0339\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.229819 (avg: 0.254618) \tsec/iter: 0.0299\n",
      "Test set (epoch 315): Average loss: 0.3131, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.314260 (avg: 0.314260) \tsec/iter: 0.0389\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.103151 (avg: 0.224248) \tsec/iter: 0.0379\n",
      "Test set (epoch 316): Average loss: 0.4125, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.150556 (avg: 0.150556) \tsec/iter: 0.0409\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.235096 (avg: 0.224700) \tsec/iter: 0.0359\n",
      "Test set (epoch 317): Average loss: 0.4163, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.307832 (avg: 0.307832) \tsec/iter: 0.0359\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.183900 (avg: 0.212102) \tsec/iter: 0.0316\n",
      "Test set (epoch 318): Average loss: 0.2866, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.228180 (avg: 0.228180) \tsec/iter: 0.0329\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.217292 (avg: 0.267984) \tsec/iter: 0.0296\n",
      "Test set (epoch 319): Average loss: 0.2602, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.211885 (avg: 0.211885) \tsec/iter: 0.0309\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.209212 (avg: 0.232189) \tsec/iter: 0.0306\n",
      "Test set (epoch 320): Average loss: 0.3631, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.191513 (avg: 0.191513) \tsec/iter: 0.0349\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.134737 (avg: 0.219825) \tsec/iter: 0.0326\n",
      "Test set (epoch 321): Average loss: 0.2572, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.243183 (avg: 0.243183) \tsec/iter: 0.0349\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.265992 (avg: 0.227915) \tsec/iter: 0.0316\n",
      "Test set (epoch 322): Average loss: 0.2139, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.217479 (avg: 0.217479) \tsec/iter: 0.0349\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.169999 (avg: 0.197366) \tsec/iter: 0.0309\n",
      "Test set (epoch 323): Average loss: 0.3718, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.235871 (avg: 0.235871) \tsec/iter: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.184683 (avg: 0.206417) \tsec/iter: 0.0276\n",
      "Test set (epoch 324): Average loss: 0.4148, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.128984 (avg: 0.128984) \tsec/iter: 0.0379\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.174965 (avg: 0.184888) \tsec/iter: 0.0329\n",
      "Test set (epoch 325): Average loss: 0.2636, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.200121 (avg: 0.200121) \tsec/iter: 0.0399\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.275902 (avg: 0.232302) \tsec/iter: 0.0392\n",
      "Test set (epoch 326): Average loss: 0.3644, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.169832 (avg: 0.169832) \tsec/iter: 0.0379\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.179396 (avg: 0.216257) \tsec/iter: 0.0319\n",
      "Test set (epoch 327): Average loss: 0.4436, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.231907 (avg: 0.231907) \tsec/iter: 0.0349\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.121680 (avg: 0.190422) \tsec/iter: 0.0306\n",
      "Test set (epoch 328): Average loss: 0.3188, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.175391 (avg: 0.175391) \tsec/iter: 0.0309\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.160709 (avg: 0.180786) \tsec/iter: 0.0312\n",
      "Test set (epoch 329): Average loss: 0.4405, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.220824 (avg: 0.220824) \tsec/iter: 0.0359\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.185170 (avg: 0.226020) \tsec/iter: 0.0329\n",
      "Test set (epoch 330): Average loss: 0.2646, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.311226 (avg: 0.311226) \tsec/iter: 0.0429\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.273517 (avg: 0.234356) \tsec/iter: 0.0359\n",
      "Test set (epoch 331): Average loss: 0.2845, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.183986 (avg: 0.183986) \tsec/iter: 0.0369\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.177879 (avg: 0.195971) \tsec/iter: 0.0326\n",
      "Test set (epoch 332): Average loss: 0.3982, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.164354 (avg: 0.164354) \tsec/iter: 0.0329\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.150079 (avg: 0.195902) \tsec/iter: 0.0296\n",
      "Test set (epoch 333): Average loss: 0.4071, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.177428 (avg: 0.177428) \tsec/iter: 0.0319\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.367934 (avg: 0.269200) \tsec/iter: 0.0296\n",
      "Test set (epoch 334): Average loss: 0.2290, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.208370 (avg: 0.208370) \tsec/iter: 0.0359\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.312229 (avg: 0.254545) \tsec/iter: 0.0346\n",
      "Test set (epoch 335): Average loss: 0.3583, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.202769 (avg: 0.202769) \tsec/iter: 0.0369\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.279827 (avg: 0.219660) \tsec/iter: 0.0332\n",
      "Test set (epoch 336): Average loss: 0.4439, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.224383 (avg: 0.224383) \tsec/iter: 0.0389\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.172095 (avg: 0.213648) \tsec/iter: 0.0306\n",
      "Test set (epoch 337): Average loss: 0.3680, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.174217 (avg: 0.174217) \tsec/iter: 0.0309\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.262950 (avg: 0.251368) \tsec/iter: 0.0293\n",
      "Test set (epoch 338): Average loss: 0.2670, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.313726 (avg: 0.313726) \tsec/iter: 0.0349\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.152111 (avg: 0.220328) \tsec/iter: 0.0303\n",
      "Test set (epoch 339): Average loss: 0.3657, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.203152 (avg: 0.203152) \tsec/iter: 0.0319\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.167902 (avg: 0.210190) \tsec/iter: 0.0299\n",
      "Test set (epoch 340): Average loss: 0.1690, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.248742 (avg: 0.248742) \tsec/iter: 0.0339\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.202875 (avg: 0.204505) \tsec/iter: 0.0326\n",
      "Test set (epoch 341): Average loss: 0.3130, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.216183 (avg: 0.216183) \tsec/iter: 0.0349\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.177160 (avg: 0.182937) \tsec/iter: 0.0329\n",
      "Test set (epoch 342): Average loss: 0.2374, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.203828 (avg: 0.203828) \tsec/iter: 0.0319\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.247553 (avg: 0.200316) \tsec/iter: 0.0299\n",
      "Test set (epoch 343): Average loss: 0.2617, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.223873 (avg: 0.223873) \tsec/iter: 0.0319\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.281299 (avg: 0.243114) \tsec/iter: 0.0306\n",
      "Test set (epoch 344): Average loss: 0.3871, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.242929 (avg: 0.242929) \tsec/iter: 0.0439\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.194111 (avg: 0.208269) \tsec/iter: 0.0389\n",
      "Test set (epoch 345): Average loss: 0.1753, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.161080 (avg: 0.161080) \tsec/iter: 0.0389\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.278168 (avg: 0.205677) \tsec/iter: 0.0342\n",
      "Test set (epoch 346): Average loss: 0.3240, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.171361 (avg: 0.171361) \tsec/iter: 0.0369\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.281211 (avg: 0.199114) \tsec/iter: 0.0312\n",
      "Test set (epoch 347): Average loss: 0.1588, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.152344 (avg: 0.152344) \tsec/iter: 0.0319\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.157276 (avg: 0.211291) \tsec/iter: 0.0316\n",
      "Test set (epoch 348): Average loss: 0.5772, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.174812 (avg: 0.174812) \tsec/iter: 0.0339\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.202204 (avg: 0.215728) \tsec/iter: 0.0303\n",
      "Test set (epoch 349): Average loss: 0.2638, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.221669 (avg: 0.221669) \tsec/iter: 0.0379\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.172299 (avg: 0.224453) \tsec/iter: 0.0316\n",
      "Test set (epoch 350): Average loss: 0.5427, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.278317 (avg: 0.278317) \tsec/iter: 0.0299\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.104834 (avg: 0.227284) \tsec/iter: 0.0303\n",
      "Test set (epoch 351): Average loss: 0.3847, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.281530 (avg: 0.281530) \tsec/iter: 0.0359\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.188418 (avg: 0.218508) \tsec/iter: 0.0319\n",
      "Test set (epoch 352): Average loss: 0.2569, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.186197 (avg: 0.186197) \tsec/iter: 0.0299\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.203242 (avg: 0.208734) \tsec/iter: 0.0279\n",
      "Test set (epoch 353): Average loss: 0.4987, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.206675 (avg: 0.206675) \tsec/iter: 0.0329\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.226216 (avg: 0.206685) \tsec/iter: 0.0339\n",
      "Test set (epoch 354): Average loss: 0.2023, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.182876 (avg: 0.182876) \tsec/iter: 0.0369\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.231964 (avg: 0.227582) \tsec/iter: 0.0332\n",
      "Test set (epoch 355): Average loss: 0.3353, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.219406 (avg: 0.219406) \tsec/iter: 0.0369\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.145938 (avg: 0.212086) \tsec/iter: 0.0336\n",
      "Test set (epoch 356): Average loss: 0.4105, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.162983 (avg: 0.162983) \tsec/iter: 0.0319\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.307701 (avg: 0.235907) \tsec/iter: 0.0296\n",
      "Test set (epoch 357): Average loss: 0.3910, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.226324 (avg: 0.226324) \tsec/iter: 0.0359\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.228073 (avg: 0.211074) \tsec/iter: 0.0342\n",
      "Test set (epoch 358): Average loss: 0.4099, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.128530 (avg: 0.128530) \tsec/iter: 0.0309\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.319731 (avg: 0.176460) \tsec/iter: 0.0283\n",
      "Test set (epoch 359): Average loss: 0.3751, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.171114 (avg: 0.171114) \tsec/iter: 0.0359\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.276300 (avg: 0.235164) \tsec/iter: 0.0329\n",
      "Test set (epoch 360): Average loss: 0.3636, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.169749 (avg: 0.169749) \tsec/iter: 0.0339\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.296389 (avg: 0.184609) \tsec/iter: 0.0319\n",
      "Test set (epoch 361): Average loss: 0.2716, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.238613 (avg: 0.238613) \tsec/iter: 0.0369\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.237598 (avg: 0.207451) \tsec/iter: 0.0336\n",
      "Test set (epoch 362): Average loss: 0.3611, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.294934 (avg: 0.294934) \tsec/iter: 0.0389\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.125412 (avg: 0.253069) \tsec/iter: 0.0326\n",
      "Test set (epoch 363): Average loss: 0.3425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.158764 (avg: 0.158764) \tsec/iter: 0.0379\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.345346 (avg: 0.271708) \tsec/iter: 0.0356\n",
      "Test set (epoch 364): Average loss: 0.2885, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.190653 (avg: 0.190653) \tsec/iter: 0.0379\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.203510 (avg: 0.188086) \tsec/iter: 0.0332\n",
      "Test set (epoch 365): Average loss: 0.2690, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.195942 (avg: 0.195942) \tsec/iter: 0.0319\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.251855 (avg: 0.221260) \tsec/iter: 0.0332\n",
      "Test set (epoch 366): Average loss: 0.4600, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.165224 (avg: 0.165224) \tsec/iter: 0.0379\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.266768 (avg: 0.223299) \tsec/iter: 0.0329\n",
      "Test set (epoch 367): Average loss: 0.2358, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.143610 (avg: 0.143610) \tsec/iter: 0.0319\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.265022 (avg: 0.189156) \tsec/iter: 0.0309\n",
      "Test set (epoch 368): Average loss: 0.3014, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.214198 (avg: 0.214198) \tsec/iter: 0.0289\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.234684 (avg: 0.210681) \tsec/iter: 0.0293\n",
      "Test set (epoch 369): Average loss: 0.2236, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.206533 (avg: 0.206533) \tsec/iter: 0.0349\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.234652 (avg: 0.223555) \tsec/iter: 0.0312\n",
      "Test set (epoch 370): Average loss: 0.3631, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.207765 (avg: 0.207765) \tsec/iter: 0.0319\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.233098 (avg: 0.188975) \tsec/iter: 0.0312\n",
      "Test set (epoch 371): Average loss: 0.3731, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.198030 (avg: 0.198030) \tsec/iter: 0.0409\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.246706 (avg: 0.220458) \tsec/iter: 0.0342\n",
      "Test set (epoch 372): Average loss: 0.2363, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.187160 (avg: 0.187160) \tsec/iter: 0.0369\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.242653 (avg: 0.231544) \tsec/iter: 0.0346\n",
      "Test set (epoch 373): Average loss: 0.4100, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.379914 (avg: 0.379914) \tsec/iter: 0.0379\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.159115 (avg: 0.239321) \tsec/iter: 0.0339\n",
      "Test set (epoch 374): Average loss: 0.3011, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.199205 (avg: 0.199205) \tsec/iter: 0.0329\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.327818 (avg: 0.207206) \tsec/iter: 0.0319\n",
      "Test set (epoch 375): Average loss: 0.2151, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.232100 (avg: 0.232100) \tsec/iter: 0.0329\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.141006 (avg: 0.187821) \tsec/iter: 0.0339\n",
      "Test set (epoch 376): Average loss: 0.2096, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.172403 (avg: 0.172403) \tsec/iter: 0.0359\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.200975 (avg: 0.209056) \tsec/iter: 0.0342\n",
      "Test set (epoch 377): Average loss: 0.2189, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.235722 (avg: 0.235722) \tsec/iter: 0.0359\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.158219 (avg: 0.187913) \tsec/iter: 0.0312\n",
      "Test set (epoch 378): Average loss: 0.2792, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.217297 (avg: 0.217297) \tsec/iter: 0.0309\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.144868 (avg: 0.211800) \tsec/iter: 0.0296\n",
      "Test set (epoch 379): Average loss: 0.3538, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.179574 (avg: 0.179574) \tsec/iter: 0.0299\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.190286 (avg: 0.198370) \tsec/iter: 0.0296\n",
      "Test set (epoch 380): Average loss: 0.1528, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.110778 (avg: 0.110778) \tsec/iter: 0.0309\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.215176 (avg: 0.203652) \tsec/iter: 0.0306\n",
      "Test set (epoch 381): Average loss: 0.3630, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.209662 (avg: 0.209662) \tsec/iter: 0.0369\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.200993 (avg: 0.194750) \tsec/iter: 0.0319\n",
      "Test set (epoch 382): Average loss: 0.3146, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.124526 (avg: 0.124526) \tsec/iter: 0.0419\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.306253 (avg: 0.206434) \tsec/iter: 0.0376\n",
      "Test set (epoch 383): Average loss: 0.2789, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.229711 (avg: 0.229711) \tsec/iter: 0.0319\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.134200 (avg: 0.189671) \tsec/iter: 0.0296\n",
      "Test set (epoch 384): Average loss: 0.3782, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.197706 (avg: 0.197706) \tsec/iter: 0.0369\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.339181 (avg: 0.223094) \tsec/iter: 0.0349\n",
      "Test set (epoch 385): Average loss: 0.3565, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.196950 (avg: 0.196950) \tsec/iter: 0.0329\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.199023 (avg: 0.183958) \tsec/iter: 0.0312\n",
      "Test set (epoch 386): Average loss: 0.2680, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.160045 (avg: 0.160045) \tsec/iter: 0.0329\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.218567 (avg: 0.234161) \tsec/iter: 0.0313\n",
      "Test set (epoch 387): Average loss: 0.2772, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.127837 (avg: 0.127837) \tsec/iter: 0.0349\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.228492 (avg: 0.182249) \tsec/iter: 0.0312\n",
      "Test set (epoch 388): Average loss: 0.2856, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.194433 (avg: 0.194433) \tsec/iter: 0.0319\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.070265 (avg: 0.165745) \tsec/iter: 0.0322\n",
      "Test set (epoch 389): Average loss: 0.3377, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.152855 (avg: 0.152855) \tsec/iter: 0.0299\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.125750 (avg: 0.192374) \tsec/iter: 0.0289\n",
      "Test set (epoch 390): Average loss: 0.3112, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.223809 (avg: 0.223809) \tsec/iter: 0.0349\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.183232 (avg: 0.189657) \tsec/iter: 0.0322\n",
      "Test set (epoch 391): Average loss: 0.3304, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.164938 (avg: 0.164938) \tsec/iter: 0.0419\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.169062 (avg: 0.204155) \tsec/iter: 0.0372\n",
      "Test set (epoch 392): Average loss: 0.2324, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.210324 (avg: 0.210324) \tsec/iter: 0.0429\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.098016 (avg: 0.181490) \tsec/iter: 0.0342\n",
      "Test set (epoch 393): Average loss: 0.5032, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.196183 (avg: 0.196183) \tsec/iter: 0.0309\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.211769 (avg: 0.192326) \tsec/iter: 0.0286\n",
      "Test set (epoch 394): Average loss: 0.3029, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.218640 (avg: 0.218640) \tsec/iter: 0.0339\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.378865 (avg: 0.226047) \tsec/iter: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 395): Average loss: 0.5405, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.174928 (avg: 0.174928) \tsec/iter: 0.0309\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.209134 (avg: 0.186511) \tsec/iter: 0.0312\n",
      "Test set (epoch 396): Average loss: 0.2655, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.288390 (avg: 0.288390) \tsec/iter: 0.0339\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.215572 (avg: 0.207357) \tsec/iter: 0.0316\n",
      "Test set (epoch 397): Average loss: 0.4867, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.225768 (avg: 0.225768) \tsec/iter: 0.0369\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.251552 (avg: 0.214431) \tsec/iter: 0.0326\n",
      "Test set (epoch 398): Average loss: 0.3998, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.186369 (avg: 0.186369) \tsec/iter: 0.0409\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.190007 (avg: 0.174899) \tsec/iter: 0.0349\n",
      "Test set (epoch 399): Average loss: 0.4095, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.228260 (avg: 0.228260) \tsec/iter: 0.0299\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.114695 (avg: 0.191775) \tsec/iter: 0.0299\n",
      "Test set (epoch 400): Average loss: 0.5397, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.208836 (avg: 0.208836) \tsec/iter: 0.0319\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.229600 (avg: 0.172792) \tsec/iter: 0.0319\n",
      "Test set (epoch 401): Average loss: 0.2781, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.122964 (avg: 0.122964) \tsec/iter: 0.0439\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.364019 (avg: 0.200557) \tsec/iter: 0.0379\n",
      "Test set (epoch 402): Average loss: 0.3388, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.183508 (avg: 0.183508) \tsec/iter: 0.0359\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.187925 (avg: 0.180271) \tsec/iter: 0.0319\n",
      "Test set (epoch 403): Average loss: 0.4381, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.171557 (avg: 0.171557) \tsec/iter: 0.0319\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.143330 (avg: 0.183477) \tsec/iter: 0.0296\n",
      "Test set (epoch 404): Average loss: 0.2543, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.155487 (avg: 0.155487) \tsec/iter: 0.0369\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.174753 (avg: 0.228133) \tsec/iter: 0.0322\n",
      "Test set (epoch 405): Average loss: 0.4611, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.296012 (avg: 0.296012) \tsec/iter: 0.0399\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.295459 (avg: 0.251723) \tsec/iter: 0.0329\n",
      "Test set (epoch 406): Average loss: 0.2948, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.201473 (avg: 0.201473) \tsec/iter: 0.0309\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.347918 (avg: 0.225984) \tsec/iter: 0.0316\n",
      "Test set (epoch 407): Average loss: 0.4353, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.316579 (avg: 0.316579) \tsec/iter: 0.0329\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.215462 (avg: 0.244623) \tsec/iter: 0.0299\n",
      "Test set (epoch 408): Average loss: 0.3822, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.169318 (avg: 0.169318) \tsec/iter: 0.0329\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.105391 (avg: 0.189252) \tsec/iter: 0.0303\n",
      "Test set (epoch 409): Average loss: 0.2970, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.154723 (avg: 0.154723) \tsec/iter: 0.0349\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.131301 (avg: 0.183651) \tsec/iter: 0.0306\n",
      "Test set (epoch 410): Average loss: 0.5041, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.202908 (avg: 0.202908) \tsec/iter: 0.0369\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.130475 (avg: 0.177472) \tsec/iter: 0.0356\n",
      "Test set (epoch 411): Average loss: 0.2917, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.190897 (avg: 0.190897) \tsec/iter: 0.0439\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.147261 (avg: 0.174977) \tsec/iter: 0.0376\n",
      "Test set (epoch 412): Average loss: 0.1877, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.119634 (avg: 0.119634) \tsec/iter: 0.0369\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.223860 (avg: 0.195428) \tsec/iter: 0.0322\n",
      "Test set (epoch 413): Average loss: 0.4349, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.097167 (avg: 0.097167) \tsec/iter: 0.0329\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.238589 (avg: 0.213069) \tsec/iter: 0.0309\n",
      "Test set (epoch 414): Average loss: 0.3327, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.154149 (avg: 0.154149) \tsec/iter: 0.0369\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.256679 (avg: 0.223772) \tsec/iter: 0.0319\n",
      "Test set (epoch 415): Average loss: 0.3841, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.157298 (avg: 0.157298) \tsec/iter: 0.0359\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.209728 (avg: 0.189777) \tsec/iter: 0.0316\n",
      "Test set (epoch 416): Average loss: 0.2060, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.157347 (avg: 0.157347) \tsec/iter: 0.0329\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.119277 (avg: 0.176583) \tsec/iter: 0.0312\n",
      "Test set (epoch 417): Average loss: 0.3746, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.193985 (avg: 0.193985) \tsec/iter: 0.0359\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.273793 (avg: 0.208516) \tsec/iter: 0.0303\n",
      "Test set (epoch 418): Average loss: 0.3158, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.245153 (avg: 0.245153) \tsec/iter: 0.0309\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.121896 (avg: 0.183461) \tsec/iter: 0.0296\n",
      "Test set (epoch 419): Average loss: 0.1504, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.140547 (avg: 0.140547) \tsec/iter: 0.0349\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.198748 (avg: 0.178821) \tsec/iter: 0.0326\n",
      "Test set (epoch 420): Average loss: 0.2839, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.208349 (avg: 0.208349) \tsec/iter: 0.0429\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.089465 (avg: 0.159338) \tsec/iter: 0.0389\n",
      "Test set (epoch 421): Average loss: 0.2031, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.252578 (avg: 0.252578) \tsec/iter: 0.0349\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.170264 (avg: 0.235976) \tsec/iter: 0.0306\n",
      "Test set (epoch 422): Average loss: 0.2526, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.127400 (avg: 0.127400) \tsec/iter: 0.0339\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.143019 (avg: 0.170769) \tsec/iter: 0.0329\n",
      "Test set (epoch 423): Average loss: 0.5241, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.217896 (avg: 0.217896) \tsec/iter: 0.0339\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.106599 (avg: 0.173273) \tsec/iter: 0.0322\n",
      "Test set (epoch 424): Average loss: 0.4074, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.222348 (avg: 0.222348) \tsec/iter: 0.0359\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.186371 (avg: 0.186900) \tsec/iter: 0.0356\n",
      "Test set (epoch 425): Average loss: 0.2929, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.233399 (avg: 0.233399) \tsec/iter: 0.0359\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.188340 (avg: 0.197879) \tsec/iter: 0.0309\n",
      "Test set (epoch 426): Average loss: 0.3405, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.148720 (avg: 0.148720) \tsec/iter: 0.0349\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.396274 (avg: 0.227990) \tsec/iter: 0.0312\n",
      "Test set (epoch 427): Average loss: 0.3619, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.396706 (avg: 0.396706) \tsec/iter: 0.0339\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.275895 (avg: 0.275299) \tsec/iter: 0.0303\n",
      "Test set (epoch 428): Average loss: 0.3451, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.228374 (avg: 0.228374) \tsec/iter: 0.0319\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.048546 (avg: 0.181890) \tsec/iter: 0.0299\n",
      "Test set (epoch 429): Average loss: 0.3181, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.178740 (avg: 0.178740) \tsec/iter: 0.0479\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.243258 (avg: 0.170577) \tsec/iter: 0.0412\n",
      "Test set (epoch 430): Average loss: 0.2370, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.228247 (avg: 0.228247) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.114002 (avg: 0.219227) \tsec/iter: 0.0379\n",
      "Test set (epoch 431): Average loss: 0.4969, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.164777 (avg: 0.164777) \tsec/iter: 0.0349\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.217773 (avg: 0.223380) \tsec/iter: 0.0299\n",
      "Test set (epoch 432): Average loss: 0.3160, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.222856 (avg: 0.222856) \tsec/iter: 0.0359\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.178484 (avg: 0.193655) \tsec/iter: 0.0336\n",
      "Test set (epoch 433): Average loss: 0.3871, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.217917 (avg: 0.217917) \tsec/iter: 0.0359\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.223442 (avg: 0.209982) \tsec/iter: 0.0309\n",
      "Test set (epoch 434): Average loss: 0.3316, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.249552 (avg: 0.249552) \tsec/iter: 0.0369\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.095675 (avg: 0.176062) \tsec/iter: 0.0306\n",
      "Test set (epoch 435): Average loss: 0.1997, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.154460 (avg: 0.154460) \tsec/iter: 0.0359\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.156012 (avg: 0.195110) \tsec/iter: 0.0309\n",
      "Test set (epoch 436): Average loss: 0.2646, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.196574 (avg: 0.196574) \tsec/iter: 0.0409\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.182406 (avg: 0.177704) \tsec/iter: 0.0349\n",
      "Test set (epoch 437): Average loss: 0.2290, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.185716 (avg: 0.185716) \tsec/iter: 0.0329\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.186804 (avg: 0.188410) \tsec/iter: 0.0319\n",
      "Test set (epoch 438): Average loss: 0.5237, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.202707 (avg: 0.202707) \tsec/iter: 0.0429\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.343058 (avg: 0.213053) \tsec/iter: 0.0392\n",
      "Test set (epoch 439): Average loss: 0.5517, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.267872 (avg: 0.267872) \tsec/iter: 0.0449\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.153231 (avg: 0.225221) \tsec/iter: 0.0346\n",
      "Test set (epoch 440): Average loss: 0.2091, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.177684 (avg: 0.177684) \tsec/iter: 0.0339\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.166648 (avg: 0.187255) \tsec/iter: 0.0336\n",
      "Test set (epoch 441): Average loss: 0.5048, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.228297 (avg: 0.228297) \tsec/iter: 0.0329\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.109205 (avg: 0.188171) \tsec/iter: 0.0312\n",
      "Test set (epoch 442): Average loss: 0.4665, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.233915 (avg: 0.233915) \tsec/iter: 0.0379\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.187120 (avg: 0.208519) \tsec/iter: 0.0336\n",
      "Test set (epoch 443): Average loss: 0.3664, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.236138 (avg: 0.236138) \tsec/iter: 0.0319\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.262722 (avg: 0.208593) \tsec/iter: 0.0316\n",
      "Test set (epoch 444): Average loss: 0.5771, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.229871 (avg: 0.229871) \tsec/iter: 0.0329\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.134830 (avg: 0.207736) \tsec/iter: 0.0309\n",
      "Test set (epoch 445): Average loss: 0.2959, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.139172 (avg: 0.139172) \tsec/iter: 0.0339\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.288891 (avg: 0.173310) \tsec/iter: 0.0316\n",
      "Test set (epoch 446): Average loss: 0.3327, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.222213 (avg: 0.222213) \tsec/iter: 0.0359\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.140477 (avg: 0.202404) \tsec/iter: 0.0329\n",
      "Test set (epoch 447): Average loss: 0.3335, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.171825 (avg: 0.171825) \tsec/iter: 0.0329\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.194938 (avg: 0.157301) \tsec/iter: 0.0336\n",
      "Test set (epoch 448): Average loss: 0.3660, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.210175 (avg: 0.210175) \tsec/iter: 0.0429\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.122806 (avg: 0.169600) \tsec/iter: 0.0376\n",
      "Test set (epoch 449): Average loss: 0.2430, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.166710 (avg: 0.166710) \tsec/iter: 0.0369\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.153640 (avg: 0.165343) \tsec/iter: 0.0319\n",
      "Test set (epoch 450): Average loss: 0.3669, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.291734 (avg: 0.291734) \tsec/iter: 0.0379\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.225937 (avg: 0.229568) \tsec/iter: 0.0322\n",
      "Test set (epoch 451): Average loss: 0.3775, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.251117 (avg: 0.251117) \tsec/iter: 0.0409\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.216116 (avg: 0.218847) \tsec/iter: 0.0336\n",
      "Test set (epoch 452): Average loss: 0.3082, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.250514 (avg: 0.250514) \tsec/iter: 0.0329\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.146286 (avg: 0.197943) \tsec/iter: 0.0322\n",
      "Test set (epoch 453): Average loss: 0.3112, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.122137 (avg: 0.122137) \tsec/iter: 0.0329\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.151550 (avg: 0.151463) \tsec/iter: 0.0326\n",
      "Test set (epoch 454): Average loss: 0.5695, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.187614 (avg: 0.187614) \tsec/iter: 0.0349\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.138981 (avg: 0.165793) \tsec/iter: 0.0326\n",
      "Test set (epoch 455): Average loss: 0.3764, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.193830 (avg: 0.193830) \tsec/iter: 0.0349\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.237163 (avg: 0.197928) \tsec/iter: 0.0326\n",
      "Test set (epoch 456): Average loss: 0.2417, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.173153 (avg: 0.173153) \tsec/iter: 0.0329\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.171226 (avg: 0.203960) \tsec/iter: 0.0316\n",
      "Test set (epoch 457): Average loss: 0.2346, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.179727 (avg: 0.179727) \tsec/iter: 0.0429\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.161412 (avg: 0.187289) \tsec/iter: 0.0372\n",
      "Test set (epoch 458): Average loss: 0.3661, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.201346 (avg: 0.201346) \tsec/iter: 0.0389\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.196377 (avg: 0.186579) \tsec/iter: 0.0346\n",
      "Test set (epoch 459): Average loss: 0.4429, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.217006 (avg: 0.217006) \tsec/iter: 0.0369\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.299550 (avg: 0.214023) \tsec/iter: 0.0329\n",
      "Test set (epoch 460): Average loss: 0.3449, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.207405 (avg: 0.207405) \tsec/iter: 0.0319\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.214739 (avg: 0.221385) \tsec/iter: 0.0296\n",
      "Test set (epoch 461): Average loss: 0.4044, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.151106 (avg: 0.151106) \tsec/iter: 0.0379\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.180577 (avg: 0.178501) \tsec/iter: 0.0309\n",
      "Test set (epoch 462): Average loss: 0.1927, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.221991 (avg: 0.221991) \tsec/iter: 0.0369\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.308594 (avg: 0.230328) \tsec/iter: 0.0332\n",
      "Test set (epoch 463): Average loss: 0.2672, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.208977 (avg: 0.208977) \tsec/iter: 0.0339\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.136784 (avg: 0.158534) \tsec/iter: 0.0316\n",
      "Test set (epoch 464): Average loss: 0.3683, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.130443 (avg: 0.130443) \tsec/iter: 0.0419\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.159514 (avg: 0.171803) \tsec/iter: 0.0369\n",
      "Test set (epoch 465): Average loss: 0.3499, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.198854 (avg: 0.198854) \tsec/iter: 0.0339\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.226678 (avg: 0.205386) \tsec/iter: 0.0309\n",
      "Test set (epoch 466): Average loss: 0.3072, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.266439 (avg: 0.266439) \tsec/iter: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.138941 (avg: 0.225121) \tsec/iter: 0.0372\n",
      "Test set (epoch 467): Average loss: 0.2626, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.162322 (avg: 0.162322) \tsec/iter: 0.0389\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.164596 (avg: 0.172263) \tsec/iter: 0.0329\n",
      "Test set (epoch 468): Average loss: 0.4346, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.184678 (avg: 0.184678) \tsec/iter: 0.0399\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.232016 (avg: 0.180005) \tsec/iter: 0.0356\n",
      "Test set (epoch 469): Average loss: 0.2167, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.160259 (avg: 0.160259) \tsec/iter: 0.0389\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.130121 (avg: 0.186673) \tsec/iter: 0.0339\n",
      "Test set (epoch 470): Average loss: 0.3436, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.212753 (avg: 0.212753) \tsec/iter: 0.0319\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.287662 (avg: 0.200569) \tsec/iter: 0.0316\n",
      "Test set (epoch 471): Average loss: 0.1853, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.262166 (avg: 0.262166) \tsec/iter: 0.0329\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.185472 (avg: 0.224506) \tsec/iter: 0.0296\n",
      "Test set (epoch 472): Average loss: 0.5298, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.168365 (avg: 0.168365) \tsec/iter: 0.0319\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.299743 (avg: 0.202929) \tsec/iter: 0.0303\n",
      "Test set (epoch 473): Average loss: 0.2289, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.232730 (avg: 0.232730) \tsec/iter: 0.0329\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.176526 (avg: 0.231118) \tsec/iter: 0.0336\n",
      "Test set (epoch 474): Average loss: 0.5400, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.080369 (avg: 0.080369) \tsec/iter: 0.0389\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.239216 (avg: 0.170064) \tsec/iter: 0.0326\n",
      "Test set (epoch 475): Average loss: 0.2905, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.273112 (avg: 0.273112) \tsec/iter: 0.0379\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.174332 (avg: 0.211027) \tsec/iter: 0.0356\n",
      "Test set (epoch 476): Average loss: 0.3783, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.096193 (avg: 0.096193) \tsec/iter: 0.0399\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.111450 (avg: 0.163960) \tsec/iter: 0.0352\n",
      "Test set (epoch 477): Average loss: 0.4549, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.208941 (avg: 0.208941) \tsec/iter: 0.0439\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.175931 (avg: 0.192799) \tsec/iter: 0.0369\n",
      "Test set (epoch 478): Average loss: 0.2211, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.199980 (avg: 0.199980) \tsec/iter: 0.0329\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.197216 (avg: 0.204253) \tsec/iter: 0.0312\n",
      "Test set (epoch 479): Average loss: 0.1718, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.253675 (avg: 0.253675) \tsec/iter: 0.0339\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.215100 (avg: 0.193599) \tsec/iter: 0.0309\n",
      "Test set (epoch 480): Average loss: 0.3721, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.113965 (avg: 0.113965) \tsec/iter: 0.0319\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.363260 (avg: 0.204924) \tsec/iter: 0.0309\n",
      "Test set (epoch 481): Average loss: 0.2765, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.194513 (avg: 0.194513) \tsec/iter: 0.0339\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.266717 (avg: 0.206013) \tsec/iter: 0.0329\n",
      "Test set (epoch 482): Average loss: 0.3001, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.236888 (avg: 0.236888) \tsec/iter: 0.0379\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.175498 (avg: 0.227830) \tsec/iter: 0.0329\n",
      "Test set (epoch 483): Average loss: 0.4226, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.190972 (avg: 0.190972) \tsec/iter: 0.0339\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.190242 (avg: 0.197218) \tsec/iter: 0.0322\n",
      "Test set (epoch 484): Average loss: 0.3260, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.190049 (avg: 0.190049) \tsec/iter: 0.0389\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.215558 (avg: 0.185451) \tsec/iter: 0.0369\n",
      "Test set (epoch 485): Average loss: 0.2739, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.126022 (avg: 0.126022) \tsec/iter: 0.0439\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.322692 (avg: 0.232057) \tsec/iter: 0.0379\n",
      "Test set (epoch 486): Average loss: 0.3456, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.171460 (avg: 0.171460) \tsec/iter: 0.0399\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.133635 (avg: 0.159982) \tsec/iter: 0.0336\n",
      "Test set (epoch 487): Average loss: 0.2613, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.158790 (avg: 0.158790) \tsec/iter: 0.0329\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.195592 (avg: 0.195083) \tsec/iter: 0.0316\n",
      "Test set (epoch 488): Average loss: 0.3692, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.216489 (avg: 0.216489) \tsec/iter: 0.0369\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.307508 (avg: 0.222591) \tsec/iter: 0.0346\n",
      "Test set (epoch 489): Average loss: 0.4813, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.202702 (avg: 0.202702) \tsec/iter: 0.0349\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.123996 (avg: 0.166390) \tsec/iter: 0.0322\n",
      "Test set (epoch 490): Average loss: 0.3964, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.237621 (avg: 0.237621) \tsec/iter: 0.0409\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.213834 (avg: 0.203570) \tsec/iter: 0.0366\n",
      "Test set (epoch 491): Average loss: 0.3656, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.155884 (avg: 0.155884) \tsec/iter: 0.0369\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.225022 (avg: 0.180166) \tsec/iter: 0.0342\n",
      "Test set (epoch 492): Average loss: 0.4709, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.209981 (avg: 0.209981) \tsec/iter: 0.0319\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.176706 (avg: 0.171838) \tsec/iter: 0.0309\n",
      "Test set (epoch 493): Average loss: 0.4788, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.162313 (avg: 0.162313) \tsec/iter: 0.0349\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.113382 (avg: 0.148671) \tsec/iter: 0.0379\n",
      "Test set (epoch 494): Average loss: 0.3191, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.227822 (avg: 0.227822) \tsec/iter: 0.0469\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.163272 (avg: 0.187474) \tsec/iter: 0.0382\n",
      "Test set (epoch 495): Average loss: 0.4465, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.138523 (avg: 0.138523) \tsec/iter: 0.0379\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.262634 (avg: 0.204889) \tsec/iter: 0.0339\n",
      "Test set (epoch 496): Average loss: 0.1747, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.154785 (avg: 0.154785) \tsec/iter: 0.0349\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.159966 (avg: 0.169864) \tsec/iter: 0.0309\n",
      "Test set (epoch 497): Average loss: 0.2412, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.147189 (avg: 0.147189) \tsec/iter: 0.0329\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.141444 (avg: 0.141391) \tsec/iter: 0.0339\n",
      "Test set (epoch 498): Average loss: 0.2993, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.163193 (avg: 0.163193) \tsec/iter: 0.0379\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.287770 (avg: 0.178508) \tsec/iter: 0.0342\n",
      "Test set (epoch 499): Average loss: 0.3510, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 3\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.448363 (avg: 1.448363) \tsec/iter: 0.0339\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 1.205171 (avg: 3.040908) \tsec/iter: 0.0303\n",
      "Test set (epoch 0): Average loss: 0.8246, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 4.346598 (avg: 4.346598) \tsec/iter: 0.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 1.845801 (avg: 2.463427) \tsec/iter: 0.0309\n",
      "Test set (epoch 1): Average loss: 0.2875, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.900965 (avg: 0.900965) \tsec/iter: 0.0329\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.658709 (avg: 0.886722) \tsec/iter: 0.0303\n",
      "Test set (epoch 2): Average loss: 0.2608, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 1.001905 (avg: 1.001905) \tsec/iter: 0.0349\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.545205 (avg: 0.963115) \tsec/iter: 0.0366\n",
      "Test set (epoch 3): Average loss: 0.2491, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.690903 (avg: 0.690903) \tsec/iter: 0.0459\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.201229 (avg: 0.499445) \tsec/iter: 0.0402\n",
      "Test set (epoch 4): Average loss: 0.8989, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 1.050813 (avg: 1.050813) \tsec/iter: 0.0409\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.251722 (avg: 0.763233) \tsec/iter: 0.0369\n",
      "Test set (epoch 5): Average loss: 1.9782, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.902266 (avg: 0.902266) \tsec/iter: 0.0339\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.884477 (avg: 0.760752) \tsec/iter: 0.0299\n",
      "Test set (epoch 6): Average loss: 0.8465, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.430107 (avg: 0.430107) \tsec/iter: 0.0349\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.467875 (avg: 0.454821) \tsec/iter: 0.0329\n",
      "Test set (epoch 7): Average loss: 0.5116, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.619159 (avg: 0.619159) \tsec/iter: 0.0349\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.443339 (avg: 0.494923) \tsec/iter: 0.0306\n",
      "Test set (epoch 8): Average loss: 0.4610, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.515901 (avg: 0.515901) \tsec/iter: 0.0319\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.435947 (avg: 0.477002) \tsec/iter: 0.0322\n",
      "Test set (epoch 9): Average loss: 1.1106, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.424462 (avg: 0.424462) \tsec/iter: 0.0349\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.361490 (avg: 0.406603) \tsec/iter: 0.0306\n",
      "Test set (epoch 10): Average loss: 0.8243, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.540715 (avg: 0.540715) \tsec/iter: 0.0379\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.302107 (avg: 0.411072) \tsec/iter: 0.0346\n",
      "Test set (epoch 11): Average loss: 1.3221, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.603456 (avg: 0.603456) \tsec/iter: 0.0329\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.257469 (avg: 0.518527) \tsec/iter: 0.0332\n",
      "Test set (epoch 12): Average loss: 0.9139, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.404265 (avg: 0.404265) \tsec/iter: 0.0429\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.398751 (avg: 0.477318) \tsec/iter: 0.0389\n",
      "Test set (epoch 13): Average loss: 0.5117, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.417055 (avg: 0.417055) \tsec/iter: 0.0379\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.405816 (avg: 0.442052) \tsec/iter: 0.0329\n",
      "Test set (epoch 14): Average loss: 0.7490, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.306345 (avg: 0.306345) \tsec/iter: 0.0309\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.560320 (avg: 0.403882) \tsec/iter: 0.0312\n",
      "Test set (epoch 15): Average loss: 0.9180, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.428053 (avg: 0.428053) \tsec/iter: 0.0309\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.382908 (avg: 0.394591) \tsec/iter: 0.0299\n",
      "Test set (epoch 16): Average loss: 0.6420, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.481568 (avg: 0.481568) \tsec/iter: 0.0389\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.473743 (avg: 0.505911) \tsec/iter: 0.0392\n",
      "Test set (epoch 17): Average loss: 0.4870, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.517128 (avg: 0.517128) \tsec/iter: 0.0409\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.444627 (avg: 0.472923) \tsec/iter: 0.0339\n",
      "Test set (epoch 18): Average loss: 0.4273, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.357056 (avg: 0.357056) \tsec/iter: 0.0379\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.373439 (avg: 0.360287) \tsec/iter: 0.0329\n",
      "Test set (epoch 19): Average loss: 0.6049, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.420993 (avg: 0.420993) \tsec/iter: 0.0339\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.254298 (avg: 0.396575) \tsec/iter: 0.0312\n",
      "Test set (epoch 20): Average loss: 0.5408, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.332302 (avg: 0.332302) \tsec/iter: 0.0369\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.420885 (avg: 0.416498) \tsec/iter: 0.0356\n",
      "Test set (epoch 21): Average loss: 0.6665, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.268095 (avg: 0.268095) \tsec/iter: 0.0419\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.460108 (avg: 0.422718) \tsec/iter: 0.0389\n",
      "Test set (epoch 22): Average loss: 0.4991, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.419477 (avg: 0.419477) \tsec/iter: 0.0479\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.428544 (avg: 0.378182) \tsec/iter: 0.0422\n",
      "Test set (epoch 23): Average loss: 0.4601, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.400141 (avg: 0.400141) \tsec/iter: 0.0529\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.453699 (avg: 0.414523) \tsec/iter: 0.0406\n",
      "Test set (epoch 24): Average loss: 0.5078, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.427818 (avg: 0.427818) \tsec/iter: 0.0359\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.344200 (avg: 0.396232) \tsec/iter: 0.0329\n",
      "Test set (epoch 25): Average loss: 0.6485, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.349897 (avg: 0.349897) \tsec/iter: 0.0362\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.366557 (avg: 0.361372) \tsec/iter: 0.0327\n",
      "Test set (epoch 26): Average loss: 0.3798, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.405019 (avg: 0.405019) \tsec/iter: 0.0379\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.405098 (avg: 0.411757) \tsec/iter: 0.0356\n",
      "Test set (epoch 27): Average loss: 0.6239, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.411368 (avg: 0.411368) \tsec/iter: 0.0319\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.339209 (avg: 0.401704) \tsec/iter: 0.0342\n",
      "Test set (epoch 28): Average loss: 0.5596, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.289077 (avg: 0.289077) \tsec/iter: 0.0499\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.488090 (avg: 0.373460) \tsec/iter: 0.0369\n",
      "Test set (epoch 29): Average loss: 0.4684, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.377223 (avg: 0.377223) \tsec/iter: 0.0389\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.439291 (avg: 0.383807) \tsec/iter: 0.0379\n",
      "Test set (epoch 30): Average loss: 0.5726, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.453457 (avg: 0.453457) \tsec/iter: 0.0404\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.362959 (avg: 0.384413) \tsec/iter: 0.0333\n",
      "Test set (epoch 31): Average loss: 0.5489, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.383511 (avg: 0.383511) \tsec/iter: 0.0359\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.422792 (avg: 0.350178) \tsec/iter: 0.0346\n",
      "Test set (epoch 32): Average loss: 0.5050, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.398505 (avg: 0.398505) \tsec/iter: 0.0359\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.257262 (avg: 0.359519) \tsec/iter: 0.0332\n",
      "Test set (epoch 33): Average loss: 0.5094, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.313294 (avg: 0.313294) \tsec/iter: 0.0334\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.365506 (avg: 0.366148) \tsec/iter: 0.0314\n",
      "Test set (epoch 34): Average loss: 0.5335, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.368126 (avg: 0.368126) \tsec/iter: 0.0324\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.356416 (avg: 0.356749) \tsec/iter: 0.0311\n",
      "Test set (epoch 35): Average loss: 0.5436, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.445589 (avg: 0.445589) \tsec/iter: 0.0309\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.353895 (avg: 0.388559) \tsec/iter: 0.0299\n",
      "Test set (epoch 36): Average loss: 0.5265, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.325634 (avg: 0.325634) \tsec/iter: 0.0329\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.387598 (avg: 0.359883) \tsec/iter: 0.0312\n",
      "Test set (epoch 37): Average loss: 0.4869, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.256091 (avg: 0.256091) \tsec/iter: 0.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.431285 (avg: 0.362435) \tsec/iter: 0.0332\n",
      "Test set (epoch 38): Average loss: 0.4930, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.375210 (avg: 0.375210) \tsec/iter: 0.0419\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.222494 (avg: 0.363067) \tsec/iter: 0.0389\n",
      "Test set (epoch 39): Average loss: 0.5022, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.489652 (avg: 0.489652) \tsec/iter: 0.0489\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.453301 (avg: 0.396912) \tsec/iter: 0.0374\n",
      "Test set (epoch 40): Average loss: 0.5005, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.365154 (avg: 0.365154) \tsec/iter: 0.0399\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.383241 (avg: 0.378135) \tsec/iter: 0.0357\n",
      "Test set (epoch 41): Average loss: 0.5072, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.330791 (avg: 0.330791) \tsec/iter: 0.0449\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.582276 (avg: 0.404049) \tsec/iter: 0.0367\n",
      "Test set (epoch 42): Average loss: 0.5265, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.421341 (avg: 0.421341) \tsec/iter: 0.0369\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.338493 (avg: 0.383177) \tsec/iter: 0.0339\n",
      "Test set (epoch 43): Average loss: 0.4233, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.354524 (avg: 0.354524) \tsec/iter: 0.0399\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.443525 (avg: 0.367006) \tsec/iter: 0.0356\n",
      "Test set (epoch 44): Average loss: 0.3865, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.310696 (avg: 0.310696) \tsec/iter: 0.0329\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.432065 (avg: 0.363134) \tsec/iter: 0.0329\n",
      "Test set (epoch 45): Average loss: 0.5143, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.321245 (avg: 0.321245) \tsec/iter: 0.0369\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.375459 (avg: 0.344761) \tsec/iter: 0.0346\n",
      "Test set (epoch 46): Average loss: 0.4372, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.379120 (avg: 0.379120) \tsec/iter: 0.0369\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.446135 (avg: 0.388106) \tsec/iter: 0.0316\n",
      "Test set (epoch 47): Average loss: 0.5033, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.359374 (avg: 0.359374) \tsec/iter: 0.0439\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.255471 (avg: 0.363125) \tsec/iter: 0.0399\n",
      "Test set (epoch 48): Average loss: 0.5614, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.295393 (avg: 0.295393) \tsec/iter: 0.0409\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.372842 (avg: 0.350445) \tsec/iter: 0.0362\n",
      "Test set (epoch 49): Average loss: 0.5279, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.274953 (avg: 0.274953) \tsec/iter: 0.0419\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.464802 (avg: 0.368850) \tsec/iter: 0.0369\n",
      "Test set (epoch 50): Average loss: 0.4937, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.350009 (avg: 0.350009) \tsec/iter: 0.0399\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.378023 (avg: 0.359785) \tsec/iter: 0.0372\n",
      "Test set (epoch 51): Average loss: 0.4700, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.353302 (avg: 0.353302) \tsec/iter: 0.0429\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.383669 (avg: 0.355245) \tsec/iter: 0.0379\n",
      "Test set (epoch 52): Average loss: 0.4581, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.314983 (avg: 0.314983) \tsec/iter: 0.0409\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.569498 (avg: 0.377865) \tsec/iter: 0.0362\n",
      "Test set (epoch 53): Average loss: 0.5733, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.327820 (avg: 0.327820) \tsec/iter: 0.0379\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.413829 (avg: 0.338571) \tsec/iter: 0.0389\n",
      "Test set (epoch 54): Average loss: 0.5138, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.422032 (avg: 0.422032) \tsec/iter: 0.0339\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.451986 (avg: 0.366800) \tsec/iter: 0.0322\n",
      "Test set (epoch 55): Average loss: 0.4350, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.378785 (avg: 0.378785) \tsec/iter: 0.0389\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.364084 (avg: 0.365045) \tsec/iter: 0.0376\n",
      "Test set (epoch 56): Average loss: 0.4711, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.455886 (avg: 0.455886) \tsec/iter: 0.0409\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.312657 (avg: 0.362661) \tsec/iter: 0.0339\n",
      "Test set (epoch 57): Average loss: 0.4144, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.285194 (avg: 0.285194) \tsec/iter: 0.0359\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.369823 (avg: 0.371538) \tsec/iter: 0.0322\n",
      "Test set (epoch 58): Average loss: 0.4109, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.347058 (avg: 0.347058) \tsec/iter: 0.0369\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.428040 (avg: 0.380637) \tsec/iter: 0.0312\n",
      "Test set (epoch 59): Average loss: 0.3771, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.347175 (avg: 0.347175) \tsec/iter: 0.0329\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.412711 (avg: 0.372727) \tsec/iter: 0.0336\n",
      "Test set (epoch 60): Average loss: 0.5017, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.441303 (avg: 0.441303) \tsec/iter: 0.0399\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.325051 (avg: 0.383444) \tsec/iter: 0.0332\n",
      "Test set (epoch 61): Average loss: 0.3415, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.259986 (avg: 0.259986) \tsec/iter: 0.0339\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.477462 (avg: 0.373572) \tsec/iter: 0.0312\n",
      "Test set (epoch 62): Average loss: 0.4613, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.460553 (avg: 0.460553) \tsec/iter: 0.0369\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.247746 (avg: 0.363921) \tsec/iter: 0.0329\n",
      "Test set (epoch 63): Average loss: 0.4499, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.324852 (avg: 0.324852) \tsec/iter: 0.0329\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.266622 (avg: 0.320504) \tsec/iter: 0.0312\n",
      "Test set (epoch 64): Average loss: 0.4232, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.396078 (avg: 0.396078) \tsec/iter: 0.0339\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.389579 (avg: 0.365391) \tsec/iter: 0.0332\n",
      "Test set (epoch 65): Average loss: 0.4308, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.261606 (avg: 0.261606) \tsec/iter: 0.0399\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.437922 (avg: 0.348022) \tsec/iter: 0.0399\n",
      "Test set (epoch 66): Average loss: 0.4614, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.328763 (avg: 0.328763) \tsec/iter: 0.0329\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.347651 (avg: 0.360566) \tsec/iter: 0.0296\n",
      "Test set (epoch 67): Average loss: 0.4097, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.393759 (avg: 0.393759) \tsec/iter: 0.0409\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.307484 (avg: 0.368282) \tsec/iter: 0.0336\n",
      "Test set (epoch 68): Average loss: 0.3718, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.404099 (avg: 0.404099) \tsec/iter: 0.0379\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.263307 (avg: 0.359067) \tsec/iter: 0.0322\n",
      "Test set (epoch 69): Average loss: 0.3891, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.419454 (avg: 0.419454) \tsec/iter: 0.0329\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.382201 (avg: 0.373952) \tsec/iter: 0.0299\n",
      "Test set (epoch 70): Average loss: 0.4424, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.424916 (avg: 0.424916) \tsec/iter: 0.0329\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.285180 (avg: 0.348260) \tsec/iter: 0.0312\n",
      "Test set (epoch 71): Average loss: 0.3938, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.370518 (avg: 0.370518) \tsec/iter: 0.0349\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.306368 (avg: 0.350107) \tsec/iter: 0.0316\n",
      "Test set (epoch 72): Average loss: 0.3794, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.419494 (avg: 0.419494) \tsec/iter: 0.0359\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.360535 (avg: 0.362112) \tsec/iter: 0.0316\n",
      "Test set (epoch 73): Average loss: 0.3782, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.421116 (avg: 0.421116) \tsec/iter: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.357325 (avg: 0.366554) \tsec/iter: 0.0293\n",
      "Test set (epoch 74): Average loss: 0.4387, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.287906 (avg: 0.287906) \tsec/iter: 0.0409\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.317766 (avg: 0.336292) \tsec/iter: 0.0362\n",
      "Test set (epoch 75): Average loss: 0.4685, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.384130 (avg: 0.384130) \tsec/iter: 0.0439\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.273473 (avg: 0.329142) \tsec/iter: 0.0349\n",
      "Test set (epoch 76): Average loss: 0.3910, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.352126 (avg: 0.352126) \tsec/iter: 0.0349\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.411577 (avg: 0.370438) \tsec/iter: 0.0329\n",
      "Test set (epoch 77): Average loss: 0.5338, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.331028 (avg: 0.331028) \tsec/iter: 0.0349\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.477579 (avg: 0.383611) \tsec/iter: 0.0322\n",
      "Test set (epoch 78): Average loss: 0.2793, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.376139 (avg: 0.376139) \tsec/iter: 0.0369\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.307652 (avg: 0.371523) \tsec/iter: 0.0329\n",
      "Test set (epoch 79): Average loss: 0.3085, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.311323 (avg: 0.311323) \tsec/iter: 0.0429\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.409988 (avg: 0.345312) \tsec/iter: 0.0356\n",
      "Test set (epoch 80): Average loss: 0.3409, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.385829 (avg: 0.385829) \tsec/iter: 0.0329\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.176528 (avg: 0.361678) \tsec/iter: 0.0309\n",
      "Test set (epoch 81): Average loss: 0.3357, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.290619 (avg: 0.290619) \tsec/iter: 0.0359\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.521059 (avg: 0.362802) \tsec/iter: 0.0332\n",
      "Test set (epoch 82): Average loss: 0.3359, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.374955 (avg: 0.374955) \tsec/iter: 0.0369\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.299778 (avg: 0.343055) \tsec/iter: 0.0326\n",
      "Test set (epoch 83): Average loss: 0.3593, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.260368 (avg: 0.260368) \tsec/iter: 0.0399\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.391191 (avg: 0.322251) \tsec/iter: 0.0369\n",
      "Test set (epoch 84): Average loss: 0.3109, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.379354 (avg: 0.379354) \tsec/iter: 0.0449\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.339995 (avg: 0.340913) \tsec/iter: 0.0376\n",
      "Test set (epoch 85): Average loss: 0.3263, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.320798 (avg: 0.320798) \tsec/iter: 0.0369\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.395894 (avg: 0.348994) \tsec/iter: 0.0339\n",
      "Test set (epoch 86): Average loss: 0.3088, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.307807 (avg: 0.307807) \tsec/iter: 0.0359\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.235222 (avg: 0.327341) \tsec/iter: 0.0322\n",
      "Test set (epoch 87): Average loss: 0.3195, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.298816 (avg: 0.298816) \tsec/iter: 0.0389\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.317327 (avg: 0.325290) \tsec/iter: 0.0346\n",
      "Test set (epoch 88): Average loss: 0.3155, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.285401 (avg: 0.285401) \tsec/iter: 0.0389\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.441525 (avg: 0.330667) \tsec/iter: 0.0352\n",
      "Test set (epoch 89): Average loss: 0.3233, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.294943 (avg: 0.294943) \tsec/iter: 0.0349\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.351079 (avg: 0.375379) \tsec/iter: 0.0332\n",
      "Test set (epoch 90): Average loss: 0.2931, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.320259 (avg: 0.320259) \tsec/iter: 0.0339\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.285863 (avg: 0.338775) \tsec/iter: 0.0322\n",
      "Test set (epoch 91): Average loss: 0.3262, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.364054 (avg: 0.364054) \tsec/iter: 0.0319\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.297462 (avg: 0.332356) \tsec/iter: 0.0319\n",
      "Test set (epoch 92): Average loss: 0.3140, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.327086 (avg: 0.327086) \tsec/iter: 0.0449\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.289575 (avg: 0.354880) \tsec/iter: 0.0389\n",
      "Test set (epoch 93): Average loss: 0.2960, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.271504 (avg: 0.271504) \tsec/iter: 0.0459\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.390865 (avg: 0.321638) \tsec/iter: 0.0349\n",
      "Test set (epoch 94): Average loss: 0.3021, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.355730 (avg: 0.355730) \tsec/iter: 0.0319\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.272705 (avg: 0.310450) \tsec/iter: 0.0303\n",
      "Test set (epoch 95): Average loss: 0.3422, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.376753 (avg: 0.376753) \tsec/iter: 0.0329\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.353675 (avg: 0.335867) \tsec/iter: 0.0316\n",
      "Test set (epoch 96): Average loss: 0.3228, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.434818 (avg: 0.434818) \tsec/iter: 0.0379\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.294999 (avg: 0.355844) \tsec/iter: 0.0319\n",
      "Test set (epoch 97): Average loss: 0.2684, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.363968 (avg: 0.363968) \tsec/iter: 0.0359\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.241622 (avg: 0.321081) \tsec/iter: 0.0336\n",
      "Test set (epoch 98): Average loss: 0.3069, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.273004 (avg: 0.273004) \tsec/iter: 0.0379\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.341695 (avg: 0.317018) \tsec/iter: 0.0316\n",
      "Test set (epoch 99): Average loss: 0.2894, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.411257 (avg: 0.411257) \tsec/iter: 0.0339\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.162281 (avg: 0.328038) \tsec/iter: 0.0312\n",
      "Test set (epoch 100): Average loss: 0.2840, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.376558 (avg: 0.376558) \tsec/iter: 0.0319\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.354440 (avg: 0.350649) \tsec/iter: 0.0299\n",
      "Test set (epoch 101): Average loss: 0.2724, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.287462 (avg: 0.287462) \tsec/iter: 0.0349\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.400067 (avg: 0.330849) \tsec/iter: 0.0332\n",
      "Test set (epoch 102): Average loss: 0.3358, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.315903 (avg: 0.315903) \tsec/iter: 0.0449\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.379277 (avg: 0.334770) \tsec/iter: 0.0382\n",
      "Test set (epoch 103): Average loss: 0.3152, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.360012 (avg: 0.360012) \tsec/iter: 0.0339\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.301433 (avg: 0.335506) \tsec/iter: 0.0316\n",
      "Test set (epoch 104): Average loss: 0.2778, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.379548 (avg: 0.379548) \tsec/iter: 0.0339\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.273254 (avg: 0.336617) \tsec/iter: 0.0309\n",
      "Test set (epoch 105): Average loss: 0.3228, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.337369 (avg: 0.337369) \tsec/iter: 0.0409\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.297429 (avg: 0.324660) \tsec/iter: 0.0352\n",
      "Test set (epoch 106): Average loss: 0.3195, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.337414 (avg: 0.337414) \tsec/iter: 0.0329\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.379068 (avg: 0.324986) \tsec/iter: 0.0313\n",
      "Test set (epoch 107): Average loss: 0.2904, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.295612 (avg: 0.295612) \tsec/iter: 0.0339\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.404856 (avg: 0.321892) \tsec/iter: 0.0322\n",
      "Test set (epoch 108): Average loss: 0.2954, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.323002 (avg: 0.323002) \tsec/iter: 0.0359\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.357306 (avg: 0.373346) \tsec/iter: 0.0303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 109): Average loss: 0.4507, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.388519 (avg: 0.388519) \tsec/iter: 0.0339\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.256481 (avg: 0.363516) \tsec/iter: 0.0309\n",
      "Test set (epoch 110): Average loss: 0.2789, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.336608 (avg: 0.336608) \tsec/iter: 0.0319\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.308527 (avg: 0.322248) \tsec/iter: 0.0289\n",
      "Test set (epoch 111): Average loss: 0.3342, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.287806 (avg: 0.287806) \tsec/iter: 0.0419\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.262333 (avg: 0.292661) \tsec/iter: 0.0362\n",
      "Test set (epoch 112): Average loss: 0.2967, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.288183 (avg: 0.288183) \tsec/iter: 0.0379\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.369463 (avg: 0.319441) \tsec/iter: 0.0349\n",
      "Test set (epoch 113): Average loss: 0.2757, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.332158 (avg: 0.332158) \tsec/iter: 0.0399\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.306479 (avg: 0.316396) \tsec/iter: 0.0349\n",
      "Test set (epoch 114): Average loss: 0.2992, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.230527 (avg: 0.230527) \tsec/iter: 0.0389\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.274271 (avg: 0.318710) \tsec/iter: 0.0359\n",
      "Test set (epoch 115): Average loss: 0.3671, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.280371 (avg: 0.280371) \tsec/iter: 0.0419\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.452811 (avg: 0.305841) \tsec/iter: 0.0339\n",
      "Test set (epoch 116): Average loss: 0.2642, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.258096 (avg: 0.258096) \tsec/iter: 0.0369\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.419091 (avg: 0.367387) \tsec/iter: 0.0329\n",
      "Test set (epoch 117): Average loss: 0.2564, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.269221 (avg: 0.269221) \tsec/iter: 0.0359\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.252635 (avg: 0.312310) \tsec/iter: 0.0299\n",
      "Test set (epoch 118): Average loss: 0.3130, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.286665 (avg: 0.286665) \tsec/iter: 0.0359\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.369104 (avg: 0.293892) \tsec/iter: 0.0312\n",
      "Test set (epoch 119): Average loss: 0.2876, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.387506 (avg: 0.387506) \tsec/iter: 0.0319\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.383690 (avg: 0.354520) \tsec/iter: 0.0303\n",
      "Test set (epoch 120): Average loss: 0.3380, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.322130 (avg: 0.322130) \tsec/iter: 0.0379\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.382099 (avg: 0.316288) \tsec/iter: 0.0372\n",
      "Test set (epoch 121): Average loss: 0.3047, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.310632 (avg: 0.310632) \tsec/iter: 0.0419\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.288036 (avg: 0.354793) \tsec/iter: 0.0349\n",
      "Test set (epoch 122): Average loss: 0.2970, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.336486 (avg: 0.336486) \tsec/iter: 0.0359\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.234761 (avg: 0.319555) \tsec/iter: 0.0346\n",
      "Test set (epoch 123): Average loss: 0.3123, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.305228 (avg: 0.305228) \tsec/iter: 0.0369\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.396704 (avg: 0.305694) \tsec/iter: 0.0316\n",
      "Test set (epoch 124): Average loss: 0.3509, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.252418 (avg: 0.252418) \tsec/iter: 0.0349\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.253439 (avg: 0.300365) \tsec/iter: 0.0342\n",
      "Test set (epoch 125): Average loss: 0.3066, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.241708 (avg: 0.241708) \tsec/iter: 0.0429\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.287655 (avg: 0.327770) \tsec/iter: 0.0382\n",
      "Test set (epoch 126): Average loss: 0.3522, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.386227 (avg: 0.386227) \tsec/iter: 0.0419\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.278133 (avg: 0.320682) \tsec/iter: 0.0382\n",
      "Test set (epoch 127): Average loss: 0.2790, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.267557 (avg: 0.267557) \tsec/iter: 0.0399\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.385747 (avg: 0.321397) \tsec/iter: 0.0366\n",
      "Test set (epoch 128): Average loss: 0.3844, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.382345 (avg: 0.382345) \tsec/iter: 0.0439\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.200708 (avg: 0.299277) \tsec/iter: 0.0362\n",
      "Test set (epoch 129): Average loss: 0.3156, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.234439 (avg: 0.234439) \tsec/iter: 0.0409\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.407999 (avg: 0.312466) \tsec/iter: 0.0489\n",
      "Test set (epoch 130): Average loss: 0.3560, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.247445 (avg: 0.247445) \tsec/iter: 0.0499\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.245833 (avg: 0.289312) \tsec/iter: 0.0406\n",
      "Test set (epoch 131): Average loss: 0.3484, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.323790 (avg: 0.323790) \tsec/iter: 0.0499\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.342566 (avg: 0.296721) \tsec/iter: 0.0495\n",
      "Test set (epoch 132): Average loss: 0.3504, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.294949 (avg: 0.294949) \tsec/iter: 0.0529\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.395120 (avg: 0.336869) \tsec/iter: 0.0515\n",
      "Test set (epoch 133): Average loss: 0.3478, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.257501 (avg: 0.257501) \tsec/iter: 0.0509\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.371217 (avg: 0.304747) \tsec/iter: 0.0495\n",
      "Test set (epoch 134): Average loss: 0.3655, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.280818 (avg: 0.280818) \tsec/iter: 0.0568\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.489988 (avg: 0.321014) \tsec/iter: 0.0499\n",
      "Test set (epoch 135): Average loss: 0.3307, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.283890 (avg: 0.283890) \tsec/iter: 0.0618\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.298268 (avg: 0.300222) \tsec/iter: 0.0572\n",
      "Test set (epoch 136): Average loss: 0.3075, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.279846 (avg: 0.279846) \tsec/iter: 0.0519\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.209331 (avg: 0.287003) \tsec/iter: 0.0462\n",
      "Test set (epoch 137): Average loss: 0.3253, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.310088 (avg: 0.310088) \tsec/iter: 0.0519\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.256760 (avg: 0.321186) \tsec/iter: 0.0492\n",
      "Test set (epoch 138): Average loss: 0.4028, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.346514 (avg: 0.346514) \tsec/iter: 0.0449\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.410530 (avg: 0.313587) \tsec/iter: 0.0442\n",
      "Test set (epoch 139): Average loss: 0.3414, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.226265 (avg: 0.226265) \tsec/iter: 0.0489\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.551934 (avg: 0.338709) \tsec/iter: 0.0449\n",
      "Test set (epoch 140): Average loss: 0.3664, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.366149 (avg: 0.366149) \tsec/iter: 0.0479\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.260157 (avg: 0.304856) \tsec/iter: 0.0432\n",
      "Test set (epoch 141): Average loss: 0.3400, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.359125 (avg: 0.359125) \tsec/iter: 0.0519\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.361384 (avg: 0.333901) \tsec/iter: 0.0472\n",
      "Test set (epoch 142): Average loss: 0.3084, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.259648 (avg: 0.259648) \tsec/iter: 0.0469\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.294245 (avg: 0.281168) \tsec/iter: 0.0426\n",
      "Test set (epoch 143): Average loss: 0.3809, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.231042 (avg: 0.231042) \tsec/iter: 0.0489\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.401130 (avg: 0.318716) \tsec/iter: 0.0482\n",
      "Test set (epoch 144): Average loss: 0.3404, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.387871 (avg: 0.387871) \tsec/iter: 0.0439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.307243 (avg: 0.293536) \tsec/iter: 0.0436\n",
      "Test set (epoch 145): Average loss: 0.3331, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.338837 (avg: 0.338837) \tsec/iter: 0.0539\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.250032 (avg: 0.307369) \tsec/iter: 0.0455\n",
      "Test set (epoch 146): Average loss: 0.3341, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.280313 (avg: 0.280313) \tsec/iter: 0.0499\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.359034 (avg: 0.316338) \tsec/iter: 0.0459\n",
      "Test set (epoch 147): Average loss: 0.3285, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.310563 (avg: 0.310563) \tsec/iter: 0.0519\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.262172 (avg: 0.284578) \tsec/iter: 0.0475\n",
      "Test set (epoch 148): Average loss: 0.3667, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.268252 (avg: 0.268252) \tsec/iter: 0.0519\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.344403 (avg: 0.275919) \tsec/iter: 0.0499\n",
      "Test set (epoch 149): Average loss: 0.3743, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.298969 (avg: 0.298969) \tsec/iter: 0.0588\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.163889 (avg: 0.279706) \tsec/iter: 0.0529\n",
      "Test set (epoch 150): Average loss: 0.4013, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.299200 (avg: 0.299200) \tsec/iter: 0.0449\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.277098 (avg: 0.274974) \tsec/iter: 0.0449\n",
      "Test set (epoch 151): Average loss: 0.3556, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.279182 (avg: 0.279182) \tsec/iter: 0.0539\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.261306 (avg: 0.280393) \tsec/iter: 0.0449\n",
      "Test set (epoch 152): Average loss: 0.4039, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.283769 (avg: 0.283769) \tsec/iter: 0.0479\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.366106 (avg: 0.300610) \tsec/iter: 0.0459\n",
      "Test set (epoch 153): Average loss: 0.3633, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.302761 (avg: 0.302761) \tsec/iter: 0.0499\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.350465 (avg: 0.311201) \tsec/iter: 0.0459\n",
      "Test set (epoch 154): Average loss: 0.3408, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.238766 (avg: 0.238766) \tsec/iter: 0.0519\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.284674 (avg: 0.253857) \tsec/iter: 0.0472\n",
      "Test set (epoch 155): Average loss: 0.3244, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.291472 (avg: 0.291472) \tsec/iter: 0.0479\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.262498 (avg: 0.286387) \tsec/iter: 0.0442\n",
      "Test set (epoch 156): Average loss: 0.3500, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.222019 (avg: 0.222019) \tsec/iter: 0.0519\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.326560 (avg: 0.273061) \tsec/iter: 0.0515\n",
      "Test set (epoch 157): Average loss: 0.3219, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.301546 (avg: 0.301546) \tsec/iter: 0.0539\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.295851 (avg: 0.322857) \tsec/iter: 0.0465\n",
      "Test set (epoch 158): Average loss: 0.3645, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.259397 (avg: 0.259397) \tsec/iter: 0.0479\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.544083 (avg: 0.325050) \tsec/iter: 0.0442\n",
      "Test set (epoch 159): Average loss: 0.3128, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.245000 (avg: 0.245000) \tsec/iter: 0.0539\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.398231 (avg: 0.305350) \tsec/iter: 0.0469\n",
      "Test set (epoch 160): Average loss: 0.3897, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.410347 (avg: 0.410347) \tsec/iter: 0.0519\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.259969 (avg: 0.345170) \tsec/iter: 0.0439\n",
      "Test set (epoch 161): Average loss: 0.2804, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.229929 (avg: 0.229929) \tsec/iter: 0.0489\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.252333 (avg: 0.285103) \tsec/iter: 0.0429\n",
      "Test set (epoch 162): Average loss: 0.3708, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.287984 (avg: 0.287984) \tsec/iter: 0.0489\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.248801 (avg: 0.275874) \tsec/iter: 0.0455\n",
      "Test set (epoch 163): Average loss: 0.3660, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.303364 (avg: 0.303364) \tsec/iter: 0.0449\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.217735 (avg: 0.284753) \tsec/iter: 0.0419\n",
      "Test set (epoch 164): Average loss: 0.3234, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.290626 (avg: 0.290626) \tsec/iter: 0.0539\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.370567 (avg: 0.311715) \tsec/iter: 0.0489\n",
      "Test set (epoch 165): Average loss: 0.3363, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.215040 (avg: 0.215040) \tsec/iter: 0.0529\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.312968 (avg: 0.292756) \tsec/iter: 0.0422\n",
      "Test set (epoch 166): Average loss: 0.3335, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.368332 (avg: 0.368332) \tsec/iter: 0.0509\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.267189 (avg: 0.311788) \tsec/iter: 0.0479\n",
      "Test set (epoch 167): Average loss: 0.3528, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.376257 (avg: 0.376257) \tsec/iter: 0.0638\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.334152 (avg: 0.320836) \tsec/iter: 0.0529\n",
      "Test set (epoch 168): Average loss: 0.2442, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.304113 (avg: 0.304113) \tsec/iter: 0.0519\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.324459 (avg: 0.288319) \tsec/iter: 0.0465\n",
      "Test set (epoch 169): Average loss: 0.3160, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.219535 (avg: 0.219535) \tsec/iter: 0.0489\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.379130 (avg: 0.301393) \tsec/iter: 0.0452\n",
      "Test set (epoch 170): Average loss: 0.3191, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.320217 (avg: 0.320217) \tsec/iter: 0.0429\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.232967 (avg: 0.289251) \tsec/iter: 0.0426\n",
      "Test set (epoch 171): Average loss: 0.3567, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.276063 (avg: 0.276063) \tsec/iter: 0.0499\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.190699 (avg: 0.340071) \tsec/iter: 0.0472\n",
      "Test set (epoch 172): Average loss: 0.3113, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.262551 (avg: 0.262551) \tsec/iter: 0.0449\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.235512 (avg: 0.265695) \tsec/iter: 0.0429\n",
      "Test set (epoch 173): Average loss: 0.2901, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.220022 (avg: 0.220022) \tsec/iter: 0.0389\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.278681 (avg: 0.285834) \tsec/iter: 0.0399\n",
      "Test set (epoch 174): Average loss: 0.2951, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.293982 (avg: 0.293982) \tsec/iter: 0.0519\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.364795 (avg: 0.314144) \tsec/iter: 0.0445\n",
      "Test set (epoch 175): Average loss: 0.3089, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.336544 (avg: 0.336544) \tsec/iter: 0.0489\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.300814 (avg: 0.289025) \tsec/iter: 0.0495\n",
      "Test set (epoch 176): Average loss: 0.3511, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.359759 (avg: 0.359759) \tsec/iter: 0.0668\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.155330 (avg: 0.321520) \tsec/iter: 0.0532\n",
      "Test set (epoch 177): Average loss: 0.3270, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.217339 (avg: 0.217339) \tsec/iter: 0.0449\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.292392 (avg: 0.309422) \tsec/iter: 0.0412\n",
      "Test set (epoch 178): Average loss: 0.3606, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.246333 (avg: 0.246333) \tsec/iter: 0.0529\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.388319 (avg: 0.270527) \tsec/iter: 0.0472\n",
      "Test set (epoch 179): Average loss: 0.2730, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.288944 (avg: 0.288944) \tsec/iter: 0.0489\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.302535 (avg: 0.278913) \tsec/iter: 0.0459\n",
      "Test set (epoch 180): Average loss: 0.4207, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.344851 (avg: 0.344851) \tsec/iter: 0.0409\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.312808 (avg: 0.281498) \tsec/iter: 0.0399\n",
      "Test set (epoch 181): Average loss: 0.3418, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.295950 (avg: 0.295950) \tsec/iter: 0.0519\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.226815 (avg: 0.262433) \tsec/iter: 0.0465\n",
      "Test set (epoch 182): Average loss: 0.4219, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.276546 (avg: 0.276546) \tsec/iter: 0.0499\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.241264 (avg: 0.263802) \tsec/iter: 0.0459\n",
      "Test set (epoch 183): Average loss: 0.3736, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.299417 (avg: 0.299417) \tsec/iter: 0.0469\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.274568 (avg: 0.268720) \tsec/iter: 0.0439\n",
      "Test set (epoch 184): Average loss: 0.3358, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.230120 (avg: 0.230120) \tsec/iter: 0.0469\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.266017 (avg: 0.285357) \tsec/iter: 0.0452\n",
      "Test set (epoch 185): Average loss: 0.3401, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.335941 (avg: 0.335941) \tsec/iter: 0.0509\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.236971 (avg: 0.288435) \tsec/iter: 0.0545\n",
      "Test set (epoch 186): Average loss: 0.3601, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.270502 (avg: 0.270502) \tsec/iter: 0.0578\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.284622 (avg: 0.278286) \tsec/iter: 0.0525\n",
      "Test set (epoch 187): Average loss: 0.2987, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.228311 (avg: 0.228311) \tsec/iter: 0.0559\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.244755 (avg: 0.269320) \tsec/iter: 0.0502\n",
      "Test set (epoch 188): Average loss: 0.3089, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.280367 (avg: 0.280367) \tsec/iter: 0.1027\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.324488 (avg: 0.288086) \tsec/iter: 0.0768\n",
      "Test set (epoch 189): Average loss: 0.4420, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.344710 (avg: 0.344710) \tsec/iter: 0.0608\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.228196 (avg: 0.319112) \tsec/iter: 0.0525\n",
      "Test set (epoch 190): Average loss: 0.2740, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.364746 (avg: 0.364746) \tsec/iter: 0.0568\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.199446 (avg: 0.287047) \tsec/iter: 0.0505\n",
      "Test set (epoch 191): Average loss: 0.4004, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.290968 (avg: 0.290968) \tsec/iter: 0.0549\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.199438 (avg: 0.264539) \tsec/iter: 0.0495\n",
      "Test set (epoch 192): Average loss: 0.3376, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.222110 (avg: 0.222110) \tsec/iter: 0.0578\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.238432 (avg: 0.276430) \tsec/iter: 0.0525\n",
      "Test set (epoch 193): Average loss: 0.3151, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.250973 (avg: 0.250973) \tsec/iter: 0.0578\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.275034 (avg: 0.269036) \tsec/iter: 0.0595\n",
      "Test set (epoch 194): Average loss: 0.3076, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.237005 (avg: 0.237005) \tsec/iter: 0.0698\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.325119 (avg: 0.261864) \tsec/iter: 0.0582\n",
      "Test set (epoch 195): Average loss: 0.3442, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.245501 (avg: 0.245501) \tsec/iter: 0.0519\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.388337 (avg: 0.269329) \tsec/iter: 0.0495\n",
      "Test set (epoch 196): Average loss: 0.2499, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.255362 (avg: 0.255362) \tsec/iter: 0.0499\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.359630 (avg: 0.289201) \tsec/iter: 0.0505\n",
      "Test set (epoch 197): Average loss: 0.3364, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.303226 (avg: 0.303226) \tsec/iter: 0.0499\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.262463 (avg: 0.263080) \tsec/iter: 0.0499\n",
      "Test set (epoch 198): Average loss: 0.4359, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.286474 (avg: 0.286474) \tsec/iter: 0.0559\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.172592 (avg: 0.287154) \tsec/iter: 0.0539\n",
      "Test set (epoch 199): Average loss: 0.3446, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.243572 (avg: 0.243572) \tsec/iter: 0.0489\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.294964 (avg: 0.274140) \tsec/iter: 0.0532\n",
      "Test set (epoch 200): Average loss: 0.2857, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.265818 (avg: 0.265818) \tsec/iter: 0.0678\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.201336 (avg: 0.269073) \tsec/iter: 0.0572\n",
      "Test set (epoch 201): Average loss: 0.2916, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.253748 (avg: 0.253748) \tsec/iter: 0.0578\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.241171 (avg: 0.238360) \tsec/iter: 0.0499\n",
      "Test set (epoch 202): Average loss: 0.3154, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.301067 (avg: 0.301067) \tsec/iter: 0.0529\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.221842 (avg: 0.286892) \tsec/iter: 0.0545\n",
      "Test set (epoch 203): Average loss: 0.2530, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.255090 (avg: 0.255090) \tsec/iter: 0.0608\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.405805 (avg: 0.272155) \tsec/iter: 0.0522\n",
      "Test set (epoch 204): Average loss: 0.2917, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.283304 (avg: 0.283304) \tsec/iter: 0.0618\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.268019 (avg: 0.302788) \tsec/iter: 0.0559\n",
      "Test set (epoch 205): Average loss: 0.2603, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.225900 (avg: 0.225900) \tsec/iter: 0.0569\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.266187 (avg: 0.260121) \tsec/iter: 0.0535\n",
      "Test set (epoch 206): Average loss: 0.3803, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.346078 (avg: 0.346078) \tsec/iter: 0.0608\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.244893 (avg: 0.268596) \tsec/iter: 0.0495\n",
      "Test set (epoch 207): Average loss: 0.2247, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.355792 (avg: 0.355792) \tsec/iter: 0.0509\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.176560 (avg: 0.281576) \tsec/iter: 0.0509\n",
      "Test set (epoch 208): Average loss: 0.2799, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.271343 (avg: 0.271343) \tsec/iter: 0.0549\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.314379 (avg: 0.262421) \tsec/iter: 0.0545\n",
      "Test set (epoch 209): Average loss: 0.2944, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.262627 (avg: 0.262627) \tsec/iter: 0.0549\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.280243 (avg: 0.282966) \tsec/iter: 0.0529\n",
      "Test set (epoch 210): Average loss: 0.3316, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.255316 (avg: 0.255316) \tsec/iter: 0.0459\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.219740 (avg: 0.312378) \tsec/iter: 0.0499\n",
      "Test set (epoch 211): Average loss: 0.3447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.243205 (avg: 0.243205) \tsec/iter: 0.0838\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.287392 (avg: 0.263422) \tsec/iter: 0.0675\n",
      "Test set (epoch 212): Average loss: 0.3052, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.141963 (avg: 0.141963) \tsec/iter: 0.0568\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.364780 (avg: 0.266566) \tsec/iter: 0.0535\n",
      "Test set (epoch 213): Average loss: 0.3199, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.285558 (avg: 0.285558) \tsec/iter: 0.0588\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.251821 (avg: 0.259379) \tsec/iter: 0.0512\n",
      "Test set (epoch 214): Average loss: 0.3184, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.258300 (avg: 0.258300) \tsec/iter: 0.0539\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.408386 (avg: 0.283248) \tsec/iter: 0.0532\n",
      "Test set (epoch 215): Average loss: 0.4105, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.297649 (avg: 0.297649) \tsec/iter: 0.0578\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.255438 (avg: 0.284419) \tsec/iter: 0.0515\n",
      "Test set (epoch 216): Average loss: 0.3038, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.294719 (avg: 0.294719) \tsec/iter: 0.0598\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.280802 (avg: 0.269962) \tsec/iter: 0.0562\n",
      "Test set (epoch 217): Average loss: 0.3044, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.197748 (avg: 0.197748) \tsec/iter: 0.0628\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.277477 (avg: 0.233873) \tsec/iter: 0.0575\n",
      "Test set (epoch 218): Average loss: 0.3502, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.145060 (avg: 0.145060) \tsec/iter: 0.0519\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.211164 (avg: 0.218309) \tsec/iter: 0.0512\n",
      "Test set (epoch 219): Average loss: 0.2851, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.237093 (avg: 0.237093) \tsec/iter: 0.0519\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.306159 (avg: 0.299927) \tsec/iter: 0.0479\n",
      "Test set (epoch 220): Average loss: 0.3003, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.300870 (avg: 0.300870) \tsec/iter: 0.0499\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.223291 (avg: 0.238940) \tsec/iter: 0.0442\n",
      "Test set (epoch 221): Average loss: 0.3169, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.240708 (avg: 0.240708) \tsec/iter: 0.0459\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.305391 (avg: 0.260452) \tsec/iter: 0.0455\n",
      "Test set (epoch 222): Average loss: 0.3331, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.326533 (avg: 0.326533) \tsec/iter: 0.0419\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.354015 (avg: 0.307784) \tsec/iter: 0.0436\n",
      "Test set (epoch 223): Average loss: 0.2845, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.357430 (avg: 0.357430) \tsec/iter: 0.0459\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.203275 (avg: 0.270875) \tsec/iter: 0.0432\n",
      "Test set (epoch 224): Average loss: 0.3436, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.330063 (avg: 0.330063) \tsec/iter: 0.0489\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.224278 (avg: 0.270070) \tsec/iter: 0.0436\n",
      "Test set (epoch 225): Average loss: 0.2763, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.351808 (avg: 0.351808) \tsec/iter: 0.0509\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.217880 (avg: 0.324757) \tsec/iter: 0.0449\n",
      "Test set (epoch 226): Average loss: 0.2531, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.208490 (avg: 0.208490) \tsec/iter: 0.0489\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.201741 (avg: 0.230894) \tsec/iter: 0.0455\n",
      "Test set (epoch 227): Average loss: 0.3393, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.259908 (avg: 0.259908) \tsec/iter: 0.0469\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.224119 (avg: 0.267201) \tsec/iter: 0.0436\n",
      "Test set (epoch 228): Average loss: 0.3301, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.266742 (avg: 0.266742) \tsec/iter: 0.0499\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.274070 (avg: 0.257766) \tsec/iter: 0.0469\n",
      "Test set (epoch 229): Average loss: 0.2361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.290579 (avg: 0.290579) \tsec/iter: 0.0499\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.168793 (avg: 0.249830) \tsec/iter: 0.0439\n",
      "Test set (epoch 230): Average loss: 0.3374, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.246534 (avg: 0.246534) \tsec/iter: 0.0509\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.210178 (avg: 0.234397) \tsec/iter: 0.0449\n",
      "Test set (epoch 231): Average loss: 0.2851, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.155621 (avg: 0.155621) \tsec/iter: 0.0499\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.307116 (avg: 0.296831) \tsec/iter: 0.0452\n",
      "Test set (epoch 232): Average loss: 0.2037, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.333195 (avg: 0.333195) \tsec/iter: 0.0509\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.211352 (avg: 0.266398) \tsec/iter: 0.0465\n",
      "Test set (epoch 233): Average loss: 0.3004, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.257228 (avg: 0.257228) \tsec/iter: 0.0529\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.242365 (avg: 0.261165) \tsec/iter: 0.0482\n",
      "Test set (epoch 234): Average loss: 0.3243, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.272899 (avg: 0.272899) \tsec/iter: 0.0449\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.197466 (avg: 0.275442) \tsec/iter: 0.0416\n",
      "Test set (epoch 235): Average loss: 0.2686, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.168984 (avg: 0.168984) \tsec/iter: 0.0469\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.302169 (avg: 0.248946) \tsec/iter: 0.0465\n",
      "Test set (epoch 236): Average loss: 0.3333, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.249598 (avg: 0.249598) \tsec/iter: 0.0459\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.312610 (avg: 0.271199) \tsec/iter: 0.0432\n",
      "Test set (epoch 237): Average loss: 0.2232, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.311365 (avg: 0.311365) \tsec/iter: 0.0549\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.362369 (avg: 0.304492) \tsec/iter: 0.0519\n",
      "Test set (epoch 238): Average loss: 0.3413, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.171598 (avg: 0.171598) \tsec/iter: 0.0549\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.265157 (avg: 0.237343) \tsec/iter: 0.0495\n",
      "Test set (epoch 239): Average loss: 0.3286, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.349713 (avg: 0.349713) \tsec/iter: 0.0429\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.176352 (avg: 0.248217) \tsec/iter: 0.0439\n",
      "Test set (epoch 240): Average loss: 0.3491, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.245645 (avg: 0.245645) \tsec/iter: 0.0469\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.352294 (avg: 0.303911) \tsec/iter: 0.0442\n",
      "Test set (epoch 241): Average loss: 0.1994, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.246208 (avg: 0.246208) \tsec/iter: 0.0419\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.209173 (avg: 0.195949) \tsec/iter: 0.0436\n",
      "Test set (epoch 242): Average loss: 0.3096, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.263975 (avg: 0.263975) \tsec/iter: 0.0559\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.232836 (avg: 0.260786) \tsec/iter: 0.0452\n",
      "Test set (epoch 243): Average loss: 0.2966, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.313838 (avg: 0.313838) \tsec/iter: 0.0519\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.231186 (avg: 0.242905) \tsec/iter: 0.0485\n",
      "Test set (epoch 244): Average loss: 0.3360, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.315992 (avg: 0.315992) \tsec/iter: 0.0568\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.339616 (avg: 0.279096) \tsec/iter: 0.0519\n",
      "Test set (epoch 245): Average loss: 0.4103, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.259535 (avg: 0.259535) \tsec/iter: 0.0568\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.320234 (avg: 0.283784) \tsec/iter: 0.0482\n",
      "Test set (epoch 246): Average loss: 0.3439, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.308196 (avg: 0.308196) \tsec/iter: 0.0489\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.473934 (avg: 0.289708) \tsec/iter: 0.0435\n",
      "Test set (epoch 247): Average loss: 0.3088, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.328048 (avg: 0.328048) \tsec/iter: 0.0509\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.216763 (avg: 0.266817) \tsec/iter: 0.0459\n",
      "Test set (epoch 248): Average loss: 0.3191, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.329755 (avg: 0.329755) \tsec/iter: 0.0509\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.247779 (avg: 0.277075) \tsec/iter: 0.0475\n",
      "Test set (epoch 249): Average loss: 0.3625, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.211584 (avg: 0.211584) \tsec/iter: 0.0539\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.269473 (avg: 0.254246) \tsec/iter: 0.0439\n",
      "Test set (epoch 250): Average loss: 0.3048, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.251140 (avg: 0.251140) \tsec/iter: 0.0539\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.292810 (avg: 0.281778) \tsec/iter: 0.0462\n",
      "Test set (epoch 251): Average loss: 0.3039, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.263968 (avg: 0.263968) \tsec/iter: 0.0459\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.218585 (avg: 0.254463) \tsec/iter: 0.0455\n",
      "Test set (epoch 252): Average loss: 0.3228, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.261456 (avg: 0.261456) \tsec/iter: 0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.310809 (avg: 0.259126) \tsec/iter: 0.0422\n",
      "Test set (epoch 253): Average loss: 0.3350, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.189617 (avg: 0.189617) \tsec/iter: 0.0429\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.232806 (avg: 0.249533) \tsec/iter: 0.0422\n",
      "Test set (epoch 254): Average loss: 0.3497, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.420239 (avg: 0.420239) \tsec/iter: 0.0369\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.262581 (avg: 0.289233) \tsec/iter: 0.0416\n",
      "Test set (epoch 255): Average loss: 0.2639, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.176806 (avg: 0.176806) \tsec/iter: 0.0419\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.282906 (avg: 0.235754) \tsec/iter: 0.0412\n",
      "Test set (epoch 256): Average loss: 0.3054, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.167082 (avg: 0.167082) \tsec/iter: 0.0409\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.413376 (avg: 0.260018) \tsec/iter: 0.0432\n",
      "Test set (epoch 257): Average loss: 0.3245, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.260457 (avg: 0.260457) \tsec/iter: 0.0539\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.302598 (avg: 0.241012) \tsec/iter: 0.0512\n",
      "Test set (epoch 258): Average loss: 0.3207, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.200978 (avg: 0.200978) \tsec/iter: 0.0489\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.346222 (avg: 0.279695) \tsec/iter: 0.0459\n",
      "Test set (epoch 259): Average loss: 0.3253, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.230856 (avg: 0.230856) \tsec/iter: 0.0529\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.322917 (avg: 0.246283) \tsec/iter: 0.0442\n",
      "Test set (epoch 260): Average loss: 0.2975, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.199060 (avg: 0.199060) \tsec/iter: 0.0459\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.195682 (avg: 0.235740) \tsec/iter: 0.0445\n",
      "Test set (epoch 261): Average loss: 0.3298, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.242346 (avg: 0.242346) \tsec/iter: 0.0449\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.259177 (avg: 0.242621) \tsec/iter: 0.0432\n",
      "Test set (epoch 262): Average loss: 0.3001, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.238420 (avg: 0.238420) \tsec/iter: 0.0529\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.217645 (avg: 0.252493) \tsec/iter: 0.0479\n",
      "Test set (epoch 263): Average loss: 0.3306, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.229034 (avg: 0.229034) \tsec/iter: 0.0489\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.268271 (avg: 0.236744) \tsec/iter: 0.0479\n",
      "Test set (epoch 264): Average loss: 0.2891, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.215936 (avg: 0.215936) \tsec/iter: 0.0559\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.224725 (avg: 0.236376) \tsec/iter: 0.0505\n",
      "Test set (epoch 265): Average loss: 0.3029, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.179861 (avg: 0.179861) \tsec/iter: 0.0539\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.285168 (avg: 0.232230) \tsec/iter: 0.0479\n",
      "Test set (epoch 266): Average loss: 0.3615, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.314916 (avg: 0.314916) \tsec/iter: 0.0429\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.262897 (avg: 0.260790) \tsec/iter: 0.0426\n",
      "Test set (epoch 267): Average loss: 0.3144, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.223518 (avg: 0.223518) \tsec/iter: 0.0499\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.241331 (avg: 0.241923) \tsec/iter: 0.0449\n",
      "Test set (epoch 268): Average loss: 0.3541, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.389294 (avg: 0.389294) \tsec/iter: 0.0529\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.222544 (avg: 0.268719) \tsec/iter: 0.0462\n",
      "Test set (epoch 269): Average loss: 0.2897, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.230716 (avg: 0.230716) \tsec/iter: 0.0399\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.226384 (avg: 0.228900) \tsec/iter: 0.0382\n",
      "Test set (epoch 270): Average loss: 0.2883, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.204040 (avg: 0.204040) \tsec/iter: 0.0489\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.317816 (avg: 0.263358) \tsec/iter: 0.0459\n",
      "Test set (epoch 271): Average loss: 0.2689, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.208490 (avg: 0.208490) \tsec/iter: 0.0489\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.208020 (avg: 0.257296) \tsec/iter: 0.0436\n",
      "Test set (epoch 272): Average loss: 0.3939, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.193595 (avg: 0.193595) \tsec/iter: 0.0469\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.313778 (avg: 0.278357) \tsec/iter: 0.0429\n",
      "Test set (epoch 273): Average loss: 0.2889, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.235835 (avg: 0.235835) \tsec/iter: 0.0499\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.228136 (avg: 0.236442) \tsec/iter: 0.0455\n",
      "Test set (epoch 274): Average loss: 0.2946, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.270437 (avg: 0.270437) \tsec/iter: 0.0479\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.232660 (avg: 0.248867) \tsec/iter: 0.0459\n",
      "Test set (epoch 275): Average loss: 0.3516, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.210299 (avg: 0.210299) \tsec/iter: 0.0449\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.117467 (avg: 0.224627) \tsec/iter: 0.0442\n",
      "Test set (epoch 276): Average loss: 0.3609, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.217240 (avg: 0.217240) \tsec/iter: 0.0479\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.247544 (avg: 0.218097) \tsec/iter: 0.0419\n",
      "Test set (epoch 277): Average loss: 0.4125, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.208443 (avg: 0.208443) \tsec/iter: 0.0529\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.157068 (avg: 0.223455) \tsec/iter: 0.0492\n",
      "Test set (epoch 278): Average loss: 0.4005, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.212214 (avg: 0.212214) \tsec/iter: 0.0568\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.233919 (avg: 0.196067) \tsec/iter: 0.0469\n",
      "Test set (epoch 279): Average loss: 0.2264, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.260540 (avg: 0.260540) \tsec/iter: 0.0549\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.179637 (avg: 0.235555) \tsec/iter: 0.0465\n",
      "Test set (epoch 280): Average loss: 0.3301, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.260299 (avg: 0.260299) \tsec/iter: 0.0459\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.293103 (avg: 0.244807) \tsec/iter: 0.0439\n",
      "Test set (epoch 281): Average loss: 0.2864, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.205251 (avg: 0.205251) \tsec/iter: 0.0469\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.215391 (avg: 0.245738) \tsec/iter: 0.0426\n",
      "Test set (epoch 282): Average loss: 0.3665, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.164231 (avg: 0.164231) \tsec/iter: 0.0509\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.301613 (avg: 0.244079) \tsec/iter: 0.0472\n",
      "Test set (epoch 283): Average loss: 0.2909, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.215613 (avg: 0.215613) \tsec/iter: 0.0469\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.202888 (avg: 0.257889) \tsec/iter: 0.0469\n",
      "Test set (epoch 284): Average loss: 0.3865, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.186787 (avg: 0.186787) \tsec/iter: 0.0578\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.339820 (avg: 0.251836) \tsec/iter: 0.0529\n",
      "Test set (epoch 285): Average loss: 0.4517, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.171856 (avg: 0.171856) \tsec/iter: 0.0449\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.403569 (avg: 0.265915) \tsec/iter: 0.0489\n",
      "Test set (epoch 286): Average loss: 0.3206, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.321026 (avg: 0.321026) \tsec/iter: 0.0539\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.360869 (avg: 0.267124) \tsec/iter: 0.0475\n",
      "Test set (epoch 287): Average loss: 0.2731, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.324746 (avg: 0.324746) \tsec/iter: 0.0509\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.227459 (avg: 0.247760) \tsec/iter: 0.0455\n",
      "Test set (epoch 288): Average loss: 0.3589, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.330324 (avg: 0.330324) \tsec/iter: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.196830 (avg: 0.254365) \tsec/iter: 0.0459\n",
      "Test set (epoch 289): Average loss: 0.4439, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.250408 (avg: 0.250408) \tsec/iter: 0.0559\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.180502 (avg: 0.195444) \tsec/iter: 0.0489\n",
      "Test set (epoch 290): Average loss: 0.3097, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.191131 (avg: 0.191131) \tsec/iter: 0.0519\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.341632 (avg: 0.203210) \tsec/iter: 0.0525\n",
      "Test set (epoch 291): Average loss: 0.3483, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.160056 (avg: 0.160056) \tsec/iter: 0.0628\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.319421 (avg: 0.246654) \tsec/iter: 0.0539\n",
      "Test set (epoch 292): Average loss: 0.4314, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.291582 (avg: 0.291582) \tsec/iter: 0.0558\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.162482 (avg: 0.253088) \tsec/iter: 0.0505\n",
      "Test set (epoch 293): Average loss: 0.3536, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.344957 (avg: 0.344957) \tsec/iter: 0.0568\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.264781 (avg: 0.284407) \tsec/iter: 0.0505\n",
      "Test set (epoch 294): Average loss: 0.3745, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.163581 (avg: 0.163581) \tsec/iter: 0.0568\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.172382 (avg: 0.234373) \tsec/iter: 0.0529\n",
      "Test set (epoch 295): Average loss: 0.2946, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.252377 (avg: 0.252377) \tsec/iter: 0.0519\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.167911 (avg: 0.240449) \tsec/iter: 0.0532\n",
      "Test set (epoch 296): Average loss: 0.2980, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.248227 (avg: 0.248227) \tsec/iter: 0.0688\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.185809 (avg: 0.215865) \tsec/iter: 0.0615\n",
      "Test set (epoch 297): Average loss: 0.2885, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.236551 (avg: 0.236551) \tsec/iter: 0.0549\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.191298 (avg: 0.251660) \tsec/iter: 0.0515\n",
      "Test set (epoch 298): Average loss: 0.3253, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.209259 (avg: 0.209259) \tsec/iter: 0.0608\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.129146 (avg: 0.229224) \tsec/iter: 0.0542\n",
      "Test set (epoch 299): Average loss: 0.3175, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.204267 (avg: 0.204267) \tsec/iter: 0.0568\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.249571 (avg: 0.219664) \tsec/iter: 0.0509\n",
      "Test set (epoch 300): Average loss: 0.3156, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.328817 (avg: 0.328817) \tsec/iter: 0.0559\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.125207 (avg: 0.227031) \tsec/iter: 0.0505\n",
      "Test set (epoch 301): Average loss: 0.3917, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.184383 (avg: 0.184383) \tsec/iter: 0.0559\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.179985 (avg: 0.229386) \tsec/iter: 0.0475\n",
      "Test set (epoch 302): Average loss: 0.3142, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.108041 (avg: 0.108041) \tsec/iter: 0.0638\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.286781 (avg: 0.205084) \tsec/iter: 0.0635\n",
      "Test set (epoch 303): Average loss: 0.3686, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.283495 (avg: 0.283495) \tsec/iter: 0.0648\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.148663 (avg: 0.222631) \tsec/iter: 0.0542\n",
      "Test set (epoch 304): Average loss: 0.2841, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.180522 (avg: 0.180522) \tsec/iter: 0.0558\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.294904 (avg: 0.226624) \tsec/iter: 0.0535\n",
      "Test set (epoch 305): Average loss: 0.3756, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.197485 (avg: 0.197485) \tsec/iter: 0.0558\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.367567 (avg: 0.253225) \tsec/iter: 0.0492\n",
      "Test set (epoch 306): Average loss: 0.2495, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.177338 (avg: 0.177338) \tsec/iter: 0.0539\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.475543 (avg: 0.233122) \tsec/iter: 0.0545\n",
      "Test set (epoch 307): Average loss: 0.4152, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.256310 (avg: 0.256310) \tsec/iter: 0.0588\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.281796 (avg: 0.230445) \tsec/iter: 0.0598\n",
      "Test set (epoch 308): Average loss: 0.3325, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.263790 (avg: 0.263790) \tsec/iter: 0.0648\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.233008 (avg: 0.249205) \tsec/iter: 0.0545\n",
      "Test set (epoch 309): Average loss: 0.3464, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.269664 (avg: 0.269664) \tsec/iter: 0.0588\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.254440 (avg: 0.241371) \tsec/iter: 0.0522\n",
      "Test set (epoch 310): Average loss: 0.4595, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.310401 (avg: 0.310401) \tsec/iter: 0.0618\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.201148 (avg: 0.239047) \tsec/iter: 0.0542\n",
      "Test set (epoch 311): Average loss: 0.2598, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.304361 (avg: 0.304361) \tsec/iter: 0.0668\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.188471 (avg: 0.208605) \tsec/iter: 0.0572\n",
      "Test set (epoch 312): Average loss: 0.3626, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.195906 (avg: 0.195906) \tsec/iter: 0.0539\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.211137 (avg: 0.227451) \tsec/iter: 0.0489\n",
      "Test set (epoch 313): Average loss: 0.3606, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.233090 (avg: 0.233090) \tsec/iter: 0.0638\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.292162 (avg: 0.241758) \tsec/iter: 0.0598\n",
      "Test set (epoch 314): Average loss: 0.3034, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.236442 (avg: 0.236442) \tsec/iter: 0.0618\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.256939 (avg: 0.237373) \tsec/iter: 0.0532\n",
      "Test set (epoch 315): Average loss: 0.3790, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.287099 (avg: 0.287099) \tsec/iter: 0.0558\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.228717 (avg: 0.252948) \tsec/iter: 0.0525\n",
      "Test set (epoch 316): Average loss: 0.3334, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.236517 (avg: 0.236517) \tsec/iter: 0.0509\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.156050 (avg: 0.211091) \tsec/iter: 0.0469\n",
      "Test set (epoch 317): Average loss: 0.2691, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.290968 (avg: 0.290968) \tsec/iter: 0.0598\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.170676 (avg: 0.226085) \tsec/iter: 0.0539\n",
      "Test set (epoch 318): Average loss: 0.2512, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.212973 (avg: 0.212973) \tsec/iter: 0.0618\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.223341 (avg: 0.220013) \tsec/iter: 0.0542\n",
      "Test set (epoch 319): Average loss: 0.4040, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.176638 (avg: 0.176638) \tsec/iter: 0.0688\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.195043 (avg: 0.218644) \tsec/iter: 0.0658\n",
      "Test set (epoch 320): Average loss: 0.5147, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.184294 (avg: 0.184294) \tsec/iter: 0.0559\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.178173 (avg: 0.201895) \tsec/iter: 0.0492\n",
      "Test set (epoch 321): Average loss: 0.3340, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.186979 (avg: 0.186979) \tsec/iter: 0.0549\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.228508 (avg: 0.227495) \tsec/iter: 0.0479\n",
      "Test set (epoch 322): Average loss: 0.2993, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.245885 (avg: 0.245885) \tsec/iter: 0.0529\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.285374 (avg: 0.243969) \tsec/iter: 0.0509\n",
      "Test set (epoch 323): Average loss: 0.3330, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.234453 (avg: 0.234453) \tsec/iter: 0.0509\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.305407 (avg: 0.252721) \tsec/iter: 0.0459\n",
      "Test set (epoch 324): Average loss: 0.3874, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.280722 (avg: 0.280722) \tsec/iter: 0.0499\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.194972 (avg: 0.243937) \tsec/iter: 0.0515\n",
      "Test set (epoch 325): Average loss: 0.3261, Accuracy: 17/18 (94.44%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.332175 (avg: 0.332175) \tsec/iter: 0.0768\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.202230 (avg: 0.245757) \tsec/iter: 0.0582\n",
      "Test set (epoch 326): Average loss: 0.3031, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.212656 (avg: 0.212656) \tsec/iter: 0.0459\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.300095 (avg: 0.253100) \tsec/iter: 0.0439\n",
      "Test set (epoch 327): Average loss: 0.3485, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.207709 (avg: 0.207709) \tsec/iter: 0.0499\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.308396 (avg: 0.237765) \tsec/iter: 0.0452\n",
      "Test set (epoch 328): Average loss: 0.2727, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.396258 (avg: 0.396258) \tsec/iter: 0.0459\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.138054 (avg: 0.265724) \tsec/iter: 0.0442\n",
      "Test set (epoch 329): Average loss: 0.2885, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.208263 (avg: 0.208263) \tsec/iter: 0.0499\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.205736 (avg: 0.233753) \tsec/iter: 0.0472\n",
      "Test set (epoch 330): Average loss: 0.3216, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.247122 (avg: 0.247122) \tsec/iter: 0.0459\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.186670 (avg: 0.245501) \tsec/iter: 0.0459\n",
      "Test set (epoch 331): Average loss: 0.2740, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.331578 (avg: 0.331578) \tsec/iter: 0.0559\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.251907 (avg: 0.236414) \tsec/iter: 0.0499\n",
      "Test set (epoch 332): Average loss: 0.3051, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.215929 (avg: 0.215929) \tsec/iter: 0.0499\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.335173 (avg: 0.219252) \tsec/iter: 0.0475\n",
      "Test set (epoch 333): Average loss: 0.3746, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.260209 (avg: 0.260209) \tsec/iter: 0.0439\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.393831 (avg: 0.262214) \tsec/iter: 0.0422\n",
      "Test set (epoch 334): Average loss: 0.3961, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.205692 (avg: 0.205692) \tsec/iter: 0.0539\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.348086 (avg: 0.227173) \tsec/iter: 0.0439\n",
      "Test set (epoch 335): Average loss: 0.3610, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.182348 (avg: 0.182348) \tsec/iter: 0.0519\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.255054 (avg: 0.236672) \tsec/iter: 0.0465\n",
      "Test set (epoch 336): Average loss: 0.2976, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.153238 (avg: 0.153238) \tsec/iter: 0.0439\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.232377 (avg: 0.196403) \tsec/iter: 0.0426\n",
      "Test set (epoch 337): Average loss: 0.3826, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.295213 (avg: 0.295213) \tsec/iter: 0.0479\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.202774 (avg: 0.236011) \tsec/iter: 0.0449\n",
      "Test set (epoch 338): Average loss: 0.3445, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.228254 (avg: 0.228254) \tsec/iter: 0.0519\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.223044 (avg: 0.226600) \tsec/iter: 0.0545\n",
      "Test set (epoch 339): Average loss: 0.4268, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.226232 (avg: 0.226232) \tsec/iter: 0.0539\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.321679 (avg: 0.239584) \tsec/iter: 0.0489\n",
      "Test set (epoch 340): Average loss: 0.2953, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.175521 (avg: 0.175521) \tsec/iter: 0.0529\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.184558 (avg: 0.196964) \tsec/iter: 0.0492\n",
      "Test set (epoch 341): Average loss: 0.3307, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.202477 (avg: 0.202477) \tsec/iter: 0.0489\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.211670 (avg: 0.236702) \tsec/iter: 0.0465\n",
      "Test set (epoch 342): Average loss: 0.3257, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.222043 (avg: 0.222043) \tsec/iter: 0.0399\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.286300 (avg: 0.230818) \tsec/iter: 0.0399\n",
      "Test set (epoch 343): Average loss: 0.4017, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.240630 (avg: 0.240630) \tsec/iter: 0.0469\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.162651 (avg: 0.228502) \tsec/iter: 0.0445\n",
      "Test set (epoch 344): Average loss: 0.3879, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.231965 (avg: 0.231965) \tsec/iter: 0.0489\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.162603 (avg: 0.240161) \tsec/iter: 0.0469\n",
      "Test set (epoch 345): Average loss: 0.3515, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.253805 (avg: 0.253805) \tsec/iter: 0.0499\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.257936 (avg: 0.238846) \tsec/iter: 0.0462\n",
      "Test set (epoch 346): Average loss: 0.3998, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.268061 (avg: 0.268061) \tsec/iter: 0.0489\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.242930 (avg: 0.251657) \tsec/iter: 0.0475\n",
      "Test set (epoch 347): Average loss: 0.4077, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.240717 (avg: 0.240717) \tsec/iter: 0.0559\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.219101 (avg: 0.198463) \tsec/iter: 0.0472\n",
      "Test set (epoch 348): Average loss: 0.4128, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.287666 (avg: 0.287666) \tsec/iter: 0.0529\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.188075 (avg: 0.240343) \tsec/iter: 0.0469\n",
      "Test set (epoch 349): Average loss: 0.4235, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.219452 (avg: 0.219452) \tsec/iter: 0.0459\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.179275 (avg: 0.204090) \tsec/iter: 0.0419\n",
      "Test set (epoch 350): Average loss: 0.3991, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.212550 (avg: 0.212550) \tsec/iter: 0.0439\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.292077 (avg: 0.218280) \tsec/iter: 0.0435\n",
      "Test set (epoch 351): Average loss: 0.3776, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.152083 (avg: 0.152083) \tsec/iter: 0.0439\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.347725 (avg: 0.223098) \tsec/iter: 0.0465\n",
      "Test set (epoch 352): Average loss: 0.3766, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.263274 (avg: 0.263274) \tsec/iter: 0.0568\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.215200 (avg: 0.217767) \tsec/iter: 0.0482\n",
      "Test set (epoch 353): Average loss: 0.4169, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.231000 (avg: 0.231000) \tsec/iter: 0.0499\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.232304 (avg: 0.260181) \tsec/iter: 0.0479\n",
      "Test set (epoch 354): Average loss: 0.4215, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.200133 (avg: 0.200133) \tsec/iter: 0.0459\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.233739 (avg: 0.241592) \tsec/iter: 0.0445\n",
      "Test set (epoch 355): Average loss: 0.3645, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.183670 (avg: 0.183670) \tsec/iter: 0.0539\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.179296 (avg: 0.208570) \tsec/iter: 0.0475\n",
      "Test set (epoch 356): Average loss: 0.3764, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.290708 (avg: 0.290708) \tsec/iter: 0.0519\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.122202 (avg: 0.247505) \tsec/iter: 0.0475\n",
      "Test set (epoch 357): Average loss: 0.3781, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.212343 (avg: 0.212343) \tsec/iter: 0.0459\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.352697 (avg: 0.254142) \tsec/iter: 0.0409\n",
      "Test set (epoch 358): Average loss: 0.4324, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.214008 (avg: 0.214008) \tsec/iter: 0.0489\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.197006 (avg: 0.263272) \tsec/iter: 0.0449\n",
      "Test set (epoch 359): Average loss: 0.4132, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.238729 (avg: 0.238729) \tsec/iter: 0.0499\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.124214 (avg: 0.217586) \tsec/iter: 0.0426\n",
      "Test set (epoch 360): Average loss: 0.3978, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.182313 (avg: 0.182313) \tsec/iter: 0.0419\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.323331 (avg: 0.200867) \tsec/iter: 0.0436\n",
      "Test set (epoch 361): Average loss: 0.3694, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.242016 (avg: 0.242016) \tsec/iter: 0.0519\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.174687 (avg: 0.249451) \tsec/iter: 0.0449\n",
      "Test set (epoch 362): Average loss: 0.3151, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.205122 (avg: 0.205122) \tsec/iter: 0.0409\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.333793 (avg: 0.229631) \tsec/iter: 0.0432\n",
      "Test set (epoch 363): Average loss: 0.3121, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.239236 (avg: 0.239236) \tsec/iter: 0.0499\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.238016 (avg: 0.242164) \tsec/iter: 0.0449\n",
      "Test set (epoch 364): Average loss: 0.4036, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.166667 (avg: 0.166667) \tsec/iter: 0.0469\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.296815 (avg: 0.242062) \tsec/iter: 0.0429\n",
      "Test set (epoch 365): Average loss: 0.3347, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.175956 (avg: 0.175956) \tsec/iter: 0.0588\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.139219 (avg: 0.194737) \tsec/iter: 0.0559\n",
      "Test set (epoch 366): Average loss: 0.3369, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.277276 (avg: 0.277276) \tsec/iter: 0.0499\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.134638 (avg: 0.240471) \tsec/iter: 0.0479\n",
      "Test set (epoch 367): Average loss: 0.4476, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.269627 (avg: 0.269627) \tsec/iter: 0.0469\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.201358 (avg: 0.226809) \tsec/iter: 0.0459\n",
      "Test set (epoch 368): Average loss: 0.3477, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.164907 (avg: 0.164907) \tsec/iter: 0.0389\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.158056 (avg: 0.177434) \tsec/iter: 0.0422\n",
      "Test set (epoch 369): Average loss: 0.3392, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.190624 (avg: 0.190624) \tsec/iter: 0.0399\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.248458 (avg: 0.237484) \tsec/iter: 0.0396\n",
      "Test set (epoch 370): Average loss: 0.3083, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.229708 (avg: 0.229708) \tsec/iter: 0.0409\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.280636 (avg: 0.236096) \tsec/iter: 0.0392\n",
      "Test set (epoch 371): Average loss: 0.4695, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.201335 (avg: 0.201335) \tsec/iter: 0.0489\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.348507 (avg: 0.257689) \tsec/iter: 0.0445\n",
      "Test set (epoch 372): Average loss: 0.3563, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.267613 (avg: 0.267613) \tsec/iter: 0.0559\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.226592 (avg: 0.230149) \tsec/iter: 0.0519\n",
      "Test set (epoch 373): Average loss: 0.3175, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.192680 (avg: 0.192680) \tsec/iter: 0.0429\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.303778 (avg: 0.203637) \tsec/iter: 0.0439\n",
      "Test set (epoch 374): Average loss: 0.2710, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.168531 (avg: 0.168531) \tsec/iter: 0.0519\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.222547 (avg: 0.217723) \tsec/iter: 0.0479\n",
      "Test set (epoch 375): Average loss: 0.3050, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.225595 (avg: 0.225595) \tsec/iter: 0.0439\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.287641 (avg: 0.195506) \tsec/iter: 0.0469\n",
      "Test set (epoch 376): Average loss: 0.3799, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.259030 (avg: 0.259030) \tsec/iter: 0.0539\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.117211 (avg: 0.195734) \tsec/iter: 0.0465\n",
      "Test set (epoch 377): Average loss: 0.3349, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.261017 (avg: 0.261017) \tsec/iter: 0.0519\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.162633 (avg: 0.226428) \tsec/iter: 0.0436\n",
      "Test set (epoch 378): Average loss: 0.3680, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.188817 (avg: 0.188817) \tsec/iter: 0.0499\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.210736 (avg: 0.210048) \tsec/iter: 0.0482\n",
      "Test set (epoch 379): Average loss: 0.3965, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.278092 (avg: 0.278092) \tsec/iter: 0.0549\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.260496 (avg: 0.233057) \tsec/iter: 0.0505\n",
      "Test set (epoch 380): Average loss: 0.3913, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.217095 (avg: 0.217095) \tsec/iter: 0.0479\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.195111 (avg: 0.195453) \tsec/iter: 0.0432\n",
      "Test set (epoch 381): Average loss: 0.2703, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.277885 (avg: 0.277885) \tsec/iter: 0.0439\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.088555 (avg: 0.199007) \tsec/iter: 0.0396\n",
      "Test set (epoch 382): Average loss: 0.3404, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.153468 (avg: 0.153468) \tsec/iter: 0.0439\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.295430 (avg: 0.221313) \tsec/iter: 0.0475\n",
      "Test set (epoch 383): Average loss: 0.4088, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.188322 (avg: 0.188322) \tsec/iter: 0.0459\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.226294 (avg: 0.203333) \tsec/iter: 0.0445\n",
      "Test set (epoch 384): Average loss: 0.3407, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.116449 (avg: 0.116449) \tsec/iter: 0.0469\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.279759 (avg: 0.204804) \tsec/iter: 0.0406\n",
      "Test set (epoch 385): Average loss: 0.4667, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.126358 (avg: 0.126358) \tsec/iter: 0.0529\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.179081 (avg: 0.165200) \tsec/iter: 0.0519\n",
      "Test set (epoch 386): Average loss: 0.3335, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.115235 (avg: 0.115235) \tsec/iter: 0.0469\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.308771 (avg: 0.183589) \tsec/iter: 0.0439\n",
      "Test set (epoch 387): Average loss: 0.4309, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.215923 (avg: 0.215923) \tsec/iter: 0.0429\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.203568 (avg: 0.234732) \tsec/iter: 0.0412\n",
      "Test set (epoch 388): Average loss: 0.5112, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.175006 (avg: 0.175006) \tsec/iter: 0.0508\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.342331 (avg: 0.231848) \tsec/iter: 0.0469\n",
      "Test set (epoch 389): Average loss: 0.3840, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.210086 (avg: 0.210086) \tsec/iter: 0.0489\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.221632 (avg: 0.236471) \tsec/iter: 0.0419\n",
      "Test set (epoch 390): Average loss: 0.4661, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.231321 (avg: 0.231321) \tsec/iter: 0.0499\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.122074 (avg: 0.205609) \tsec/iter: 0.0455\n",
      "Test set (epoch 391): Average loss: 0.4314, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.297973 (avg: 0.297973) \tsec/iter: 0.0519\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.210783 (avg: 0.236342) \tsec/iter: 0.0452\n",
      "Test set (epoch 392): Average loss: 0.4376, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.233178 (avg: 0.233178) \tsec/iter: 0.0539\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.151618 (avg: 0.206759) \tsec/iter: 0.0495\n",
      "Test set (epoch 393): Average loss: 0.3678, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.136934 (avg: 0.136934) \tsec/iter: 0.0549\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.304945 (avg: 0.207549) \tsec/iter: 0.0469\n",
      "Test set (epoch 394): Average loss: 0.3412, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.253991 (avg: 0.253991) \tsec/iter: 0.0499\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.254449 (avg: 0.208544) \tsec/iter: 0.0426\n",
      "Test set (epoch 395): Average loss: 0.3778, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.219462 (avg: 0.219462) \tsec/iter: 0.0529\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.190997 (avg: 0.253728) \tsec/iter: 0.0449\n",
      "Test set (epoch 396): Average loss: 0.5148, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.278457 (avg: 0.278457) \tsec/iter: 0.0379\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.146423 (avg: 0.224555) \tsec/iter: 0.0392\n",
      "Test set (epoch 397): Average loss: 0.3238, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.157650 (avg: 0.157650) \tsec/iter: 0.0429\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.189408 (avg: 0.212748) \tsec/iter: 0.0416\n",
      "Test set (epoch 398): Average loss: 0.3673, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.233884 (avg: 0.233884) \tsec/iter: 0.0519\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.120966 (avg: 0.215987) \tsec/iter: 0.0482\n",
      "Test set (epoch 399): Average loss: 0.3541, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.274905 (avg: 0.274905) \tsec/iter: 0.0588\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.280698 (avg: 0.257483) \tsec/iter: 0.0522\n",
      "Test set (epoch 400): Average loss: 0.1921, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.331888 (avg: 0.331888) \tsec/iter: 0.0529\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.145752 (avg: 0.241092) \tsec/iter: 0.0482\n",
      "Test set (epoch 401): Average loss: 0.3733, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.217571 (avg: 0.217571) \tsec/iter: 0.0519\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.215633 (avg: 0.208642) \tsec/iter: 0.0475\n",
      "Test set (epoch 402): Average loss: 0.2695, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.194511 (avg: 0.194511) \tsec/iter: 0.0389\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.288280 (avg: 0.202345) \tsec/iter: 0.0439\n",
      "Test set (epoch 403): Average loss: 0.3139, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.138439 (avg: 0.138439) \tsec/iter: 0.0549\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.388451 (avg: 0.257502) \tsec/iter: 0.0475\n",
      "Test set (epoch 404): Average loss: 0.3284, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.235003 (avg: 0.235003) \tsec/iter: 0.0509\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.317184 (avg: 0.221656) \tsec/iter: 0.0479\n",
      "Test set (epoch 405): Average loss: 0.3899, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.208303 (avg: 0.208303) \tsec/iter: 0.0559\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.139592 (avg: 0.212895) \tsec/iter: 0.0485\n",
      "Test set (epoch 406): Average loss: 0.3108, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.225647 (avg: 0.225647) \tsec/iter: 0.0539\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.235972 (avg: 0.226565) \tsec/iter: 0.0479\n",
      "Test set (epoch 407): Average loss: 0.4241, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.251115 (avg: 0.251115) \tsec/iter: 0.0439\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.241101 (avg: 0.248994) \tsec/iter: 0.0429\n",
      "Test set (epoch 408): Average loss: 0.2885, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.255730 (avg: 0.255730) \tsec/iter: 0.0469\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.206400 (avg: 0.211077) \tsec/iter: 0.0445\n",
      "Test set (epoch 409): Average loss: 0.3609, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.254903 (avg: 0.254903) \tsec/iter: 0.0399\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.155740 (avg: 0.218129) \tsec/iter: 0.0396\n",
      "Test set (epoch 410): Average loss: 0.3773, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.257992 (avg: 0.257992) \tsec/iter: 0.0469\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.139017 (avg: 0.215217) \tsec/iter: 0.0459\n",
      "Test set (epoch 411): Average loss: 0.4307, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.247397 (avg: 0.247397) \tsec/iter: 0.0419\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.185448 (avg: 0.255139) \tsec/iter: 0.0419\n",
      "Test set (epoch 412): Average loss: 0.4903, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.216109 (avg: 0.216109) \tsec/iter: 0.0509\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.211317 (avg: 0.235208) \tsec/iter: 0.0449\n",
      "Test set (epoch 413): Average loss: 0.3451, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.230917 (avg: 0.230917) \tsec/iter: 0.0479\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.159110 (avg: 0.190571) \tsec/iter: 0.0445\n",
      "Test set (epoch 414): Average loss: 0.3710, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.228720 (avg: 0.228720) \tsec/iter: 0.0598\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.318622 (avg: 0.229157) \tsec/iter: 0.0502\n",
      "Test set (epoch 415): Average loss: 0.3712, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.220825 (avg: 0.220825) \tsec/iter: 0.0549\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.193536 (avg: 0.194030) \tsec/iter: 0.0489\n",
      "Test set (epoch 416): Average loss: 0.4037, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.244736 (avg: 0.244736) \tsec/iter: 0.0509\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.252998 (avg: 0.193920) \tsec/iter: 0.0442\n",
      "Test set (epoch 417): Average loss: 0.3483, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.323313 (avg: 0.323313) \tsec/iter: 0.0578\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.230581 (avg: 0.270423) \tsec/iter: 0.0479\n",
      "Test set (epoch 418): Average loss: 0.3136, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.213360 (avg: 0.213360) \tsec/iter: 0.0529\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.238346 (avg: 0.209274) \tsec/iter: 0.0455\n",
      "Test set (epoch 419): Average loss: 0.3005, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.169243 (avg: 0.169243) \tsec/iter: 0.0489\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.111066 (avg: 0.195957) \tsec/iter: 0.0568\n",
      "Test set (epoch 420): Average loss: 0.4171, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.233891 (avg: 0.233891) \tsec/iter: 0.0588\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.249192 (avg: 0.224400) \tsec/iter: 0.0489\n",
      "Test set (epoch 421): Average loss: 0.5018, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.167420 (avg: 0.167420) \tsec/iter: 0.0459\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.198349 (avg: 0.218533) \tsec/iter: 0.0465\n",
      "Test set (epoch 422): Average loss: 0.3552, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.232042 (avg: 0.232042) \tsec/iter: 0.0429\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.271343 (avg: 0.207858) \tsec/iter: 0.0439\n",
      "Test set (epoch 423): Average loss: 0.2838, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.216869 (avg: 0.216869) \tsec/iter: 0.0539\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.264713 (avg: 0.197515) \tsec/iter: 0.0465\n",
      "Test set (epoch 424): Average loss: 0.3954, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.148787 (avg: 0.148787) \tsec/iter: 0.0419\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.295785 (avg: 0.219614) \tsec/iter: 0.0406\n",
      "Test set (epoch 425): Average loss: 0.4333, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.128519 (avg: 0.128519) \tsec/iter: 0.0559\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.390350 (avg: 0.205433) \tsec/iter: 0.0598\n",
      "Test set (epoch 426): Average loss: 0.4187, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.163946 (avg: 0.163946) \tsec/iter: 0.0578\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.254068 (avg: 0.209314) \tsec/iter: 0.0502\n",
      "Test set (epoch 427): Average loss: 0.2688, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.294297 (avg: 0.294297) \tsec/iter: 0.0539\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.272643 (avg: 0.239061) \tsec/iter: 0.0492\n",
      "Test set (epoch 428): Average loss: 0.3847, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.147624 (avg: 0.147624) \tsec/iter: 0.0389\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.214438 (avg: 0.200788) \tsec/iter: 0.0402\n",
      "Test set (epoch 429): Average loss: 0.3830, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.187730 (avg: 0.187730) \tsec/iter: 0.0459\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.242774 (avg: 0.196719) \tsec/iter: 0.0419\n",
      "Test set (epoch 430): Average loss: 0.3569, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.274702 (avg: 0.274702) \tsec/iter: 0.0559\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.085090 (avg: 0.214593) \tsec/iter: 0.0495\n",
      "Test set (epoch 431): Average loss: 0.2515, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.190725 (avg: 0.190725) \tsec/iter: 0.0489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.228171 (avg: 0.210852) \tsec/iter: 0.0499\n",
      "Test set (epoch 432): Average loss: 0.3348, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.179168 (avg: 0.179168) \tsec/iter: 0.0539\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.319736 (avg: 0.191825) \tsec/iter: 0.0502\n",
      "Test set (epoch 433): Average loss: 0.3982, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.238737 (avg: 0.238737) \tsec/iter: 0.0559\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.176217 (avg: 0.189463) \tsec/iter: 0.0502\n",
      "Test set (epoch 434): Average loss: 0.2915, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.311499 (avg: 0.311499) \tsec/iter: 0.0469\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.144500 (avg: 0.263209) \tsec/iter: 0.0435\n",
      "Test set (epoch 435): Average loss: 0.2267, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.214282 (avg: 0.214282) \tsec/iter: 0.0539\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.343059 (avg: 0.252211) \tsec/iter: 0.0489\n",
      "Test set (epoch 436): Average loss: 0.2763, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.245290 (avg: 0.245290) \tsec/iter: 0.0499\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.223357 (avg: 0.195735) \tsec/iter: 0.0436\n",
      "Test set (epoch 437): Average loss: 0.3726, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.250433 (avg: 0.250433) \tsec/iter: 0.0539\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.188585 (avg: 0.211009) \tsec/iter: 0.0469\n",
      "Test set (epoch 438): Average loss: 0.2798, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.238234 (avg: 0.238234) \tsec/iter: 0.0489\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.311773 (avg: 0.236118) \tsec/iter: 0.0489\n",
      "Test set (epoch 439): Average loss: 0.3523, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.302428 (avg: 0.302428) \tsec/iter: 0.0539\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.238879 (avg: 0.208032) \tsec/iter: 0.0489\n",
      "Test set (epoch 440): Average loss: 0.4279, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.257999 (avg: 0.257999) \tsec/iter: 0.0558\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.098140 (avg: 0.207830) \tsec/iter: 0.0502\n",
      "Test set (epoch 441): Average loss: 0.3269, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.304012 (avg: 0.304012) \tsec/iter: 0.0459\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.218882 (avg: 0.224354) \tsec/iter: 0.0465\n",
      "Test set (epoch 442): Average loss: 0.3836, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.199504 (avg: 0.199504) \tsec/iter: 0.0519\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.208124 (avg: 0.200101) \tsec/iter: 0.0436\n",
      "Test set (epoch 443): Average loss: 0.4133, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.161443 (avg: 0.161443) \tsec/iter: 0.0509\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.078557 (avg: 0.216582) \tsec/iter: 0.0442\n",
      "Test set (epoch 444): Average loss: 0.3074, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.196537 (avg: 0.196537) \tsec/iter: 0.0539\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.217257 (avg: 0.194036) \tsec/iter: 0.0475\n",
      "Test set (epoch 445): Average loss: 0.3475, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.178058 (avg: 0.178058) \tsec/iter: 0.0549\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.168813 (avg: 0.202636) \tsec/iter: 0.0489\n",
      "Test set (epoch 446): Average loss: 0.3035, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.175140 (avg: 0.175140) \tsec/iter: 0.0578\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.239753 (avg: 0.213402) \tsec/iter: 0.0565\n",
      "Test set (epoch 447): Average loss: 0.1776, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.210534 (avg: 0.210534) \tsec/iter: 0.0549\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.187688 (avg: 0.180232) \tsec/iter: 0.0472\n",
      "Test set (epoch 448): Average loss: 0.2856, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.265877 (avg: 0.265877) \tsec/iter: 0.0469\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.256883 (avg: 0.227772) \tsec/iter: 0.0459\n",
      "Test set (epoch 449): Average loss: 0.3968, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.219071 (avg: 0.219071) \tsec/iter: 0.0549\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.244492 (avg: 0.197181) \tsec/iter: 0.0505\n",
      "Test set (epoch 450): Average loss: 0.3428, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.242051 (avg: 0.242051) \tsec/iter: 0.0549\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.153915 (avg: 0.181495) \tsec/iter: 0.0472\n",
      "Test set (epoch 451): Average loss: 0.3645, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.190478 (avg: 0.190478) \tsec/iter: 0.0509\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.203828 (avg: 0.225621) \tsec/iter: 0.0489\n",
      "Test set (epoch 452): Average loss: 0.3077, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.296347 (avg: 0.296347) \tsec/iter: 0.0469\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.075600 (avg: 0.171154) \tsec/iter: 0.0436\n",
      "Test set (epoch 453): Average loss: 0.4237, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.193330 (avg: 0.193330) \tsec/iter: 0.0419\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.219428 (avg: 0.210407) \tsec/iter: 0.0409\n",
      "Test set (epoch 454): Average loss: 0.2507, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.328815 (avg: 0.328815) \tsec/iter: 0.0449\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.102500 (avg: 0.233883) \tsec/iter: 0.0422\n",
      "Test set (epoch 455): Average loss: 0.3300, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.178605 (avg: 0.178605) \tsec/iter: 0.0509\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.340465 (avg: 0.244476) \tsec/iter: 0.0445\n",
      "Test set (epoch 456): Average loss: 0.4371, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.207063 (avg: 0.207063) \tsec/iter: 0.0439\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.211120 (avg: 0.216070) \tsec/iter: 0.0442\n",
      "Test set (epoch 457): Average loss: 0.4036, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.149435 (avg: 0.149435) \tsec/iter: 0.0529\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.314573 (avg: 0.200387) \tsec/iter: 0.0495\n",
      "Test set (epoch 458): Average loss: 0.2871, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.217575 (avg: 0.217575) \tsec/iter: 0.0578\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.165254 (avg: 0.224060) \tsec/iter: 0.0512\n",
      "Test set (epoch 459): Average loss: 0.2946, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.248674 (avg: 0.248674) \tsec/iter: 0.0509\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.226813 (avg: 0.204915) \tsec/iter: 0.0475\n",
      "Test set (epoch 460): Average loss: 0.3315, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.180172 (avg: 0.180172) \tsec/iter: 0.0429\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.220006 (avg: 0.179335) \tsec/iter: 0.0426\n",
      "Test set (epoch 461): Average loss: 0.3312, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.169267 (avg: 0.169267) \tsec/iter: 0.0479\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.305806 (avg: 0.187757) \tsec/iter: 0.0406\n",
      "Test set (epoch 462): Average loss: 0.3842, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.253208 (avg: 0.253208) \tsec/iter: 0.0509\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.280958 (avg: 0.270018) \tsec/iter: 0.0459\n",
      "Test set (epoch 463): Average loss: 0.3517, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.182754 (avg: 0.182754) \tsec/iter: 0.0499\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.348701 (avg: 0.227214) \tsec/iter: 0.0445\n",
      "Test set (epoch 464): Average loss: 0.3978, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.328420 (avg: 0.328420) \tsec/iter: 0.0419\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.161321 (avg: 0.239359) \tsec/iter: 0.0432\n",
      "Test set (epoch 465): Average loss: 0.3141, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.315844 (avg: 0.315844) \tsec/iter: 0.0489\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.137076 (avg: 0.208863) \tsec/iter: 0.0455\n",
      "Test set (epoch 466): Average loss: 0.3437, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.212000 (avg: 0.212000) \tsec/iter: 0.0469\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.160158 (avg: 0.189897) \tsec/iter: 0.0462\n",
      "Test set (epoch 467): Average loss: 0.3750, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.304401 (avg: 0.304401) \tsec/iter: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.148718 (avg: 0.207035) \tsec/iter: 0.0459\n",
      "Test set (epoch 468): Average loss: 0.3005, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.209877 (avg: 0.209877) \tsec/iter: 0.0529\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.179028 (avg: 0.178839) \tsec/iter: 0.0475\n",
      "Test set (epoch 469): Average loss: 0.3103, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.143951 (avg: 0.143951) \tsec/iter: 0.0409\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.147597 (avg: 0.192612) \tsec/iter: 0.0422\n",
      "Test set (epoch 470): Average loss: 0.3166, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.146734 (avg: 0.146734) \tsec/iter: 0.0439\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.317426 (avg: 0.238690) \tsec/iter: 0.0432\n",
      "Test set (epoch 471): Average loss: 0.2235, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.210369 (avg: 0.210369) \tsec/iter: 0.0489\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.175570 (avg: 0.190321) \tsec/iter: 0.0452\n",
      "Test set (epoch 472): Average loss: 0.3455, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.221454 (avg: 0.221454) \tsec/iter: 0.0489\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.197110 (avg: 0.211867) \tsec/iter: 0.0472\n",
      "Test set (epoch 473): Average loss: 0.2014, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.156837 (avg: 0.156837) \tsec/iter: 0.0469\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.272812 (avg: 0.171915) \tsec/iter: 0.0442\n",
      "Test set (epoch 474): Average loss: 0.3510, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.081439 (avg: 0.081439) \tsec/iter: 0.0559\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.239568 (avg: 0.203057) \tsec/iter: 0.0502\n",
      "Test set (epoch 475): Average loss: 0.2604, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.159111 (avg: 0.159111) \tsec/iter: 0.0519\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.348251 (avg: 0.209305) \tsec/iter: 0.0482\n",
      "Test set (epoch 476): Average loss: 0.2939, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.057974 (avg: 0.057974) \tsec/iter: 0.0539\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.306526 (avg: 0.167405) \tsec/iter: 0.0462\n",
      "Test set (epoch 477): Average loss: 0.3935, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.230400 (avg: 0.230400) \tsec/iter: 0.0429\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.141276 (avg: 0.205275) \tsec/iter: 0.0439\n",
      "Test set (epoch 478): Average loss: 0.2782, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.145300 (avg: 0.145300) \tsec/iter: 0.0559\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.180663 (avg: 0.198647) \tsec/iter: 0.0519\n",
      "Test set (epoch 479): Average loss: 0.3091, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.261137 (avg: 0.261137) \tsec/iter: 0.0568\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.056215 (avg: 0.159796) \tsec/iter: 0.0499\n",
      "Test set (epoch 480): Average loss: 0.2790, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.158296 (avg: 0.158296) \tsec/iter: 0.0439\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.185849 (avg: 0.242021) \tsec/iter: 0.0455\n",
      "Test set (epoch 481): Average loss: 0.4084, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.244180 (avg: 0.244180) \tsec/iter: 0.0399\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.099177 (avg: 0.205053) \tsec/iter: 0.0406\n",
      "Test set (epoch 482): Average loss: 0.4055, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.269784 (avg: 0.269784) \tsec/iter: 0.0489\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.061559 (avg: 0.209819) \tsec/iter: 0.0459\n",
      "Test set (epoch 483): Average loss: 0.3452, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.193930 (avg: 0.193930) \tsec/iter: 0.0509\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.299509 (avg: 0.239264) \tsec/iter: 0.0439\n",
      "Test set (epoch 484): Average loss: 0.3728, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.135490 (avg: 0.135490) \tsec/iter: 0.0509\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.294432 (avg: 0.202667) \tsec/iter: 0.0515\n",
      "Test set (epoch 485): Average loss: 0.3000, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.190574 (avg: 0.190574) \tsec/iter: 0.0668\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.270291 (avg: 0.228470) \tsec/iter: 0.0618\n",
      "Test set (epoch 486): Average loss: 0.4606, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.187846 (avg: 0.187846) \tsec/iter: 0.0638\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.254921 (avg: 0.255117) \tsec/iter: 0.0592\n",
      "Test set (epoch 487): Average loss: 0.3244, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.249873 (avg: 0.249873) \tsec/iter: 0.0549\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.245911 (avg: 0.255421) \tsec/iter: 0.0485\n",
      "Test set (epoch 488): Average loss: 0.2067, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.184821 (avg: 0.184821) \tsec/iter: 0.0509\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.213021 (avg: 0.168680) \tsec/iter: 0.0475\n",
      "Test set (epoch 489): Average loss: 0.3001, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.181553 (avg: 0.181553) \tsec/iter: 0.0559\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.174289 (avg: 0.200664) \tsec/iter: 0.0492\n",
      "Test set (epoch 490): Average loss: 0.2718, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.251595 (avg: 0.251595) \tsec/iter: 0.0588\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.171523 (avg: 0.192456) \tsec/iter: 0.0519\n",
      "Test set (epoch 491): Average loss: 0.2998, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.204633 (avg: 0.204633) \tsec/iter: 0.0568\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.142659 (avg: 0.178092) \tsec/iter: 0.0475\n",
      "Test set (epoch 492): Average loss: 0.3452, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.310459 (avg: 0.310459) \tsec/iter: 0.0519\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.128597 (avg: 0.199577) \tsec/iter: 0.0489\n",
      "Test set (epoch 493): Average loss: 0.3753, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.215441 (avg: 0.215441) \tsec/iter: 0.0499\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.241368 (avg: 0.237772) \tsec/iter: 0.0465\n",
      "Test set (epoch 494): Average loss: 0.3926, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.171476 (avg: 0.171476) \tsec/iter: 0.0598\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.224961 (avg: 0.219591) \tsec/iter: 0.0522\n",
      "Test set (epoch 495): Average loss: 0.3850, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.119254 (avg: 0.119254) \tsec/iter: 0.0459\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.232298 (avg: 0.188862) \tsec/iter: 0.0462\n",
      "Test set (epoch 496): Average loss: 0.3128, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.288487 (avg: 0.288487) \tsec/iter: 0.0479\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.068675 (avg: 0.203229) \tsec/iter: 0.0445\n",
      "Test set (epoch 497): Average loss: 0.4162, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.170995 (avg: 0.170995) \tsec/iter: 0.0588\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.184150 (avg: 0.242413) \tsec/iter: 0.0492\n",
      "Test set (epoch 498): Average loss: 0.3183, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.246857 (avg: 0.246857) \tsec/iter: 0.0509\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.232639 (avg: 0.238708) \tsec/iter: 0.0422\n",
      "Test set (epoch 499): Average loss: 0.3819, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 4\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 0.966410 (avg: 0.966410) \tsec/iter: 0.0568\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 1.156976 (avg: 2.924077) \tsec/iter: 0.0489\n",
      "Test set (epoch 0): Average loss: 0.9534, Accuracy: 9/18 (50.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 5.096076 (avg: 5.096076) \tsec/iter: 0.0429\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.961716 (avg: 2.402597) \tsec/iter: 0.0419\n",
      "Test set (epoch 1): Average loss: 0.3161, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.683153 (avg: 0.683153) \tsec/iter: 0.0499\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.666300 (avg: 0.572205) \tsec/iter: 0.0472\n",
      "Test set (epoch 2): Average loss: 0.8458, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.648600 (avg: 0.648600) \tsec/iter: 0.0529\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 1.102454 (avg: 0.796004) \tsec/iter: 0.0479\n",
      "Test set (epoch 3): Average loss: 1.6885, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.778548 (avg: 0.778548) \tsec/iter: 0.0568\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.330520 (avg: 0.565598) \tsec/iter: 0.0645\n",
      "Test set (epoch 4): Average loss: 0.7437, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.491617 (avg: 0.491617) \tsec/iter: 0.0559\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.311045 (avg: 0.438866) \tsec/iter: 0.0495\n",
      "Test set (epoch 5): Average loss: 1.2295, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.434005 (avg: 0.434005) \tsec/iter: 0.0439\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.796261 (avg: 0.604082) \tsec/iter: 0.0459\n",
      "Test set (epoch 6): Average loss: 1.6161, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.349250 (avg: 0.349250) \tsec/iter: 0.0529\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.407317 (avg: 0.426387) \tsec/iter: 0.0482\n",
      "Test set (epoch 7): Average loss: 1.8230, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.480802 (avg: 0.480802) \tsec/iter: 0.0489\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.371415 (avg: 0.428915) \tsec/iter: 0.0459\n",
      "Test set (epoch 8): Average loss: 1.4068, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.535700 (avg: 0.535700) \tsec/iter: 0.0469\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.610410 (avg: 0.494061) \tsec/iter: 0.0472\n",
      "Test set (epoch 9): Average loss: 1.9872, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.549839 (avg: 0.549839) \tsec/iter: 0.0549\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.277858 (avg: 0.509529) \tsec/iter: 0.0522\n",
      "Test set (epoch 10): Average loss: 2.0805, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.412932 (avg: 0.412932) \tsec/iter: 0.0549\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.331277 (avg: 0.352857) \tsec/iter: 0.0465\n",
      "Test set (epoch 11): Average loss: 1.7676, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.378789 (avg: 0.378789) \tsec/iter: 0.0449\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.234313 (avg: 0.359427) \tsec/iter: 0.0416\n",
      "Test set (epoch 12): Average loss: 2.4102, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.257300 (avg: 0.257300) \tsec/iter: 0.0519\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.665300 (avg: 0.424894) \tsec/iter: 0.0475\n",
      "Test set (epoch 13): Average loss: 1.8209, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.370859 (avg: 0.370859) \tsec/iter: 0.0509\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.504660 (avg: 0.379743) \tsec/iter: 0.0469\n",
      "Test set (epoch 14): Average loss: 1.7496, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.534361 (avg: 0.534361) \tsec/iter: 0.0499\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.362219 (avg: 0.472571) \tsec/iter: 0.0462\n",
      "Test set (epoch 15): Average loss: 1.9071, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.614599 (avg: 0.614599) \tsec/iter: 0.0499\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.438085 (avg: 0.608210) \tsec/iter: 0.0442\n",
      "Test set (epoch 16): Average loss: 2.0090, Accuracy: 4/18 (22.22%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.535867 (avg: 0.535867) \tsec/iter: 0.0489\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.463805 (avg: 0.448940) \tsec/iter: 0.0765\n",
      "Test set (epoch 17): Average loss: 1.1607, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.395204 (avg: 0.395204) \tsec/iter: 0.0499\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.363209 (avg: 0.367207) \tsec/iter: 0.0455\n",
      "Test set (epoch 18): Average loss: 1.2186, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.334646 (avg: 0.334646) \tsec/iter: 0.0568\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.322778 (avg: 0.357031) \tsec/iter: 0.0482\n",
      "Test set (epoch 19): Average loss: 1.2224, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.361843 (avg: 0.361843) \tsec/iter: 0.0539\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.389188 (avg: 0.375526) \tsec/iter: 0.0505\n",
      "Test set (epoch 20): Average loss: 1.1139, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.323637 (avg: 0.323637) \tsec/iter: 0.0559\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.428094 (avg: 0.341163) \tsec/iter: 0.0525\n",
      "Test set (epoch 21): Average loss: 1.2110, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.279609 (avg: 0.279609) \tsec/iter: 0.0539\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.571949 (avg: 0.367935) \tsec/iter: 0.0625\n",
      "Test set (epoch 22): Average loss: 1.0680, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.299658 (avg: 0.299658) \tsec/iter: 0.0868\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.430973 (avg: 0.347243) \tsec/iter: 0.0592\n",
      "Test set (epoch 23): Average loss: 1.2650, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.383489 (avg: 0.383489) \tsec/iter: 0.0479\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.412092 (avg: 0.379096) \tsec/iter: 0.0422\n",
      "Test set (epoch 24): Average loss: 0.9795, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.281923 (avg: 0.281923) \tsec/iter: 0.0499\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.365040 (avg: 0.332121) \tsec/iter: 0.0479\n",
      "Test set (epoch 25): Average loss: 1.0047, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.382952 (avg: 0.382952) \tsec/iter: 0.0499\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.299541 (avg: 0.350657) \tsec/iter: 0.0429\n",
      "Test set (epoch 26): Average loss: 1.2343, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.446003 (avg: 0.446003) \tsec/iter: 0.0419\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.327099 (avg: 0.374730) \tsec/iter: 0.0429\n",
      "Test set (epoch 27): Average loss: 0.9260, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.319212 (avg: 0.319212) \tsec/iter: 0.0549\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.446562 (avg: 0.364303) \tsec/iter: 0.0475\n",
      "Test set (epoch 28): Average loss: 1.1780, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.376840 (avg: 0.376840) \tsec/iter: 0.0519\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.415874 (avg: 0.349466) \tsec/iter: 0.0502\n",
      "Test set (epoch 29): Average loss: 1.1021, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.370205 (avg: 0.370205) \tsec/iter: 0.0439\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.367891 (avg: 0.362502) \tsec/iter: 0.0459\n",
      "Test set (epoch 30): Average loss: 1.1965, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.385557 (avg: 0.385557) \tsec/iter: 0.0429\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.234427 (avg: 0.360639) \tsec/iter: 0.0442\n",
      "Test set (epoch 31): Average loss: 1.1466, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.502242 (avg: 0.502242) \tsec/iter: 0.0519\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.243791 (avg: 0.352003) \tsec/iter: 0.0475\n",
      "Test set (epoch 32): Average loss: 1.0608, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.347372 (avg: 0.347372) \tsec/iter: 0.0449\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.296274 (avg: 0.348932) \tsec/iter: 0.0422\n",
      "Test set (epoch 33): Average loss: 1.0051, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.350764 (avg: 0.350764) \tsec/iter: 0.0529\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.267262 (avg: 0.337061) \tsec/iter: 0.0439\n",
      "Test set (epoch 34): Average loss: 0.9451, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.336742 (avg: 0.336742) \tsec/iter: 0.0519\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.423181 (avg: 0.364216) \tsec/iter: 0.0519\n",
      "Test set (epoch 35): Average loss: 1.0777, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.305608 (avg: 0.305608) \tsec/iter: 0.0598\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.346344 (avg: 0.321793) \tsec/iter: 0.0532\n",
      "Test set (epoch 36): Average loss: 1.1540, Accuracy: 7/18 (38.89%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.304286 (avg: 0.304286) \tsec/iter: 0.0489\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.602824 (avg: 0.382943) \tsec/iter: 0.0522\n",
      "Test set (epoch 37): Average loss: 1.1506, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.347503 (avg: 0.347503) \tsec/iter: 0.0559\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.297451 (avg: 0.350627) \tsec/iter: 0.0462\n",
      "Test set (epoch 38): Average loss: 1.0505, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.416700 (avg: 0.416700) \tsec/iter: 0.0449\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.323782 (avg: 0.374536) \tsec/iter: 0.0439\n",
      "Test set (epoch 39): Average loss: 0.9282, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.381209 (avg: 0.381209) \tsec/iter: 0.0449\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.363872 (avg: 0.349910) \tsec/iter: 0.0452\n",
      "Test set (epoch 40): Average loss: 1.0326, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.337697 (avg: 0.337697) \tsec/iter: 0.0519\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.316627 (avg: 0.347168) \tsec/iter: 0.0462\n",
      "Test set (epoch 41): Average loss: 0.9560, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.392990 (avg: 0.392990) \tsec/iter: 0.0718\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.323629 (avg: 0.335236) \tsec/iter: 0.0552\n",
      "Test set (epoch 42): Average loss: 1.0412, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.323788 (avg: 0.323788) \tsec/iter: 0.0439\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.366169 (avg: 0.323341) \tsec/iter: 0.0419\n",
      "Test set (epoch 43): Average loss: 1.1218, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.280476 (avg: 0.280476) \tsec/iter: 0.0549\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.392170 (avg: 0.353908) \tsec/iter: 0.0472\n",
      "Test set (epoch 44): Average loss: 0.9887, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.409286 (avg: 0.409286) \tsec/iter: 0.0499\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.207400 (avg: 0.362867) \tsec/iter: 0.0429\n",
      "Test set (epoch 45): Average loss: 0.9257, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.373582 (avg: 0.373582) \tsec/iter: 0.0429\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.465304 (avg: 0.390508) \tsec/iter: 0.0442\n",
      "Test set (epoch 46): Average loss: 0.9335, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.292603 (avg: 0.292603) \tsec/iter: 0.0439\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.257430 (avg: 0.353840) \tsec/iter: 0.0416\n",
      "Test set (epoch 47): Average loss: 0.9458, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.340765 (avg: 0.340765) \tsec/iter: 0.0399\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.429226 (avg: 0.344823) \tsec/iter: 0.0422\n",
      "Test set (epoch 48): Average loss: 0.9186, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.252028 (avg: 0.252028) \tsec/iter: 0.0499\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.388587 (avg: 0.323607) \tsec/iter: 0.0455\n",
      "Test set (epoch 49): Average loss: 0.9218, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.390572 (avg: 0.390572) \tsec/iter: 0.0479\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.315241 (avg: 0.358186) \tsec/iter: 0.0459\n",
      "Test set (epoch 50): Average loss: 0.9165, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.406387 (avg: 0.406387) \tsec/iter: 0.0449\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.378861 (avg: 0.371766) \tsec/iter: 0.0475\n",
      "Test set (epoch 51): Average loss: 0.9681, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.296336 (avg: 0.296336) \tsec/iter: 0.0509\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.368408 (avg: 0.342287) \tsec/iter: 0.0455\n",
      "Test set (epoch 52): Average loss: 1.0206, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.367189 (avg: 0.367189) \tsec/iter: 0.0499\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.313337 (avg: 0.359410) \tsec/iter: 0.0469\n",
      "Test set (epoch 53): Average loss: 0.8906, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.337427 (avg: 0.337427) \tsec/iter: 0.0509\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.425175 (avg: 0.350017) \tsec/iter: 0.0472\n",
      "Test set (epoch 54): Average loss: 0.9992, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.316640 (avg: 0.316640) \tsec/iter: 0.0489\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.470035 (avg: 0.333191) \tsec/iter: 0.0545\n",
      "Test set (epoch 55): Average loss: 0.9415, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.346090 (avg: 0.346090) \tsec/iter: 0.0499\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.331963 (avg: 0.304041) \tsec/iter: 0.0482\n",
      "Test set (epoch 56): Average loss: 0.8163, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.299632 (avg: 0.299632) \tsec/iter: 0.0499\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.368124 (avg: 0.322590) \tsec/iter: 0.0462\n",
      "Test set (epoch 57): Average loss: 0.9295, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.287190 (avg: 0.287190) \tsec/iter: 0.0499\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.247314 (avg: 0.334965) \tsec/iter: 0.0449\n",
      "Test set (epoch 58): Average loss: 0.8815, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.263955 (avg: 0.263955) \tsec/iter: 0.0499\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.335559 (avg: 0.362201) \tsec/iter: 0.0502\n",
      "Test set (epoch 59): Average loss: 0.8826, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.373264 (avg: 0.373264) \tsec/iter: 0.0638\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.303828 (avg: 0.357591) \tsec/iter: 0.0525\n",
      "Test set (epoch 60): Average loss: 0.8884, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.300025 (avg: 0.300025) \tsec/iter: 0.0509\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.438499 (avg: 0.339946) \tsec/iter: 0.0479\n",
      "Test set (epoch 61): Average loss: 0.7730, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.330178 (avg: 0.330178) \tsec/iter: 0.0568\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.370681 (avg: 0.366840) \tsec/iter: 0.0525\n",
      "Test set (epoch 62): Average loss: 0.9349, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.315478 (avg: 0.315478) \tsec/iter: 0.0449\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.458413 (avg: 0.335248) \tsec/iter: 0.0429\n",
      "Test set (epoch 63): Average loss: 0.8287, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.290898 (avg: 0.290898) \tsec/iter: 0.0539\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.371498 (avg: 0.363658) \tsec/iter: 0.0495\n",
      "Test set (epoch 64): Average loss: 0.8130, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.194734 (avg: 0.194734) \tsec/iter: 0.0559\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.298519 (avg: 0.327274) \tsec/iter: 0.0465\n",
      "Test set (epoch 65): Average loss: 0.8865, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.297233 (avg: 0.297233) \tsec/iter: 0.0509\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.567472 (avg: 0.354117) \tsec/iter: 0.0499\n",
      "Test set (epoch 66): Average loss: 0.9327, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.345748 (avg: 0.345748) \tsec/iter: 0.0499\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.495101 (avg: 0.358779) \tsec/iter: 0.0468\n",
      "Test set (epoch 67): Average loss: 0.7919, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.296842 (avg: 0.296842) \tsec/iter: 0.0489\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.337691 (avg: 0.323458) \tsec/iter: 0.0459\n",
      "Test set (epoch 68): Average loss: 0.6004, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.300449 (avg: 0.300449) \tsec/iter: 0.0519\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.375818 (avg: 0.314165) \tsec/iter: 0.0439\n",
      "Test set (epoch 69): Average loss: 0.6682, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.387218 (avg: 0.387218) \tsec/iter: 0.0499\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.471001 (avg: 0.367728) \tsec/iter: 0.0485\n",
      "Test set (epoch 70): Average loss: 0.6285, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.292413 (avg: 0.292413) \tsec/iter: 0.0449\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.316992 (avg: 0.317270) \tsec/iter: 0.0465\n",
      "Test set (epoch 71): Average loss: 0.6710, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.382837 (avg: 0.382837) \tsec/iter: 0.0469\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.257531 (avg: 0.335789) \tsec/iter: 0.0432\n",
      "Test set (epoch 72): Average loss: 0.6566, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.348721 (avg: 0.348721) \tsec/iter: 0.0499\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.412490 (avg: 0.319182) \tsec/iter: 0.0455\n",
      "Test set (epoch 73): Average loss: 0.6469, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.331352 (avg: 0.331352) \tsec/iter: 0.0429\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.342253 (avg: 0.317383) \tsec/iter: 0.0442\n",
      "Test set (epoch 74): Average loss: 0.7257, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.396220 (avg: 0.396220) \tsec/iter: 0.0588\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.242876 (avg: 0.336050) \tsec/iter: 0.0549\n",
      "Test set (epoch 75): Average loss: 0.7571, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.364011 (avg: 0.364011) \tsec/iter: 0.0559\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.345402 (avg: 0.328963) \tsec/iter: 0.0505\n",
      "Test set (epoch 76): Average loss: 0.6260, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.332153 (avg: 0.332153) \tsec/iter: 0.0558\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.256375 (avg: 0.325215) \tsec/iter: 0.0499\n",
      "Test set (epoch 77): Average loss: 0.7914, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.288709 (avg: 0.288709) \tsec/iter: 0.0549\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.320517 (avg: 0.321303) \tsec/iter: 0.0455\n",
      "Test set (epoch 78): Average loss: 0.7269, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.282206 (avg: 0.282206) \tsec/iter: 0.0479\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.304230 (avg: 0.329740) \tsec/iter: 0.0462\n",
      "Test set (epoch 79): Average loss: 0.7014, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.371018 (avg: 0.371018) \tsec/iter: 0.0588\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.491440 (avg: 0.350518) \tsec/iter: 0.0512\n",
      "Test set (epoch 80): Average loss: 0.6501, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.275792 (avg: 0.275792) \tsec/iter: 0.0549\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.232816 (avg: 0.320790) \tsec/iter: 0.0555\n",
      "Test set (epoch 81): Average loss: 0.6488, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.297920 (avg: 0.297920) \tsec/iter: 0.0678\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.467964 (avg: 0.313745) \tsec/iter: 0.0559\n",
      "Test set (epoch 82): Average loss: 0.6158, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.272966 (avg: 0.272966) \tsec/iter: 0.0549\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.433450 (avg: 0.327210) \tsec/iter: 0.0472\n",
      "Test set (epoch 83): Average loss: 0.6206, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.404575 (avg: 0.404575) \tsec/iter: 0.0628\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.223728 (avg: 0.311020) \tsec/iter: 0.0545\n",
      "Test set (epoch 84): Average loss: 0.6480, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.418719 (avg: 0.418719) \tsec/iter: 0.0549\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.206849 (avg: 0.318388) \tsec/iter: 0.0462\n",
      "Test set (epoch 85): Average loss: 0.6841, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.217087 (avg: 0.217087) \tsec/iter: 0.0459\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.337745 (avg: 0.312884) \tsec/iter: 0.0469\n",
      "Test set (epoch 86): Average loss: 0.6273, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.268599 (avg: 0.268599) \tsec/iter: 0.0509\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.267837 (avg: 0.329473) \tsec/iter: 0.0502\n",
      "Test set (epoch 87): Average loss: 0.7108, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.339216 (avg: 0.339216) \tsec/iter: 0.0529\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.406462 (avg: 0.326555) \tsec/iter: 0.0459\n",
      "Test set (epoch 88): Average loss: 0.5661, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.340902 (avg: 0.340902) \tsec/iter: 0.0559\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.306532 (avg: 0.320869) \tsec/iter: 0.0465\n",
      "Test set (epoch 89): Average loss: 0.7553, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.353794 (avg: 0.353794) \tsec/iter: 0.0519\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.366780 (avg: 0.338485) \tsec/iter: 0.0479\n",
      "Test set (epoch 90): Average loss: 0.6887, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.285352 (avg: 0.285352) \tsec/iter: 0.0479\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.304763 (avg: 0.294909) \tsec/iter: 0.0465\n",
      "Test set (epoch 91): Average loss: 0.5284, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.323929 (avg: 0.323929) \tsec/iter: 0.0549\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.268272 (avg: 0.301646) \tsec/iter: 0.0455\n",
      "Test set (epoch 92): Average loss: 0.6352, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.379279 (avg: 0.379279) \tsec/iter: 0.0519\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.342477 (avg: 0.372198) \tsec/iter: 0.0465\n",
      "Test set (epoch 93): Average loss: 0.4792, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.345707 (avg: 0.345707) \tsec/iter: 0.0648\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.274485 (avg: 0.318492) \tsec/iter: 0.0585\n",
      "Test set (epoch 94): Average loss: 0.5289, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.340703 (avg: 0.340703) \tsec/iter: 0.0529\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.374675 (avg: 0.321605) \tsec/iter: 0.0475\n",
      "Test set (epoch 95): Average loss: 0.5500, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.401680 (avg: 0.401680) \tsec/iter: 0.0578\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.269911 (avg: 0.334839) \tsec/iter: 0.0515\n",
      "Test set (epoch 96): Average loss: 0.5495, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.283033 (avg: 0.283033) \tsec/iter: 0.0509\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.305603 (avg: 0.301469) \tsec/iter: 0.0495\n",
      "Test set (epoch 97): Average loss: 0.5849, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.296471 (avg: 0.296471) \tsec/iter: 0.0459\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.260648 (avg: 0.285304) \tsec/iter: 0.0429\n",
      "Test set (epoch 98): Average loss: 0.7329, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.364872 (avg: 0.364872) \tsec/iter: 0.0439\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.230292 (avg: 0.308289) \tsec/iter: 0.0426\n",
      "Test set (epoch 99): Average loss: 0.5592, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.291930 (avg: 0.291930) \tsec/iter: 0.0479\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.227075 (avg: 0.315745) \tsec/iter: 0.0452\n",
      "Test set (epoch 100): Average loss: 0.5629, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.341421 (avg: 0.341421) \tsec/iter: 0.0509\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.259878 (avg: 0.326990) \tsec/iter: 0.0469\n",
      "Test set (epoch 101): Average loss: 0.5216, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.385497 (avg: 0.385497) \tsec/iter: 0.0489\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.286642 (avg: 0.326152) \tsec/iter: 0.0475\n",
      "Test set (epoch 102): Average loss: 0.6278, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.329434 (avg: 0.329434) \tsec/iter: 0.0479\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.429118 (avg: 0.315572) \tsec/iter: 0.0455\n",
      "Test set (epoch 103): Average loss: 0.5781, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.246952 (avg: 0.246952) \tsec/iter: 0.0469\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.300501 (avg: 0.312777) \tsec/iter: 0.0445\n",
      "Test set (epoch 104): Average loss: 0.4793, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.240850 (avg: 0.240850) \tsec/iter: 0.0539\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.422044 (avg: 0.337775) \tsec/iter: 0.0482\n",
      "Test set (epoch 105): Average loss: 0.7851, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.314849 (avg: 0.314849) \tsec/iter: 0.0539\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.349321 (avg: 0.325758) \tsec/iter: 0.0502\n",
      "Test set (epoch 106): Average loss: 0.5304, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.259033 (avg: 0.259033) \tsec/iter: 0.0758\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.366319 (avg: 0.292620) \tsec/iter: 0.0585\n",
      "Test set (epoch 107): Average loss: 0.6228, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.281413 (avg: 0.281413) \tsec/iter: 0.0549\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.372990 (avg: 0.288854) \tsec/iter: 0.0479\n",
      "Test set (epoch 108): Average loss: 0.8083, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.270479 (avg: 0.270479) \tsec/iter: 0.0529\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.343261 (avg: 0.345517) \tsec/iter: 0.0459\n",
      "Test set (epoch 109): Average loss: 0.3998, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.343968 (avg: 0.343968) \tsec/iter: 0.0429\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.352075 (avg: 0.339172) \tsec/iter: 0.0449\n",
      "Test set (epoch 110): Average loss: 0.5706, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.280962 (avg: 0.280962) \tsec/iter: 0.0529\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.224439 (avg: 0.320349) \tsec/iter: 0.0449\n",
      "Test set (epoch 111): Average loss: 0.5765, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.357187 (avg: 0.357187) \tsec/iter: 0.0529\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.373802 (avg: 0.328215) \tsec/iter: 0.0495\n",
      "Test set (epoch 112): Average loss: 0.6347, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.354407 (avg: 0.354407) \tsec/iter: 0.0539\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.250757 (avg: 0.308761) \tsec/iter: 0.0512\n",
      "Test set (epoch 113): Average loss: 0.6709, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.259641 (avg: 0.259641) \tsec/iter: 0.0529\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.185728 (avg: 0.293545) \tsec/iter: 0.0459\n",
      "Test set (epoch 114): Average loss: 0.4705, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.361227 (avg: 0.361227) \tsec/iter: 0.0509\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.285453 (avg: 0.300705) \tsec/iter: 0.0442\n",
      "Test set (epoch 115): Average loss: 0.5486, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.227074 (avg: 0.227074) \tsec/iter: 0.0459\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.466929 (avg: 0.312685) \tsec/iter: 0.0445\n",
      "Test set (epoch 116): Average loss: 0.5174, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.206298 (avg: 0.206298) \tsec/iter: 0.0509\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.340526 (avg: 0.297124) \tsec/iter: 0.0479\n",
      "Test set (epoch 117): Average loss: 0.5248, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.461717 (avg: 0.461717) \tsec/iter: 0.0409\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.310439 (avg: 0.321040) \tsec/iter: 0.0419\n",
      "Test set (epoch 118): Average loss: 0.5197, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.355635 (avg: 0.355635) \tsec/iter: 0.0409\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.287061 (avg: 0.318326) \tsec/iter: 0.0436\n",
      "Test set (epoch 119): Average loss: 0.5650, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.295286 (avg: 0.295286) \tsec/iter: 0.0568\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.473633 (avg: 0.307869) \tsec/iter: 0.0495\n",
      "Test set (epoch 120): Average loss: 0.6633, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.302108 (avg: 0.302108) \tsec/iter: 0.0479\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.273993 (avg: 0.308410) \tsec/iter: 0.0422\n",
      "Test set (epoch 121): Average loss: 0.4571, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.257749 (avg: 0.257749) \tsec/iter: 0.0529\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.293542 (avg: 0.284761) \tsec/iter: 0.0479\n",
      "Test set (epoch 122): Average loss: 0.4333, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.232714 (avg: 0.232714) \tsec/iter: 0.0469\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.366603 (avg: 0.311081) \tsec/iter: 0.0455\n",
      "Test set (epoch 123): Average loss: 0.5330, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.336671 (avg: 0.336671) \tsec/iter: 0.0469\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.250364 (avg: 0.286598) \tsec/iter: 0.0469\n",
      "Test set (epoch 124): Average loss: 0.4312, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.382028 (avg: 0.382028) \tsec/iter: 0.0489\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.218108 (avg: 0.288456) \tsec/iter: 0.0455\n",
      "Test set (epoch 125): Average loss: 0.5640, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.319903 (avg: 0.319903) \tsec/iter: 0.0509\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.221660 (avg: 0.307734) \tsec/iter: 0.0495\n",
      "Test set (epoch 126): Average loss: 0.5056, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.327349 (avg: 0.327349) \tsec/iter: 0.0519\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.152435 (avg: 0.326964) \tsec/iter: 0.0485\n",
      "Test set (epoch 127): Average loss: 0.5636, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.310489 (avg: 0.310489) \tsec/iter: 0.0549\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.323756 (avg: 0.324132) \tsec/iter: 0.0512\n",
      "Test set (epoch 128): Average loss: 0.4259, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.261110 (avg: 0.261110) \tsec/iter: 0.0459\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.201818 (avg: 0.301546) \tsec/iter: 0.0445\n",
      "Test set (epoch 129): Average loss: 0.7019, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.319741 (avg: 0.319741) \tsec/iter: 0.0459\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.294136 (avg: 0.356034) \tsec/iter: 0.0412\n",
      "Test set (epoch 130): Average loss: 0.3939, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.423187 (avg: 0.423187) \tsec/iter: 0.0489\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.259263 (avg: 0.326880) \tsec/iter: 0.0422\n",
      "Test set (epoch 131): Average loss: 0.4724, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.221758 (avg: 0.221758) \tsec/iter: 0.0459\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.235254 (avg: 0.283084) \tsec/iter: 0.0426\n",
      "Test set (epoch 132): Average loss: 0.4618, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.273150 (avg: 0.273150) \tsec/iter: 0.0568\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.295490 (avg: 0.317344) \tsec/iter: 0.0515\n",
      "Test set (epoch 133): Average loss: 0.5272, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.315199 (avg: 0.315199) \tsec/iter: 0.0519\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.264663 (avg: 0.344654) \tsec/iter: 0.0455\n",
      "Test set (epoch 134): Average loss: 0.4107, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.350845 (avg: 0.350845) \tsec/iter: 0.0539\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.371706 (avg: 0.336076) \tsec/iter: 0.0442\n",
      "Test set (epoch 135): Average loss: 0.4371, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.177318 (avg: 0.177318) \tsec/iter: 0.0499\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.311765 (avg: 0.270324) \tsec/iter: 0.0416\n",
      "Test set (epoch 136): Average loss: 0.5828, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.226119 (avg: 0.226119) \tsec/iter: 0.0429\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.313609 (avg: 0.302848) \tsec/iter: 0.0412\n",
      "Test set (epoch 137): Average loss: 0.4923, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.296015 (avg: 0.296015) \tsec/iter: 0.0539\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.176452 (avg: 0.295941) \tsec/iter: 0.0459\n",
      "Test set (epoch 138): Average loss: 0.4205, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.374509 (avg: 0.374509) \tsec/iter: 0.0549\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.243826 (avg: 0.289264) \tsec/iter: 0.0472\n",
      "Test set (epoch 139): Average loss: 0.4938, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.284255 (avg: 0.284255) \tsec/iter: 0.0549\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.267212 (avg: 0.264748) \tsec/iter: 0.0502\n",
      "Test set (epoch 140): Average loss: 0.5334, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.314519 (avg: 0.314519) \tsec/iter: 0.0519\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.242491 (avg: 0.314043) \tsec/iter: 0.0472\n",
      "Test set (epoch 141): Average loss: 0.5499, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.326312 (avg: 0.326312) \tsec/iter: 0.0469\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.357101 (avg: 0.311844) \tsec/iter: 0.0452\n",
      "Test set (epoch 142): Average loss: 0.5418, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.240207 (avg: 0.240207) \tsec/iter: 0.0539\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.241641 (avg: 0.269378) \tsec/iter: 0.0512\n",
      "Test set (epoch 143): Average loss: 0.4626, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.268599 (avg: 0.268599) \tsec/iter: 0.0509\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.344485 (avg: 0.287187) \tsec/iter: 0.0489\n",
      "Test set (epoch 144): Average loss: 0.5228, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.337761 (avg: 0.337761) \tsec/iter: 0.0489\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.361796 (avg: 0.318330) \tsec/iter: 0.0469\n",
      "Test set (epoch 145): Average loss: 0.7283, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.327028 (avg: 0.327028) \tsec/iter: 0.0608\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.250306 (avg: 0.311261) \tsec/iter: 0.0874\n",
      "Test set (epoch 146): Average loss: 0.3201, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.344767 (avg: 0.344767) \tsec/iter: 0.1037\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.248294 (avg: 0.283139) \tsec/iter: 0.0761\n",
      "Test set (epoch 147): Average loss: 0.4521, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.273527 (avg: 0.273527) \tsec/iter: 0.0708\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.289775 (avg: 0.288911) \tsec/iter: 0.0582\n",
      "Test set (epoch 148): Average loss: 0.4167, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.202475 (avg: 0.202475) \tsec/iter: 0.0519\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.384689 (avg: 0.300159) \tsec/iter: 0.0472\n",
      "Test set (epoch 149): Average loss: 0.4581, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.362272 (avg: 0.362272) \tsec/iter: 0.0519\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.263788 (avg: 0.312046) \tsec/iter: 0.0469\n",
      "Test set (epoch 150): Average loss: 0.3758, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.283081 (avg: 0.283081) \tsec/iter: 0.0489\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.304493 (avg: 0.290054) \tsec/iter: 0.0475\n",
      "Test set (epoch 151): Average loss: 0.5570, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.266988 (avg: 0.266988) \tsec/iter: 0.0658\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.242305 (avg: 0.328112) \tsec/iter: 0.0545\n",
      "Test set (epoch 152): Average loss: 0.6292, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.267005 (avg: 0.267005) \tsec/iter: 0.0558\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.296777 (avg: 0.270754) \tsec/iter: 0.0479\n",
      "Test set (epoch 153): Average loss: 0.4507, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.304411 (avg: 0.304411) \tsec/iter: 0.0509\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.333972 (avg: 0.282240) \tsec/iter: 0.0452\n",
      "Test set (epoch 154): Average loss: 0.4852, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.301008 (avg: 0.301008) \tsec/iter: 0.0459\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.298019 (avg: 0.295857) \tsec/iter: 0.0509\n",
      "Test set (epoch 155): Average loss: 0.4549, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.249180 (avg: 0.249180) \tsec/iter: 0.0768\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.263262 (avg: 0.282596) \tsec/iter: 0.0565\n",
      "Test set (epoch 156): Average loss: 0.7639, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.244579 (avg: 0.244579) \tsec/iter: 0.0459\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.284080 (avg: 0.255837) \tsec/iter: 0.0429\n",
      "Test set (epoch 157): Average loss: 0.4626, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.379275 (avg: 0.379275) \tsec/iter: 0.0558\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.354687 (avg: 0.302998) \tsec/iter: 0.0492\n",
      "Test set (epoch 158): Average loss: 0.5178, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.263024 (avg: 0.263024) \tsec/iter: 0.0459\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.274066 (avg: 0.251751) \tsec/iter: 0.0568\n",
      "Test set (epoch 159): Average loss: 0.5637, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.260039 (avg: 0.260039) \tsec/iter: 0.0539\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.255595 (avg: 0.290091) \tsec/iter: 0.0492\n",
      "Test set (epoch 160): Average loss: 0.4316, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.170343 (avg: 0.170343) \tsec/iter: 0.0578\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.351094 (avg: 0.250595) \tsec/iter: 0.0492\n",
      "Test set (epoch 161): Average loss: 0.7625, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.299735 (avg: 0.299735) \tsec/iter: 0.0459\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.198041 (avg: 0.324716) \tsec/iter: 0.0459\n",
      "Test set (epoch 162): Average loss: 0.4360, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.258342 (avg: 0.258342) \tsec/iter: 0.0429\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.309417 (avg: 0.275011) \tsec/iter: 0.0436\n",
      "Test set (epoch 163): Average loss: 0.5870, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.325807 (avg: 0.325807) \tsec/iter: 0.0588\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.444590 (avg: 0.300211) \tsec/iter: 0.0592\n",
      "Test set (epoch 164): Average loss: 0.5401, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.341920 (avg: 0.341920) \tsec/iter: 0.0658\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.267695 (avg: 0.299957) \tsec/iter: 0.0628\n",
      "Test set (epoch 165): Average loss: 0.3572, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.270002 (avg: 0.270002) \tsec/iter: 0.0638\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.362799 (avg: 0.272710) \tsec/iter: 0.0592\n",
      "Test set (epoch 166): Average loss: 0.5974, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.234446 (avg: 0.234446) \tsec/iter: 0.0598\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.269317 (avg: 0.262367) \tsec/iter: 0.0595\n",
      "Test set (epoch 167): Average loss: 0.4547, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.225344 (avg: 0.225344) \tsec/iter: 0.0668\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.334170 (avg: 0.273799) \tsec/iter: 0.0575\n",
      "Test set (epoch 168): Average loss: 0.5230, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.328566 (avg: 0.328566) \tsec/iter: 0.0578\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.172351 (avg: 0.241722) \tsec/iter: 0.0542\n",
      "Test set (epoch 169): Average loss: 0.3524, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.275604 (avg: 0.275604) \tsec/iter: 0.0479\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.254967 (avg: 0.278251) \tsec/iter: 0.0462\n",
      "Test set (epoch 170): Average loss: 0.4913, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.248611 (avg: 0.248611) \tsec/iter: 0.0419\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.285015 (avg: 0.256065) \tsec/iter: 0.0426\n",
      "Test set (epoch 171): Average loss: 0.4903, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.229985 (avg: 0.229985) \tsec/iter: 0.0558\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.219189 (avg: 0.280253) \tsec/iter: 0.0475\n",
      "Test set (epoch 172): Average loss: 0.5084, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.234830 (avg: 0.234830) \tsec/iter: 0.0409\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.178814 (avg: 0.243659) \tsec/iter: 0.0439\n",
      "Test set (epoch 173): Average loss: 0.4112, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.306176 (avg: 0.306176) \tsec/iter: 0.0529\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.290087 (avg: 0.287793) \tsec/iter: 0.0492\n",
      "Test set (epoch 174): Average loss: 0.2826, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.431360 (avg: 0.431360) \tsec/iter: 0.0519\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.250262 (avg: 0.324644) \tsec/iter: 0.0482\n",
      "Test set (epoch 175): Average loss: 0.5345, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.190644 (avg: 0.190644) \tsec/iter: 0.0519\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.303091 (avg: 0.226268) \tsec/iter: 0.0479\n",
      "Test set (epoch 176): Average loss: 0.4880, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.382309 (avg: 0.382309) \tsec/iter: 0.0499\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.313153 (avg: 0.278926) \tsec/iter: 0.0472\n",
      "Test set (epoch 177): Average loss: 0.4534, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.237991 (avg: 0.237991) \tsec/iter: 0.0439\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.287196 (avg: 0.275759) \tsec/iter: 0.0465\n",
      "Test set (epoch 178): Average loss: 0.4350, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.265117 (avg: 0.265117) \tsec/iter: 0.0628\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.349819 (avg: 0.273287) \tsec/iter: 0.0492\n",
      "Test set (epoch 179): Average loss: 0.5300, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.288941 (avg: 0.288941) \tsec/iter: 0.0499\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.256797 (avg: 0.268071) \tsec/iter: 0.0472\n",
      "Test set (epoch 180): Average loss: 0.3824, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.275840 (avg: 0.275840) \tsec/iter: 0.0499\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.236098 (avg: 0.246814) \tsec/iter: 0.0479\n",
      "Test set (epoch 181): Average loss: 0.5704, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.210588 (avg: 0.210588) \tsec/iter: 0.0479\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.265781 (avg: 0.236301) \tsec/iter: 0.0475\n",
      "Test set (epoch 182): Average loss: 0.4815, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.217129 (avg: 0.217129) \tsec/iter: 0.0479\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.206740 (avg: 0.246898) \tsec/iter: 0.0475\n",
      "Test set (epoch 183): Average loss: 0.3607, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.284620 (avg: 0.284620) \tsec/iter: 0.0578\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.163445 (avg: 0.262933) \tsec/iter: 0.0485\n",
      "Test set (epoch 184): Average loss: 0.4996, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.358792 (avg: 0.358792) \tsec/iter: 0.0509\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.230073 (avg: 0.289243) \tsec/iter: 0.0419\n",
      "Test set (epoch 185): Average loss: 0.3513, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.289379 (avg: 0.289379) \tsec/iter: 0.0539\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.330737 (avg: 0.256310) \tsec/iter: 0.0499\n",
      "Test set (epoch 186): Average loss: 0.3925, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.183259 (avg: 0.183259) \tsec/iter: 0.0549\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.313244 (avg: 0.262242) \tsec/iter: 0.0492\n",
      "Test set (epoch 187): Average loss: 0.3885, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.285026 (avg: 0.285026) \tsec/iter: 0.0628\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.260072 (avg: 0.281637) \tsec/iter: 0.0745\n",
      "Test set (epoch 188): Average loss: 0.3063, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.415920 (avg: 0.415920) \tsec/iter: 0.0598\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.262122 (avg: 0.329704) \tsec/iter: 0.0628\n",
      "Test set (epoch 189): Average loss: 0.3675, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.306350 (avg: 0.306350) \tsec/iter: 0.0509\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.253724 (avg: 0.269841) \tsec/iter: 0.0452\n",
      "Test set (epoch 190): Average loss: 0.3618, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.312919 (avg: 0.312919) \tsec/iter: 0.0519\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.250966 (avg: 0.253898) \tsec/iter: 0.0452\n",
      "Test set (epoch 191): Average loss: 0.2957, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.262577 (avg: 0.262577) \tsec/iter: 0.0429\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.205381 (avg: 0.242976) \tsec/iter: 0.0442\n",
      "Test set (epoch 192): Average loss: 0.3627, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.324474 (avg: 0.324474) \tsec/iter: 0.0499\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.189723 (avg: 0.253193) \tsec/iter: 0.0449\n",
      "Test set (epoch 193): Average loss: 0.4474, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.276896 (avg: 0.276896) \tsec/iter: 0.0598\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.366333 (avg: 0.259348) \tsec/iter: 0.0555\n",
      "Test set (epoch 194): Average loss: 0.4581, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.267931 (avg: 0.267931) \tsec/iter: 0.0598\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.377156 (avg: 0.300299) \tsec/iter: 0.0542\n",
      "Test set (epoch 195): Average loss: 0.3387, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.150951 (avg: 0.150951) \tsec/iter: 0.0439\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.294121 (avg: 0.242980) \tsec/iter: 0.0406\n",
      "Test set (epoch 196): Average loss: 0.4756, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.223875 (avg: 0.223875) \tsec/iter: 0.0519\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.263275 (avg: 0.234971) \tsec/iter: 0.0462\n",
      "Test set (epoch 197): Average loss: 0.4049, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.223309 (avg: 0.223309) \tsec/iter: 0.0558\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.204633 (avg: 0.244751) \tsec/iter: 0.0465\n",
      "Test set (epoch 198): Average loss: 0.2955, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.189421 (avg: 0.189421) \tsec/iter: 0.0489\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.369083 (avg: 0.264700) \tsec/iter: 0.0452\n",
      "Test set (epoch 199): Average loss: 0.3763, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.322126 (avg: 0.322126) \tsec/iter: 0.0489\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.189830 (avg: 0.255465) \tsec/iter: 0.0502\n",
      "Test set (epoch 200): Average loss: 0.4040, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.252147 (avg: 0.252147) \tsec/iter: 0.0638\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.226132 (avg: 0.275896) \tsec/iter: 0.0552\n",
      "Test set (epoch 201): Average loss: 0.4693, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.233525 (avg: 0.233525) \tsec/iter: 0.0539\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.333383 (avg: 0.256925) \tsec/iter: 0.0555\n",
      "Test set (epoch 202): Average loss: 0.2348, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.264556 (avg: 0.264556) \tsec/iter: 0.0499\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.172564 (avg: 0.316177) \tsec/iter: 0.0482\n",
      "Test set (epoch 203): Average loss: 0.6080, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.269269 (avg: 0.269269) \tsec/iter: 0.0598\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.324134 (avg: 0.255632) \tsec/iter: 0.0785\n",
      "Test set (epoch 204): Average loss: 0.3524, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.362301 (avg: 0.362301) \tsec/iter: 0.0768\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.278899 (avg: 0.288157) \tsec/iter: 0.0559\n",
      "Test set (epoch 205): Average loss: 0.4040, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.271442 (avg: 0.271442) \tsec/iter: 0.0588\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.248639 (avg: 0.240239) \tsec/iter: 0.0519\n",
      "Test set (epoch 206): Average loss: 0.4765, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.168562 (avg: 0.168562) \tsec/iter: 0.0509\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.286164 (avg: 0.234170) \tsec/iter: 0.0492\n",
      "Test set (epoch 207): Average loss: 0.3976, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.290396 (avg: 0.290396) \tsec/iter: 0.0808\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.229522 (avg: 0.254287) \tsec/iter: 0.0798\n",
      "Test set (epoch 208): Average loss: 0.3308, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.249559 (avg: 0.249559) \tsec/iter: 0.0937\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.309159 (avg: 0.329850) \tsec/iter: 0.0622\n",
      "Test set (epoch 209): Average loss: 0.3304, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.214476 (avg: 0.214476) \tsec/iter: 0.0519\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.246537 (avg: 0.240907) \tsec/iter: 0.0465\n",
      "Test set (epoch 210): Average loss: 0.2601, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.228332 (avg: 0.228332) \tsec/iter: 0.0588\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.215876 (avg: 0.252054) \tsec/iter: 0.0542\n",
      "Test set (epoch 211): Average loss: 0.3503, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.275154 (avg: 0.275154) \tsec/iter: 0.1057\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.449383 (avg: 0.281369) \tsec/iter: 0.0691\n",
      "Test set (epoch 212): Average loss: 0.3178, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.192383 (avg: 0.192383) \tsec/iter: 0.0549\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.357127 (avg: 0.270106) \tsec/iter: 0.0465\n",
      "Test set (epoch 213): Average loss: 0.5031, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.257485 (avg: 0.257485) \tsec/iter: 0.0509\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.240160 (avg: 0.228292) \tsec/iter: 0.0462\n",
      "Test set (epoch 214): Average loss: 0.3885, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.156006 (avg: 0.156006) \tsec/iter: 0.0479\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.168251 (avg: 0.212174) \tsec/iter: 0.0455\n",
      "Test set (epoch 215): Average loss: 0.3133, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.297442 (avg: 0.297442) \tsec/iter: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.212296 (avg: 0.265838) \tsec/iter: 0.0495\n",
      "Test set (epoch 216): Average loss: 0.2857, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.255867 (avg: 0.255867) \tsec/iter: 0.0519\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.264874 (avg: 0.241714) \tsec/iter: 0.0502\n",
      "Test set (epoch 217): Average loss: 0.3146, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.330545 (avg: 0.330545) \tsec/iter: 0.0578\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.245708 (avg: 0.260463) \tsec/iter: 0.0505\n",
      "Test set (epoch 218): Average loss: 0.3036, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.286114 (avg: 0.286114) \tsec/iter: 0.0928\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.275121 (avg: 0.238160) \tsec/iter: 0.0891\n",
      "Test set (epoch 219): Average loss: 0.2782, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.265537 (avg: 0.265537) \tsec/iter: 0.0957\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.304730 (avg: 0.284902) \tsec/iter: 0.0795\n",
      "Test set (epoch 220): Average loss: 0.3286, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.206750 (avg: 0.206750) \tsec/iter: 0.0529\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.307149 (avg: 0.261342) \tsec/iter: 0.0475\n",
      "Test set (epoch 221): Average loss: 0.3508, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.221188 (avg: 0.221188) \tsec/iter: 0.0598\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.260482 (avg: 0.255187) \tsec/iter: 0.0529\n",
      "Test set (epoch 222): Average loss: 0.4111, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.279303 (avg: 0.279303) \tsec/iter: 0.0928\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.270463 (avg: 0.264516) \tsec/iter: 0.0605\n",
      "Test set (epoch 223): Average loss: 0.4210, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.248446 (avg: 0.248446) \tsec/iter: 0.0539\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.270135 (avg: 0.246185) \tsec/iter: 0.0535\n",
      "Test set (epoch 224): Average loss: 0.3411, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.235038 (avg: 0.235038) \tsec/iter: 0.0449\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.358302 (avg: 0.245487) \tsec/iter: 0.0455\n",
      "Test set (epoch 225): Average loss: 0.4044, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.205650 (avg: 0.205650) \tsec/iter: 0.0549\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.350883 (avg: 0.279315) \tsec/iter: 0.0502\n",
      "Test set (epoch 226): Average loss: 0.3259, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.264894 (avg: 0.264894) \tsec/iter: 0.0489\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.112248 (avg: 0.226364) \tsec/iter: 0.0472\n",
      "Test set (epoch 227): Average loss: 0.5446, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.208860 (avg: 0.208860) \tsec/iter: 0.0549\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.163307 (avg: 0.248792) \tsec/iter: 0.0499\n",
      "Test set (epoch 228): Average loss: 0.4387, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.263673 (avg: 0.263673) \tsec/iter: 0.0559\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.207525 (avg: 0.248103) \tsec/iter: 0.0495\n",
      "Test set (epoch 229): Average loss: 0.3934, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.198026 (avg: 0.198026) \tsec/iter: 0.0728\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.173066 (avg: 0.235915) \tsec/iter: 0.0605\n",
      "Test set (epoch 230): Average loss: 0.4698, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.200706 (avg: 0.200706) \tsec/iter: 0.0568\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.349762 (avg: 0.290323) \tsec/iter: 0.0485\n",
      "Test set (epoch 231): Average loss: 0.4149, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.359256 (avg: 0.359256) \tsec/iter: 0.0499\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.150623 (avg: 0.242739) \tsec/iter: 0.0455\n",
      "Test set (epoch 232): Average loss: 0.2991, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.155202 (avg: 0.155202) \tsec/iter: 0.0459\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.304074 (avg: 0.216844) \tsec/iter: 0.0455\n",
      "Test set (epoch 233): Average loss: 0.4440, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.200727 (avg: 0.200727) \tsec/iter: 0.0598\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.324443 (avg: 0.261405) \tsec/iter: 0.0542\n",
      "Test set (epoch 234): Average loss: 0.3922, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.247196 (avg: 0.247196) \tsec/iter: 0.0559\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.210207 (avg: 0.219903) \tsec/iter: 0.0495\n",
      "Test set (epoch 235): Average loss: 0.3095, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.276618 (avg: 0.276618) \tsec/iter: 0.0718\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.191695 (avg: 0.256054) \tsec/iter: 0.0628\n",
      "Test set (epoch 236): Average loss: 0.3952, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.233191 (avg: 0.233191) \tsec/iter: 0.0509\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.256395 (avg: 0.242354) \tsec/iter: 0.0472\n",
      "Test set (epoch 237): Average loss: 0.3367, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.219572 (avg: 0.219572) \tsec/iter: 0.0549\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.489211 (avg: 0.274799) \tsec/iter: 0.0489\n",
      "Test set (epoch 238): Average loss: 0.6902, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.294654 (avg: 0.294654) \tsec/iter: 0.0539\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.146733 (avg: 0.291265) \tsec/iter: 0.0472\n",
      "Test set (epoch 239): Average loss: 0.3296, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.175140 (avg: 0.175140) \tsec/iter: 0.0578\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.208821 (avg: 0.269253) \tsec/iter: 0.0525\n",
      "Test set (epoch 240): Average loss: 0.4664, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.252397 (avg: 0.252397) \tsec/iter: 0.0549\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.288767 (avg: 0.267407) \tsec/iter: 0.0472\n",
      "Test set (epoch 241): Average loss: 0.3213, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.292564 (avg: 0.292564) \tsec/iter: 0.0499\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.206632 (avg: 0.253177) \tsec/iter: 0.0472\n",
      "Test set (epoch 242): Average loss: 0.3251, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.271716 (avg: 0.271716) \tsec/iter: 0.0469\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.319802 (avg: 0.248200) \tsec/iter: 0.0449\n",
      "Test set (epoch 243): Average loss: 0.3038, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.187043 (avg: 0.187043) \tsec/iter: 0.0459\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.226263 (avg: 0.224767) \tsec/iter: 0.0386\n",
      "Test set (epoch 244): Average loss: 0.3943, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.227254 (avg: 0.227254) \tsec/iter: 0.0339\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.128159 (avg: 0.236901) \tsec/iter: 0.0366\n",
      "Test set (epoch 245): Average loss: 0.3684, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.251517 (avg: 0.251517) \tsec/iter: 0.0419\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.196748 (avg: 0.241846) \tsec/iter: 0.0406\n",
      "Test set (epoch 246): Average loss: 0.3050, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.167771 (avg: 0.167771) \tsec/iter: 0.0449\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.260644 (avg: 0.249546) \tsec/iter: 0.0449\n",
      "Test set (epoch 247): Average loss: 0.6686, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.179014 (avg: 0.179014) \tsec/iter: 0.0708\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.286566 (avg: 0.246687) \tsec/iter: 0.0529\n",
      "Test set (epoch 248): Average loss: 0.2824, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.242163 (avg: 0.242163) \tsec/iter: 0.0519\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.158823 (avg: 0.228024) \tsec/iter: 0.0449\n",
      "Test set (epoch 249): Average loss: 0.4314, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.229150 (avg: 0.229150) \tsec/iter: 0.0469\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.293859 (avg: 0.222541) \tsec/iter: 0.0445\n",
      "Test set (epoch 250): Average loss: 0.3967, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.134757 (avg: 0.134757) \tsec/iter: 0.0479\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.339841 (avg: 0.204033) \tsec/iter: 0.0469\n",
      "Test set (epoch 251): Average loss: 0.4665, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.279655 (avg: 0.279655) \tsec/iter: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.203779 (avg: 0.266911) \tsec/iter: 0.0422\n",
      "Test set (epoch 252): Average loss: 0.3755, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.323842 (avg: 0.323842) \tsec/iter: 0.0469\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.178711 (avg: 0.239333) \tsec/iter: 0.0419\n",
      "Test set (epoch 253): Average loss: 0.4525, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.289695 (avg: 0.289695) \tsec/iter: 0.0469\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.220190 (avg: 0.248120) \tsec/iter: 0.0436\n",
      "Test set (epoch 254): Average loss: 0.3871, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.245449 (avg: 0.245449) \tsec/iter: 0.0499\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.150713 (avg: 0.195257) \tsec/iter: 0.0432\n",
      "Test set (epoch 255): Average loss: 0.3308, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.191072 (avg: 0.191072) \tsec/iter: 0.0489\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.357810 (avg: 0.260865) \tsec/iter: 0.0445\n",
      "Test set (epoch 256): Average loss: 0.4818, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.279774 (avg: 0.279774) \tsec/iter: 0.0469\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.313693 (avg: 0.259450) \tsec/iter: 0.0419\n",
      "Test set (epoch 257): Average loss: 0.2841, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.259751 (avg: 0.259751) \tsec/iter: 0.0449\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.230237 (avg: 0.247330) \tsec/iter: 0.0396\n",
      "Test set (epoch 258): Average loss: 0.4695, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.261031 (avg: 0.261031) \tsec/iter: 0.0469\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.238899 (avg: 0.257534) \tsec/iter: 0.0396\n",
      "Test set (epoch 259): Average loss: 0.3277, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.166099 (avg: 0.166099) \tsec/iter: 0.0399\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.182329 (avg: 0.236660) \tsec/iter: 0.0366\n",
      "Test set (epoch 260): Average loss: 0.3215, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.251627 (avg: 0.251627) \tsec/iter: 0.0469\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.328396 (avg: 0.242184) \tsec/iter: 0.0505\n",
      "Test set (epoch 261): Average loss: 0.3878, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.276965 (avg: 0.276965) \tsec/iter: 0.0489\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.291434 (avg: 0.254247) \tsec/iter: 0.0449\n",
      "Test set (epoch 262): Average loss: 0.3842, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.258205 (avg: 0.258205) \tsec/iter: 0.0489\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.297431 (avg: 0.251142) \tsec/iter: 0.0452\n",
      "Test set (epoch 263): Average loss: 0.3555, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.237834 (avg: 0.237834) \tsec/iter: 0.0359\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.219517 (avg: 0.264984) \tsec/iter: 0.0336\n",
      "Test set (epoch 264): Average loss: 0.4021, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.131549 (avg: 0.131549) \tsec/iter: 0.0349\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.366268 (avg: 0.222238) \tsec/iter: 0.0309\n",
      "Test set (epoch 265): Average loss: 0.4077, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.261338 (avg: 0.261338) \tsec/iter: 0.0319\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.227491 (avg: 0.223336) \tsec/iter: 0.0303\n",
      "Test set (epoch 266): Average loss: 0.3087, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.231303 (avg: 0.231303) \tsec/iter: 0.0409\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.283452 (avg: 0.261574) \tsec/iter: 0.0369\n",
      "Test set (epoch 267): Average loss: 0.2844, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.087482 (avg: 0.087482) \tsec/iter: 0.0329\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.333620 (avg: 0.228784) \tsec/iter: 0.0316\n",
      "Test set (epoch 268): Average loss: 0.3426, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.199328 (avg: 0.199328) \tsec/iter: 0.0319\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.400750 (avg: 0.247288) \tsec/iter: 0.0336\n",
      "Test set (epoch 269): Average loss: 0.5958, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.317822 (avg: 0.317822) \tsec/iter: 0.0419\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.306414 (avg: 0.297717) \tsec/iter: 0.0352\n",
      "Test set (epoch 270): Average loss: 0.2681, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.131571 (avg: 0.131571) \tsec/iter: 0.0319\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.300780 (avg: 0.219679) \tsec/iter: 0.0299\n",
      "Test set (epoch 271): Average loss: 0.3081, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.214992 (avg: 0.214992) \tsec/iter: 0.0369\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.200281 (avg: 0.261408) \tsec/iter: 0.0319\n",
      "Test set (epoch 272): Average loss: 0.2649, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.243999 (avg: 0.243999) \tsec/iter: 0.0349\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.226725 (avg: 0.228845) \tsec/iter: 0.0299\n",
      "Test set (epoch 273): Average loss: 0.4168, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.233296 (avg: 0.233296) \tsec/iter: 0.0309\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.178808 (avg: 0.225845) \tsec/iter: 0.0286\n",
      "Test set (epoch 274): Average loss: 0.2267, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.258313 (avg: 0.258313) \tsec/iter: 0.0319\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.343436 (avg: 0.259132) \tsec/iter: 0.0296\n",
      "Test set (epoch 275): Average loss: 0.3414, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.210801 (avg: 0.210801) \tsec/iter: 0.0349\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.600345 (avg: 0.294433) \tsec/iter: 0.0312\n",
      "Test set (epoch 276): Average loss: 0.5676, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.163561 (avg: 0.163561) \tsec/iter: 0.0349\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.251577 (avg: 0.298428) \tsec/iter: 0.0326\n",
      "Test set (epoch 277): Average loss: 0.2592, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.189469 (avg: 0.189469) \tsec/iter: 0.0359\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.182284 (avg: 0.196773) \tsec/iter: 0.0309\n",
      "Test set (epoch 278): Average loss: 0.3162, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.264069 (avg: 0.264069) \tsec/iter: 0.0389\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.146386 (avg: 0.245348) \tsec/iter: 0.0356\n",
      "Test set (epoch 279): Average loss: 0.3565, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.234486 (avg: 0.234486) \tsec/iter: 0.0399\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.187500 (avg: 0.225964) \tsec/iter: 0.0372\n",
      "Test set (epoch 280): Average loss: 0.3168, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.203099 (avg: 0.203099) \tsec/iter: 0.0648\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.229466 (avg: 0.230697) \tsec/iter: 0.0545\n",
      "Test set (epoch 281): Average loss: 0.4374, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.164317 (avg: 0.164317) \tsec/iter: 0.0349\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.421240 (avg: 0.230713) \tsec/iter: 0.0332\n",
      "Test set (epoch 282): Average loss: 0.3979, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.334193 (avg: 0.334193) \tsec/iter: 0.0389\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.094157 (avg: 0.223122) \tsec/iter: 0.0346\n",
      "Test set (epoch 283): Average loss: 0.1672, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.138612 (avg: 0.138612) \tsec/iter: 0.0329\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.252552 (avg: 0.216025) \tsec/iter: 0.0306\n",
      "Test set (epoch 284): Average loss: 0.3989, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.223162 (avg: 0.223162) \tsec/iter: 0.0359\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.249389 (avg: 0.215852) \tsec/iter: 0.0306\n",
      "Test set (epoch 285): Average loss: 0.4079, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.188692 (avg: 0.188692) \tsec/iter: 0.0379\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.118625 (avg: 0.200458) \tsec/iter: 0.0326\n",
      "Test set (epoch 286): Average loss: 0.3561, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.148459 (avg: 0.148459) \tsec/iter: 0.0349\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.230408 (avg: 0.220535) \tsec/iter: 0.0339\n",
      "Test set (epoch 287): Average loss: 0.3960, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.229787 (avg: 0.229787) \tsec/iter: 0.0389\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.198686 (avg: 0.229089) \tsec/iter: 0.0349\n",
      "Test set (epoch 288): Average loss: 0.2939, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.208680 (avg: 0.208680) \tsec/iter: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.321393 (avg: 0.233370) \tsec/iter: 0.0312\n",
      "Test set (epoch 289): Average loss: 0.3657, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.185462 (avg: 0.185462) \tsec/iter: 0.0329\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.164153 (avg: 0.215036) \tsec/iter: 0.0309\n",
      "Test set (epoch 290): Average loss: 0.2332, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.267887 (avg: 0.267887) \tsec/iter: 0.0319\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.213655 (avg: 0.239733) \tsec/iter: 0.0289\n",
      "Test set (epoch 291): Average loss: 0.3606, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.177046 (avg: 0.177046) \tsec/iter: 0.0349\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.268421 (avg: 0.239701) \tsec/iter: 0.0312\n",
      "Test set (epoch 292): Average loss: 0.3070, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.210536 (avg: 0.210536) \tsec/iter: 0.0379\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.125433 (avg: 0.202569) \tsec/iter: 0.0342\n",
      "Test set (epoch 293): Average loss: 0.4658, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.163339 (avg: 0.163339) \tsec/iter: 0.0339\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.245253 (avg: 0.250320) \tsec/iter: 0.0303\n",
      "Test set (epoch 294): Average loss: 0.4023, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.212133 (avg: 0.212133) \tsec/iter: 0.0309\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.272598 (avg: 0.237568) \tsec/iter: 0.0293\n",
      "Test set (epoch 295): Average loss: 0.4888, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.307963 (avg: 0.307963) \tsec/iter: 0.0329\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.214417 (avg: 0.256143) \tsec/iter: 0.0289\n",
      "Test set (epoch 296): Average loss: 0.2647, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.169700 (avg: 0.169700) \tsec/iter: 0.0369\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.322231 (avg: 0.290926) \tsec/iter: 0.0356\n",
      "Test set (epoch 297): Average loss: 0.2683, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.208762 (avg: 0.208762) \tsec/iter: 0.0409\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.251591 (avg: 0.201014) \tsec/iter: 0.0356\n",
      "Test set (epoch 298): Average loss: 0.3053, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.154092 (avg: 0.154092) \tsec/iter: 0.0339\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.120031 (avg: 0.199866) \tsec/iter: 0.0322\n",
      "Test set (epoch 299): Average loss: 0.2905, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.219946 (avg: 0.219946) \tsec/iter: 0.0309\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.262583 (avg: 0.221711) \tsec/iter: 0.0293\n",
      "Test set (epoch 300): Average loss: 0.3818, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.267500 (avg: 0.267500) \tsec/iter: 0.0349\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.129637 (avg: 0.269473) \tsec/iter: 0.0296\n",
      "Test set (epoch 301): Average loss: 0.6015, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.260144 (avg: 0.260144) \tsec/iter: 0.0369\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.243355 (avg: 0.238566) \tsec/iter: 0.0326\n",
      "Test set (epoch 302): Average loss: 0.2843, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.216907 (avg: 0.216907) \tsec/iter: 0.0339\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.331814 (avg: 0.233621) \tsec/iter: 0.0309\n",
      "Test set (epoch 303): Average loss: 0.4194, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.215853 (avg: 0.215853) \tsec/iter: 0.0349\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.233729 (avg: 0.237616) \tsec/iter: 0.0306\n",
      "Test set (epoch 304): Average loss: 0.4169, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.239745 (avg: 0.239745) \tsec/iter: 0.0349\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.226684 (avg: 0.251508) \tsec/iter: 0.0296\n",
      "Test set (epoch 305): Average loss: 0.4241, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.305001 (avg: 0.305001) \tsec/iter: 0.0329\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.158283 (avg: 0.225644) \tsec/iter: 0.0316\n",
      "Test set (epoch 306): Average loss: 0.4249, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.289567 (avg: 0.289567) \tsec/iter: 0.0439\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.139768 (avg: 0.215680) \tsec/iter: 0.0465\n",
      "Test set (epoch 307): Average loss: 0.3176, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.301306 (avg: 0.301306) \tsec/iter: 0.0359\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.268570 (avg: 0.259493) \tsec/iter: 0.0322\n",
      "Test set (epoch 308): Average loss: 0.3329, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.224490 (avg: 0.224490) \tsec/iter: 0.0319\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.177923 (avg: 0.227192) \tsec/iter: 0.0306\n",
      "Test set (epoch 309): Average loss: 0.3640, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.163762 (avg: 0.163762) \tsec/iter: 0.0309\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.248219 (avg: 0.198976) \tsec/iter: 0.0296\n",
      "Test set (epoch 310): Average loss: 0.3925, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.188166 (avg: 0.188166) \tsec/iter: 0.0349\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.184764 (avg: 0.208966) \tsec/iter: 0.0342\n",
      "Test set (epoch 311): Average loss: 0.4068, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.247263 (avg: 0.247263) \tsec/iter: 0.0349\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.256145 (avg: 0.240561) \tsec/iter: 0.0319\n",
      "Test set (epoch 312): Average loss: 0.2369, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.167616 (avg: 0.167616) \tsec/iter: 0.0329\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.233161 (avg: 0.197113) \tsec/iter: 0.0322\n",
      "Test set (epoch 313): Average loss: 0.3504, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.206647 (avg: 0.206647) \tsec/iter: 0.0379\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.219426 (avg: 0.210278) \tsec/iter: 0.0303\n",
      "Test set (epoch 314): Average loss: 0.3116, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.201389 (avg: 0.201389) \tsec/iter: 0.0309\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.333648 (avg: 0.231686) \tsec/iter: 0.0299\n",
      "Test set (epoch 315): Average loss: 0.2664, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.180547 (avg: 0.180547) \tsec/iter: 0.0369\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.215003 (avg: 0.229181) \tsec/iter: 0.0342\n",
      "Test set (epoch 316): Average loss: 0.3873, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.301085 (avg: 0.301085) \tsec/iter: 0.0399\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.146715 (avg: 0.265584) \tsec/iter: 0.0379\n",
      "Test set (epoch 317): Average loss: 0.4023, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.175009 (avg: 0.175009) \tsec/iter: 0.0379\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.249711 (avg: 0.205104) \tsec/iter: 0.0319\n",
      "Test set (epoch 318): Average loss: 0.4098, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.267923 (avg: 0.267923) \tsec/iter: 0.0309\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.129253 (avg: 0.227603) \tsec/iter: 0.0289\n",
      "Test set (epoch 319): Average loss: 0.3605, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.176610 (avg: 0.176610) \tsec/iter: 0.0299\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.265501 (avg: 0.192618) \tsec/iter: 0.0286\n",
      "Test set (epoch 320): Average loss: 0.3440, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.190792 (avg: 0.190792) \tsec/iter: 0.0299\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.102257 (avg: 0.192458) \tsec/iter: 0.0313\n",
      "Test set (epoch 321): Average loss: 0.3217, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.171794 (avg: 0.171794) \tsec/iter: 0.0319\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.354014 (avg: 0.202261) \tsec/iter: 0.0306\n",
      "Test set (epoch 322): Average loss: 0.4825, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.144048 (avg: 0.144048) \tsec/iter: 0.0339\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.315620 (avg: 0.222911) \tsec/iter: 0.0309\n",
      "Test set (epoch 323): Average loss: 0.4577, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.153416 (avg: 0.153416) \tsec/iter: 0.0359\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.274133 (avg: 0.248833) \tsec/iter: 0.0296\n",
      "Test set (epoch 324): Average loss: 0.4513, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.279960 (avg: 0.279960) \tsec/iter: 0.0329\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.255927 (avg: 0.260196) \tsec/iter: 0.0299\n",
      "Test set (epoch 325): Average loss: 0.2928, Accuracy: 16/18 (88.89%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.121211 (avg: 0.121211) \tsec/iter: 0.0369\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.255320 (avg: 0.190921) \tsec/iter: 0.0349\n",
      "Test set (epoch 326): Average loss: 0.4618, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.162686 (avg: 0.162686) \tsec/iter: 0.0379\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.248140 (avg: 0.174762) \tsec/iter: 0.0352\n",
      "Test set (epoch 327): Average loss: 0.3901, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.261709 (avg: 0.261709) \tsec/iter: 0.0379\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.114493 (avg: 0.199557) \tsec/iter: 0.0336\n",
      "Test set (epoch 328): Average loss: 0.3552, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.206397 (avg: 0.206397) \tsec/iter: 0.0319\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.254393 (avg: 0.219908) \tsec/iter: 0.0296\n",
      "Test set (epoch 329): Average loss: 0.4231, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.222224 (avg: 0.222224) \tsec/iter: 0.0309\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.221328 (avg: 0.189354) \tsec/iter: 0.0279\n",
      "Test set (epoch 330): Average loss: 0.2508, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.199156 (avg: 0.199156) \tsec/iter: 0.0359\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.301268 (avg: 0.208047) \tsec/iter: 0.0339\n",
      "Test set (epoch 331): Average loss: 0.3626, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.208905 (avg: 0.208905) \tsec/iter: 0.0349\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.180084 (avg: 0.191900) \tsec/iter: 0.0312\n",
      "Test set (epoch 332): Average loss: 0.3403, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.291943 (avg: 0.291943) \tsec/iter: 0.0359\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.145170 (avg: 0.221375) \tsec/iter: 0.0306\n",
      "Test set (epoch 333): Average loss: 0.3090, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.257655 (avg: 0.257655) \tsec/iter: 0.0319\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.216032 (avg: 0.230728) \tsec/iter: 0.0286\n",
      "Test set (epoch 334): Average loss: 0.2770, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.203598 (avg: 0.203598) \tsec/iter: 0.0309\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.096733 (avg: 0.191744) \tsec/iter: 0.0319\n",
      "Test set (epoch 335): Average loss: 0.3611, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.325619 (avg: 0.325619) \tsec/iter: 0.0369\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.184525 (avg: 0.233466) \tsec/iter: 0.0339\n",
      "Test set (epoch 336): Average loss: 0.2883, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.197607 (avg: 0.197607) \tsec/iter: 0.0319\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.144493 (avg: 0.194498) \tsec/iter: 0.0322\n",
      "Test set (epoch 337): Average loss: 0.4135, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.233530 (avg: 0.233530) \tsec/iter: 0.0389\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.104773 (avg: 0.162337) \tsec/iter: 0.0346\n",
      "Test set (epoch 338): Average loss: 0.4181, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.196181 (avg: 0.196181) \tsec/iter: 0.0359\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.188262 (avg: 0.184045) \tsec/iter: 0.0309\n",
      "Test set (epoch 339): Average loss: 0.2206, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.208105 (avg: 0.208105) \tsec/iter: 0.0329\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.173909 (avg: 0.191475) \tsec/iter: 0.0286\n",
      "Test set (epoch 340): Average loss: 0.3423, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.320254 (avg: 0.320254) \tsec/iter: 0.0309\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.173621 (avg: 0.193688) \tsec/iter: 0.0286\n",
      "Test set (epoch 341): Average loss: 0.2349, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.142961 (avg: 0.142961) \tsec/iter: 0.0369\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.195570 (avg: 0.173520) \tsec/iter: 0.0322\n",
      "Test set (epoch 342): Average loss: 0.3023, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.187390 (avg: 0.187390) \tsec/iter: 0.0339\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.126333 (avg: 0.190795) \tsec/iter: 0.0306\n",
      "Test set (epoch 343): Average loss: 0.3567, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.259075 (avg: 0.259075) \tsec/iter: 0.0319\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.121760 (avg: 0.207893) \tsec/iter: 0.0283\n",
      "Test set (epoch 344): Average loss: 0.4470, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.244754 (avg: 0.244754) \tsec/iter: 0.0379\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.220154 (avg: 0.211190) \tsec/iter: 0.0376\n",
      "Test set (epoch 345): Average loss: 0.2786, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.234342 (avg: 0.234342) \tsec/iter: 0.0429\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.183599 (avg: 0.234758) \tsec/iter: 0.0356\n",
      "Test set (epoch 346): Average loss: 0.3100, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.279089 (avg: 0.279089) \tsec/iter: 0.0359\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.216648 (avg: 0.200563) \tsec/iter: 0.0319\n",
      "Test set (epoch 347): Average loss: 0.5147, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.254959 (avg: 0.254959) \tsec/iter: 0.0329\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.142439 (avg: 0.212002) \tsec/iter: 0.0303\n",
      "Test set (epoch 348): Average loss: 0.3490, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.134828 (avg: 0.134828) \tsec/iter: 0.0329\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.273727 (avg: 0.199912) \tsec/iter: 0.0283\n",
      "Test set (epoch 349): Average loss: 0.4361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.142435 (avg: 0.142435) \tsec/iter: 0.0319\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.173422 (avg: 0.178188) \tsec/iter: 0.0309\n",
      "Test set (epoch 350): Average loss: 0.2869, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.249801 (avg: 0.249801) \tsec/iter: 0.0329\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.119576 (avg: 0.243551) \tsec/iter: 0.0303\n",
      "Test set (epoch 351): Average loss: 0.3357, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.168449 (avg: 0.168449) \tsec/iter: 0.0359\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.309556 (avg: 0.217951) \tsec/iter: 0.0303\n",
      "Test set (epoch 352): Average loss: 0.4746, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.220680 (avg: 0.220680) \tsec/iter: 0.0329\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.203658 (avg: 0.219404) \tsec/iter: 0.0293\n",
      "Test set (epoch 353): Average loss: 0.3016, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.260266 (avg: 0.260266) \tsec/iter: 0.0319\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.182938 (avg: 0.212529) \tsec/iter: 0.0296\n",
      "Test set (epoch 354): Average loss: 0.2851, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.147211 (avg: 0.147211) \tsec/iter: 0.0359\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.301401 (avg: 0.234596) \tsec/iter: 0.0346\n",
      "Test set (epoch 355): Average loss: 0.2702, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.198084 (avg: 0.198084) \tsec/iter: 0.0429\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.277813 (avg: 0.229786) \tsec/iter: 0.0356\n",
      "Test set (epoch 356): Average loss: 0.3525, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.156643 (avg: 0.156643) \tsec/iter: 0.0329\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.218534 (avg: 0.220356) \tsec/iter: 0.0289\n",
      "Test set (epoch 357): Average loss: 0.4840, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.193589 (avg: 0.193589) \tsec/iter: 0.0319\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.196859 (avg: 0.179139) \tsec/iter: 0.0306\n",
      "Test set (epoch 358): Average loss: 0.2845, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.139526 (avg: 0.139526) \tsec/iter: 0.0409\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.171246 (avg: 0.166427) \tsec/iter: 0.0352\n",
      "Test set (epoch 359): Average loss: 0.4893, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.230245 (avg: 0.230245) \tsec/iter: 0.0329\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.218184 (avg: 0.238662) \tsec/iter: 0.0319\n",
      "Test set (epoch 360): Average loss: 0.3542, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.205052 (avg: 0.205052) \tsec/iter: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.170996 (avg: 0.194976) \tsec/iter: 0.0322\n",
      "Test set (epoch 361): Average loss: 0.1948, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.139130 (avg: 0.139130) \tsec/iter: 0.0299\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.140350 (avg: 0.163780) \tsec/iter: 0.0303\n",
      "Test set (epoch 362): Average loss: 0.3356, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.195672 (avg: 0.195672) \tsec/iter: 0.0319\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.129419 (avg: 0.181975) \tsec/iter: 0.0316\n",
      "Test set (epoch 363): Average loss: 0.2552, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.173763 (avg: 0.173763) \tsec/iter: 0.0329\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.175023 (avg: 0.233966) \tsec/iter: 0.0326\n",
      "Test set (epoch 364): Average loss: 0.3435, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.158951 (avg: 0.158951) \tsec/iter: 0.0379\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.233635 (avg: 0.194427) \tsec/iter: 0.0356\n",
      "Test set (epoch 365): Average loss: 0.4809, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.231742 (avg: 0.231742) \tsec/iter: 0.0369\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.222383 (avg: 0.211342) \tsec/iter: 0.0342\n",
      "Test set (epoch 366): Average loss: 0.3458, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.193355 (avg: 0.193355) \tsec/iter: 0.0369\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.192544 (avg: 0.195637) \tsec/iter: 0.0309\n",
      "Test set (epoch 367): Average loss: 0.3919, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.154841 (avg: 0.154841) \tsec/iter: 0.0339\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.232289 (avg: 0.188882) \tsec/iter: 0.0296\n",
      "Test set (epoch 368): Average loss: 0.2136, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.121306 (avg: 0.121306) \tsec/iter: 0.0329\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.223884 (avg: 0.194347) \tsec/iter: 0.0289\n",
      "Test set (epoch 369): Average loss: 0.3493, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.194747 (avg: 0.194747) \tsec/iter: 0.0299\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.244411 (avg: 0.209924) \tsec/iter: 0.0296\n",
      "Test set (epoch 370): Average loss: 0.2247, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.220969 (avg: 0.220969) \tsec/iter: 0.0319\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.276011 (avg: 0.206432) \tsec/iter: 0.0296\n",
      "Test set (epoch 371): Average loss: 0.2290, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.123808 (avg: 0.123808) \tsec/iter: 0.0349\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.267930 (avg: 0.213901) \tsec/iter: 0.0316\n",
      "Test set (epoch 372): Average loss: 0.3000, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.134729 (avg: 0.134729) \tsec/iter: 0.0369\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.109112 (avg: 0.155188) \tsec/iter: 0.0319\n",
      "Test set (epoch 373): Average loss: 0.3115, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.276820 (avg: 0.276820) \tsec/iter: 0.0389\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.173732 (avg: 0.174733) \tsec/iter: 0.0362\n",
      "Test set (epoch 374): Average loss: 0.4280, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.196976 (avg: 0.196976) \tsec/iter: 0.0429\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.263210 (avg: 0.196406) \tsec/iter: 0.0349\n",
      "Test set (epoch 375): Average loss: 0.3240, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.133005 (avg: 0.133005) \tsec/iter: 0.0399\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.190657 (avg: 0.144480) \tsec/iter: 0.0326\n",
      "Test set (epoch 376): Average loss: 0.2814, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.123622 (avg: 0.123622) \tsec/iter: 0.0329\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.188258 (avg: 0.179494) \tsec/iter: 0.0309\n",
      "Test set (epoch 377): Average loss: 0.2083, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.144514 (avg: 0.144514) \tsec/iter: 0.0339\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.229178 (avg: 0.177128) \tsec/iter: 0.0296\n",
      "Test set (epoch 378): Average loss: 0.2826, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.211909 (avg: 0.211909) \tsec/iter: 0.0379\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.133459 (avg: 0.182680) \tsec/iter: 0.0316\n",
      "Test set (epoch 379): Average loss: 0.2950, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.267260 (avg: 0.267260) \tsec/iter: 0.0339\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.158320 (avg: 0.221113) \tsec/iter: 0.0309\n",
      "Test set (epoch 380): Average loss: 0.3288, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.220862 (avg: 0.220862) \tsec/iter: 0.0339\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.156459 (avg: 0.214614) \tsec/iter: 0.0309\n",
      "Test set (epoch 381): Average loss: 0.1757, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.203570 (avg: 0.203570) \tsec/iter: 0.0319\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.205865 (avg: 0.246314) \tsec/iter: 0.0289\n",
      "Test set (epoch 382): Average loss: 0.4664, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.150936 (avg: 0.150936) \tsec/iter: 0.0329\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.101013 (avg: 0.154220) \tsec/iter: 0.0286\n",
      "Test set (epoch 383): Average loss: 0.3685, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.124233 (avg: 0.124233) \tsec/iter: 0.0359\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.140515 (avg: 0.194661) \tsec/iter: 0.0352\n",
      "Test set (epoch 384): Average loss: 0.3774, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.091952 (avg: 0.091952) \tsec/iter: 0.0399\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.251342 (avg: 0.173971) \tsec/iter: 0.0342\n",
      "Test set (epoch 385): Average loss: 0.3077, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.397652 (avg: 0.397652) \tsec/iter: 0.0369\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.127417 (avg: 0.304872) \tsec/iter: 0.0356\n",
      "Test set (epoch 386): Average loss: 0.3457, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.163130 (avg: 0.163130) \tsec/iter: 0.0299\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.199170 (avg: 0.190092) \tsec/iter: 0.0283\n",
      "Test set (epoch 387): Average loss: 0.3908, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.177595 (avg: 0.177595) \tsec/iter: 0.0319\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.281372 (avg: 0.201934) \tsec/iter: 0.0299\n",
      "Test set (epoch 388): Average loss: 0.2728, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.168572 (avg: 0.168572) \tsec/iter: 0.0319\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.182504 (avg: 0.197221) \tsec/iter: 0.0299\n",
      "Test set (epoch 389): Average loss: 0.4742, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.201773 (avg: 0.201773) \tsec/iter: 0.0349\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.322421 (avg: 0.213295) \tsec/iter: 0.0346\n",
      "Test set (epoch 390): Average loss: 0.2757, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.218018 (avg: 0.218018) \tsec/iter: 0.0379\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.304885 (avg: 0.224229) \tsec/iter: 0.0322\n",
      "Test set (epoch 391): Average loss: 0.2992, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.185118 (avg: 0.185118) \tsec/iter: 0.0339\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.209620 (avg: 0.197585) \tsec/iter: 0.0303\n",
      "Test set (epoch 392): Average loss: 0.2705, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.113025 (avg: 0.113025) \tsec/iter: 0.0339\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.317528 (avg: 0.212524) \tsec/iter: 0.0319\n",
      "Test set (epoch 393): Average loss: 0.2699, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.238315 (avg: 0.238315) \tsec/iter: 0.0379\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.089715 (avg: 0.179959) \tsec/iter: 0.0356\n",
      "Test set (epoch 394): Average loss: 0.3857, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.238719 (avg: 0.238719) \tsec/iter: 0.0339\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.130491 (avg: 0.203319) \tsec/iter: 0.0326\n",
      "Test set (epoch 395): Average loss: 0.3283, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.156763 (avg: 0.156763) \tsec/iter: 0.0369\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.264157 (avg: 0.174133) \tsec/iter: 0.0326\n",
      "Test set (epoch 396): Average loss: 0.2808, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.230739 (avg: 0.230739) \tsec/iter: 0.0329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.165332 (avg: 0.197557) \tsec/iter: 0.0312\n",
      "Test set (epoch 397): Average loss: 0.4017, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.197185 (avg: 0.197185) \tsec/iter: 0.0299\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.104129 (avg: 0.177413) \tsec/iter: 0.0289\n",
      "Test set (epoch 398): Average loss: 0.3766, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.138167 (avg: 0.138167) \tsec/iter: 0.0309\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.321381 (avg: 0.198721) \tsec/iter: 0.0286\n",
      "Test set (epoch 399): Average loss: 0.5576, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.157148 (avg: 0.157148) \tsec/iter: 0.0379\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.164249 (avg: 0.200913) \tsec/iter: 0.0336\n",
      "Test set (epoch 400): Average loss: 0.3783, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.173501 (avg: 0.173501) \tsec/iter: 0.0329\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.191586 (avg: 0.177697) \tsec/iter: 0.0316\n",
      "Test set (epoch 401): Average loss: 0.2801, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.145423 (avg: 0.145423) \tsec/iter: 0.0319\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.253240 (avg: 0.208919) \tsec/iter: 0.0306\n",
      "Test set (epoch 402): Average loss: 0.3475, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.185657 (avg: 0.185657) \tsec/iter: 0.0369\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.162041 (avg: 0.191363) \tsec/iter: 0.0352\n",
      "Test set (epoch 403): Average loss: 0.2567, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.114960 (avg: 0.114960) \tsec/iter: 0.0389\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.171848 (avg: 0.169179) \tsec/iter: 0.0322\n",
      "Test set (epoch 404): Average loss: 0.3804, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.168179 (avg: 0.168179) \tsec/iter: 0.0359\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.088043 (avg: 0.200165) \tsec/iter: 0.0332\n",
      "Test set (epoch 405): Average loss: 0.2803, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.152074 (avg: 0.152074) \tsec/iter: 0.0369\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.100623 (avg: 0.186404) \tsec/iter: 0.0309\n",
      "Test set (epoch 406): Average loss: 0.3016, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.233609 (avg: 0.233609) \tsec/iter: 0.0339\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.142771 (avg: 0.206019) \tsec/iter: 0.0316\n",
      "Test set (epoch 407): Average loss: 0.2737, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.154790 (avg: 0.154790) \tsec/iter: 0.0339\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.210595 (avg: 0.239485) \tsec/iter: 0.0303\n",
      "Test set (epoch 408): Average loss: 0.4728, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.199159 (avg: 0.199159) \tsec/iter: 0.0329\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.327757 (avg: 0.214139) \tsec/iter: 0.0293\n",
      "Test set (epoch 409): Average loss: 0.4918, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.159541 (avg: 0.159541) \tsec/iter: 0.0379\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.328815 (avg: 0.190512) \tsec/iter: 0.0332\n",
      "Test set (epoch 410): Average loss: 0.2990, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.232716 (avg: 0.232716) \tsec/iter: 0.0339\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.135833 (avg: 0.207848) \tsec/iter: 0.0319\n",
      "Test set (epoch 411): Average loss: 0.2608, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.355582 (avg: 0.355582) \tsec/iter: 0.0319\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.118712 (avg: 0.226921) \tsec/iter: 0.0306\n",
      "Test set (epoch 412): Average loss: 0.3476, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.238267 (avg: 0.238267) \tsec/iter: 0.0389\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.082148 (avg: 0.182403) \tsec/iter: 0.0386\n",
      "Test set (epoch 413): Average loss: 0.3254, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.141771 (avg: 0.141771) \tsec/iter: 0.0339\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.171260 (avg: 0.183219) \tsec/iter: 0.0312\n",
      "Test set (epoch 414): Average loss: 0.3986, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.271450 (avg: 0.271450) \tsec/iter: 0.0349\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.181227 (avg: 0.182767) \tsec/iter: 0.0332\n",
      "Test set (epoch 415): Average loss: 0.2546, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.177841 (avg: 0.177841) \tsec/iter: 0.0359\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.228416 (avg: 0.208495) \tsec/iter: 0.0326\n",
      "Test set (epoch 416): Average loss: 0.3810, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.091789 (avg: 0.091789) \tsec/iter: 0.0329\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.222157 (avg: 0.154328) \tsec/iter: 0.0306\n",
      "Test set (epoch 417): Average loss: 0.2971, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.071708 (avg: 0.071708) \tsec/iter: 0.0369\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.190111 (avg: 0.177593) \tsec/iter: 0.0312\n",
      "Test set (epoch 418): Average loss: 0.3729, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.166844 (avg: 0.166844) \tsec/iter: 0.0349\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.272750 (avg: 0.188325) \tsec/iter: 0.0303\n",
      "Test set (epoch 419): Average loss: 0.3171, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.153490 (avg: 0.153490) \tsec/iter: 0.0309\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.106830 (avg: 0.176200) \tsec/iter: 0.0319\n",
      "Test set (epoch 420): Average loss: 0.3259, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.168451 (avg: 0.168451) \tsec/iter: 0.0359\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.102781 (avg: 0.174060) \tsec/iter: 0.0303\n",
      "Test set (epoch 421): Average loss: 0.3347, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.184174 (avg: 0.184174) \tsec/iter: 0.0369\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.421868 (avg: 0.241453) \tsec/iter: 0.0349\n",
      "Test set (epoch 422): Average loss: 0.3261, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.211974 (avg: 0.211974) \tsec/iter: 0.0359\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.261119 (avg: 0.205014) \tsec/iter: 0.0349\n",
      "Test set (epoch 423): Average loss: 0.2122, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.253315 (avg: 0.253315) \tsec/iter: 0.0389\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.192449 (avg: 0.235493) \tsec/iter: 0.0322\n",
      "Test set (epoch 424): Average loss: 0.3468, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.161211 (avg: 0.161211) \tsec/iter: 0.0349\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.214577 (avg: 0.171175) \tsec/iter: 0.0336\n",
      "Test set (epoch 425): Average loss: 0.2933, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.267623 (avg: 0.267623) \tsec/iter: 0.0349\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.205905 (avg: 0.226642) \tsec/iter: 0.0332\n",
      "Test set (epoch 426): Average loss: 0.3425, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.231269 (avg: 0.231269) \tsec/iter: 0.0379\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.180556 (avg: 0.181675) \tsec/iter: 0.0346\n",
      "Test set (epoch 427): Average loss: 0.2906, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.233785 (avg: 0.233785) \tsec/iter: 0.0289\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.091797 (avg: 0.183765) \tsec/iter: 0.0293\n",
      "Test set (epoch 428): Average loss: 0.2887, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.196752 (avg: 0.196752) \tsec/iter: 0.0329\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.143948 (avg: 0.167170) \tsec/iter: 0.0309\n",
      "Test set (epoch 429): Average loss: 0.2581, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.159706 (avg: 0.159706) \tsec/iter: 0.0359\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.231042 (avg: 0.166299) \tsec/iter: 0.0319\n",
      "Test set (epoch 430): Average loss: 0.3956, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.201632 (avg: 0.201632) \tsec/iter: 0.0349\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.078168 (avg: 0.176949) \tsec/iter: 0.0346\n",
      "Test set (epoch 431): Average loss: 0.3326, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.229743 (avg: 0.229743) \tsec/iter: 0.0359\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.198780 (avg: 0.246155) \tsec/iter: 0.0356\n",
      "Test set (epoch 432): Average loss: 0.4218, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.153724 (avg: 0.153724) \tsec/iter: 0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.186980 (avg: 0.188331) \tsec/iter: 0.0376\n",
      "Test set (epoch 433): Average loss: 0.3346, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.110295 (avg: 0.110295) \tsec/iter: 0.0389\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.081502 (avg: 0.148438) \tsec/iter: 0.0376\n",
      "Test set (epoch 434): Average loss: 0.2310, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.165672 (avg: 0.165672) \tsec/iter: 0.0459\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.132018 (avg: 0.158240) \tsec/iter: 0.0406\n",
      "Test set (epoch 435): Average loss: 0.3695, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.213075 (avg: 0.213075) \tsec/iter: 0.0429\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.120082 (avg: 0.166621) \tsec/iter: 0.0389\n",
      "Test set (epoch 436): Average loss: 0.3702, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.247302 (avg: 0.247302) \tsec/iter: 0.0389\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.167715 (avg: 0.171115) \tsec/iter: 0.0382\n",
      "Test set (epoch 437): Average loss: 0.3227, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.173410 (avg: 0.173410) \tsec/iter: 0.0429\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.245438 (avg: 0.157681) \tsec/iter: 0.0392\n",
      "Test set (epoch 438): Average loss: 0.3964, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.090234 (avg: 0.090234) \tsec/iter: 0.0449\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.218619 (avg: 0.143575) \tsec/iter: 0.0419\n",
      "Test set (epoch 439): Average loss: 0.3960, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.195749 (avg: 0.195749) \tsec/iter: 0.0509\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.167954 (avg: 0.170886) \tsec/iter: 0.0462\n",
      "Test set (epoch 440): Average loss: 0.2851, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.105349 (avg: 0.105349) \tsec/iter: 0.0359\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.434158 (avg: 0.184819) \tsec/iter: 0.0319\n",
      "Test set (epoch 441): Average loss: 0.5359, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.312789 (avg: 0.312789) \tsec/iter: 0.0309\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.090912 (avg: 0.225181) \tsec/iter: 0.0303\n",
      "Test set (epoch 442): Average loss: 0.4167, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.201873 (avg: 0.201873) \tsec/iter: 0.0319\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.079479 (avg: 0.179985) \tsec/iter: 0.0299\n",
      "Test set (epoch 443): Average loss: 0.3214, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.158346 (avg: 0.158346) \tsec/iter: 0.0339\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.219969 (avg: 0.213282) \tsec/iter: 0.0309\n",
      "Test set (epoch 444): Average loss: 0.2752, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.189829 (avg: 0.189829) \tsec/iter: 0.0329\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.213995 (avg: 0.159830) \tsec/iter: 0.0326\n",
      "Test set (epoch 445): Average loss: 0.2738, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.122927 (avg: 0.122927) \tsec/iter: 0.0339\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.285057 (avg: 0.156364) \tsec/iter: 0.0312\n",
      "Test set (epoch 446): Average loss: 0.2438, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.118704 (avg: 0.118704) \tsec/iter: 0.0339\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.190891 (avg: 0.159957) \tsec/iter: 0.0309\n",
      "Test set (epoch 447): Average loss: 0.3352, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.130743 (avg: 0.130743) \tsec/iter: 0.0339\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.164713 (avg: 0.139120) \tsec/iter: 0.0336\n",
      "Test set (epoch 448): Average loss: 0.3203, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.207731 (avg: 0.207731) \tsec/iter: 0.0379\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.232647 (avg: 0.206987) \tsec/iter: 0.0359\n",
      "Test set (epoch 449): Average loss: 0.3143, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.234822 (avg: 0.234822) \tsec/iter: 0.0339\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.304819 (avg: 0.209900) \tsec/iter: 0.0326\n",
      "Test set (epoch 450): Average loss: 0.5159, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.130156 (avg: 0.130156) \tsec/iter: 0.0349\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.140570 (avg: 0.178226) \tsec/iter: 0.0312\n",
      "Test set (epoch 451): Average loss: 0.3016, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.180458 (avg: 0.180458) \tsec/iter: 0.0349\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.131756 (avg: 0.167266) \tsec/iter: 0.0326\n",
      "Test set (epoch 452): Average loss: 0.3834, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.094902 (avg: 0.094902) \tsec/iter: 0.0399\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.167981 (avg: 0.183861) \tsec/iter: 0.0329\n",
      "Test set (epoch 453): Average loss: 0.3423, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.177748 (avg: 0.177748) \tsec/iter: 0.0309\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.188310 (avg: 0.211327) \tsec/iter: 0.0316\n",
      "Test set (epoch 454): Average loss: 0.4858, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.204093 (avg: 0.204093) \tsec/iter: 0.0349\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.139601 (avg: 0.154334) \tsec/iter: 0.0329\n",
      "Test set (epoch 455): Average loss: 0.2854, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.117844 (avg: 0.117844) \tsec/iter: 0.0339\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.127970 (avg: 0.185851) \tsec/iter: 0.0306\n",
      "Test set (epoch 456): Average loss: 0.4301, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.135404 (avg: 0.135404) \tsec/iter: 0.0379\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.323390 (avg: 0.193172) \tsec/iter: 0.0309\n",
      "Test set (epoch 457): Average loss: 0.3647, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.250694 (avg: 0.250694) \tsec/iter: 0.0399\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.114462 (avg: 0.205587) \tsec/iter: 0.0442\n",
      "Test set (epoch 458): Average loss: 0.3647, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.209589 (avg: 0.209589) \tsec/iter: 0.0429\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.097076 (avg: 0.172656) \tsec/iter: 0.0389\n",
      "Test set (epoch 459): Average loss: 0.2646, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.213651 (avg: 0.213651) \tsec/iter: 0.0509\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.211325 (avg: 0.210129) \tsec/iter: 0.0555\n",
      "Test set (epoch 460): Average loss: 0.3522, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.223423 (avg: 0.223423) \tsec/iter: 0.0439\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.109720 (avg: 0.166973) \tsec/iter: 0.0422\n",
      "Test set (epoch 461): Average loss: 0.3747, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.145614 (avg: 0.145614) \tsec/iter: 0.0449\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.144454 (avg: 0.132427) \tsec/iter: 0.0416\n",
      "Test set (epoch 462): Average loss: 0.2306, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.199401 (avg: 0.199401) \tsec/iter: 0.0449\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.258047 (avg: 0.193420) \tsec/iter: 0.0402\n",
      "Test set (epoch 463): Average loss: 0.2913, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.096275 (avg: 0.096275) \tsec/iter: 0.0469\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.133742 (avg: 0.174943) \tsec/iter: 0.0429\n",
      "Test set (epoch 464): Average loss: 0.3216, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.121717 (avg: 0.121717) \tsec/iter: 0.0479\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.135210 (avg: 0.176291) \tsec/iter: 0.0432\n",
      "Test set (epoch 465): Average loss: 0.3816, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.166112 (avg: 0.166112) \tsec/iter: 0.0459\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.125389 (avg: 0.153717) \tsec/iter: 0.0369\n",
      "Test set (epoch 466): Average loss: 0.3988, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.099226 (avg: 0.099226) \tsec/iter: 0.0319\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.226448 (avg: 0.163482) \tsec/iter: 0.0306\n",
      "Test set (epoch 467): Average loss: 0.2823, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.174869 (avg: 0.174869) \tsec/iter: 0.0349\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.163729 (avg: 0.172699) \tsec/iter: 0.0336\n",
      "Test set (epoch 468): Average loss: 0.2777, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.174052 (avg: 0.174052) \tsec/iter: 0.0339\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.117811 (avg: 0.149896) \tsec/iter: 0.0316\n",
      "Test set (epoch 469): Average loss: 0.3544, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.105452 (avg: 0.105452) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.143769 (avg: 0.136983) \tsec/iter: 0.0342\n",
      "Test set (epoch 470): Average loss: 0.2418, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.239769 (avg: 0.239769) \tsec/iter: 0.0409\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.228953 (avg: 0.196107) \tsec/iter: 0.0346\n",
      "Test set (epoch 471): Average loss: 0.3702, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.134249 (avg: 0.134249) \tsec/iter: 0.0329\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.205043 (avg: 0.167653) \tsec/iter: 0.0293\n",
      "Test set (epoch 472): Average loss: 0.4973, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.161251 (avg: 0.161251) \tsec/iter: 0.0339\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.134229 (avg: 0.164156) \tsec/iter: 0.0299\n",
      "Test set (epoch 473): Average loss: 0.3894, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.208295 (avg: 0.208295) \tsec/iter: 0.0379\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.193738 (avg: 0.190226) \tsec/iter: 0.0369\n",
      "Test set (epoch 474): Average loss: 0.3739, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.234501 (avg: 0.234501) \tsec/iter: 0.0409\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.277993 (avg: 0.196907) \tsec/iter: 0.0339\n",
      "Test set (epoch 475): Average loss: 0.2079, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.205412 (avg: 0.205412) \tsec/iter: 0.0349\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.278258 (avg: 0.207358) \tsec/iter: 0.0306\n",
      "Test set (epoch 476): Average loss: 0.4279, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.139086 (avg: 0.139086) \tsec/iter: 0.0349\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.221664 (avg: 0.169688) \tsec/iter: 0.0329\n",
      "Test set (epoch 477): Average loss: 0.4573, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.185500 (avg: 0.185500) \tsec/iter: 0.0389\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.146842 (avg: 0.162049) \tsec/iter: 0.0336\n",
      "Test set (epoch 478): Average loss: 0.3914, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.183684 (avg: 0.183684) \tsec/iter: 0.0329\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.171736 (avg: 0.151701) \tsec/iter: 0.0296\n",
      "Test set (epoch 479): Average loss: 0.2950, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.142045 (avg: 0.142045) \tsec/iter: 0.0349\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.173732 (avg: 0.148037) \tsec/iter: 0.0312\n",
      "Test set (epoch 480): Average loss: 0.3451, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.092391 (avg: 0.092391) \tsec/iter: 0.0369\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.074320 (avg: 0.199805) \tsec/iter: 0.0322\n",
      "Test set (epoch 481): Average loss: 0.4397, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.213211 (avg: 0.213211) \tsec/iter: 0.0339\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.196985 (avg: 0.226983) \tsec/iter: 0.0329\n",
      "Test set (epoch 482): Average loss: 0.2890, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.121575 (avg: 0.121575) \tsec/iter: 0.0369\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.136660 (avg: 0.187026) \tsec/iter: 0.0346\n",
      "Test set (epoch 483): Average loss: 0.2957, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.137935 (avg: 0.137935) \tsec/iter: 0.0399\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.165213 (avg: 0.158926) \tsec/iter: 0.0362\n",
      "Test set (epoch 484): Average loss: 0.2541, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.245621 (avg: 0.245621) \tsec/iter: 0.0409\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.235344 (avg: 0.181344) \tsec/iter: 0.0336\n",
      "Test set (epoch 485): Average loss: 0.2756, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.178816 (avg: 0.178816) \tsec/iter: 0.0369\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.118607 (avg: 0.162760) \tsec/iter: 0.0359\n",
      "Test set (epoch 486): Average loss: 0.3011, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.303581 (avg: 0.303581) \tsec/iter: 0.0409\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.109463 (avg: 0.178714) \tsec/iter: 0.0336\n",
      "Test set (epoch 487): Average loss: 0.3084, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.147607 (avg: 0.147607) \tsec/iter: 0.0369\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.099852 (avg: 0.169119) \tsec/iter: 0.0326\n",
      "Test set (epoch 488): Average loss: 0.2846, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.091313 (avg: 0.091313) \tsec/iter: 0.0349\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.298710 (avg: 0.176070) \tsec/iter: 0.0312\n",
      "Test set (epoch 489): Average loss: 0.6200, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.196895 (avg: 0.196895) \tsec/iter: 0.0379\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.170717 (avg: 0.195366) \tsec/iter: 0.0332\n",
      "Test set (epoch 490): Average loss: 0.3313, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.096604 (avg: 0.096604) \tsec/iter: 0.0439\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.130188 (avg: 0.157630) \tsec/iter: 0.0359\n",
      "Test set (epoch 491): Average loss: 0.4258, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.188982 (avg: 0.188982) \tsec/iter: 0.0329\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.225651 (avg: 0.174209) \tsec/iter: 0.0349\n",
      "Test set (epoch 492): Average loss: 0.2728, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.202339 (avg: 0.202339) \tsec/iter: 0.0409\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.301354 (avg: 0.186209) \tsec/iter: 0.0372\n",
      "Test set (epoch 493): Average loss: 0.3369, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.182961 (avg: 0.182961) \tsec/iter: 0.0379\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.245513 (avg: 0.216634) \tsec/iter: 0.0352\n",
      "Test set (epoch 494): Average loss: 0.4546, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.207758 (avg: 0.207758) \tsec/iter: 0.0409\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.075484 (avg: 0.176573) \tsec/iter: 0.0346\n",
      "Test set (epoch 495): Average loss: 0.2462, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.298958 (avg: 0.298958) \tsec/iter: 0.0419\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.080842 (avg: 0.215019) \tsec/iter: 0.0382\n",
      "Test set (epoch 496): Average loss: 0.2853, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.224648 (avg: 0.224648) \tsec/iter: 0.0429\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.207240 (avg: 0.172197) \tsec/iter: 0.0356\n",
      "Test set (epoch 497): Average loss: 0.1819, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.270309 (avg: 0.270309) \tsec/iter: 0.0359\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.298059 (avg: 0.265929) \tsec/iter: 0.0342\n",
      "Test set (epoch 498): Average loss: 0.2980, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.192433 (avg: 0.192433) \tsec/iter: 0.0419\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.172776 (avg: 0.250797) \tsec/iter: 0.0342\n",
      "Test set (epoch 499): Average loss: 0.3391, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 5\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 3.798150 (avg: 3.798150) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 4.279862 (avg: 4.637965) \tsec/iter: 0.0329\n",
      "Test set (epoch 0): Average loss: 3.6491, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 1.690823 (avg: 1.690823) \tsec/iter: 0.1705\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.566311 (avg: 1.444954) \tsec/iter: 0.0967\n",
      "Test set (epoch 1): Average loss: 1.8674, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 1.196787 (avg: 1.196787) \tsec/iter: 0.0568\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.624549 (avg: 1.182223) \tsec/iter: 0.0505\n",
      "Test set (epoch 2): Average loss: 0.4050, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.525320 (avg: 0.525320) \tsec/iter: 0.0379\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 1.178402 (avg: 0.683118) \tsec/iter: 0.0339\n",
      "Test set (epoch 3): Average loss: 0.5332, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.399401 (avg: 0.399401) \tsec/iter: 0.0469\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.759265 (avg: 0.551240) \tsec/iter: 0.0472\n",
      "Test set (epoch 4): Average loss: 0.4395, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.426037 (avg: 0.426037) \tsec/iter: 0.0628\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.517909 (avg: 0.530829) \tsec/iter: 0.0522\n",
      "Test set (epoch 5): Average loss: 0.4210, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.370114 (avg: 0.370114) \tsec/iter: 0.0429\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.465964 (avg: 0.428829) \tsec/iter: 0.0419\n",
      "Test set (epoch 6): Average loss: 0.6274, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.482544 (avg: 0.482544) \tsec/iter: 0.0499\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.308238 (avg: 0.501398) \tsec/iter: 0.0459\n",
      "Test set (epoch 7): Average loss: 0.7151, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.571249 (avg: 0.571249) \tsec/iter: 0.0529\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.467597 (avg: 0.505936) \tsec/iter: 0.0449\n",
      "Test set (epoch 8): Average loss: 0.8105, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.415834 (avg: 0.415834) \tsec/iter: 0.0519\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.534622 (avg: 0.449536) \tsec/iter: 0.0436\n",
      "Test set (epoch 9): Average loss: 0.6428, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.418464 (avg: 0.418464) \tsec/iter: 0.0529\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.254747 (avg: 0.362069) \tsec/iter: 0.0482\n",
      "Test set (epoch 10): Average loss: 0.6404, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.535811 (avg: 0.535811) \tsec/iter: 0.0509\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.186386 (avg: 0.368771) \tsec/iter: 0.0449\n",
      "Test set (epoch 11): Average loss: 0.5686, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.581361 (avg: 0.581361) \tsec/iter: 0.0469\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.641199 (avg: 0.595572) \tsec/iter: 0.0432\n",
      "Test set (epoch 12): Average loss: 0.4654, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.442389 (avg: 0.442389) \tsec/iter: 0.0578\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.427025 (avg: 0.455930) \tsec/iter: 0.0469\n",
      "Test set (epoch 13): Average loss: 0.4179, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.474137 (avg: 0.474137) \tsec/iter: 0.0479\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.594752 (avg: 0.411641) \tsec/iter: 0.0462\n",
      "Test set (epoch 14): Average loss: 0.5954, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.487302 (avg: 0.487302) \tsec/iter: 0.0549\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.315273 (avg: 0.372484) \tsec/iter: 0.0479\n",
      "Test set (epoch 15): Average loss: 0.4573, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.372522 (avg: 0.372522) \tsec/iter: 0.0509\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.461431 (avg: 0.396519) \tsec/iter: 0.0459\n",
      "Test set (epoch 16): Average loss: 0.8594, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.644861 (avg: 0.644861) \tsec/iter: 0.0459\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.619631 (avg: 0.520983) \tsec/iter: 0.0422\n",
      "Test set (epoch 17): Average loss: 0.7680, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.467228 (avg: 0.467228) \tsec/iter: 0.0479\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.258037 (avg: 0.389604) \tsec/iter: 0.0442\n",
      "Test set (epoch 18): Average loss: 0.4628, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.398992 (avg: 0.398992) \tsec/iter: 0.0559\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.282447 (avg: 0.350961) \tsec/iter: 0.0492\n",
      "Test set (epoch 19): Average loss: 0.5481, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.328096 (avg: 0.328096) \tsec/iter: 0.0499\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.412267 (avg: 0.351664) \tsec/iter: 0.0472\n",
      "Test set (epoch 20): Average loss: 0.5019, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.372202 (avg: 0.372202) \tsec/iter: 0.0509\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.392173 (avg: 0.334202) \tsec/iter: 0.0482\n",
      "Test set (epoch 21): Average loss: 0.5291, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.309473 (avg: 0.309473) \tsec/iter: 0.0539\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.338073 (avg: 0.361331) \tsec/iter: 0.0479\n",
      "Test set (epoch 22): Average loss: 0.5376, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.330946 (avg: 0.330946) \tsec/iter: 0.0499\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.400959 (avg: 0.345229) \tsec/iter: 0.0412\n",
      "Test set (epoch 23): Average loss: 0.5414, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.407043 (avg: 0.407043) \tsec/iter: 0.0459\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.283282 (avg: 0.337301) \tsec/iter: 0.0439\n",
      "Test set (epoch 24): Average loss: 0.5064, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.263247 (avg: 0.263247) \tsec/iter: 0.0578\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.340542 (avg: 0.372280) \tsec/iter: 0.0495\n",
      "Test set (epoch 25): Average loss: 0.5132, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.312564 (avg: 0.312564) \tsec/iter: 0.0559\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.385319 (avg: 0.379167) \tsec/iter: 0.0505\n",
      "Test set (epoch 26): Average loss: 0.5217, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.327150 (avg: 0.327150) \tsec/iter: 0.0539\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.510191 (avg: 0.376063) \tsec/iter: 0.0479\n",
      "Test set (epoch 27): Average loss: 0.4962, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.440455 (avg: 0.440455) \tsec/iter: 0.0379\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.617620 (avg: 0.391270) \tsec/iter: 0.0329\n",
      "Test set (epoch 28): Average loss: 0.5355, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.398530 (avg: 0.398530) \tsec/iter: 0.0489\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.325246 (avg: 0.354568) \tsec/iter: 0.0462\n",
      "Test set (epoch 29): Average loss: 0.5275, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.465934 (avg: 0.465934) \tsec/iter: 0.0459\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.299000 (avg: 0.356955) \tsec/iter: 0.0452\n",
      "Test set (epoch 30): Average loss: 0.4646, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.354038 (avg: 0.354038) \tsec/iter: 0.0419\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.396737 (avg: 0.342393) \tsec/iter: 0.0379\n",
      "Test set (epoch 31): Average loss: 0.4838, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.455910 (avg: 0.455910) \tsec/iter: 0.0379\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.273097 (avg: 0.359903) \tsec/iter: 0.0349\n",
      "Test set (epoch 32): Average loss: 0.4810, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.291729 (avg: 0.291729) \tsec/iter: 0.0329\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.393965 (avg: 0.345787) \tsec/iter: 0.0322\n",
      "Test set (epoch 33): Average loss: 0.4866, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.271431 (avg: 0.271431) \tsec/iter: 0.0369\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.325653 (avg: 0.320533) \tsec/iter: 0.0332\n",
      "Test set (epoch 34): Average loss: 0.4640, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.339492 (avg: 0.339492) \tsec/iter: 0.0419\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.497411 (avg: 0.356470) \tsec/iter: 0.0379\n",
      "Test set (epoch 35): Average loss: 0.4718, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.307944 (avg: 0.307944) \tsec/iter: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.259138 (avg: 0.353416) \tsec/iter: 0.0339\n",
      "Test set (epoch 36): Average loss: 0.4668, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.355535 (avg: 0.355535) \tsec/iter: 0.0329\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.302722 (avg: 0.330351) \tsec/iter: 0.0312\n",
      "Test set (epoch 37): Average loss: 0.4787, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.358058 (avg: 0.358058) \tsec/iter: 0.0359\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.353896 (avg: 0.313401) \tsec/iter: 0.0336\n",
      "Test set (epoch 38): Average loss: 0.4771, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.381373 (avg: 0.381373) \tsec/iter: 0.0309\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.290600 (avg: 0.353811) \tsec/iter: 0.0306\n",
      "Test set (epoch 39): Average loss: 0.4624, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.238248 (avg: 0.238248) \tsec/iter: 0.0319\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.335051 (avg: 0.328091) \tsec/iter: 0.0319\n",
      "Test set (epoch 40): Average loss: 0.4420, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.299204 (avg: 0.299204) \tsec/iter: 0.0329\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.315200 (avg: 0.334747) \tsec/iter: 0.0289\n",
      "Test set (epoch 41): Average loss: 0.4714, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.373167 (avg: 0.373167) \tsec/iter: 0.0319\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.486185 (avg: 0.352427) \tsec/iter: 0.0312\n",
      "Test set (epoch 42): Average loss: 0.4674, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.313212 (avg: 0.313212) \tsec/iter: 0.0339\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.473691 (avg: 0.361204) \tsec/iter: 0.0319\n",
      "Test set (epoch 43): Average loss: 0.4712, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.438300 (avg: 0.438300) \tsec/iter: 0.0379\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.295547 (avg: 0.388284) \tsec/iter: 0.0369\n",
      "Test set (epoch 44): Average loss: 0.4578, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.428340 (avg: 0.428340) \tsec/iter: 0.0489\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.270453 (avg: 0.361315) \tsec/iter: 0.0392\n",
      "Test set (epoch 45): Average loss: 0.4575, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.326445 (avg: 0.326445) \tsec/iter: 0.0369\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.264874 (avg: 0.334301) \tsec/iter: 0.0336\n",
      "Test set (epoch 46): Average loss: 0.4404, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.287852 (avg: 0.287852) \tsec/iter: 0.0339\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.467691 (avg: 0.361358) \tsec/iter: 0.0296\n",
      "Test set (epoch 47): Average loss: 0.4403, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.297890 (avg: 0.297890) \tsec/iter: 0.0329\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.324229 (avg: 0.339201) \tsec/iter: 0.0286\n",
      "Test set (epoch 48): Average loss: 0.4652, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.378018 (avg: 0.378018) \tsec/iter: 0.0389\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.338933 (avg: 0.342024) \tsec/iter: 0.0332\n",
      "Test set (epoch 49): Average loss: 0.4309, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.367807 (avg: 0.367807) \tsec/iter: 0.0409\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.245488 (avg: 0.337269) \tsec/iter: 0.0332\n",
      "Test set (epoch 50): Average loss: 0.4365, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.469299 (avg: 0.469299) \tsec/iter: 0.0329\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.236924 (avg: 0.364553) \tsec/iter: 0.0312\n",
      "Test set (epoch 51): Average loss: 0.4190, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.396399 (avg: 0.396399) \tsec/iter: 0.0359\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.304291 (avg: 0.327913) \tsec/iter: 0.0319\n",
      "Test set (epoch 52): Average loss: 0.4423, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.306969 (avg: 0.306969) \tsec/iter: 0.0319\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.393508 (avg: 0.342361) \tsec/iter: 0.0339\n",
      "Test set (epoch 53): Average loss: 0.4781, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.285878 (avg: 0.285878) \tsec/iter: 0.0369\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.343584 (avg: 0.324096) \tsec/iter: 0.0369\n",
      "Test set (epoch 54): Average loss: 0.4371, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.460499 (avg: 0.460499) \tsec/iter: 0.0329\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.395794 (avg: 0.368336) \tsec/iter: 0.0329\n",
      "Test set (epoch 55): Average loss: 0.4488, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.367742 (avg: 0.367742) \tsec/iter: 0.0339\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.280993 (avg: 0.314809) \tsec/iter: 0.0306\n",
      "Test set (epoch 56): Average loss: 0.4711, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.356270 (avg: 0.356270) \tsec/iter: 0.0319\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.343113 (avg: 0.332458) \tsec/iter: 0.0312\n",
      "Test set (epoch 57): Average loss: 0.4415, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.342970 (avg: 0.342970) \tsec/iter: 0.0379\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.309244 (avg: 0.362266) \tsec/iter: 0.0366\n",
      "Test set (epoch 58): Average loss: 0.4303, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.267708 (avg: 0.267708) \tsec/iter: 0.0359\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.260601 (avg: 0.310719) \tsec/iter: 0.0309\n",
      "Test set (epoch 59): Average loss: 0.4217, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.296765 (avg: 0.296765) \tsec/iter: 0.0329\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.381395 (avg: 0.324064) \tsec/iter: 0.0316\n",
      "Test set (epoch 60): Average loss: 0.4540, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.380507 (avg: 0.380507) \tsec/iter: 0.0389\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.328405 (avg: 0.361803) \tsec/iter: 0.0326\n",
      "Test set (epoch 61): Average loss: 0.4325, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.374255 (avg: 0.374255) \tsec/iter: 0.0389\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.289096 (avg: 0.327970) \tsec/iter: 0.0349\n",
      "Test set (epoch 62): Average loss: 0.4511, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.291104 (avg: 0.291104) \tsec/iter: 0.0389\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.340159 (avg: 0.334822) \tsec/iter: 0.0376\n",
      "Test set (epoch 63): Average loss: 0.5249, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.425984 (avg: 0.425984) \tsec/iter: 0.0359\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.232469 (avg: 0.344206) \tsec/iter: 0.0319\n",
      "Test set (epoch 64): Average loss: 0.4252, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.367726 (avg: 0.367726) \tsec/iter: 0.0349\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.247685 (avg: 0.337956) \tsec/iter: 0.0312\n",
      "Test set (epoch 65): Average loss: 0.4294, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.264707 (avg: 0.264707) \tsec/iter: 0.0349\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.405363 (avg: 0.335497) \tsec/iter: 0.0309\n",
      "Test set (epoch 66): Average loss: 0.4763, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.320992 (avg: 0.320992) \tsec/iter: 0.0359\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.296313 (avg: 0.374305) \tsec/iter: 0.0319\n",
      "Test set (epoch 67): Average loss: 0.4834, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.387936 (avg: 0.387936) \tsec/iter: 0.0339\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.273176 (avg: 0.340938) \tsec/iter: 0.0332\n",
      "Test set (epoch 68): Average loss: 0.4412, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.338411 (avg: 0.338411) \tsec/iter: 0.0339\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.332320 (avg: 0.324929) \tsec/iter: 0.0312\n",
      "Test set (epoch 69): Average loss: 0.4593, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.284632 (avg: 0.284632) \tsec/iter: 0.0539\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.323763 (avg: 0.340281) \tsec/iter: 0.0389\n",
      "Test set (epoch 70): Average loss: 0.4415, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.261378 (avg: 0.261378) \tsec/iter: 0.0359\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.319523 (avg: 0.300167) \tsec/iter: 0.0362\n",
      "Test set (epoch 71): Average loss: 0.4837, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.297791 (avg: 0.297791) \tsec/iter: 0.0499\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.345337 (avg: 0.318782) \tsec/iter: 0.0445\n",
      "Test set (epoch 72): Average loss: 0.4888, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.270074 (avg: 0.270074) \tsec/iter: 0.0329\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.435158 (avg: 0.313758) \tsec/iter: 0.0312\n",
      "Test set (epoch 73): Average loss: 0.4796, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.340020 (avg: 0.340020) \tsec/iter: 0.0359\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.191886 (avg: 0.325334) \tsec/iter: 0.0336\n",
      "Test set (epoch 74): Average loss: 0.4899, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.320091 (avg: 0.320091) \tsec/iter: 0.0349\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.239344 (avg: 0.309691) \tsec/iter: 0.0336\n",
      "Test set (epoch 75): Average loss: 0.4646, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.335198 (avg: 0.335198) \tsec/iter: 0.0379\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.409726 (avg: 0.343130) \tsec/iter: 0.0419\n",
      "Test set (epoch 76): Average loss: 0.4506, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.350615 (avg: 0.350615) \tsec/iter: 0.0509\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.386812 (avg: 0.333459) \tsec/iter: 0.0386\n",
      "Test set (epoch 77): Average loss: 0.4777, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.215893 (avg: 0.215893) \tsec/iter: 0.0349\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.392375 (avg: 0.325400) \tsec/iter: 0.0309\n",
      "Test set (epoch 78): Average loss: 0.4327, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.265995 (avg: 0.265995) \tsec/iter: 0.0339\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.390588 (avg: 0.318386) \tsec/iter: 0.0319\n",
      "Test set (epoch 79): Average loss: 0.4285, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.329187 (avg: 0.329187) \tsec/iter: 0.0399\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.234868 (avg: 0.310209) \tsec/iter: 0.0382\n",
      "Test set (epoch 80): Average loss: 0.4665, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.277778 (avg: 0.277778) \tsec/iter: 0.0419\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.387619 (avg: 0.304030) \tsec/iter: 0.0339\n",
      "Test set (epoch 81): Average loss: 0.4843, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.264691 (avg: 0.264691) \tsec/iter: 0.0429\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.330320 (avg: 0.316827) \tsec/iter: 0.0356\n",
      "Test set (epoch 82): Average loss: 0.4284, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.267194 (avg: 0.267194) \tsec/iter: 0.0359\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.253161 (avg: 0.333603) \tsec/iter: 0.0346\n",
      "Test set (epoch 83): Average loss: 0.5020, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.264337 (avg: 0.264337) \tsec/iter: 0.0409\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.259478 (avg: 0.314090) \tsec/iter: 0.0336\n",
      "Test set (epoch 84): Average loss: 0.4405, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.296355 (avg: 0.296355) \tsec/iter: 0.0349\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.302157 (avg: 0.310775) \tsec/iter: 0.0336\n",
      "Test set (epoch 85): Average loss: 0.4597, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.297440 (avg: 0.297440) \tsec/iter: 0.0329\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.256245 (avg: 0.276939) \tsec/iter: 0.0322\n",
      "Test set (epoch 86): Average loss: 0.4551, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.352248 (avg: 0.352248) \tsec/iter: 0.0359\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.291261 (avg: 0.329221) \tsec/iter: 0.0319\n",
      "Test set (epoch 87): Average loss: 0.4432, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.260430 (avg: 0.260430) \tsec/iter: 0.0339\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.440861 (avg: 0.346671) \tsec/iter: 0.0322\n",
      "Test set (epoch 88): Average loss: 0.4276, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.356835 (avg: 0.356835) \tsec/iter: 0.0349\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.278068 (avg: 0.342498) \tsec/iter: 0.0352\n",
      "Test set (epoch 89): Average loss: 0.4216, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.363133 (avg: 0.363133) \tsec/iter: 0.0369\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.298362 (avg: 0.316139) \tsec/iter: 0.0346\n",
      "Test set (epoch 90): Average loss: 0.5003, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.284086 (avg: 0.284086) \tsec/iter: 0.0329\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.393104 (avg: 0.333335) \tsec/iter: 0.0322\n",
      "Test set (epoch 91): Average loss: 0.4015, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.351376 (avg: 0.351376) \tsec/iter: 0.0359\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.415119 (avg: 0.350880) \tsec/iter: 0.0309\n",
      "Test set (epoch 92): Average loss: 0.4085, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.351079 (avg: 0.351079) \tsec/iter: 0.0329\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.201378 (avg: 0.323511) \tsec/iter: 0.0322\n",
      "Test set (epoch 93): Average loss: 0.4628, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.377911 (avg: 0.377911) \tsec/iter: 0.0379\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.332054 (avg: 0.342094) \tsec/iter: 0.0332\n",
      "Test set (epoch 94): Average loss: 0.4344, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.376214 (avg: 0.376214) \tsec/iter: 0.0349\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.378120 (avg: 0.345732) \tsec/iter: 0.0312\n",
      "Test set (epoch 95): Average loss: 0.4108, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.392995 (avg: 0.392995) \tsec/iter: 0.0379\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.298666 (avg: 0.339183) \tsec/iter: 0.0312\n",
      "Test set (epoch 96): Average loss: 0.4725, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.299059 (avg: 0.299059) \tsec/iter: 0.0369\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.479628 (avg: 0.345036) \tsec/iter: 0.0349\n",
      "Test set (epoch 97): Average loss: 0.4438, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.259247 (avg: 0.259247) \tsec/iter: 0.0329\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.451988 (avg: 0.325078) \tsec/iter: 0.0326\n",
      "Test set (epoch 98): Average loss: 0.4465, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.386303 (avg: 0.386303) \tsec/iter: 0.0419\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.277977 (avg: 0.345183) \tsec/iter: 0.0389\n",
      "Test set (epoch 99): Average loss: 0.4051, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.353858 (avg: 0.353858) \tsec/iter: 0.0349\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.294841 (avg: 0.308812) \tsec/iter: 0.0329\n",
      "Test set (epoch 100): Average loss: 0.4228, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.367163 (avg: 0.367163) \tsec/iter: 0.0379\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.286439 (avg: 0.336884) \tsec/iter: 0.0319\n",
      "Test set (epoch 101): Average loss: 0.4180, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.299850 (avg: 0.299850) \tsec/iter: 0.0359\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.176433 (avg: 0.309898) \tsec/iter: 0.0322\n",
      "Test set (epoch 102): Average loss: 0.3863, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.319364 (avg: 0.319364) \tsec/iter: 0.0389\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.321143 (avg: 0.312508) \tsec/iter: 0.0359\n",
      "Test set (epoch 103): Average loss: 0.4629, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.247059 (avg: 0.247059) \tsec/iter: 0.0339\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.400458 (avg: 0.314808) \tsec/iter: 0.0322\n",
      "Test set (epoch 104): Average loss: 0.4035, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.245673 (avg: 0.245673) \tsec/iter: 0.0369\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.430137 (avg: 0.369761) \tsec/iter: 0.0306\n",
      "Test set (epoch 105): Average loss: 0.4204, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.241580 (avg: 0.241580) \tsec/iter: 0.0309\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.382047 (avg: 0.303562) \tsec/iter: 0.0303\n",
      "Test set (epoch 106): Average loss: 0.3813, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.249284 (avg: 0.249284) \tsec/iter: 0.0349\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.428466 (avg: 0.323402) \tsec/iter: 0.0316\n",
      "Test set (epoch 107): Average loss: 0.4022, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.212781 (avg: 0.212781) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.386636 (avg: 0.302508) \tsec/iter: 0.0362\n",
      "Test set (epoch 108): Average loss: 0.4196, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.352934 (avg: 0.352934) \tsec/iter: 0.0379\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.342378 (avg: 0.329106) \tsec/iter: 0.0332\n",
      "Test set (epoch 109): Average loss: 0.3978, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.329178 (avg: 0.329178) \tsec/iter: 0.0369\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.281204 (avg: 0.322482) \tsec/iter: 0.0359\n",
      "Test set (epoch 110): Average loss: 0.4025, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.345771 (avg: 0.345771) \tsec/iter: 0.0409\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.347329 (avg: 0.313003) \tsec/iter: 0.0336\n",
      "Test set (epoch 111): Average loss: 0.4260, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.210014 (avg: 0.210014) \tsec/iter: 0.0379\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.333844 (avg: 0.296615) \tsec/iter: 0.0349\n",
      "Test set (epoch 112): Average loss: 0.4017, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.278768 (avg: 0.278768) \tsec/iter: 0.0359\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.255733 (avg: 0.327202) \tsec/iter: 0.0316\n",
      "Test set (epoch 113): Average loss: 0.4268, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.274819 (avg: 0.274819) \tsec/iter: 0.0369\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.400414 (avg: 0.332939) \tsec/iter: 0.0349\n",
      "Test set (epoch 114): Average loss: 0.3898, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.254141 (avg: 0.254141) \tsec/iter: 0.0359\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.380423 (avg: 0.307510) \tsec/iter: 0.0336\n",
      "Test set (epoch 115): Average loss: 0.4419, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.209280 (avg: 0.209280) \tsec/iter: 0.0349\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.386568 (avg: 0.326787) \tsec/iter: 0.0349\n",
      "Test set (epoch 116): Average loss: 0.4026, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.324882 (avg: 0.324882) \tsec/iter: 0.0409\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.319602 (avg: 0.304302) \tsec/iter: 0.0366\n",
      "Test set (epoch 117): Average loss: 0.4128, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.386345 (avg: 0.386345) \tsec/iter: 0.0399\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.309261 (avg: 0.327316) \tsec/iter: 0.0342\n",
      "Test set (epoch 118): Average loss: 0.4146, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.253665 (avg: 0.253665) \tsec/iter: 0.0399\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.298189 (avg: 0.324573) \tsec/iter: 0.0332\n",
      "Test set (epoch 119): Average loss: 0.4158, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.234155 (avg: 0.234155) \tsec/iter: 0.0389\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.353587 (avg: 0.294183) \tsec/iter: 0.0359\n",
      "Test set (epoch 120): Average loss: 0.4150, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.255048 (avg: 0.255048) \tsec/iter: 0.0379\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.452298 (avg: 0.294561) \tsec/iter: 0.0332\n",
      "Test set (epoch 121): Average loss: 0.4079, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.247049 (avg: 0.247049) \tsec/iter: 0.0359\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.312335 (avg: 0.327664) \tsec/iter: 0.0346\n",
      "Test set (epoch 122): Average loss: 0.4080, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.244036 (avg: 0.244036) \tsec/iter: 0.0489\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.395170 (avg: 0.302863) \tsec/iter: 0.0409\n",
      "Test set (epoch 123): Average loss: 0.4241, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.223339 (avg: 0.223339) \tsec/iter: 0.0399\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.354545 (avg: 0.310203) \tsec/iter: 0.0352\n",
      "Test set (epoch 124): Average loss: 0.4276, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.290353 (avg: 0.290353) \tsec/iter: 0.0359\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.297232 (avg: 0.300883) \tsec/iter: 0.0329\n",
      "Test set (epoch 125): Average loss: 0.3919, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.324435 (avg: 0.324435) \tsec/iter: 0.0399\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.265345 (avg: 0.327971) \tsec/iter: 0.0369\n",
      "Test set (epoch 126): Average loss: 0.4079, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.249486 (avg: 0.249486) \tsec/iter: 0.0329\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.361806 (avg: 0.285256) \tsec/iter: 0.0326\n",
      "Test set (epoch 127): Average loss: 0.4204, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.322758 (avg: 0.322758) \tsec/iter: 0.0349\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.303069 (avg: 0.306950) \tsec/iter: 0.0326\n",
      "Test set (epoch 128): Average loss: 0.3770, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.282622 (avg: 0.282622) \tsec/iter: 0.0389\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.365438 (avg: 0.299440) \tsec/iter: 0.0329\n",
      "Test set (epoch 129): Average loss: 0.3952, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.271331 (avg: 0.271331) \tsec/iter: 0.0339\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.413666 (avg: 0.288902) \tsec/iter: 0.0299\n",
      "Test set (epoch 130): Average loss: 0.3608, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.286739 (avg: 0.286739) \tsec/iter: 0.0349\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.177337 (avg: 0.278034) \tsec/iter: 0.0299\n",
      "Test set (epoch 131): Average loss: 0.4100, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.270556 (avg: 0.270556) \tsec/iter: 0.0349\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.158507 (avg: 0.274002) \tsec/iter: 0.0316\n",
      "Test set (epoch 132): Average loss: 0.4005, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.264343 (avg: 0.264343) \tsec/iter: 0.0359\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.353285 (avg: 0.323429) \tsec/iter: 0.0326\n",
      "Test set (epoch 133): Average loss: 0.4034, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.337245 (avg: 0.337245) \tsec/iter: 0.0389\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.169364 (avg: 0.287247) \tsec/iter: 0.0366\n",
      "Test set (epoch 134): Average loss: 0.4218, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.341801 (avg: 0.341801) \tsec/iter: 0.0479\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.270194 (avg: 0.284069) \tsec/iter: 0.0465\n",
      "Test set (epoch 135): Average loss: 0.3923, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.197697 (avg: 0.197697) \tsec/iter: 0.0539\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.408575 (avg: 0.307446) \tsec/iter: 0.0426\n",
      "Test set (epoch 136): Average loss: 0.3998, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.314201 (avg: 0.314201) \tsec/iter: 0.0379\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.238448 (avg: 0.286468) \tsec/iter: 0.0396\n",
      "Test set (epoch 137): Average loss: 0.3730, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.175090 (avg: 0.175090) \tsec/iter: 0.0379\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.297832 (avg: 0.327827) \tsec/iter: 0.0342\n",
      "Test set (epoch 138): Average loss: 0.4400, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.273743 (avg: 0.273743) \tsec/iter: 0.0439\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.394624 (avg: 0.314382) \tsec/iter: 0.0356\n",
      "Test set (epoch 139): Average loss: 0.4266, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.273196 (avg: 0.273196) \tsec/iter: 0.0379\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.460928 (avg: 0.316356) \tsec/iter: 0.0372\n",
      "Test set (epoch 140): Average loss: 0.4143, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.314470 (avg: 0.314470) \tsec/iter: 0.0419\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.326226 (avg: 0.318571) \tsec/iter: 0.0372\n",
      "Test set (epoch 141): Average loss: 0.3795, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.250312 (avg: 0.250312) \tsec/iter: 0.0409\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.307434 (avg: 0.300584) \tsec/iter: 0.0376\n",
      "Test set (epoch 142): Average loss: 0.4169, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.344651 (avg: 0.344651) \tsec/iter: 0.0499\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.215419 (avg: 0.305485) \tsec/iter: 0.0426\n",
      "Test set (epoch 143): Average loss: 0.3989, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.241365 (avg: 0.241365) \tsec/iter: 0.0419\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.250524 (avg: 0.286128) \tsec/iter: 0.0406\n",
      "Test set (epoch 144): Average loss: 0.4216, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.347865 (avg: 0.347865) \tsec/iter: 0.0449\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.283733 (avg: 0.282529) \tsec/iter: 0.0392\n",
      "Test set (epoch 145): Average loss: 0.3914, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.254384 (avg: 0.254384) \tsec/iter: 0.0459\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.303166 (avg: 0.334576) \tsec/iter: 0.0396\n",
      "Test set (epoch 146): Average loss: 0.4460, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.308901 (avg: 0.308901) \tsec/iter: 0.0369\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.410774 (avg: 0.317018) \tsec/iter: 0.0399\n",
      "Test set (epoch 147): Average loss: 0.4128, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.415691 (avg: 0.415691) \tsec/iter: 0.0459\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.167009 (avg: 0.290313) \tsec/iter: 0.0369\n",
      "Test set (epoch 148): Average loss: 0.3929, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.254876 (avg: 0.254876) \tsec/iter: 0.0379\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.373543 (avg: 0.281444) \tsec/iter: 0.0346\n",
      "Test set (epoch 149): Average loss: 0.3662, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.288977 (avg: 0.288977) \tsec/iter: 0.0449\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.241709 (avg: 0.289037) \tsec/iter: 0.0419\n",
      "Test set (epoch 150): Average loss: 0.3985, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.329248 (avg: 0.329248) \tsec/iter: 0.0529\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.249359 (avg: 0.281188) \tsec/iter: 0.0455\n",
      "Test set (epoch 151): Average loss: 0.4274, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.360887 (avg: 0.360887) \tsec/iter: 0.0459\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.289209 (avg: 0.315847) \tsec/iter: 0.0399\n",
      "Test set (epoch 152): Average loss: 0.3766, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.270978 (avg: 0.270978) \tsec/iter: 0.0439\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.346541 (avg: 0.289052) \tsec/iter: 0.0366\n",
      "Test set (epoch 153): Average loss: 0.3992, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.324639 (avg: 0.324639) \tsec/iter: 0.0339\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.229509 (avg: 0.275077) \tsec/iter: 0.0362\n",
      "Test set (epoch 154): Average loss: 0.3447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.434474 (avg: 0.434474) \tsec/iter: 0.0479\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.235597 (avg: 0.281244) \tsec/iter: 0.0399\n",
      "Test set (epoch 155): Average loss: 0.3874, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.141676 (avg: 0.141676) \tsec/iter: 0.0429\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.217655 (avg: 0.300383) \tsec/iter: 0.0402\n",
      "Test set (epoch 156): Average loss: 0.3776, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.299118 (avg: 0.299118) \tsec/iter: 0.0429\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.177782 (avg: 0.277469) \tsec/iter: 0.0392\n",
      "Test set (epoch 157): Average loss: 0.3865, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.202052 (avg: 0.202052) \tsec/iter: 0.0469\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.453577 (avg: 0.293211) \tsec/iter: 0.0439\n",
      "Test set (epoch 158): Average loss: 0.3455, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.325444 (avg: 0.325444) \tsec/iter: 0.0509\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.272085 (avg: 0.276858) \tsec/iter: 0.0432\n",
      "Test set (epoch 159): Average loss: 0.4095, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.333631 (avg: 0.333631) \tsec/iter: 0.0439\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.285269 (avg: 0.310511) \tsec/iter: 0.0422\n",
      "Test set (epoch 160): Average loss: 0.3642, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.272007 (avg: 0.272007) \tsec/iter: 0.0379\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.284774 (avg: 0.287594) \tsec/iter: 0.0366\n",
      "Test set (epoch 161): Average loss: 0.3652, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.320383 (avg: 0.320383) \tsec/iter: 0.0499\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.216173 (avg: 0.249789) \tsec/iter: 0.0409\n",
      "Test set (epoch 162): Average loss: 0.3773, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.272442 (avg: 0.272442) \tsec/iter: 0.0389\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.213043 (avg: 0.258468) \tsec/iter: 0.0339\n",
      "Test set (epoch 163): Average loss: 0.3710, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.204544 (avg: 0.204544) \tsec/iter: 0.0369\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.362304 (avg: 0.277577) \tsec/iter: 0.0379\n",
      "Test set (epoch 164): Average loss: 0.4533, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.246917 (avg: 0.246917) \tsec/iter: 0.0469\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.215476 (avg: 0.265327) \tsec/iter: 0.0402\n",
      "Test set (epoch 165): Average loss: 0.3927, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.265944 (avg: 0.265944) \tsec/iter: 0.0529\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.137228 (avg: 0.279930) \tsec/iter: 0.0462\n",
      "Test set (epoch 166): Average loss: 0.3976, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.284355 (avg: 0.284355) \tsec/iter: 0.0489\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.430048 (avg: 0.311706) \tsec/iter: 0.0416\n",
      "Test set (epoch 167): Average loss: 0.3500, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.326780 (avg: 0.326780) \tsec/iter: 0.0409\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.229385 (avg: 0.301009) \tsec/iter: 0.0356\n",
      "Test set (epoch 168): Average loss: 0.3750, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.239153 (avg: 0.239153) \tsec/iter: 0.0409\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.327919 (avg: 0.275451) \tsec/iter: 0.0386\n",
      "Test set (epoch 169): Average loss: 0.3666, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.301969 (avg: 0.301969) \tsec/iter: 0.0559\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.382385 (avg: 0.339104) \tsec/iter: 0.0452\n",
      "Test set (epoch 170): Average loss: 0.3966, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.211210 (avg: 0.211210) \tsec/iter: 0.0479\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.378453 (avg: 0.251272) \tsec/iter: 0.0416\n",
      "Test set (epoch 171): Average loss: 0.3744, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.396516 (avg: 0.396516) \tsec/iter: 0.0419\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.214234 (avg: 0.292063) \tsec/iter: 0.0399\n",
      "Test set (epoch 172): Average loss: 0.3625, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.256601 (avg: 0.256601) \tsec/iter: 0.0379\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.244872 (avg: 0.267623) \tsec/iter: 0.0342\n",
      "Test set (epoch 173): Average loss: 0.4203, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.330970 (avg: 0.330970) \tsec/iter: 0.0409\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.196583 (avg: 0.260905) \tsec/iter: 0.0429\n",
      "Test set (epoch 174): Average loss: 0.4187, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.260098 (avg: 0.260098) \tsec/iter: 0.0459\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.231447 (avg: 0.239062) \tsec/iter: 0.0416\n",
      "Test set (epoch 175): Average loss: 0.3517, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.225643 (avg: 0.225643) \tsec/iter: 0.0449\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.262368 (avg: 0.272480) \tsec/iter: 0.0422\n",
      "Test set (epoch 176): Average loss: 0.3909, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.215147 (avg: 0.215147) \tsec/iter: 0.0419\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.343068 (avg: 0.261734) \tsec/iter: 0.0392\n",
      "Test set (epoch 177): Average loss: 0.3074, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.189383 (avg: 0.189383) \tsec/iter: 0.0339\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.431951 (avg: 0.260021) \tsec/iter: 0.0342\n",
      "Test set (epoch 178): Average loss: 0.3641, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.293690 (avg: 0.293690) \tsec/iter: 0.0399\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.251126 (avg: 0.266000) \tsec/iter: 0.0366\n",
      "Test set (epoch 179): Average loss: 0.3715, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.270423 (avg: 0.270423) \tsec/iter: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.263539 (avg: 0.290487) \tsec/iter: 0.0376\n",
      "Test set (epoch 180): Average loss: 0.3150, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.174203 (avg: 0.174203) \tsec/iter: 0.0519\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.414372 (avg: 0.311189) \tsec/iter: 0.0525\n",
      "Test set (epoch 181): Average loss: 0.3576, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.222549 (avg: 0.222549) \tsec/iter: 0.0648\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.294726 (avg: 0.252488) \tsec/iter: 0.0499\n",
      "Test set (epoch 182): Average loss: 0.3746, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.266629 (avg: 0.266629) \tsec/iter: 0.0459\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.449441 (avg: 0.292037) \tsec/iter: 0.0416\n",
      "Test set (epoch 183): Average loss: 0.3564, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.214143 (avg: 0.214143) \tsec/iter: 0.0439\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.268052 (avg: 0.259972) \tsec/iter: 0.0389\n",
      "Test set (epoch 184): Average loss: 0.3181, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.270049 (avg: 0.270049) \tsec/iter: 0.0439\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.354239 (avg: 0.275218) \tsec/iter: 0.0372\n",
      "Test set (epoch 185): Average loss: 0.3861, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.259227 (avg: 0.259227) \tsec/iter: 0.0359\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.352934 (avg: 0.281760) \tsec/iter: 0.0316\n",
      "Test set (epoch 186): Average loss: 0.3959, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.292956 (avg: 0.292956) \tsec/iter: 0.0319\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.373000 (avg: 0.283298) \tsec/iter: 0.0293\n",
      "Test set (epoch 187): Average loss: 0.3574, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.323307 (avg: 0.323307) \tsec/iter: 0.0309\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.201851 (avg: 0.241288) \tsec/iter: 0.0279\n",
      "Test set (epoch 188): Average loss: 0.4160, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.266398 (avg: 0.266398) \tsec/iter: 0.0359\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.206943 (avg: 0.275194) \tsec/iter: 0.0336\n",
      "Test set (epoch 189): Average loss: 0.3323, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.266947 (avg: 0.266947) \tsec/iter: 0.0479\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.341820 (avg: 0.254225) \tsec/iter: 0.0439\n",
      "Test set (epoch 190): Average loss: 0.3667, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.266377 (avg: 0.266377) \tsec/iter: 0.0529\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.187390 (avg: 0.240399) \tsec/iter: 0.0469\n",
      "Test set (epoch 191): Average loss: 0.3646, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.266934 (avg: 0.266934) \tsec/iter: 0.0499\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.258408 (avg: 0.263252) \tsec/iter: 0.0452\n",
      "Test set (epoch 192): Average loss: 0.3440, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.345164 (avg: 0.345164) \tsec/iter: 0.0479\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.221191 (avg: 0.284753) \tsec/iter: 0.0442\n",
      "Test set (epoch 193): Average loss: 0.3293, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.232345 (avg: 0.232345) \tsec/iter: 0.0479\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.333307 (avg: 0.296150) \tsec/iter: 0.0452\n",
      "Test set (epoch 194): Average loss: 0.3905, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.217219 (avg: 0.217219) \tsec/iter: 0.0329\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.299028 (avg: 0.249465) \tsec/iter: 0.0332\n",
      "Test set (epoch 195): Average loss: 0.3052, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.361920 (avg: 0.361920) \tsec/iter: 0.0419\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.208653 (avg: 0.262483) \tsec/iter: 0.0349\n",
      "Test set (epoch 196): Average loss: 0.3808, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.244123 (avg: 0.244123) \tsec/iter: 0.0399\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.191036 (avg: 0.222183) \tsec/iter: 0.0379\n",
      "Test set (epoch 197): Average loss: 0.3185, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.278462 (avg: 0.278462) \tsec/iter: 0.0399\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.155710 (avg: 0.228332) \tsec/iter: 0.0319\n",
      "Test set (epoch 198): Average loss: 0.3101, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.311442 (avg: 0.311442) \tsec/iter: 0.0309\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.301135 (avg: 0.270010) \tsec/iter: 0.0309\n",
      "Test set (epoch 199): Average loss: 0.3157, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.201100 (avg: 0.201100) \tsec/iter: 0.0329\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.233622 (avg: 0.249473) \tsec/iter: 0.0319\n",
      "Test set (epoch 200): Average loss: 0.3644, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.334838 (avg: 0.334838) \tsec/iter: 0.0389\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.217028 (avg: 0.227811) \tsec/iter: 0.0389\n",
      "Test set (epoch 201): Average loss: 0.2825, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.330423 (avg: 0.330423) \tsec/iter: 0.0369\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.298797 (avg: 0.266520) \tsec/iter: 0.0312\n",
      "Test set (epoch 202): Average loss: 0.3862, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.158669 (avg: 0.158669) \tsec/iter: 0.0329\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.265923 (avg: 0.230370) \tsec/iter: 0.0326\n",
      "Test set (epoch 203): Average loss: 0.3273, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.270735 (avg: 0.270735) \tsec/iter: 0.0419\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.296066 (avg: 0.287712) \tsec/iter: 0.0349\n",
      "Test set (epoch 204): Average loss: 0.3081, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.296333 (avg: 0.296333) \tsec/iter: 0.0379\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.318002 (avg: 0.276926) \tsec/iter: 0.0339\n",
      "Test set (epoch 205): Average loss: 0.3059, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.296244 (avg: 0.296244) \tsec/iter: 0.0449\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.202019 (avg: 0.251463) \tsec/iter: 0.0386\n",
      "Test set (epoch 206): Average loss: 0.2481, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.260539 (avg: 0.260539) \tsec/iter: 0.0409\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.211470 (avg: 0.274266) \tsec/iter: 0.0372\n",
      "Test set (epoch 207): Average loss: 0.3067, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.271489 (avg: 0.271489) \tsec/iter: 0.0339\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.239030 (avg: 0.238554) \tsec/iter: 0.0293\n",
      "Test set (epoch 208): Average loss: 0.2855, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.280723 (avg: 0.280723) \tsec/iter: 0.0319\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.136799 (avg: 0.212317) \tsec/iter: 0.0299\n",
      "Test set (epoch 209): Average loss: 0.2945, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.217612 (avg: 0.217612) \tsec/iter: 0.0359\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.340440 (avg: 0.246819) \tsec/iter: 0.0336\n",
      "Test set (epoch 210): Average loss: 0.3411, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.231517 (avg: 0.231517) \tsec/iter: 0.0369\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.373361 (avg: 0.304124) \tsec/iter: 0.0336\n",
      "Test set (epoch 211): Average loss: 0.2481, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.276123 (avg: 0.276123) \tsec/iter: 0.0339\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.196845 (avg: 0.234831) \tsec/iter: 0.0309\n",
      "Test set (epoch 212): Average loss: 0.3282, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.192429 (avg: 0.192429) \tsec/iter: 0.0299\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.330224 (avg: 0.247786) \tsec/iter: 0.0289\n",
      "Test set (epoch 213): Average loss: 0.2798, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.292749 (avg: 0.292749) \tsec/iter: 0.0339\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.312633 (avg: 0.275844) \tsec/iter: 0.0329\n",
      "Test set (epoch 214): Average loss: 0.3004, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.187040 (avg: 0.187040) \tsec/iter: 0.0429\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.409415 (avg: 0.261248) \tsec/iter: 0.0392\n",
      "Test set (epoch 215): Average loss: 0.3225, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.228977 (avg: 0.228977) \tsec/iter: 0.0409\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.313846 (avg: 0.233217) \tsec/iter: 0.0369\n",
      "Test set (epoch 216): Average loss: 0.3163, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.201339 (avg: 0.201339) \tsec/iter: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.271565 (avg: 0.234393) \tsec/iter: 0.0312\n",
      "Test set (epoch 217): Average loss: 0.2661, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.212532 (avg: 0.212532) \tsec/iter: 0.0379\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.255294 (avg: 0.254022) \tsec/iter: 0.0312\n",
      "Test set (epoch 218): Average loss: 0.3283, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.305476 (avg: 0.305476) \tsec/iter: 0.0319\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.371591 (avg: 0.313829) \tsec/iter: 0.0306\n",
      "Test set (epoch 219): Average loss: 0.3834, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.241147 (avg: 0.241147) \tsec/iter: 0.0379\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.299554 (avg: 0.246728) \tsec/iter: 0.0346\n",
      "Test set (epoch 220): Average loss: 0.3001, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.341266 (avg: 0.341266) \tsec/iter: 0.0349\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.227312 (avg: 0.268840) \tsec/iter: 0.0306\n",
      "Test set (epoch 221): Average loss: 0.3127, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.272262 (avg: 0.272262) \tsec/iter: 0.0319\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.379646 (avg: 0.255177) \tsec/iter: 0.0303\n",
      "Test set (epoch 222): Average loss: 0.2579, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.340579 (avg: 0.340579) \tsec/iter: 0.0349\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.238025 (avg: 0.267693) \tsec/iter: 0.0329\n",
      "Test set (epoch 223): Average loss: 0.3014, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.294838 (avg: 0.294838) \tsec/iter: 0.0329\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.239002 (avg: 0.225972) \tsec/iter: 0.0316\n",
      "Test set (epoch 224): Average loss: 0.2747, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.365850 (avg: 0.365850) \tsec/iter: 0.0409\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.229109 (avg: 0.268465) \tsec/iter: 0.0386\n",
      "Test set (epoch 225): Average loss: 0.2795, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.292451 (avg: 0.292451) \tsec/iter: 0.0379\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.160824 (avg: 0.246804) \tsec/iter: 0.0322\n",
      "Test set (epoch 226): Average loss: 0.2995, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.321604 (avg: 0.321604) \tsec/iter: 0.0359\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.342408 (avg: 0.252208) \tsec/iter: 0.0322\n",
      "Test set (epoch 227): Average loss: 0.3442, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.249531 (avg: 0.249531) \tsec/iter: 0.0389\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.386144 (avg: 0.254234) \tsec/iter: 0.0342\n",
      "Test set (epoch 228): Average loss: 0.2576, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.222558 (avg: 0.222558) \tsec/iter: 0.0309\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.218777 (avg: 0.235701) \tsec/iter: 0.0329\n",
      "Test set (epoch 229): Average loss: 0.3521, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.291099 (avg: 0.291099) \tsec/iter: 0.0409\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.247859 (avg: 0.245539) \tsec/iter: 0.0352\n",
      "Test set (epoch 230): Average loss: 0.3443, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.176934 (avg: 0.176934) \tsec/iter: 0.0359\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.285918 (avg: 0.237740) \tsec/iter: 0.0336\n",
      "Test set (epoch 231): Average loss: 0.2714, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.376187 (avg: 0.376187) \tsec/iter: 0.0319\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.152462 (avg: 0.270730) \tsec/iter: 0.0283\n",
      "Test set (epoch 232): Average loss: 0.3745, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.233477 (avg: 0.233477) \tsec/iter: 0.0319\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.271714 (avg: 0.240093) \tsec/iter: 0.0322\n",
      "Test set (epoch 233): Average loss: 0.2675, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.220669 (avg: 0.220669) \tsec/iter: 0.0419\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.253127 (avg: 0.242261) \tsec/iter: 0.0362\n",
      "Test set (epoch 234): Average loss: 0.2297, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.203332 (avg: 0.203332) \tsec/iter: 0.0389\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.252732 (avg: 0.328111) \tsec/iter: 0.0332\n",
      "Test set (epoch 235): Average loss: 0.2691, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.137749 (avg: 0.137749) \tsec/iter: 0.0339\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.354732 (avg: 0.260439) \tsec/iter: 0.0316\n",
      "Test set (epoch 236): Average loss: 0.4217, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.220543 (avg: 0.220543) \tsec/iter: 0.0369\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.251419 (avg: 0.278571) \tsec/iter: 0.0303\n",
      "Test set (epoch 237): Average loss: 0.2798, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.319894 (avg: 0.319894) \tsec/iter: 0.0339\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.222383 (avg: 0.264161) \tsec/iter: 0.0293\n",
      "Test set (epoch 238): Average loss: 0.3732, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.258702 (avg: 0.258702) \tsec/iter: 0.0379\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.275567 (avg: 0.267558) \tsec/iter: 0.0319\n",
      "Test set (epoch 239): Average loss: 0.2944, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.296451 (avg: 0.296451) \tsec/iter: 0.0349\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.121877 (avg: 0.264977) \tsec/iter: 0.0299\n",
      "Test set (epoch 240): Average loss: 0.3106, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.275068 (avg: 0.275068) \tsec/iter: 0.0349\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.133591 (avg: 0.229276) \tsec/iter: 0.0349\n",
      "Test set (epoch 241): Average loss: 0.2969, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.210747 (avg: 0.210747) \tsec/iter: 0.0349\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.263554 (avg: 0.235051) \tsec/iter: 0.0316\n",
      "Test set (epoch 242): Average loss: 0.3314, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.322543 (avg: 0.322543) \tsec/iter: 0.0369\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.267940 (avg: 0.246950) \tsec/iter: 0.0359\n",
      "Test set (epoch 243): Average loss: 0.2904, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.336647 (avg: 0.336647) \tsec/iter: 0.0359\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.183084 (avg: 0.238623) \tsec/iter: 0.0342\n",
      "Test set (epoch 244): Average loss: 0.3322, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.244518 (avg: 0.244518) \tsec/iter: 0.0309\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.302178 (avg: 0.272867) \tsec/iter: 0.0299\n",
      "Test set (epoch 245): Average loss: 0.3497, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.171901 (avg: 0.171901) \tsec/iter: 0.0399\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.248897 (avg: 0.264330) \tsec/iter: 0.0322\n",
      "Test set (epoch 246): Average loss: 0.3515, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.191995 (avg: 0.191995) \tsec/iter: 0.0349\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.183139 (avg: 0.257855) \tsec/iter: 0.0309\n",
      "Test set (epoch 247): Average loss: 0.2938, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.274155 (avg: 0.274155) \tsec/iter: 0.0349\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.264077 (avg: 0.253191) \tsec/iter: 0.0312\n",
      "Test set (epoch 248): Average loss: 0.3041, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.184743 (avg: 0.184743) \tsec/iter: 0.0339\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.244798 (avg: 0.255767) \tsec/iter: 0.0316\n",
      "Test set (epoch 249): Average loss: 0.3010, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.281046 (avg: 0.281046) \tsec/iter: 0.0309\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.234471 (avg: 0.242416) \tsec/iter: 0.0303\n",
      "Test set (epoch 250): Average loss: 0.3092, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.240184 (avg: 0.240184) \tsec/iter: 0.0399\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.260921 (avg: 0.237362) \tsec/iter: 0.0326\n",
      "Test set (epoch 251): Average loss: 0.2750, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.171548 (avg: 0.171548) \tsec/iter: 0.0309\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.151760 (avg: 0.283094) \tsec/iter: 0.0309\n",
      "Test set (epoch 252): Average loss: 0.2547, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.284456 (avg: 0.284456) \tsec/iter: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.263293 (avg: 0.252230) \tsec/iter: 0.0442\n",
      "Test set (epoch 253): Average loss: 0.3385, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.238579 (avg: 0.238579) \tsec/iter: 0.0369\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.196401 (avg: 0.199121) \tsec/iter: 0.0346\n",
      "Test set (epoch 254): Average loss: 0.3408, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.189606 (avg: 0.189606) \tsec/iter: 0.0499\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.127822 (avg: 0.238179) \tsec/iter: 0.0399\n",
      "Test set (epoch 255): Average loss: 0.3435, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.246436 (avg: 0.246436) \tsec/iter: 0.0529\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.372615 (avg: 0.232430) \tsec/iter: 0.0409\n",
      "Test set (epoch 256): Average loss: 0.2706, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.275448 (avg: 0.275448) \tsec/iter: 0.0329\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.177904 (avg: 0.246716) \tsec/iter: 0.0312\n",
      "Test set (epoch 257): Average loss: 0.2837, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.164545 (avg: 0.164545) \tsec/iter: 0.0339\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.351514 (avg: 0.239559) \tsec/iter: 0.0306\n",
      "Test set (epoch 258): Average loss: 0.3040, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.156843 (avg: 0.156843) \tsec/iter: 0.0339\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.217645 (avg: 0.224145) \tsec/iter: 0.0309\n",
      "Test set (epoch 259): Average loss: 0.3129, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.223947 (avg: 0.223947) \tsec/iter: 0.0329\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.192405 (avg: 0.219370) \tsec/iter: 0.0322\n",
      "Test set (epoch 260): Average loss: 0.3122, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.191922 (avg: 0.191922) \tsec/iter: 0.0379\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.115235 (avg: 0.213488) \tsec/iter: 0.0386\n",
      "Test set (epoch 261): Average loss: 0.2283, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.234407 (avg: 0.234407) \tsec/iter: 0.0439\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.215555 (avg: 0.281442) \tsec/iter: 0.0389\n",
      "Test set (epoch 262): Average loss: 0.2493, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.286568 (avg: 0.286568) \tsec/iter: 0.0369\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.284818 (avg: 0.275804) \tsec/iter: 0.0342\n",
      "Test set (epoch 263): Average loss: 0.2784, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.255072 (avg: 0.255072) \tsec/iter: 0.0379\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.180116 (avg: 0.260615) \tsec/iter: 0.0336\n",
      "Test set (epoch 264): Average loss: 0.3105, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.334388 (avg: 0.334388) \tsec/iter: 0.0379\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.195866 (avg: 0.270524) \tsec/iter: 0.0339\n",
      "Test set (epoch 265): Average loss: 0.3500, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.228710 (avg: 0.228710) \tsec/iter: 0.0469\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.319418 (avg: 0.231669) \tsec/iter: 0.0372\n",
      "Test set (epoch 266): Average loss: 0.2725, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.286903 (avg: 0.286903) \tsec/iter: 0.0419\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.217215 (avg: 0.229503) \tsec/iter: 0.0399\n",
      "Test set (epoch 267): Average loss: 0.2721, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.130501 (avg: 0.130501) \tsec/iter: 0.0349\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.255147 (avg: 0.265757) \tsec/iter: 0.0326\n",
      "Test set (epoch 268): Average loss: 0.2875, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.172215 (avg: 0.172215) \tsec/iter: 0.0349\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.223491 (avg: 0.223482) \tsec/iter: 0.0326\n",
      "Test set (epoch 269): Average loss: 0.2362, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.245228 (avg: 0.245228) \tsec/iter: 0.0409\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.269234 (avg: 0.230675) \tsec/iter: 0.0386\n",
      "Test set (epoch 270): Average loss: 0.2495, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.226290 (avg: 0.226290) \tsec/iter: 0.0359\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.192010 (avg: 0.229123) \tsec/iter: 0.0342\n",
      "Test set (epoch 271): Average loss: 0.2696, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.184607 (avg: 0.184607) \tsec/iter: 0.0309\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.261526 (avg: 0.230081) \tsec/iter: 0.0309\n",
      "Test set (epoch 272): Average loss: 0.2272, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.223417 (avg: 0.223417) \tsec/iter: 0.0309\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.287975 (avg: 0.254719) \tsec/iter: 0.0312\n",
      "Test set (epoch 273): Average loss: 0.2917, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.194712 (avg: 0.194712) \tsec/iter: 0.0379\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.158037 (avg: 0.207966) \tsec/iter: 0.0329\n",
      "Test set (epoch 274): Average loss: 0.2738, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.334192 (avg: 0.334192) \tsec/iter: 0.0339\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.183210 (avg: 0.292634) \tsec/iter: 0.0312\n",
      "Test set (epoch 275): Average loss: 0.2942, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.273767 (avg: 0.273767) \tsec/iter: 0.0359\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.271993 (avg: 0.236838) \tsec/iter: 0.0326\n",
      "Test set (epoch 276): Average loss: 0.3081, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.210659 (avg: 0.210659) \tsec/iter: 0.0419\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.172733 (avg: 0.232126) \tsec/iter: 0.0342\n",
      "Test set (epoch 277): Average loss: 0.2716, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.237031 (avg: 0.237031) \tsec/iter: 0.0339\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.235790 (avg: 0.244065) \tsec/iter: 0.0303\n",
      "Test set (epoch 278): Average loss: 0.3361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.197028 (avg: 0.197028) \tsec/iter: 0.0339\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.250809 (avg: 0.221259) \tsec/iter: 0.0342\n",
      "Test set (epoch 279): Average loss: 0.3752, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.192558 (avg: 0.192558) \tsec/iter: 0.0419\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.136594 (avg: 0.207190) \tsec/iter: 0.0436\n",
      "Test set (epoch 280): Average loss: 0.2567, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.279400 (avg: 0.279400) \tsec/iter: 0.0359\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.115463 (avg: 0.221074) \tsec/iter: 0.0336\n",
      "Test set (epoch 281): Average loss: 0.2741, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.279043 (avg: 0.279043) \tsec/iter: 0.0319\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.117325 (avg: 0.237278) \tsec/iter: 0.0309\n",
      "Test set (epoch 282): Average loss: 0.2661, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.159825 (avg: 0.159825) \tsec/iter: 0.0349\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.237171 (avg: 0.191952) \tsec/iter: 0.0319\n",
      "Test set (epoch 283): Average loss: 0.2901, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.282566 (avg: 0.282566) \tsec/iter: 0.0399\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.172085 (avg: 0.236576) \tsec/iter: 0.0322\n",
      "Test set (epoch 284): Average loss: 0.3002, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.235454 (avg: 0.235454) \tsec/iter: 0.0329\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.162843 (avg: 0.217252) \tsec/iter: 0.0319\n",
      "Test set (epoch 285): Average loss: 0.3610, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.177116 (avg: 0.177116) \tsec/iter: 0.0369\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.169768 (avg: 0.203869) \tsec/iter: 0.0309\n",
      "Test set (epoch 286): Average loss: 0.2887, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.179210 (avg: 0.179210) \tsec/iter: 0.0349\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.351838 (avg: 0.244397) \tsec/iter: 0.0299\n",
      "Test set (epoch 287): Average loss: 0.3390, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.249569 (avg: 0.249569) \tsec/iter: 0.0379\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.223073 (avg: 0.245184) \tsec/iter: 0.0346\n",
      "Test set (epoch 288): Average loss: 0.3162, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.149363 (avg: 0.149363) \tsec/iter: 0.0399\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.222374 (avg: 0.238416) \tsec/iter: 0.0376\n",
      "Test set (epoch 289): Average loss: 0.3286, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.222261 (avg: 0.222261) \tsec/iter: 0.0379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.235500 (avg: 0.219186) \tsec/iter: 0.0326\n",
      "Test set (epoch 290): Average loss: 0.3193, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.301443 (avg: 0.301443) \tsec/iter: 0.0359\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.153234 (avg: 0.213362) \tsec/iter: 0.0329\n",
      "Test set (epoch 291): Average loss: 0.2405, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.254402 (avg: 0.254402) \tsec/iter: 0.0319\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.177429 (avg: 0.227322) \tsec/iter: 0.0303\n",
      "Test set (epoch 292): Average loss: 0.2975, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.226233 (avg: 0.226233) \tsec/iter: 0.0369\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.249068 (avg: 0.237654) \tsec/iter: 0.0336\n",
      "Test set (epoch 293): Average loss: 0.2833, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.371048 (avg: 0.371048) \tsec/iter: 0.0439\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.247204 (avg: 0.257671) \tsec/iter: 0.0342\n",
      "Test set (epoch 294): Average loss: 0.3449, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.246848 (avg: 0.246848) \tsec/iter: 0.0359\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.206574 (avg: 0.246113) \tsec/iter: 0.0356\n",
      "Test set (epoch 295): Average loss: 0.2531, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.253781 (avg: 0.253781) \tsec/iter: 0.0369\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.154200 (avg: 0.253893) \tsec/iter: 0.0322\n",
      "Test set (epoch 296): Average loss: 0.3554, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.171351 (avg: 0.171351) \tsec/iter: 0.0359\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.314189 (avg: 0.221522) \tsec/iter: 0.0336\n",
      "Test set (epoch 297): Average loss: 0.2953, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.235983 (avg: 0.235983) \tsec/iter: 0.0479\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.286702 (avg: 0.220878) \tsec/iter: 0.0422\n",
      "Test set (epoch 298): Average loss: 0.3806, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.172858 (avg: 0.172858) \tsec/iter: 0.0379\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.117292 (avg: 0.233783) \tsec/iter: 0.0339\n",
      "Test set (epoch 299): Average loss: 0.2681, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.218470 (avg: 0.218470) \tsec/iter: 0.0379\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.259061 (avg: 0.211463) \tsec/iter: 0.0349\n",
      "Test set (epoch 300): Average loss: 0.2480, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.242940 (avg: 0.242940) \tsec/iter: 0.0339\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.189577 (avg: 0.209979) \tsec/iter: 0.0711\n",
      "Test set (epoch 301): Average loss: 0.2662, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.226271 (avg: 0.226271) \tsec/iter: 0.0529\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.276735 (avg: 0.238042) \tsec/iter: 0.0512\n",
      "Test set (epoch 302): Average loss: 0.3044, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.225491 (avg: 0.225491) \tsec/iter: 0.0598\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.274460 (avg: 0.212967) \tsec/iter: 0.0432\n",
      "Test set (epoch 303): Average loss: 0.3400, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.194133 (avg: 0.194133) \tsec/iter: 0.0359\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.345745 (avg: 0.256576) \tsec/iter: 0.0336\n",
      "Test set (epoch 304): Average loss: 0.3077, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.240088 (avg: 0.240088) \tsec/iter: 0.0429\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.195068 (avg: 0.188044) \tsec/iter: 0.0386\n",
      "Test set (epoch 305): Average loss: 0.3291, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.198911 (avg: 0.198911) \tsec/iter: 0.0339\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.378695 (avg: 0.250497) \tsec/iter: 0.0359\n",
      "Test set (epoch 306): Average loss: 0.2866, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.284276 (avg: 0.284276) \tsec/iter: 0.0359\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.167169 (avg: 0.246589) \tsec/iter: 0.0386\n",
      "Test set (epoch 307): Average loss: 0.3660, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.304318 (avg: 0.304318) \tsec/iter: 0.0469\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.160273 (avg: 0.233158) \tsec/iter: 0.0469\n",
      "Test set (epoch 308): Average loss: 0.3254, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.273903 (avg: 0.273903) \tsec/iter: 0.0479\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.334505 (avg: 0.248562) \tsec/iter: 0.0432\n",
      "Test set (epoch 309): Average loss: 0.2965, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.248850 (avg: 0.248850) \tsec/iter: 0.1426\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.117238 (avg: 0.219747) \tsec/iter: 0.0888\n",
      "Test set (epoch 310): Average loss: 0.3056, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.279840 (avg: 0.279840) \tsec/iter: 0.0838\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.180763 (avg: 0.216757) \tsec/iter: 0.0788\n",
      "Test set (epoch 311): Average loss: 0.3029, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.293624 (avg: 0.293624) \tsec/iter: 0.0738\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.199002 (avg: 0.226432) \tsec/iter: 0.0642\n",
      "Test set (epoch 312): Average loss: 0.3361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.262398 (avg: 0.262398) \tsec/iter: 0.0608\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.171509 (avg: 0.222733) \tsec/iter: 0.0525\n",
      "Test set (epoch 313): Average loss: 0.3214, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.237151 (avg: 0.237151) \tsec/iter: 0.0509\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.212246 (avg: 0.250619) \tsec/iter: 0.0515\n",
      "Test set (epoch 314): Average loss: 0.2977, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.167473 (avg: 0.167473) \tsec/iter: 0.0549\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.317491 (avg: 0.222595) \tsec/iter: 0.0535\n",
      "Test set (epoch 315): Average loss: 0.4290, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.217324 (avg: 0.217324) \tsec/iter: 0.0578\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.271949 (avg: 0.244979) \tsec/iter: 0.0532\n",
      "Test set (epoch 316): Average loss: 0.3245, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.150087 (avg: 0.150087) \tsec/iter: 0.0628\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.362038 (avg: 0.216381) \tsec/iter: 0.0542\n",
      "Test set (epoch 317): Average loss: 0.2349, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.178236 (avg: 0.178236) \tsec/iter: 0.0568\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.371801 (avg: 0.233931) \tsec/iter: 0.0515\n",
      "Test set (epoch 318): Average loss: 0.2693, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.301477 (avg: 0.301477) \tsec/iter: 0.0479\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.178228 (avg: 0.242962) \tsec/iter: 0.0472\n",
      "Test set (epoch 319): Average loss: 0.4031, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.271843 (avg: 0.271843) \tsec/iter: 0.0628\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.322311 (avg: 0.247669) \tsec/iter: 0.0532\n",
      "Test set (epoch 320): Average loss: 0.2722, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.338320 (avg: 0.338320) \tsec/iter: 0.0539\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.124255 (avg: 0.244163) \tsec/iter: 0.0492\n",
      "Test set (epoch 321): Average loss: 0.3013, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.141702 (avg: 0.141702) \tsec/iter: 0.0469\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.290993 (avg: 0.226271) \tsec/iter: 0.1496\n",
      "Test set (epoch 322): Average loss: 0.2521, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.209104 (avg: 0.209104) \tsec/iter: 0.0868\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.357629 (avg: 0.212821) \tsec/iter: 0.0904\n",
      "Test set (epoch 323): Average loss: 0.2993, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.232039 (avg: 0.232039) \tsec/iter: 0.1157\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.208549 (avg: 0.206808) \tsec/iter: 0.0871\n",
      "Test set (epoch 324): Average loss: 0.4022, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.272211 (avg: 0.272211) \tsec/iter: 0.0908\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.197362 (avg: 0.219462) \tsec/iter: 0.0765\n",
      "Test set (epoch 325): Average loss: 0.2308, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.239477 (avg: 0.239477) \tsec/iter: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.291937 (avg: 0.267911) \tsec/iter: 0.0652\n",
      "Test set (epoch 326): Average loss: 0.3341, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.289540 (avg: 0.289540) \tsec/iter: 0.0459\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.186739 (avg: 0.224059) \tsec/iter: 0.0416\n",
      "Test set (epoch 327): Average loss: 0.3508, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.295019 (avg: 0.295019) \tsec/iter: 0.0578\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.258189 (avg: 0.266278) \tsec/iter: 0.0515\n",
      "Test set (epoch 328): Average loss: 0.2994, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.316579 (avg: 0.316579) \tsec/iter: 0.0439\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.226939 (avg: 0.226766) \tsec/iter: 0.0432\n",
      "Test set (epoch 329): Average loss: 0.3371, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.281099 (avg: 0.281099) \tsec/iter: 0.0539\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.255232 (avg: 0.229640) \tsec/iter: 0.0485\n",
      "Test set (epoch 330): Average loss: 0.3473, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.214568 (avg: 0.214568) \tsec/iter: 0.0738\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.270865 (avg: 0.239118) \tsec/iter: 0.0612\n",
      "Test set (epoch 331): Average loss: 0.3220, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.202006 (avg: 0.202006) \tsec/iter: 0.0618\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.264376 (avg: 0.216890) \tsec/iter: 0.0568\n",
      "Test set (epoch 332): Average loss: 0.3089, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.194826 (avg: 0.194826) \tsec/iter: 0.1047\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.129692 (avg: 0.205468) \tsec/iter: 0.0795\n",
      "Test set (epoch 333): Average loss: 0.2315, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.235707 (avg: 0.235707) \tsec/iter: 0.0818\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.355347 (avg: 0.221482) \tsec/iter: 0.0698\n",
      "Test set (epoch 334): Average loss: 0.2988, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.183264 (avg: 0.183264) \tsec/iter: 0.0559\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.171679 (avg: 0.225149) \tsec/iter: 0.0515\n",
      "Test set (epoch 335): Average loss: 0.2619, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.170650 (avg: 0.170650) \tsec/iter: 0.0499\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.293307 (avg: 0.222756) \tsec/iter: 0.0455\n",
      "Test set (epoch 336): Average loss: 0.3468, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.130016 (avg: 0.130016) \tsec/iter: 0.0529\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.160954 (avg: 0.190145) \tsec/iter: 0.0482\n",
      "Test set (epoch 337): Average loss: 0.3613, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.200398 (avg: 0.200398) \tsec/iter: 0.0558\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.282826 (avg: 0.205511) \tsec/iter: 0.0485\n",
      "Test set (epoch 338): Average loss: 0.2987, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.118198 (avg: 0.118198) \tsec/iter: 0.0519\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.523898 (avg: 0.270105) \tsec/iter: 0.0445\n",
      "Test set (epoch 339): Average loss: 0.3620, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.153987 (avg: 0.153987) \tsec/iter: 0.0509\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.407130 (avg: 0.243922) \tsec/iter: 0.0465\n",
      "Test set (epoch 340): Average loss: 0.3791, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.298539 (avg: 0.298539) \tsec/iter: 0.0519\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.178819 (avg: 0.218544) \tsec/iter: 0.0449\n",
      "Test set (epoch 341): Average loss: 0.3454, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.184271 (avg: 0.184271) \tsec/iter: 0.0549\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.202042 (avg: 0.198338) \tsec/iter: 0.0545\n",
      "Test set (epoch 342): Average loss: 0.3496, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.165801 (avg: 0.165801) \tsec/iter: 0.0499\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.368714 (avg: 0.209442) \tsec/iter: 0.0469\n",
      "Test set (epoch 343): Average loss: 0.3184, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.250774 (avg: 0.250774) \tsec/iter: 0.0509\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.286611 (avg: 0.247665) \tsec/iter: 0.0499\n",
      "Test set (epoch 344): Average loss: 0.3267, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.166591 (avg: 0.166591) \tsec/iter: 0.0469\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.255232 (avg: 0.232290) \tsec/iter: 0.0469\n",
      "Test set (epoch 345): Average loss: 0.3100, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.239064 (avg: 0.239064) \tsec/iter: 0.0549\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.227540 (avg: 0.226092) \tsec/iter: 0.0439\n",
      "Test set (epoch 346): Average loss: 0.3576, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.239221 (avg: 0.239221) \tsec/iter: 0.0559\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.253421 (avg: 0.237910) \tsec/iter: 0.0485\n",
      "Test set (epoch 347): Average loss: 0.3389, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.190736 (avg: 0.190736) \tsec/iter: 0.0429\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.348532 (avg: 0.235257) \tsec/iter: 0.0505\n",
      "Test set (epoch 348): Average loss: 0.3510, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.188306 (avg: 0.188306) \tsec/iter: 0.0578\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.301953 (avg: 0.234202) \tsec/iter: 0.0509\n",
      "Test set (epoch 349): Average loss: 0.2356, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.126339 (avg: 0.126339) \tsec/iter: 0.0499\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.345980 (avg: 0.225652) \tsec/iter: 0.0472\n",
      "Test set (epoch 350): Average loss: 0.3520, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.181582 (avg: 0.181582) \tsec/iter: 0.0469\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.263689 (avg: 0.233069) \tsec/iter: 0.0462\n",
      "Test set (epoch 351): Average loss: 0.2903, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.212859 (avg: 0.212859) \tsec/iter: 0.0539\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.266076 (avg: 0.218430) \tsec/iter: 0.0485\n",
      "Test set (epoch 352): Average loss: 0.2810, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.260037 (avg: 0.260037) \tsec/iter: 0.0509\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.280604 (avg: 0.214494) \tsec/iter: 0.0462\n",
      "Test set (epoch 353): Average loss: 0.2848, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.220753 (avg: 0.220753) \tsec/iter: 0.0489\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.173120 (avg: 0.216152) \tsec/iter: 0.0519\n",
      "Test set (epoch 354): Average loss: 0.3157, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.232733 (avg: 0.232733) \tsec/iter: 0.0568\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.180886 (avg: 0.204828) \tsec/iter: 0.0499\n",
      "Test set (epoch 355): Average loss: 0.2847, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.189108 (avg: 0.189108) \tsec/iter: 0.0798\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.220388 (avg: 0.200833) \tsec/iter: 0.0628\n",
      "Test set (epoch 356): Average loss: 0.2623, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.157359 (avg: 0.157359) \tsec/iter: 0.0628\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.344389 (avg: 0.222471) \tsec/iter: 0.0502\n",
      "Test set (epoch 357): Average loss: 0.2755, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.237805 (avg: 0.237805) \tsec/iter: 0.0439\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.171809 (avg: 0.237965) \tsec/iter: 0.0439\n",
      "Test set (epoch 358): Average loss: 0.3956, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.230849 (avg: 0.230849) \tsec/iter: 0.0469\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.252880 (avg: 0.248215) \tsec/iter: 0.0459\n",
      "Test set (epoch 359): Average loss: 0.2522, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.252577 (avg: 0.252577) \tsec/iter: 0.0529\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.207377 (avg: 0.244575) \tsec/iter: 0.1297\n",
      "Test set (epoch 360): Average loss: 0.3236, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.184830 (avg: 0.184830) \tsec/iter: 0.1326\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.321267 (avg: 0.235899) \tsec/iter: 0.1041\n",
      "Test set (epoch 361): Average loss: 0.2899, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.390243 (avg: 0.390243) \tsec/iter: 0.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.166810 (avg: 0.305982) \tsec/iter: 0.0691\n",
      "Test set (epoch 362): Average loss: 0.3763, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.340106 (avg: 0.340106) \tsec/iter: 0.0618\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.212133 (avg: 0.249891) \tsec/iter: 0.0602\n",
      "Test set (epoch 363): Average loss: 0.2971, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.290200 (avg: 0.290200) \tsec/iter: 0.0489\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.202189 (avg: 0.215493) \tsec/iter: 0.0452\n",
      "Test set (epoch 364): Average loss: 0.2697, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.146803 (avg: 0.146803) \tsec/iter: 0.0728\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.215862 (avg: 0.225788) \tsec/iter: 0.0625\n",
      "Test set (epoch 365): Average loss: 0.3135, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.171369 (avg: 0.171369) \tsec/iter: 0.0509\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.199309 (avg: 0.229673) \tsec/iter: 0.0572\n",
      "Test set (epoch 366): Average loss: 0.3388, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.226050 (avg: 0.226050) \tsec/iter: 0.0658\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.191431 (avg: 0.233337) \tsec/iter: 0.0665\n",
      "Test set (epoch 367): Average loss: 0.2594, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.247144 (avg: 0.247144) \tsec/iter: 0.0878\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.138290 (avg: 0.198670) \tsec/iter: 0.0678\n",
      "Test set (epoch 368): Average loss: 0.3382, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.189012 (avg: 0.189012) \tsec/iter: 0.0818\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.225761 (avg: 0.220803) \tsec/iter: 0.0698\n",
      "Test set (epoch 369): Average loss: 0.3017, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.312129 (avg: 0.312129) \tsec/iter: 0.0479\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.231033 (avg: 0.254469) \tsec/iter: 0.0462\n",
      "Test set (epoch 370): Average loss: 0.4196, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.257679 (avg: 0.257679) \tsec/iter: 0.0558\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.120691 (avg: 0.210626) \tsec/iter: 0.0469\n",
      "Test set (epoch 371): Average loss: 0.2237, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.223329 (avg: 0.223329) \tsec/iter: 0.0459\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.233573 (avg: 0.223426) \tsec/iter: 0.0455\n",
      "Test set (epoch 372): Average loss: 0.3095, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.215252 (avg: 0.215252) \tsec/iter: 0.0628\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.322138 (avg: 0.233819) \tsec/iter: 0.0585\n",
      "Test set (epoch 373): Average loss: 0.3427, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.226907 (avg: 0.226907) \tsec/iter: 0.0578\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.262529 (avg: 0.262471) \tsec/iter: 0.0482\n",
      "Test set (epoch 374): Average loss: 0.4253, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.123329 (avg: 0.123329) \tsec/iter: 0.0578\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.230180 (avg: 0.196843) \tsec/iter: 0.0495\n",
      "Test set (epoch 375): Average loss: 0.2795, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.261392 (avg: 0.261392) \tsec/iter: 0.0479\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.212997 (avg: 0.207089) \tsec/iter: 0.0459\n",
      "Test set (epoch 376): Average loss: 0.3202, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.163947 (avg: 0.163947) \tsec/iter: 0.0509\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.243284 (avg: 0.233469) \tsec/iter: 0.0459\n",
      "Test set (epoch 377): Average loss: 0.2945, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.203442 (avg: 0.203442) \tsec/iter: 0.0529\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.352419 (avg: 0.276076) \tsec/iter: 0.0502\n",
      "Test set (epoch 378): Average loss: 0.2940, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.289207 (avg: 0.289207) \tsec/iter: 0.0529\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.334074 (avg: 0.255738) \tsec/iter: 0.0449\n",
      "Test set (epoch 379): Average loss: 0.4281, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.238213 (avg: 0.238213) \tsec/iter: 0.0509\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.127832 (avg: 0.218271) \tsec/iter: 0.0416\n",
      "Test set (epoch 380): Average loss: 0.3205, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.187711 (avg: 0.187711) \tsec/iter: 0.0509\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.273351 (avg: 0.250873) \tsec/iter: 0.0485\n",
      "Test set (epoch 381): Average loss: 0.3656, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.284628 (avg: 0.284628) \tsec/iter: 0.0868\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.176417 (avg: 0.235851) \tsec/iter: 0.0618\n",
      "Test set (epoch 382): Average loss: 0.3170, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.227572 (avg: 0.227572) \tsec/iter: 0.0509\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.229134 (avg: 0.216292) \tsec/iter: 0.0449\n",
      "Test set (epoch 383): Average loss: 0.3398, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.265495 (avg: 0.265495) \tsec/iter: 0.0489\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.191110 (avg: 0.219155) \tsec/iter: 0.0475\n",
      "Test set (epoch 384): Average loss: 0.2825, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.246450 (avg: 0.246450) \tsec/iter: 0.0449\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.120332 (avg: 0.220076) \tsec/iter: 0.0455\n",
      "Test set (epoch 385): Average loss: 0.3433, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.183608 (avg: 0.183608) \tsec/iter: 0.0519\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.298964 (avg: 0.250290) \tsec/iter: 0.0442\n",
      "Test set (epoch 386): Average loss: 0.3662, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.324638 (avg: 0.324638) \tsec/iter: 0.0529\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.186247 (avg: 0.216402) \tsec/iter: 0.0479\n",
      "Test set (epoch 387): Average loss: 0.3450, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.167609 (avg: 0.167609) \tsec/iter: 0.0638\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.225313 (avg: 0.209132) \tsec/iter: 0.0492\n",
      "Test set (epoch 388): Average loss: 0.3512, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.168153 (avg: 0.168153) \tsec/iter: 0.0489\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.274218 (avg: 0.205031) \tsec/iter: 0.0479\n",
      "Test set (epoch 389): Average loss: 0.2296, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.211552 (avg: 0.211552) \tsec/iter: 0.0519\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.382483 (avg: 0.239309) \tsec/iter: 0.0459\n",
      "Test set (epoch 390): Average loss: 0.3173, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.180975 (avg: 0.180975) \tsec/iter: 0.0489\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.410453 (avg: 0.268538) \tsec/iter: 0.0419\n",
      "Test set (epoch 391): Average loss: 0.3315, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.241958 (avg: 0.241958) \tsec/iter: 0.0519\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.251971 (avg: 0.228347) \tsec/iter: 0.0436\n",
      "Test set (epoch 392): Average loss: 0.2564, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.178761 (avg: 0.178761) \tsec/iter: 0.0459\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.238400 (avg: 0.229253) \tsec/iter: 0.0436\n",
      "Test set (epoch 393): Average loss: 0.3139, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.182413 (avg: 0.182413) \tsec/iter: 0.0419\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.263568 (avg: 0.203364) \tsec/iter: 0.0495\n",
      "Test set (epoch 394): Average loss: 0.2521, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.338596 (avg: 0.338596) \tsec/iter: 0.0568\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.193760 (avg: 0.237828) \tsec/iter: 0.0539\n",
      "Test set (epoch 395): Average loss: 0.2103, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.223580 (avg: 0.223580) \tsec/iter: 0.0489\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.229081 (avg: 0.234161) \tsec/iter: 0.0455\n",
      "Test set (epoch 396): Average loss: 0.2887, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.207673 (avg: 0.207673) \tsec/iter: 0.0489\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.115286 (avg: 0.189249) \tsec/iter: 0.0485\n",
      "Test set (epoch 397): Average loss: 0.3202, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.263133 (avg: 0.263133) \tsec/iter: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.203976 (avg: 0.247946) \tsec/iter: 0.0495\n",
      "Test set (epoch 398): Average loss: 0.3664, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.245738 (avg: 0.245738) \tsec/iter: 0.0568\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.280035 (avg: 0.231375) \tsec/iter: 0.0539\n",
      "Test set (epoch 399): Average loss: 0.2260, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.224355 (avg: 0.224355) \tsec/iter: 0.0559\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.200926 (avg: 0.208009) \tsec/iter: 0.0519\n",
      "Test set (epoch 400): Average loss: 0.3059, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.238185 (avg: 0.238185) \tsec/iter: 0.0568\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.173994 (avg: 0.224477) \tsec/iter: 0.0522\n",
      "Test set (epoch 401): Average loss: 0.3379, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.150668 (avg: 0.150668) \tsec/iter: 0.0529\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.471172 (avg: 0.258998) \tsec/iter: 0.0718\n",
      "Test set (epoch 402): Average loss: 0.3261, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.168480 (avg: 0.168480) \tsec/iter: 0.1257\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.317536 (avg: 0.273183) \tsec/iter: 0.0898\n",
      "Test set (epoch 403): Average loss: 0.3085, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.206457 (avg: 0.206457) \tsec/iter: 0.0568\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.378431 (avg: 0.248072) \tsec/iter: 0.0549\n",
      "Test set (epoch 404): Average loss: 0.2722, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.220516 (avg: 0.220516) \tsec/iter: 0.0738\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.310355 (avg: 0.263871) \tsec/iter: 0.0701\n",
      "Test set (epoch 405): Average loss: 0.2230, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.207089 (avg: 0.207089) \tsec/iter: 0.0618\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.169273 (avg: 0.212878) \tsec/iter: 0.0495\n",
      "Test set (epoch 406): Average loss: 0.3317, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.147625 (avg: 0.147625) \tsec/iter: 0.0499\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.390858 (avg: 0.244784) \tsec/iter: 0.0439\n",
      "Test set (epoch 407): Average loss: 0.3165, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.231070 (avg: 0.231070) \tsec/iter: 0.0529\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.104728 (avg: 0.223587) \tsec/iter: 0.0449\n",
      "Test set (epoch 408): Average loss: 0.2480, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.280011 (avg: 0.280011) \tsec/iter: 0.0429\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.168518 (avg: 0.240215) \tsec/iter: 0.0442\n",
      "Test set (epoch 409): Average loss: 0.3748, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.188949 (avg: 0.188949) \tsec/iter: 0.0519\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.289169 (avg: 0.226668) \tsec/iter: 0.0482\n",
      "Test set (epoch 410): Average loss: 0.3313, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.216208 (avg: 0.216208) \tsec/iter: 0.0479\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.235590 (avg: 0.212385) \tsec/iter: 0.0489\n",
      "Test set (epoch 411): Average loss: 0.3352, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.210208 (avg: 0.210208) \tsec/iter: 0.1127\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.175207 (avg: 0.217130) \tsec/iter: 0.0735\n",
      "Test set (epoch 412): Average loss: 0.4039, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.281182 (avg: 0.281182) \tsec/iter: 0.0728\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.148687 (avg: 0.240318) \tsec/iter: 0.0791\n",
      "Test set (epoch 413): Average loss: 0.3476, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.300712 (avg: 0.300712) \tsec/iter: 0.0718\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.332283 (avg: 0.258849) \tsec/iter: 0.0675\n",
      "Test set (epoch 414): Average loss: 0.2425, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.206797 (avg: 0.206797) \tsec/iter: 0.0778\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.123020 (avg: 0.258940) \tsec/iter: 0.0608\n",
      "Test set (epoch 415): Average loss: 0.3044, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.256159 (avg: 0.256159) \tsec/iter: 0.0878\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.168917 (avg: 0.217990) \tsec/iter: 0.0791\n",
      "Test set (epoch 416): Average loss: 0.3851, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.183793 (avg: 0.183793) \tsec/iter: 0.0608\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.150118 (avg: 0.215005) \tsec/iter: 0.0505\n",
      "Test set (epoch 417): Average loss: 0.3197, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.308940 (avg: 0.308940) \tsec/iter: 0.0509\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.089213 (avg: 0.240358) \tsec/iter: 0.0452\n",
      "Test set (epoch 418): Average loss: 0.3760, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.135405 (avg: 0.135405) \tsec/iter: 0.0479\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.195010 (avg: 0.236279) \tsec/iter: 0.0445\n",
      "Test set (epoch 419): Average loss: 0.2416, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.193387 (avg: 0.193387) \tsec/iter: 0.0439\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.352289 (avg: 0.241869) \tsec/iter: 0.0442\n",
      "Test set (epoch 420): Average loss: 0.3587, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.248542 (avg: 0.248542) \tsec/iter: 0.0529\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.238916 (avg: 0.206766) \tsec/iter: 0.0479\n",
      "Test set (epoch 421): Average loss: 0.2813, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.240075 (avg: 0.240075) \tsec/iter: 0.0708\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.186107 (avg: 0.190830) \tsec/iter: 0.0578\n",
      "Test set (epoch 422): Average loss: 0.2736, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.153991 (avg: 0.153991) \tsec/iter: 0.0489\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.189967 (avg: 0.174933) \tsec/iter: 0.0455\n",
      "Test set (epoch 423): Average loss: 0.2220, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.277018 (avg: 0.277018) \tsec/iter: 0.0549\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.198332 (avg: 0.239219) \tsec/iter: 0.0495\n",
      "Test set (epoch 424): Average loss: 0.3327, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.210875 (avg: 0.210875) \tsec/iter: 0.0449\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.193181 (avg: 0.231054) \tsec/iter: 0.0432\n",
      "Test set (epoch 425): Average loss: 0.3122, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.256529 (avg: 0.256529) \tsec/iter: 0.0509\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.145947 (avg: 0.209412) \tsec/iter: 0.0495\n",
      "Test set (epoch 426): Average loss: 0.3451, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.177581 (avg: 0.177581) \tsec/iter: 0.0519\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.144151 (avg: 0.177095) \tsec/iter: 0.0552\n",
      "Test set (epoch 427): Average loss: 0.2966, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.232865 (avg: 0.232865) \tsec/iter: 0.1027\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.290422 (avg: 0.261307) \tsec/iter: 0.0821\n",
      "Test set (epoch 428): Average loss: 0.2364, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.238302 (avg: 0.238302) \tsec/iter: 0.0459\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.245497 (avg: 0.231038) \tsec/iter: 0.0512\n",
      "Test set (epoch 429): Average loss: 0.4690, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.140133 (avg: 0.140133) \tsec/iter: 0.0559\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.124401 (avg: 0.215763) \tsec/iter: 0.0512\n",
      "Test set (epoch 430): Average loss: 0.3560, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.144437 (avg: 0.144437) \tsec/iter: 0.0499\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.257165 (avg: 0.200864) \tsec/iter: 0.0462\n",
      "Test set (epoch 431): Average loss: 0.2450, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.228713 (avg: 0.228713) \tsec/iter: 0.0449\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.178456 (avg: 0.220348) \tsec/iter: 0.0449\n",
      "Test set (epoch 432): Average loss: 0.2484, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.234280 (avg: 0.234280) \tsec/iter: 0.0519\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.308060 (avg: 0.233838) \tsec/iter: 0.0505\n",
      "Test set (epoch 433): Average loss: 0.2934, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.173446 (avg: 0.173446) \tsec/iter: 0.0718\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.120846 (avg: 0.190218) \tsec/iter: 0.0931\n",
      "Test set (epoch 434): Average loss: 0.2539, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.271026 (avg: 0.271026) \tsec/iter: 0.0688\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.241704 (avg: 0.244499) \tsec/iter: 0.0598\n",
      "Test set (epoch 435): Average loss: 0.2625, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.229776 (avg: 0.229776) \tsec/iter: 0.0489\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.181346 (avg: 0.189653) \tsec/iter: 0.0445\n",
      "Test set (epoch 436): Average loss: 0.2237, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.206899 (avg: 0.206899) \tsec/iter: 0.0519\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.228809 (avg: 0.222936) \tsec/iter: 0.0452\n",
      "Test set (epoch 437): Average loss: 0.2547, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.198166 (avg: 0.198166) \tsec/iter: 0.0429\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.283928 (avg: 0.237786) \tsec/iter: 0.0475\n",
      "Test set (epoch 438): Average loss: 0.2548, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.242636 (avg: 0.242636) \tsec/iter: 0.0539\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.174816 (avg: 0.237098) \tsec/iter: 0.0592\n",
      "Test set (epoch 439): Average loss: 0.4007, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.193325 (avg: 0.193325) \tsec/iter: 0.0638\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.337440 (avg: 0.250676) \tsec/iter: 0.0562\n",
      "Test set (epoch 440): Average loss: 0.2392, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.171603 (avg: 0.171603) \tsec/iter: 0.0529\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.311142 (avg: 0.225926) \tsec/iter: 0.0652\n",
      "Test set (epoch 441): Average loss: 0.2845, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.206619 (avg: 0.206619) \tsec/iter: 0.0638\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.242269 (avg: 0.213527) \tsec/iter: 0.0575\n",
      "Test set (epoch 442): Average loss: 0.3416, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.199108 (avg: 0.199108) \tsec/iter: 0.0977\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.237901 (avg: 0.217673) \tsec/iter: 0.0771\n",
      "Test set (epoch 443): Average loss: 0.3037, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.219082 (avg: 0.219082) \tsec/iter: 0.0798\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.111385 (avg: 0.229413) \tsec/iter: 0.0745\n",
      "Test set (epoch 444): Average loss: 0.3861, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.131104 (avg: 0.131104) \tsec/iter: 0.0578\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.300834 (avg: 0.234086) \tsec/iter: 0.0499\n",
      "Test set (epoch 445): Average loss: 0.3143, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.309577 (avg: 0.309577) \tsec/iter: 0.0539\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.164060 (avg: 0.218389) \tsec/iter: 0.0492\n",
      "Test set (epoch 446): Average loss: 0.3021, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.145539 (avg: 0.145539) \tsec/iter: 0.0529\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.146722 (avg: 0.215339) \tsec/iter: 0.0499\n",
      "Test set (epoch 447): Average loss: 0.2691, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.184916 (avg: 0.184916) \tsec/iter: 0.0469\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.115560 (avg: 0.188697) \tsec/iter: 0.0449\n",
      "Test set (epoch 448): Average loss: 0.2097, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.254842 (avg: 0.254842) \tsec/iter: 0.0668\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.119284 (avg: 0.188696) \tsec/iter: 0.0608\n",
      "Test set (epoch 449): Average loss: 0.3448, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.153832 (avg: 0.153832) \tsec/iter: 0.0778\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.227864 (avg: 0.206044) \tsec/iter: 0.0678\n",
      "Test set (epoch 450): Average loss: 0.3507, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.173875 (avg: 0.173875) \tsec/iter: 0.0509\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.137680 (avg: 0.210792) \tsec/iter: 0.0489\n",
      "Test set (epoch 451): Average loss: 0.2606, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.256635 (avg: 0.256635) \tsec/iter: 0.0499\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.289969 (avg: 0.268666) \tsec/iter: 0.0492\n",
      "Test set (epoch 452): Average loss: 0.3816, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.285411 (avg: 0.285411) \tsec/iter: 0.0519\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.245777 (avg: 0.232082) \tsec/iter: 0.0519\n",
      "Test set (epoch 453): Average loss: 0.2679, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.148923 (avg: 0.148923) \tsec/iter: 0.0559\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.245295 (avg: 0.210693) \tsec/iter: 0.0495\n",
      "Test set (epoch 454): Average loss: 0.3810, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.229377 (avg: 0.229377) \tsec/iter: 0.0549\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.224238 (avg: 0.231063) \tsec/iter: 0.0485\n",
      "Test set (epoch 455): Average loss: 0.2911, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.180920 (avg: 0.180920) \tsec/iter: 0.0559\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.173724 (avg: 0.205149) \tsec/iter: 0.0505\n",
      "Test set (epoch 456): Average loss: 0.3121, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.227554 (avg: 0.227554) \tsec/iter: 0.0549\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.204618 (avg: 0.203257) \tsec/iter: 0.0492\n",
      "Test set (epoch 457): Average loss: 0.2883, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.288059 (avg: 0.288059) \tsec/iter: 0.0449\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.205397 (avg: 0.219862) \tsec/iter: 0.0432\n",
      "Test set (epoch 458): Average loss: 0.2684, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.240383 (avg: 0.240383) \tsec/iter: 0.0519\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.194801 (avg: 0.197945) \tsec/iter: 0.0482\n",
      "Test set (epoch 459): Average loss: 0.3699, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.328106 (avg: 0.328106) \tsec/iter: 0.0519\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.114655 (avg: 0.195422) \tsec/iter: 0.0469\n",
      "Test set (epoch 460): Average loss: 0.3347, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.149968 (avg: 0.149968) \tsec/iter: 0.0489\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.176826 (avg: 0.205763) \tsec/iter: 0.0436\n",
      "Test set (epoch 461): Average loss: 0.2656, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.174008 (avg: 0.174008) \tsec/iter: 0.0519\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.275440 (avg: 0.214790) \tsec/iter: 0.0512\n",
      "Test set (epoch 462): Average loss: 0.3060, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.199509 (avg: 0.199509) \tsec/iter: 0.0598\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.162322 (avg: 0.205878) \tsec/iter: 0.0532\n",
      "Test set (epoch 463): Average loss: 0.3005, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.175249 (avg: 0.175249) \tsec/iter: 0.0469\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.190879 (avg: 0.201240) \tsec/iter: 0.0469\n",
      "Test set (epoch 464): Average loss: 0.2804, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.170046 (avg: 0.170046) \tsec/iter: 0.0568\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.241269 (avg: 0.214094) \tsec/iter: 0.0492\n",
      "Test set (epoch 465): Average loss: 0.2524, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.165793 (avg: 0.165793) \tsec/iter: 0.0529\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.218092 (avg: 0.200311) \tsec/iter: 0.0482\n",
      "Test set (epoch 466): Average loss: 0.2593, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.202831 (avg: 0.202831) \tsec/iter: 0.0509\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.235536 (avg: 0.199156) \tsec/iter: 0.0479\n",
      "Test set (epoch 467): Average loss: 0.3502, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.169013 (avg: 0.169013) \tsec/iter: 0.0529\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.252437 (avg: 0.209241) \tsec/iter: 0.0469\n",
      "Test set (epoch 468): Average loss: 0.3559, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.242731 (avg: 0.242731) \tsec/iter: 0.0519\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.230659 (avg: 0.243920) \tsec/iter: 0.0459\n",
      "Test set (epoch 469): Average loss: 0.3850, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.235481 (avg: 0.235481) \tsec/iter: 0.0618\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.269137 (avg: 0.239248) \tsec/iter: 0.0588\n",
      "Test set (epoch 470): Average loss: 0.3491, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.263977 (avg: 0.263977) \tsec/iter: 0.0608\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.338050 (avg: 0.257287) \tsec/iter: 0.0525\n",
      "Test set (epoch 471): Average loss: 0.2999, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.212478 (avg: 0.212478) \tsec/iter: 0.0479\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.325746 (avg: 0.226825) \tsec/iter: 0.0469\n",
      "Test set (epoch 472): Average loss: 0.3641, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.212420 (avg: 0.212420) \tsec/iter: 0.0489\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.159214 (avg: 0.217396) \tsec/iter: 0.0462\n",
      "Test set (epoch 473): Average loss: 0.3452, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.163398 (avg: 0.163398) \tsec/iter: 0.0558\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.203874 (avg: 0.192994) \tsec/iter: 0.0495\n",
      "Test set (epoch 474): Average loss: 0.3560, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.113397 (avg: 0.113397) \tsec/iter: 0.0539\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.257236 (avg: 0.219487) \tsec/iter: 0.0472\n",
      "Test set (epoch 475): Average loss: 0.2909, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.264070 (avg: 0.264070) \tsec/iter: 0.0598\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.230072 (avg: 0.230366) \tsec/iter: 0.0495\n",
      "Test set (epoch 476): Average loss: 0.3460, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.204234 (avg: 0.204234) \tsec/iter: 0.0539\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.125085 (avg: 0.212543) \tsec/iter: 0.0539\n",
      "Test set (epoch 477): Average loss: 0.2278, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.096817 (avg: 0.096817) \tsec/iter: 0.0648\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.187882 (avg: 0.187712) \tsec/iter: 0.0592\n",
      "Test set (epoch 478): Average loss: 0.2718, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.226563 (avg: 0.226563) \tsec/iter: 0.0708\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.177829 (avg: 0.194487) \tsec/iter: 0.0625\n",
      "Test set (epoch 479): Average loss: 0.2583, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.231344 (avg: 0.231344) \tsec/iter: 0.0718\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.202833 (avg: 0.198059) \tsec/iter: 0.0598\n",
      "Test set (epoch 480): Average loss: 0.3334, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.187821 (avg: 0.187821) \tsec/iter: 0.0529\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.152419 (avg: 0.207270) \tsec/iter: 0.0509\n",
      "Test set (epoch 481): Average loss: 0.2713, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.216388 (avg: 0.216388) \tsec/iter: 0.0519\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.155167 (avg: 0.222463) \tsec/iter: 0.0465\n",
      "Test set (epoch 482): Average loss: 0.3186, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.183345 (avg: 0.183345) \tsec/iter: 0.0539\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.299949 (avg: 0.230972) \tsec/iter: 0.0472\n",
      "Test set (epoch 483): Average loss: 0.4215, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.200282 (avg: 0.200282) \tsec/iter: 0.0419\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.220727 (avg: 0.214071) \tsec/iter: 0.0429\n",
      "Test set (epoch 484): Average loss: 0.3492, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.223856 (avg: 0.223856) \tsec/iter: 0.0489\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.361747 (avg: 0.247819) \tsec/iter: 0.0472\n",
      "Test set (epoch 485): Average loss: 0.3399, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.172150 (avg: 0.172150) \tsec/iter: 0.0449\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.305477 (avg: 0.226136) \tsec/iter: 0.0432\n",
      "Test set (epoch 486): Average loss: 0.2525, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.205115 (avg: 0.205115) \tsec/iter: 0.0558\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.197956 (avg: 0.244281) \tsec/iter: 0.0512\n",
      "Test set (epoch 487): Average loss: 0.3913, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.298077 (avg: 0.298077) \tsec/iter: 0.0559\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.135087 (avg: 0.255325) \tsec/iter: 0.0485\n",
      "Test set (epoch 488): Average loss: 0.4244, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.235461 (avg: 0.235461) \tsec/iter: 0.0539\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.519293 (avg: 0.272285) \tsec/iter: 0.0462\n",
      "Test set (epoch 489): Average loss: 0.2940, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.295953 (avg: 0.295953) \tsec/iter: 0.0539\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.202175 (avg: 0.249602) \tsec/iter: 0.0445\n",
      "Test set (epoch 490): Average loss: 0.3819, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.222279 (avg: 0.222279) \tsec/iter: 0.0529\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.254329 (avg: 0.217121) \tsec/iter: 0.0472\n",
      "Test set (epoch 491): Average loss: 0.3773, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.149976 (avg: 0.149976) \tsec/iter: 0.0519\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.271663 (avg: 0.206571) \tsec/iter: 0.0465\n",
      "Test set (epoch 492): Average loss: 0.3956, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.163045 (avg: 0.163045) \tsec/iter: 0.0559\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.227752 (avg: 0.192973) \tsec/iter: 0.0512\n",
      "Test set (epoch 493): Average loss: 0.2608, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.186826 (avg: 0.186826) \tsec/iter: 0.0539\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.158479 (avg: 0.212296) \tsec/iter: 0.0469\n",
      "Test set (epoch 494): Average loss: 0.3372, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.251601 (avg: 0.251601) \tsec/iter: 0.0608\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.231544 (avg: 0.232874) \tsec/iter: 0.0525\n",
      "Test set (epoch 495): Average loss: 0.4644, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.207492 (avg: 0.207492) \tsec/iter: 0.0479\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.212662 (avg: 0.224488) \tsec/iter: 0.0449\n",
      "Test set (epoch 496): Average loss: 0.3215, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.234832 (avg: 0.234832) \tsec/iter: 0.0529\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.237954 (avg: 0.228557) \tsec/iter: 0.0442\n",
      "Test set (epoch 497): Average loss: 0.2979, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.276920 (avg: 0.276920) \tsec/iter: 0.0459\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.299143 (avg: 0.232636) \tsec/iter: 0.0439\n",
      "Test set (epoch 498): Average loss: 0.3151, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.249369 (avg: 0.249369) \tsec/iter: 0.0549\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.155364 (avg: 0.212485) \tsec/iter: 0.0509\n",
      "Test set (epoch 499): Average loss: 0.3700, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 6\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.845523 (avg: 1.845523) \tsec/iter: 0.0559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 4.773209 (avg: 4.126488) \tsec/iter: 0.0502\n",
      "Test set (epoch 0): Average loss: 0.5031, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 1.625873 (avg: 1.625873) \tsec/iter: 0.0489\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.908316 (avg: 1.400855) \tsec/iter: 0.0439\n",
      "Test set (epoch 1): Average loss: 0.3631, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.878811 (avg: 0.878811) \tsec/iter: 0.0539\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.511642 (avg: 0.799774) \tsec/iter: 0.0479\n",
      "Test set (epoch 2): Average loss: 1.0230, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.496722 (avg: 0.496722) \tsec/iter: 0.0499\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.905085 (avg: 0.533562) \tsec/iter: 0.0419\n",
      "Test set (epoch 3): Average loss: 1.8217, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.806013 (avg: 0.806013) \tsec/iter: 0.0549\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.510441 (avg: 0.527928) \tsec/iter: 0.0489\n",
      "Test set (epoch 4): Average loss: 1.5010, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.434541 (avg: 0.434541) \tsec/iter: 0.0539\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.307370 (avg: 0.470140) \tsec/iter: 0.0465\n",
      "Test set (epoch 5): Average loss: 1.1251, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.349105 (avg: 0.349105) \tsec/iter: 0.0519\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.435209 (avg: 0.381604) \tsec/iter: 0.0495\n",
      "Test set (epoch 6): Average loss: 0.9740, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.598280 (avg: 0.598280) \tsec/iter: 0.0499\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.428313 (avg: 0.507817) \tsec/iter: 0.0472\n",
      "Test set (epoch 7): Average loss: 0.9509, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.575346 (avg: 0.575346) \tsec/iter: 0.0539\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 1.144164 (avg: 0.696407) \tsec/iter: 0.0469\n",
      "Test set (epoch 8): Average loss: 0.3933, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 1.594172 (avg: 1.594172) \tsec/iter: 0.0509\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.455031 (avg: 0.958087) \tsec/iter: 0.0479\n",
      "Test set (epoch 9): Average loss: 2.6232, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.717946 (avg: 0.717946) \tsec/iter: 0.0419\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.695401 (avg: 0.614667) \tsec/iter: 0.0432\n",
      "Test set (epoch 10): Average loss: 1.8010, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.577638 (avg: 0.577638) \tsec/iter: 0.0529\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.399034 (avg: 0.452587) \tsec/iter: 0.0479\n",
      "Test set (epoch 11): Average loss: 1.0619, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.312078 (avg: 0.312078) \tsec/iter: 0.0529\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.317883 (avg: 0.395059) \tsec/iter: 0.0482\n",
      "Test set (epoch 12): Average loss: 1.0058, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.439120 (avg: 0.439120) \tsec/iter: 0.0708\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.441475 (avg: 0.374485) \tsec/iter: 0.0568\n",
      "Test set (epoch 13): Average loss: 1.0116, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.360607 (avg: 0.360607) \tsec/iter: 0.0578\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.421381 (avg: 0.406067) \tsec/iter: 0.0545\n",
      "Test set (epoch 14): Average loss: 0.6852, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.397822 (avg: 0.397822) \tsec/iter: 0.0648\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.264011 (avg: 0.342158) \tsec/iter: 0.0605\n",
      "Test set (epoch 15): Average loss: 1.3885, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.326387 (avg: 0.326387) \tsec/iter: 0.0529\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.337047 (avg: 0.349873) \tsec/iter: 0.0445\n",
      "Test set (epoch 16): Average loss: 1.0638, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.277787 (avg: 0.277787) \tsec/iter: 0.0419\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.362119 (avg: 0.373535) \tsec/iter: 0.0455\n",
      "Test set (epoch 17): Average loss: 1.4847, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.451312 (avg: 0.451312) \tsec/iter: 0.0539\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.337595 (avg: 0.467123) \tsec/iter: 0.0479\n",
      "Test set (epoch 18): Average loss: 1.2396, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.362003 (avg: 0.362003) \tsec/iter: 0.0509\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.584797 (avg: 0.400275) \tsec/iter: 0.0465\n",
      "Test set (epoch 19): Average loss: 1.0910, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.369239 (avg: 0.369239) \tsec/iter: 0.0409\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.511405 (avg: 0.401507) \tsec/iter: 0.0455\n",
      "Test set (epoch 20): Average loss: 1.0412, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.336017 (avg: 0.336017) \tsec/iter: 0.0519\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.296856 (avg: 0.367871) \tsec/iter: 0.0459\n",
      "Test set (epoch 21): Average loss: 0.8490, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.266446 (avg: 0.266446) \tsec/iter: 0.0449\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.385234 (avg: 0.307995) \tsec/iter: 0.0462\n",
      "Test set (epoch 22): Average loss: 1.0461, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.503027 (avg: 0.503027) \tsec/iter: 0.0499\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.482611 (avg: 0.450217) \tsec/iter: 0.0465\n",
      "Test set (epoch 23): Average loss: 0.9063, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.430092 (avg: 0.430092) \tsec/iter: 0.0509\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.277905 (avg: 0.361748) \tsec/iter: 0.0459\n",
      "Test set (epoch 24): Average loss: 0.8013, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.327031 (avg: 0.327031) \tsec/iter: 0.0519\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.345192 (avg: 0.365215) \tsec/iter: 0.0502\n",
      "Test set (epoch 25): Average loss: 1.0433, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.415268 (avg: 0.415268) \tsec/iter: 0.0509\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.216609 (avg: 0.393441) \tsec/iter: 0.0455\n",
      "Test set (epoch 26): Average loss: 0.7880, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.379422 (avg: 0.379422) \tsec/iter: 0.0519\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.269504 (avg: 0.379978) \tsec/iter: 0.0475\n",
      "Test set (epoch 27): Average loss: 0.9509, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.312762 (avg: 0.312762) \tsec/iter: 0.0479\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.499676 (avg: 0.362887) \tsec/iter: 0.0455\n",
      "Test set (epoch 28): Average loss: 0.8770, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.417494 (avg: 0.417494) \tsec/iter: 0.0499\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.574043 (avg: 0.401934) \tsec/iter: 0.0469\n",
      "Test set (epoch 29): Average loss: 0.9283, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.454100 (avg: 0.454100) \tsec/iter: 0.0459\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.296605 (avg: 0.377185) \tsec/iter: 0.0452\n",
      "Test set (epoch 30): Average loss: 0.8497, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.401987 (avg: 0.401987) \tsec/iter: 0.0509\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.398749 (avg: 0.387134) \tsec/iter: 0.0495\n",
      "Test set (epoch 31): Average loss: 0.8268, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.345568 (avg: 0.345568) \tsec/iter: 0.0698\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.248162 (avg: 0.386159) \tsec/iter: 0.0578\n",
      "Test set (epoch 32): Average loss: 0.8748, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.345248 (avg: 0.345248) \tsec/iter: 0.0568\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.480522 (avg: 0.352770) \tsec/iter: 0.0465\n",
      "Test set (epoch 33): Average loss: 0.8870, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.359216 (avg: 0.359216) \tsec/iter: 0.0449\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.346006 (avg: 0.354451) \tsec/iter: 0.0439\n",
      "Test set (epoch 34): Average loss: 0.8593, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.391916 (avg: 0.391916) \tsec/iter: 0.0439\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.410983 (avg: 0.356976) \tsec/iter: 0.0449\n",
      "Test set (epoch 35): Average loss: 0.8729, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.384576 (avg: 0.384576) \tsec/iter: 0.0439\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.389304 (avg: 0.363250) \tsec/iter: 0.0419\n",
      "Test set (epoch 36): Average loss: 0.8045, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.480632 (avg: 0.480632) \tsec/iter: 0.0519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.398927 (avg: 0.373353) \tsec/iter: 0.0472\n",
      "Test set (epoch 37): Average loss: 0.8718, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.395244 (avg: 0.395244) \tsec/iter: 0.0529\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.340269 (avg: 0.363453) \tsec/iter: 0.0462\n",
      "Test set (epoch 38): Average loss: 0.8539, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.368742 (avg: 0.368742) \tsec/iter: 0.0768\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.414174 (avg: 0.356475) \tsec/iter: 0.0615\n",
      "Test set (epoch 39): Average loss: 0.8660, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.381004 (avg: 0.381004) \tsec/iter: 0.0549\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.509909 (avg: 0.377816) \tsec/iter: 0.0479\n",
      "Test set (epoch 40): Average loss: 0.7818, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.310829 (avg: 0.310829) \tsec/iter: 0.0549\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.356303 (avg: 0.359209) \tsec/iter: 0.0499\n",
      "Test set (epoch 41): Average loss: 0.7783, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.491963 (avg: 0.491963) \tsec/iter: 0.0499\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.251622 (avg: 0.384374) \tsec/iter: 0.0472\n",
      "Test set (epoch 42): Average loss: 0.8875, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.339631 (avg: 0.339631) \tsec/iter: 0.0479\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.332726 (avg: 0.342458) \tsec/iter: 0.0436\n",
      "Test set (epoch 43): Average loss: 0.8502, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.325664 (avg: 0.325664) \tsec/iter: 0.0489\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.302905 (avg: 0.334352) \tsec/iter: 0.0465\n",
      "Test set (epoch 44): Average loss: 0.8604, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.326406 (avg: 0.326406) \tsec/iter: 0.0549\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.295296 (avg: 0.337203) \tsec/iter: 0.0495\n",
      "Test set (epoch 45): Average loss: 0.8761, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.429240 (avg: 0.429240) \tsec/iter: 0.0509\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.297731 (avg: 0.389839) \tsec/iter: 0.0465\n",
      "Test set (epoch 46): Average loss: 0.8279, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.286698 (avg: 0.286698) \tsec/iter: 0.0519\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.331670 (avg: 0.329828) \tsec/iter: 0.0429\n",
      "Test set (epoch 47): Average loss: 0.8663, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.305865 (avg: 0.305865) \tsec/iter: 0.0429\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.224490 (avg: 0.342418) \tsec/iter: 0.0462\n",
      "Test set (epoch 48): Average loss: 0.9178, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.368467 (avg: 0.368467) \tsec/iter: 0.0529\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.349209 (avg: 0.340780) \tsec/iter: 0.0462\n",
      "Test set (epoch 49): Average loss: 0.8915, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.304408 (avg: 0.304408) \tsec/iter: 0.0489\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.341505 (avg: 0.348577) \tsec/iter: 0.0465\n",
      "Test set (epoch 50): Average loss: 0.8726, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.378774 (avg: 0.378774) \tsec/iter: 0.0519\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.249207 (avg: 0.344702) \tsec/iter: 0.0469\n",
      "Test set (epoch 51): Average loss: 0.9155, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.316874 (avg: 0.316874) \tsec/iter: 0.0549\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.280396 (avg: 0.342857) \tsec/iter: 0.0455\n",
      "Test set (epoch 52): Average loss: 0.8180, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.236597 (avg: 0.236597) \tsec/iter: 0.0449\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.492682 (avg: 0.339623) \tsec/iter: 0.0452\n",
      "Test set (epoch 53): Average loss: 0.7834, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.327159 (avg: 0.327159) \tsec/iter: 0.0449\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.288947 (avg: 0.335054) \tsec/iter: 0.0432\n",
      "Test set (epoch 54): Average loss: 0.7962, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.344309 (avg: 0.344309) \tsec/iter: 0.0439\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.336877 (avg: 0.328006) \tsec/iter: 0.0429\n",
      "Test set (epoch 55): Average loss: 0.8175, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.306372 (avg: 0.306372) \tsec/iter: 0.0489\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.398826 (avg: 0.337846) \tsec/iter: 0.0426\n",
      "Test set (epoch 56): Average loss: 0.8923, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.406763 (avg: 0.406763) \tsec/iter: 0.0469\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.226179 (avg: 0.341365) \tsec/iter: 0.0419\n",
      "Test set (epoch 57): Average loss: 0.8795, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.242228 (avg: 0.242228) \tsec/iter: 0.0489\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.485140 (avg: 0.352391) \tsec/iter: 0.0465\n",
      "Test set (epoch 58): Average loss: 0.8086, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.425053 (avg: 0.425053) \tsec/iter: 0.0559\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.232808 (avg: 0.335179) \tsec/iter: 0.0485\n",
      "Test set (epoch 59): Average loss: 0.7070, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.291381 (avg: 0.291381) \tsec/iter: 0.0559\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.268855 (avg: 0.335301) \tsec/iter: 0.0482\n",
      "Test set (epoch 60): Average loss: 0.6947, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.353536 (avg: 0.353536) \tsec/iter: 0.0519\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.332318 (avg: 0.340704) \tsec/iter: 0.0455\n",
      "Test set (epoch 61): Average loss: 0.8200, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.487004 (avg: 0.487004) \tsec/iter: 0.0529\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.288538 (avg: 0.360464) \tsec/iter: 0.0462\n",
      "Test set (epoch 62): Average loss: 0.7953, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.376663 (avg: 0.376663) \tsec/iter: 0.0449\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.355323 (avg: 0.317936) \tsec/iter: 0.0426\n",
      "Test set (epoch 63): Average loss: 0.7723, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.403274 (avg: 0.403274) \tsec/iter: 0.0449\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.381611 (avg: 0.319619) \tsec/iter: 0.0452\n",
      "Test set (epoch 64): Average loss: 0.7475, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.296662 (avg: 0.296662) \tsec/iter: 0.0499\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.286034 (avg: 0.418806) \tsec/iter: 0.0469\n",
      "Test set (epoch 65): Average loss: 0.7240, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.291849 (avg: 0.291849) \tsec/iter: 0.0578\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.342305 (avg: 0.360089) \tsec/iter: 0.0482\n",
      "Test set (epoch 66): Average loss: 0.6730, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.333013 (avg: 0.333013) \tsec/iter: 0.0519\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.403649 (avg: 0.341613) \tsec/iter: 0.0485\n",
      "Test set (epoch 67): Average loss: 0.6748, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.325074 (avg: 0.325074) \tsec/iter: 0.0459\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.272944 (avg: 0.343861) \tsec/iter: 0.0462\n",
      "Test set (epoch 68): Average loss: 0.6799, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.237804 (avg: 0.237804) \tsec/iter: 0.0519\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.370250 (avg: 0.321557) \tsec/iter: 0.0479\n",
      "Test set (epoch 69): Average loss: 0.7230, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.312864 (avg: 0.312864) \tsec/iter: 0.0529\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.198221 (avg: 0.310058) \tsec/iter: 0.0482\n",
      "Test set (epoch 70): Average loss: 0.6807, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.344507 (avg: 0.344507) \tsec/iter: 0.0549\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.190756 (avg: 0.304839) \tsec/iter: 0.0515\n",
      "Test set (epoch 71): Average loss: 0.7074, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.383081 (avg: 0.383081) \tsec/iter: 0.0519\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.255884 (avg: 0.322025) \tsec/iter: 0.0475\n",
      "Test set (epoch 72): Average loss: 0.6341, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.227944 (avg: 0.227944) \tsec/iter: 0.0469\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.496318 (avg: 0.329965) \tsec/iter: 0.0462\n",
      "Test set (epoch 73): Average loss: 0.6772, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.377190 (avg: 0.377190) \tsec/iter: 0.0379\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.293621 (avg: 0.318432) \tsec/iter: 0.0396\n",
      "Test set (epoch 74): Average loss: 0.7951, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.420191 (avg: 0.420191) \tsec/iter: 0.0549\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.310778 (avg: 0.333675) \tsec/iter: 0.0469\n",
      "Test set (epoch 75): Average loss: 0.7791, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.386024 (avg: 0.386024) \tsec/iter: 0.0539\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.305118 (avg: 0.320898) \tsec/iter: 0.0479\n",
      "Test set (epoch 76): Average loss: 0.6924, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.317977 (avg: 0.317977) \tsec/iter: 0.0499\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.582461 (avg: 0.357577) \tsec/iter: 0.0455\n",
      "Test set (epoch 77): Average loss: 0.8350, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.341799 (avg: 0.341799) \tsec/iter: 0.0549\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.287464 (avg: 0.320852) \tsec/iter: 0.0502\n",
      "Test set (epoch 78): Average loss: 0.6817, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.290809 (avg: 0.290809) \tsec/iter: 0.0549\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.265309 (avg: 0.348945) \tsec/iter: 0.0492\n",
      "Test set (epoch 79): Average loss: 0.6600, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.279037 (avg: 0.279037) \tsec/iter: 0.0449\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.305729 (avg: 0.323166) \tsec/iter: 0.0472\n",
      "Test set (epoch 80): Average loss: 0.6502, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.328620 (avg: 0.328620) \tsec/iter: 0.0558\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.271138 (avg: 0.342052) \tsec/iter: 0.0482\n",
      "Test set (epoch 81): Average loss: 0.5040, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.304637 (avg: 0.304637) \tsec/iter: 0.0449\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.269802 (avg: 0.329945) \tsec/iter: 0.0442\n",
      "Test set (epoch 82): Average loss: 0.6430, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.353815 (avg: 0.353815) \tsec/iter: 0.0469\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.305934 (avg: 0.328167) \tsec/iter: 0.0469\n",
      "Test set (epoch 83): Average loss: 0.6537, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.335073 (avg: 0.335073) \tsec/iter: 0.0519\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.312270 (avg: 0.305827) \tsec/iter: 0.0489\n",
      "Test set (epoch 84): Average loss: 0.5445, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.288246 (avg: 0.288246) \tsec/iter: 0.0588\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.348954 (avg: 0.309744) \tsec/iter: 0.0515\n",
      "Test set (epoch 85): Average loss: 0.5808, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.365652 (avg: 0.365652) \tsec/iter: 0.0509\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.257209 (avg: 0.354088) \tsec/iter: 0.0462\n",
      "Test set (epoch 86): Average loss: 0.5019, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.316580 (avg: 0.316580) \tsec/iter: 0.0519\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.308142 (avg: 0.306617) \tsec/iter: 0.0455\n",
      "Test set (epoch 87): Average loss: 0.5816, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.351322 (avg: 0.351322) \tsec/iter: 0.0499\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.359735 (avg: 0.337314) \tsec/iter: 0.0475\n",
      "Test set (epoch 88): Average loss: 0.5931, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.301228 (avg: 0.301228) \tsec/iter: 0.0559\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.513700 (avg: 0.327491) \tsec/iter: 0.0575\n",
      "Test set (epoch 89): Average loss: 0.6914, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.288463 (avg: 0.288463) \tsec/iter: 0.0708\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.208497 (avg: 0.300051) \tsec/iter: 0.0562\n",
      "Test set (epoch 90): Average loss: 0.5316, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.280274 (avg: 0.280274) \tsec/iter: 0.0568\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.254748 (avg: 0.303989) \tsec/iter: 0.0492\n",
      "Test set (epoch 91): Average loss: 0.6061, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.337338 (avg: 0.337338) \tsec/iter: 0.0529\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.278191 (avg: 0.302826) \tsec/iter: 0.0502\n",
      "Test set (epoch 92): Average loss: 0.5512, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.342490 (avg: 0.342490) \tsec/iter: 0.0539\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.266533 (avg: 0.324380) \tsec/iter: 0.0462\n",
      "Test set (epoch 93): Average loss: 0.6564, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.223406 (avg: 0.223406) \tsec/iter: 0.0469\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.327552 (avg: 0.297022) \tsec/iter: 0.0455\n",
      "Test set (epoch 94): Average loss: 0.6498, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.311687 (avg: 0.311687) \tsec/iter: 0.0519\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.317804 (avg: 0.292463) \tsec/iter: 0.0479\n",
      "Test set (epoch 95): Average loss: 0.5642, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.363390 (avg: 0.363390) \tsec/iter: 0.0479\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.408181 (avg: 0.325012) \tsec/iter: 0.0495\n",
      "Test set (epoch 96): Average loss: 0.5685, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.301366 (avg: 0.301366) \tsec/iter: 0.0688\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.275202 (avg: 0.303346) \tsec/iter: 0.0572\n",
      "Test set (epoch 97): Average loss: 0.5222, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.349133 (avg: 0.349133) \tsec/iter: 0.0598\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.355802 (avg: 0.303681) \tsec/iter: 0.0522\n",
      "Test set (epoch 98): Average loss: 0.7094, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.358595 (avg: 0.358595) \tsec/iter: 0.0529\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.513397 (avg: 0.359229) \tsec/iter: 0.0539\n",
      "Test set (epoch 99): Average loss: 0.6742, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.336212 (avg: 0.336212) \tsec/iter: 0.0708\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.491561 (avg: 0.335076) \tsec/iter: 0.0801\n",
      "Test set (epoch 100): Average loss: 0.5223, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.333439 (avg: 0.333439) \tsec/iter: 0.0608\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.307664 (avg: 0.297690) \tsec/iter: 0.0562\n",
      "Test set (epoch 101): Average loss: 0.4771, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.351416 (avg: 0.351416) \tsec/iter: 0.0549\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.342586 (avg: 0.309451) \tsec/iter: 0.0519\n",
      "Test set (epoch 102): Average loss: 0.5662, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.288595 (avg: 0.288595) \tsec/iter: 0.0588\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.333741 (avg: 0.306502) \tsec/iter: 0.0549\n",
      "Test set (epoch 103): Average loss: 0.5409, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.220503 (avg: 0.220503) \tsec/iter: 0.0578\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.330834 (avg: 0.296241) \tsec/iter: 0.0492\n",
      "Test set (epoch 104): Average loss: 0.4533, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.216110 (avg: 0.216110) \tsec/iter: 0.0568\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.339575 (avg: 0.301802) \tsec/iter: 0.0838\n",
      "Test set (epoch 105): Average loss: 0.6767, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.300335 (avg: 0.300335) \tsec/iter: 0.0578\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.246132 (avg: 0.276523) \tsec/iter: 0.0559\n",
      "Test set (epoch 106): Average loss: 0.5480, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.336311 (avg: 0.336311) \tsec/iter: 0.1376\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.274395 (avg: 0.327650) \tsec/iter: 0.0851\n",
      "Test set (epoch 107): Average loss: 0.5202, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.281622 (avg: 0.281622) \tsec/iter: 0.0499\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.241085 (avg: 0.298283) \tsec/iter: 0.0475\n",
      "Test set (epoch 108): Average loss: 0.6512, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.344677 (avg: 0.344677) \tsec/iter: 0.0499\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.287155 (avg: 0.308411) \tsec/iter: 0.0479\n",
      "Test set (epoch 109): Average loss: 0.5641, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.306614 (avg: 0.306614) \tsec/iter: 0.0539\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.204792 (avg: 0.282041) \tsec/iter: 0.0469\n",
      "Test set (epoch 110): Average loss: 0.5561, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.311189 (avg: 0.311189) \tsec/iter: 0.0539\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.328359 (avg: 0.287950) \tsec/iter: 0.0489\n",
      "Test set (epoch 111): Average loss: 0.6602, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.285372 (avg: 0.285372) \tsec/iter: 0.0549\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.246643 (avg: 0.295135) \tsec/iter: 0.0505\n",
      "Test set (epoch 112): Average loss: 0.5419, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.212689 (avg: 0.212689) \tsec/iter: 0.0578\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.246404 (avg: 0.274307) \tsec/iter: 0.0542\n",
      "Test set (epoch 113): Average loss: 0.5546, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.213234 (avg: 0.213234) \tsec/iter: 0.0439\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.274878 (avg: 0.282627) \tsec/iter: 0.0422\n",
      "Test set (epoch 114): Average loss: 0.7159, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.296699 (avg: 0.296699) \tsec/iter: 0.0539\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.270180 (avg: 0.308548) \tsec/iter: 0.0469\n",
      "Test set (epoch 115): Average loss: 0.4667, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.313058 (avg: 0.313058) \tsec/iter: 0.0698\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.309051 (avg: 0.289953) \tsec/iter: 0.0635\n",
      "Test set (epoch 116): Average loss: 0.6354, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.279133 (avg: 0.279133) \tsec/iter: 0.0549\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.274648 (avg: 0.305669) \tsec/iter: 0.0489\n",
      "Test set (epoch 117): Average loss: 0.5830, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.247608 (avg: 0.247608) \tsec/iter: 0.0409\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.296659 (avg: 0.287944) \tsec/iter: 0.0412\n",
      "Test set (epoch 118): Average loss: 0.5649, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.303405 (avg: 0.303405) \tsec/iter: 0.0489\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.321355 (avg: 0.322361) \tsec/iter: 0.0482\n",
      "Test set (epoch 119): Average loss: 0.5103, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.305411 (avg: 0.305411) \tsec/iter: 0.0529\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.402803 (avg: 0.319067) \tsec/iter: 0.0445\n",
      "Test set (epoch 120): Average loss: 0.7191, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.333886 (avg: 0.333886) \tsec/iter: 0.0539\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.236212 (avg: 0.317889) \tsec/iter: 0.0459\n",
      "Test set (epoch 121): Average loss: 0.4002, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.338105 (avg: 0.338105) \tsec/iter: 0.0449\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.159551 (avg: 0.298877) \tsec/iter: 0.0502\n",
      "Test set (epoch 122): Average loss: 0.5420, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.326323 (avg: 0.326323) \tsec/iter: 0.0788\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.220591 (avg: 0.269378) \tsec/iter: 0.0698\n",
      "Test set (epoch 123): Average loss: 0.5531, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.216284 (avg: 0.216284) \tsec/iter: 0.0578\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.543490 (avg: 0.318340) \tsec/iter: 0.0495\n",
      "Test set (epoch 124): Average loss: 0.6560, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.301578 (avg: 0.301578) \tsec/iter: 0.0558\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.262892 (avg: 0.298517) \tsec/iter: 0.0475\n",
      "Test set (epoch 125): Average loss: 0.4854, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.347802 (avg: 0.347802) \tsec/iter: 0.0479\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.164932 (avg: 0.285815) \tsec/iter: 0.0445\n",
      "Test set (epoch 126): Average loss: 0.5891, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.183333 (avg: 0.183333) \tsec/iter: 0.0499\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.378941 (avg: 0.273483) \tsec/iter: 0.0469\n",
      "Test set (epoch 127): Average loss: 0.7033, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.297481 (avg: 0.297481) \tsec/iter: 0.0558\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.237318 (avg: 0.281983) \tsec/iter: 0.0492\n",
      "Test set (epoch 128): Average loss: 0.6905, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.297502 (avg: 0.297502) \tsec/iter: 0.0459\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.293716 (avg: 0.278601) \tsec/iter: 0.0559\n",
      "Test set (epoch 129): Average loss: 0.4644, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.365374 (avg: 0.365374) \tsec/iter: 0.0578\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.146045 (avg: 0.307259) \tsec/iter: 0.0512\n",
      "Test set (epoch 130): Average loss: 0.5845, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.217629 (avg: 0.217629) \tsec/iter: 0.0499\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.241755 (avg: 0.277590) \tsec/iter: 0.0558\n",
      "Test set (epoch 131): Average loss: 0.4930, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.239186 (avg: 0.239186) \tsec/iter: 0.0588\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.308403 (avg: 0.278550) \tsec/iter: 0.0472\n",
      "Test set (epoch 132): Average loss: 0.5057, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.341569 (avg: 0.341569) \tsec/iter: 0.0559\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.228726 (avg: 0.315426) \tsec/iter: 0.0605\n",
      "Test set (epoch 133): Average loss: 0.5566, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.250635 (avg: 0.250635) \tsec/iter: 0.0618\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.357632 (avg: 0.271518) \tsec/iter: 0.0499\n",
      "Test set (epoch 134): Average loss: 0.6115, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.211611 (avg: 0.211611) \tsec/iter: 0.0519\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.315335 (avg: 0.252277) \tsec/iter: 0.0475\n",
      "Test set (epoch 135): Average loss: 0.5510, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.275079 (avg: 0.275079) \tsec/iter: 0.0489\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.254225 (avg: 0.273192) \tsec/iter: 0.0452\n",
      "Test set (epoch 136): Average loss: 0.6625, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.290538 (avg: 0.290538) \tsec/iter: 0.0509\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.184330 (avg: 0.270912) \tsec/iter: 0.0525\n",
      "Test set (epoch 137): Average loss: 0.4797, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.262291 (avg: 0.262291) \tsec/iter: 0.0638\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.234049 (avg: 0.252042) \tsec/iter: 0.0532\n",
      "Test set (epoch 138): Average loss: 0.7269, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.386157 (avg: 0.386157) \tsec/iter: 0.0509\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.147501 (avg: 0.292861) \tsec/iter: 0.0482\n",
      "Test set (epoch 139): Average loss: 0.6837, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.343242 (avg: 0.343242) \tsec/iter: 0.0549\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.293982 (avg: 0.297884) \tsec/iter: 0.0479\n",
      "Test set (epoch 140): Average loss: 0.3812, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.271311 (avg: 0.271311) \tsec/iter: 0.0459\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.204363 (avg: 0.295267) \tsec/iter: 0.0455\n",
      "Test set (epoch 141): Average loss: 0.6782, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.261184 (avg: 0.261184) \tsec/iter: 0.0509\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.254593 (avg: 0.263343) \tsec/iter: 0.0442\n",
      "Test set (epoch 142): Average loss: 0.5692, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.349875 (avg: 0.349875) \tsec/iter: 0.0539\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.303471 (avg: 0.275118) \tsec/iter: 0.0452\n",
      "Test set (epoch 143): Average loss: 0.4835, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.263719 (avg: 0.263719) \tsec/iter: 0.0489\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.215063 (avg: 0.242416) \tsec/iter: 0.0489\n",
      "Test set (epoch 144): Average loss: 0.5584, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.252892 (avg: 0.252892) \tsec/iter: 0.0439\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.200437 (avg: 0.239688) \tsec/iter: 0.0439\n",
      "Test set (epoch 145): Average loss: 0.6332, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.264067 (avg: 0.264067) \tsec/iter: 0.0509\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.331872 (avg: 0.264915) \tsec/iter: 0.0459\n",
      "Test set (epoch 146): Average loss: 0.7676, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.289595 (avg: 0.289595) \tsec/iter: 0.0479\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.431406 (avg: 0.296782) \tsec/iter: 0.0475\n",
      "Test set (epoch 147): Average loss: 0.6043, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.261072 (avg: 0.261072) \tsec/iter: 0.0479\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.510961 (avg: 0.314579) \tsec/iter: 0.0449\n",
      "Test set (epoch 148): Average loss: 0.8268, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.288435 (avg: 0.288435) \tsec/iter: 0.0449\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.215588 (avg: 0.263646) \tsec/iter: 0.0419\n",
      "Test set (epoch 149): Average loss: 0.4342, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.415723 (avg: 0.415723) \tsec/iter: 0.0529\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.292225 (avg: 0.295261) \tsec/iter: 0.0492\n",
      "Test set (epoch 150): Average loss: 0.4816, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.345569 (avg: 0.345569) \tsec/iter: 0.0509\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.118519 (avg: 0.256683) \tsec/iter: 0.0455\n",
      "Test set (epoch 151): Average loss: 0.5807, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.309523 (avg: 0.309523) \tsec/iter: 0.0499\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.244217 (avg: 0.267759) \tsec/iter: 0.0452\n",
      "Test set (epoch 152): Average loss: 0.4724, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.204712 (avg: 0.204712) \tsec/iter: 0.0539\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.285204 (avg: 0.237006) \tsec/iter: 0.0492\n",
      "Test set (epoch 153): Average loss: 0.7086, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.235487 (avg: 0.235487) \tsec/iter: 0.0748\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.532670 (avg: 0.299891) \tsec/iter: 0.0725\n",
      "Test set (epoch 154): Average loss: 0.4005, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.393343 (avg: 0.393343) \tsec/iter: 0.0688\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.194443 (avg: 0.280664) \tsec/iter: 0.0529\n",
      "Test set (epoch 155): Average loss: 0.5833, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.300348 (avg: 0.300348) \tsec/iter: 0.0429\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.248995 (avg: 0.300907) \tsec/iter: 0.0432\n",
      "Test set (epoch 156): Average loss: 0.4992, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.336818 (avg: 0.336818) \tsec/iter: 0.0509\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.169952 (avg: 0.260850) \tsec/iter: 0.0479\n",
      "Test set (epoch 157): Average loss: 0.5184, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.222199 (avg: 0.222199) \tsec/iter: 0.0519\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.177621 (avg: 0.239043) \tsec/iter: 0.0628\n",
      "Test set (epoch 158): Average loss: 0.6684, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.266433 (avg: 0.266433) \tsec/iter: 0.0758\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.286097 (avg: 0.252866) \tsec/iter: 0.0559\n",
      "Test set (epoch 159): Average loss: 0.4538, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.249823 (avg: 0.249823) \tsec/iter: 0.0688\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.252364 (avg: 0.245763) \tsec/iter: 0.0655\n",
      "Test set (epoch 160): Average loss: 0.5583, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.247737 (avg: 0.247737) \tsec/iter: 0.0618\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.174186 (avg: 0.259124) \tsec/iter: 0.0512\n",
      "Test set (epoch 161): Average loss: 0.6368, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.273648 (avg: 0.273648) \tsec/iter: 0.0628\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.215339 (avg: 0.268734) \tsec/iter: 0.0701\n",
      "Test set (epoch 162): Average loss: 0.4454, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.253750 (avg: 0.253750) \tsec/iter: 0.0399\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.300036 (avg: 0.263686) \tsec/iter: 0.0419\n",
      "Test set (epoch 163): Average loss: 0.4546, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.228382 (avg: 0.228382) \tsec/iter: 0.0539\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.231374 (avg: 0.253243) \tsec/iter: 0.0465\n",
      "Test set (epoch 164): Average loss: 0.5820, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.283188 (avg: 0.283188) \tsec/iter: 0.0479\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.249206 (avg: 0.218129) \tsec/iter: 0.0475\n",
      "Test set (epoch 165): Average loss: 0.3796, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.252154 (avg: 0.252154) \tsec/iter: 0.0439\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.212102 (avg: 0.266526) \tsec/iter: 0.0442\n",
      "Test set (epoch 166): Average loss: 0.7147, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.401248 (avg: 0.401248) \tsec/iter: 0.0578\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.121731 (avg: 0.284959) \tsec/iter: 0.0522\n",
      "Test set (epoch 167): Average loss: 0.5569, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.297262 (avg: 0.297262) \tsec/iter: 0.0549\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.127578 (avg: 0.215134) \tsec/iter: 0.0505\n",
      "Test set (epoch 168): Average loss: 0.6084, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.215490 (avg: 0.215490) \tsec/iter: 0.0559\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.443756 (avg: 0.251614) \tsec/iter: 0.0505\n",
      "Test set (epoch 169): Average loss: 0.4814, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.238001 (avg: 0.238001) \tsec/iter: 0.0529\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.228474 (avg: 0.246170) \tsec/iter: 0.0465\n",
      "Test set (epoch 170): Average loss: 0.5320, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.308715 (avg: 0.308715) \tsec/iter: 0.0489\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.317867 (avg: 0.269949) \tsec/iter: 0.0449\n",
      "Test set (epoch 171): Average loss: 0.3883, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.305572 (avg: 0.305572) \tsec/iter: 0.0409\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.229174 (avg: 0.269477) \tsec/iter: 0.0436\n",
      "Test set (epoch 172): Average loss: 0.7179, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.271797 (avg: 0.271797) \tsec/iter: 0.0519\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.156095 (avg: 0.249591) \tsec/iter: 0.0535\n",
      "Test set (epoch 173): Average loss: 0.4373, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.245930 (avg: 0.245930) \tsec/iter: 0.0698\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.206741 (avg: 0.236953) \tsec/iter: 0.0615\n",
      "Test set (epoch 174): Average loss: 0.6077, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.170209 (avg: 0.170209) \tsec/iter: 0.0588\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.344634 (avg: 0.283233) \tsec/iter: 0.0509\n",
      "Test set (epoch 175): Average loss: 0.6005, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.245751 (avg: 0.245751) \tsec/iter: 0.0479\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.280673 (avg: 0.235248) \tsec/iter: 0.0465\n",
      "Test set (epoch 176): Average loss: 0.5516, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.174946 (avg: 0.174946) \tsec/iter: 0.0509\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.245787 (avg: 0.221975) \tsec/iter: 0.0462\n",
      "Test set (epoch 177): Average loss: 0.6798, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.254305 (avg: 0.254305) \tsec/iter: 0.0419\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.405232 (avg: 0.293783) \tsec/iter: 0.0429\n",
      "Test set (epoch 178): Average loss: 0.4122, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.305540 (avg: 0.305540) \tsec/iter: 0.0509\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.211399 (avg: 0.277446) \tsec/iter: 0.0485\n",
      "Test set (epoch 179): Average loss: 0.5386, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.209436 (avg: 0.209436) \tsec/iter: 0.0489\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.187340 (avg: 0.268330) \tsec/iter: 0.0495\n",
      "Test set (epoch 180): Average loss: 0.4994, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.211960 (avg: 0.211960) \tsec/iter: 0.0539\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.219832 (avg: 0.219875) \tsec/iter: 0.0462\n",
      "Test set (epoch 181): Average loss: 0.4245, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.302512 (avg: 0.302512) \tsec/iter: 0.0419\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.181215 (avg: 0.251465) \tsec/iter: 0.0432\n",
      "Test set (epoch 182): Average loss: 0.4339, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.275927 (avg: 0.275927) \tsec/iter: 0.0479\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.120563 (avg: 0.215870) \tsec/iter: 0.0465\n",
      "Test set (epoch 183): Average loss: 0.5788, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.235832 (avg: 0.235832) \tsec/iter: 0.0519\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.345479 (avg: 0.232617) \tsec/iter: 0.0482\n",
      "Test set (epoch 184): Average loss: 0.5686, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.277660 (avg: 0.277660) \tsec/iter: 0.0509\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.171347 (avg: 0.233496) \tsec/iter: 0.0495\n",
      "Test set (epoch 185): Average loss: 0.4697, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.302297 (avg: 0.302297) \tsec/iter: 0.0529\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.197994 (avg: 0.236162) \tsec/iter: 0.0479\n",
      "Test set (epoch 186): Average loss: 0.4880, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.199131 (avg: 0.199131) \tsec/iter: 0.0549\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.422284 (avg: 0.288347) \tsec/iter: 0.0522\n",
      "Test set (epoch 187): Average loss: 0.3826, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.257642 (avg: 0.257642) \tsec/iter: 0.0578\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.284351 (avg: 0.223980) \tsec/iter: 0.0485\n",
      "Test set (epoch 188): Average loss: 0.5192, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.167872 (avg: 0.167872) \tsec/iter: 0.0439\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.245494 (avg: 0.239231) \tsec/iter: 0.0479\n",
      "Test set (epoch 189): Average loss: 0.7722, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.246843 (avg: 0.246843) \tsec/iter: 0.0439\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.187129 (avg: 0.231230) \tsec/iter: 0.0455\n",
      "Test set (epoch 190): Average loss: 0.4776, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.294733 (avg: 0.294733) \tsec/iter: 0.0658\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.279070 (avg: 0.265465) \tsec/iter: 0.0635\n",
      "Test set (epoch 191): Average loss: 0.5839, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.322432 (avg: 0.322432) \tsec/iter: 0.0678\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.186562 (avg: 0.307842) \tsec/iter: 0.0539\n",
      "Test set (epoch 192): Average loss: 0.4884, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.251673 (avg: 0.251673) \tsec/iter: 0.0758\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.229009 (avg: 0.224105) \tsec/iter: 0.0645\n",
      "Test set (epoch 193): Average loss: 0.4828, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.198649 (avg: 0.198649) \tsec/iter: 0.0519\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.215893 (avg: 0.217362) \tsec/iter: 0.0469\n",
      "Test set (epoch 194): Average loss: 0.5083, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.185374 (avg: 0.185374) \tsec/iter: 0.0489\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.211622 (avg: 0.180676) \tsec/iter: 0.0436\n",
      "Test set (epoch 195): Average loss: 0.5057, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.171142 (avg: 0.171142) \tsec/iter: 0.0509\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.200306 (avg: 0.198129) \tsec/iter: 0.0442\n",
      "Test set (epoch 196): Average loss: 0.5623, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.189256 (avg: 0.189256) \tsec/iter: 0.0419\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.341275 (avg: 0.281779) \tsec/iter: 0.0396\n",
      "Test set (epoch 197): Average loss: 0.5408, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.194910 (avg: 0.194910) \tsec/iter: 0.0399\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.281106 (avg: 0.197507) \tsec/iter: 0.0449\n",
      "Test set (epoch 198): Average loss: 0.6150, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.309626 (avg: 0.309626) \tsec/iter: 0.0469\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.363064 (avg: 0.297708) \tsec/iter: 0.0449\n",
      "Test set (epoch 199): Average loss: 0.4315, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.393670 (avg: 0.393670) \tsec/iter: 0.0549\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.136464 (avg: 0.273243) \tsec/iter: 0.0492\n",
      "Test set (epoch 200): Average loss: 0.4201, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.278719 (avg: 0.278719) \tsec/iter: 0.0459\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.259661 (avg: 0.237486) \tsec/iter: 0.0449\n",
      "Test set (epoch 201): Average loss: 0.5703, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.188946 (avg: 0.188946) \tsec/iter: 0.0549\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.217866 (avg: 0.226909) \tsec/iter: 0.0475\n",
      "Test set (epoch 202): Average loss: 0.4515, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.148787 (avg: 0.148787) \tsec/iter: 0.0399\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.217543 (avg: 0.209526) \tsec/iter: 0.0402\n",
      "Test set (epoch 203): Average loss: 0.5648, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.214961 (avg: 0.214961) \tsec/iter: 0.0529\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.279969 (avg: 0.228670) \tsec/iter: 0.0485\n",
      "Test set (epoch 204): Average loss: 0.4211, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.225646 (avg: 0.225646) \tsec/iter: 0.0549\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.083246 (avg: 0.201995) \tsec/iter: 0.0479\n",
      "Test set (epoch 205): Average loss: 0.6031, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.207985 (avg: 0.207985) \tsec/iter: 0.0499\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.294969 (avg: 0.214414) \tsec/iter: 0.0479\n",
      "Test set (epoch 206): Average loss: 0.4994, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.263737 (avg: 0.263737) \tsec/iter: 0.0578\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.243982 (avg: 0.219553) \tsec/iter: 0.0495\n",
      "Test set (epoch 207): Average loss: 0.6012, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.226801 (avg: 0.226801) \tsec/iter: 0.0489\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.165915 (avg: 0.191972) \tsec/iter: 0.0426\n",
      "Test set (epoch 208): Average loss: 0.5293, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.216598 (avg: 0.216598) \tsec/iter: 0.0519\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.207116 (avg: 0.211660) \tsec/iter: 0.0475\n",
      "Test set (epoch 209): Average loss: 0.6098, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.238405 (avg: 0.238405) \tsec/iter: 0.0549\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.426162 (avg: 0.289805) \tsec/iter: 0.0489\n",
      "Test set (epoch 210): Average loss: 0.3145, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.401596 (avg: 0.401596) \tsec/iter: 0.0419\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.165168 (avg: 0.290223) \tsec/iter: 0.0435\n",
      "Test set (epoch 211): Average loss: 0.5362, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.249656 (avg: 0.249656) \tsec/iter: 0.0449\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.159205 (avg: 0.204877) \tsec/iter: 0.0419\n",
      "Test set (epoch 212): Average loss: 0.4497, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.223345 (avg: 0.223345) \tsec/iter: 0.0509\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.215740 (avg: 0.227465) \tsec/iter: 0.0482\n",
      "Test set (epoch 213): Average loss: 0.6642, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.153631 (avg: 0.153631) \tsec/iter: 0.0519\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.241498 (avg: 0.224577) \tsec/iter: 0.0436\n",
      "Test set (epoch 214): Average loss: 0.7445, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.231533 (avg: 0.231533) \tsec/iter: 0.0459\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.247729 (avg: 0.241943) \tsec/iter: 0.0449\n",
      "Test set (epoch 215): Average loss: 0.3938, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.345390 (avg: 0.345390) \tsec/iter: 0.0459\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.122783 (avg: 0.278058) \tsec/iter: 0.0455\n",
      "Test set (epoch 216): Average loss: 0.4758, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.241316 (avg: 0.241316) \tsec/iter: 0.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.143008 (avg: 0.192989) \tsec/iter: 0.0432\n",
      "Test set (epoch 217): Average loss: 0.4870, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.221370 (avg: 0.221370) \tsec/iter: 0.0439\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.178765 (avg: 0.213224) \tsec/iter: 0.0412\n",
      "Test set (epoch 218): Average loss: 0.5739, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.167814 (avg: 0.167814) \tsec/iter: 0.0529\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.143808 (avg: 0.177221) \tsec/iter: 0.0452\n",
      "Test set (epoch 219): Average loss: 0.5763, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.224258 (avg: 0.224258) \tsec/iter: 0.0539\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.203723 (avg: 0.214441) \tsec/iter: 0.0509\n",
      "Test set (epoch 220): Average loss: 0.5023, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.200532 (avg: 0.200532) \tsec/iter: 0.0479\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.393816 (avg: 0.217656) \tsec/iter: 0.0452\n",
      "Test set (epoch 221): Average loss: 1.0607, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.287524 (avg: 0.287524) \tsec/iter: 0.0489\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.256767 (avg: 0.281544) \tsec/iter: 0.0416\n",
      "Test set (epoch 222): Average loss: 0.4812, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.145945 (avg: 0.145945) \tsec/iter: 0.0449\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.259386 (avg: 0.190705) \tsec/iter: 0.0409\n",
      "Test set (epoch 223): Average loss: 0.5794, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.235796 (avg: 0.235796) \tsec/iter: 0.0429\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.189301 (avg: 0.207513) \tsec/iter: 0.0442\n",
      "Test set (epoch 224): Average loss: 0.5746, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.217761 (avg: 0.217761) \tsec/iter: 0.0479\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.238987 (avg: 0.216971) \tsec/iter: 0.0442\n",
      "Test set (epoch 225): Average loss: 0.5090, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.162109 (avg: 0.162109) \tsec/iter: 0.0479\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.315215 (avg: 0.195306) \tsec/iter: 0.0452\n",
      "Test set (epoch 226): Average loss: 0.6350, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.133809 (avg: 0.133809) \tsec/iter: 0.0479\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.225025 (avg: 0.190426) \tsec/iter: 0.0442\n",
      "Test set (epoch 227): Average loss: 0.5364, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.242383 (avg: 0.242383) \tsec/iter: 0.0489\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.106803 (avg: 0.209110) \tsec/iter: 0.0439\n",
      "Test set (epoch 228): Average loss: 0.4887, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.271120 (avg: 0.271120) \tsec/iter: 0.0519\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.204933 (avg: 0.208553) \tsec/iter: 0.0429\n",
      "Test set (epoch 229): Average loss: 0.7255, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.211103 (avg: 0.211103) \tsec/iter: 0.0439\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.180714 (avg: 0.203745) \tsec/iter: 0.0432\n",
      "Test set (epoch 230): Average loss: 0.3934, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.163196 (avg: 0.163196) \tsec/iter: 0.0469\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.224454 (avg: 0.214565) \tsec/iter: 0.0459\n",
      "Test set (epoch 231): Average loss: 0.4501, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.309287 (avg: 0.309287) \tsec/iter: 0.0499\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.187868 (avg: 0.221874) \tsec/iter: 0.0462\n",
      "Test set (epoch 232): Average loss: 0.5067, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.127309 (avg: 0.127309) \tsec/iter: 0.0519\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.284982 (avg: 0.211085) \tsec/iter: 0.0439\n",
      "Test set (epoch 233): Average loss: 0.5669, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.224388 (avg: 0.224388) \tsec/iter: 0.0539\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.144112 (avg: 0.213098) \tsec/iter: 0.0482\n",
      "Test set (epoch 234): Average loss: 0.4688, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.249968 (avg: 0.249968) \tsec/iter: 0.0519\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.180576 (avg: 0.188269) \tsec/iter: 0.0442\n",
      "Test set (epoch 235): Average loss: 0.4882, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.260967 (avg: 0.260967) \tsec/iter: 0.0519\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.165350 (avg: 0.180224) \tsec/iter: 0.0445\n",
      "Test set (epoch 236): Average loss: 0.3686, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.174776 (avg: 0.174776) \tsec/iter: 0.0409\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.214623 (avg: 0.169019) \tsec/iter: 0.0429\n",
      "Test set (epoch 237): Average loss: 0.5406, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.180962 (avg: 0.180962) \tsec/iter: 0.0389\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.278043 (avg: 0.212544) \tsec/iter: 0.0445\n",
      "Test set (epoch 238): Average loss: 0.6685, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.235940 (avg: 0.235940) \tsec/iter: 0.0608\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.192660 (avg: 0.217070) \tsec/iter: 0.0499\n",
      "Test set (epoch 239): Average loss: 0.5877, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.199175 (avg: 0.199175) \tsec/iter: 0.0698\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.117430 (avg: 0.179386) \tsec/iter: 0.0698\n",
      "Test set (epoch 240): Average loss: 0.5165, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.174138 (avg: 0.174138) \tsec/iter: 0.0668\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.293509 (avg: 0.228540) \tsec/iter: 0.0549\n",
      "Test set (epoch 241): Average loss: 0.3684, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.183180 (avg: 0.183180) \tsec/iter: 0.0608\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.212283 (avg: 0.214993) \tsec/iter: 0.0549\n",
      "Test set (epoch 242): Average loss: 0.6900, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.198586 (avg: 0.198586) \tsec/iter: 0.0549\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.199627 (avg: 0.207479) \tsec/iter: 0.0509\n",
      "Test set (epoch 243): Average loss: 0.5172, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.132422 (avg: 0.132422) \tsec/iter: 0.0578\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.322352 (avg: 0.199754) \tsec/iter: 0.0502\n",
      "Test set (epoch 244): Average loss: 0.5657, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.207165 (avg: 0.207165) \tsec/iter: 0.0499\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.168863 (avg: 0.195583) \tsec/iter: 0.0502\n",
      "Test set (epoch 245): Average loss: 0.4848, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.243991 (avg: 0.243991) \tsec/iter: 0.0559\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.189358 (avg: 0.220817) \tsec/iter: 0.0745\n",
      "Test set (epoch 246): Average loss: 0.5152, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.111436 (avg: 0.111436) \tsec/iter: 0.0558\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.174774 (avg: 0.188836) \tsec/iter: 0.0655\n",
      "Test set (epoch 247): Average loss: 0.6471, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.184287 (avg: 0.184287) \tsec/iter: 0.0638\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.145217 (avg: 0.183153) \tsec/iter: 0.0612\n",
      "Test set (epoch 248): Average loss: 0.5269, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.163238 (avg: 0.163238) \tsec/iter: 0.0658\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.185320 (avg: 0.181671) \tsec/iter: 0.0532\n",
      "Test set (epoch 249): Average loss: 0.4126, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.190294 (avg: 0.190294) \tsec/iter: 0.0598\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.198230 (avg: 0.172849) \tsec/iter: 0.0715\n",
      "Test set (epoch 250): Average loss: 0.5862, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.141780 (avg: 0.141780) \tsec/iter: 0.0928\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.276417 (avg: 0.199225) \tsec/iter: 0.0778\n",
      "Test set (epoch 251): Average loss: 0.4802, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.153946 (avg: 0.153946) \tsec/iter: 0.0539\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.310418 (avg: 0.206187) \tsec/iter: 0.0499\n",
      "Test set (epoch 252): Average loss: 0.6805, Accuracy: 13/18 (72.22%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.199521 (avg: 0.199521) \tsec/iter: 0.0568\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.234909 (avg: 0.240370) \tsec/iter: 0.0499\n",
      "Test set (epoch 253): Average loss: 0.7276, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.128144 (avg: 0.128144) \tsec/iter: 0.0529\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.198588 (avg: 0.206058) \tsec/iter: 0.0495\n",
      "Test set (epoch 254): Average loss: 0.4646, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.171496 (avg: 0.171496) \tsec/iter: 0.0479\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.165023 (avg: 0.189261) \tsec/iter: 0.0479\n",
      "Test set (epoch 255): Average loss: 0.6198, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.285704 (avg: 0.285704) \tsec/iter: 0.0628\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.348224 (avg: 0.278647) \tsec/iter: 0.0718\n",
      "Test set (epoch 256): Average loss: 0.5297, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.210094 (avg: 0.210094) \tsec/iter: 0.0568\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.231098 (avg: 0.254140) \tsec/iter: 0.0499\n",
      "Test set (epoch 257): Average loss: 0.3655, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.337361 (avg: 0.337361) \tsec/iter: 0.0588\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.211557 (avg: 0.247538) \tsec/iter: 0.0505\n",
      "Test set (epoch 258): Average loss: 0.4737, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.122379 (avg: 0.122379) \tsec/iter: 0.1007\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.344621 (avg: 0.212075) \tsec/iter: 0.0668\n",
      "Test set (epoch 259): Average loss: 0.5177, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.160319 (avg: 0.160319) \tsec/iter: 0.0479\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.255709 (avg: 0.199922) \tsec/iter: 0.0462\n",
      "Test set (epoch 260): Average loss: 0.5361, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.196428 (avg: 0.196428) \tsec/iter: 0.0419\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.288067 (avg: 0.200975) \tsec/iter: 0.0426\n",
      "Test set (epoch 261): Average loss: 0.5174, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.213376 (avg: 0.213376) \tsec/iter: 0.0479\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.195635 (avg: 0.212066) \tsec/iter: 0.0459\n",
      "Test set (epoch 262): Average loss: 0.6106, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.191756 (avg: 0.191756) \tsec/iter: 0.0578\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.241315 (avg: 0.228771) \tsec/iter: 0.0535\n",
      "Test set (epoch 263): Average loss: 0.4456, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.252319 (avg: 0.252319) \tsec/iter: 0.0538\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.296479 (avg: 0.226254) \tsec/iter: 0.0745\n",
      "Test set (epoch 264): Average loss: 0.6781, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.270474 (avg: 0.270474) \tsec/iter: 0.0668\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.138182 (avg: 0.181634) \tsec/iter: 0.0575\n",
      "Test set (epoch 265): Average loss: 0.4804, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.324427 (avg: 0.324427) \tsec/iter: 0.0529\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.124792 (avg: 0.230288) \tsec/iter: 0.0482\n",
      "Test set (epoch 266): Average loss: 0.5481, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.197950 (avg: 0.197950) \tsec/iter: 0.0529\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.288270 (avg: 0.243326) \tsec/iter: 0.0475\n",
      "Test set (epoch 267): Average loss: 0.6314, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.217743 (avg: 0.217743) \tsec/iter: 0.0559\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.150246 (avg: 0.190133) \tsec/iter: 0.0485\n",
      "Test set (epoch 268): Average loss: 0.4984, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.179339 (avg: 0.179339) \tsec/iter: 0.0499\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.194181 (avg: 0.164199) \tsec/iter: 0.0469\n",
      "Test set (epoch 269): Average loss: 0.7739, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.233574 (avg: 0.233574) \tsec/iter: 0.0519\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.170568 (avg: 0.177435) \tsec/iter: 0.0465\n",
      "Test set (epoch 270): Average loss: 0.4622, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.179668 (avg: 0.179668) \tsec/iter: 0.0389\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.263690 (avg: 0.201913) \tsec/iter: 0.0382\n",
      "Test set (epoch 271): Average loss: 0.6330, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.170764 (avg: 0.170764) \tsec/iter: 0.0529\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.204132 (avg: 0.188988) \tsec/iter: 0.0485\n",
      "Test set (epoch 272): Average loss: 0.5355, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.322227 (avg: 0.322227) \tsec/iter: 0.0399\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.158397 (avg: 0.222100) \tsec/iter: 0.0426\n",
      "Test set (epoch 273): Average loss: 0.5447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.183386 (avg: 0.183386) \tsec/iter: 0.0519\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.089327 (avg: 0.146812) \tsec/iter: 0.0509\n",
      "Test set (epoch 274): Average loss: 0.5502, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.167459 (avg: 0.167459) \tsec/iter: 0.0618\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.221167 (avg: 0.165566) \tsec/iter: 0.0509\n",
      "Test set (epoch 275): Average loss: 0.5270, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.189239 (avg: 0.189239) \tsec/iter: 0.1227\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.113923 (avg: 0.166585) \tsec/iter: 0.0838\n",
      "Test set (epoch 276): Average loss: 0.5960, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.212986 (avg: 0.212986) \tsec/iter: 0.0628\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.213245 (avg: 0.205826) \tsec/iter: 0.0592\n",
      "Test set (epoch 277): Average loss: 0.4363, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.238231 (avg: 0.238231) \tsec/iter: 0.0598\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.184973 (avg: 0.217410) \tsec/iter: 0.0532\n",
      "Test set (epoch 278): Average loss: 0.4899, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.193536 (avg: 0.193536) \tsec/iter: 0.0668\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.148536 (avg: 0.167637) \tsec/iter: 0.0868\n",
      "Test set (epoch 279): Average loss: 0.5823, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.146428 (avg: 0.146428) \tsec/iter: 0.0798\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.132043 (avg: 0.177957) \tsec/iter: 0.0665\n",
      "Test set (epoch 280): Average loss: 0.5516, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.145983 (avg: 0.145983) \tsec/iter: 0.0618\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.387401 (avg: 0.238053) \tsec/iter: 0.0559\n",
      "Test set (epoch 281): Average loss: 0.5621, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.174105 (avg: 0.174105) \tsec/iter: 0.0549\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.241215 (avg: 0.173546) \tsec/iter: 0.0495\n",
      "Test set (epoch 282): Average loss: 0.5462, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.231851 (avg: 0.231851) \tsec/iter: 0.0628\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.178042 (avg: 0.176591) \tsec/iter: 0.0532\n",
      "Test set (epoch 283): Average loss: 0.5018, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.229988 (avg: 0.229988) \tsec/iter: 0.0539\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.127708 (avg: 0.202032) \tsec/iter: 0.0672\n",
      "Test set (epoch 284): Average loss: 0.4826, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.270663 (avg: 0.270663) \tsec/iter: 0.0628\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.165838 (avg: 0.225478) \tsec/iter: 0.0499\n",
      "Test set (epoch 285): Average loss: 0.6306, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.268551 (avg: 0.268551) \tsec/iter: 0.0529\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.073297 (avg: 0.180840) \tsec/iter: 0.0475\n",
      "Test set (epoch 286): Average loss: 0.5774, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.306520 (avg: 0.306520) \tsec/iter: 0.0489\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.194983 (avg: 0.225911) \tsec/iter: 0.0422\n",
      "Test set (epoch 287): Average loss: 0.5760, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.172429 (avg: 0.172429) \tsec/iter: 0.1536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.186324 (avg: 0.164237) \tsec/iter: 0.1263\n",
      "Test set (epoch 288): Average loss: 0.7471, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.201866 (avg: 0.201866) \tsec/iter: 0.1307\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.139668 (avg: 0.198694) \tsec/iter: 0.1220\n",
      "Test set (epoch 289): Average loss: 0.5242, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.214812 (avg: 0.214812) \tsec/iter: 0.0738\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.126701 (avg: 0.178897) \tsec/iter: 0.0708\n",
      "Test set (epoch 290): Average loss: 0.5101, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.145451 (avg: 0.145451) \tsec/iter: 0.0638\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.122240 (avg: 0.157416) \tsec/iter: 0.0795\n",
      "Test set (epoch 291): Average loss: 0.7200, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.102427 (avg: 0.102427) \tsec/iter: 0.1227\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.277084 (avg: 0.167358) \tsec/iter: 0.0741\n",
      "Test set (epoch 292): Average loss: 0.4842, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.260051 (avg: 0.260051) \tsec/iter: 0.0499\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.286206 (avg: 0.216308) \tsec/iter: 0.0445\n",
      "Test set (epoch 293): Average loss: 0.6059, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.176259 (avg: 0.176259) \tsec/iter: 0.0529\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.150393 (avg: 0.191534) \tsec/iter: 0.0445\n",
      "Test set (epoch 294): Average loss: 0.6671, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.276166 (avg: 0.276166) \tsec/iter: 0.0439\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.202022 (avg: 0.198747) \tsec/iter: 0.0422\n",
      "Test set (epoch 295): Average loss: 0.4491, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.210922 (avg: 0.210922) \tsec/iter: 0.0529\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.332332 (avg: 0.216051) \tsec/iter: 0.0462\n",
      "Test set (epoch 296): Average loss: 0.6576, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.235844 (avg: 0.235844) \tsec/iter: 0.0519\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.179715 (avg: 0.202574) \tsec/iter: 0.0462\n",
      "Test set (epoch 297): Average loss: 0.4697, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.140905 (avg: 0.140905) \tsec/iter: 0.0529\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.145347 (avg: 0.176100) \tsec/iter: 0.0492\n",
      "Test set (epoch 298): Average loss: 0.6719, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.305836 (avg: 0.305836) \tsec/iter: 0.0578\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.111038 (avg: 0.199606) \tsec/iter: 0.0562\n",
      "Test set (epoch 299): Average loss: 0.5826, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.277467 (avg: 0.277467) \tsec/iter: 0.0588\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.235424 (avg: 0.249399) \tsec/iter: 0.0505\n",
      "Test set (epoch 300): Average loss: 0.5426, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.270587 (avg: 0.270587) \tsec/iter: 0.0509\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.187750 (avg: 0.178575) \tsec/iter: 0.0472\n",
      "Test set (epoch 301): Average loss: 0.6059, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.192889 (avg: 0.192889) \tsec/iter: 0.0519\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.156381 (avg: 0.171672) \tsec/iter: 0.0459\n",
      "Test set (epoch 302): Average loss: 0.5261, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.153148 (avg: 0.153148) \tsec/iter: 0.0549\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.346554 (avg: 0.182536) \tsec/iter: 0.0532\n",
      "Test set (epoch 303): Average loss: 0.6249, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.192640 (avg: 0.192640) \tsec/iter: 0.0578\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.119589 (avg: 0.179793) \tsec/iter: 0.0525\n",
      "Test set (epoch 304): Average loss: 0.4293, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.111371 (avg: 0.111371) \tsec/iter: 0.0588\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.226016 (avg: 0.199765) \tsec/iter: 0.0588\n",
      "Test set (epoch 305): Average loss: 0.7409, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.314672 (avg: 0.314672) \tsec/iter: 0.0568\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.198546 (avg: 0.245168) \tsec/iter: 0.0565\n",
      "Test set (epoch 306): Average loss: 0.5614, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.176258 (avg: 0.176258) \tsec/iter: 0.0788\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.370268 (avg: 0.207096) \tsec/iter: 0.0672\n",
      "Test set (epoch 307): Average loss: 0.4963, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.230866 (avg: 0.230866) \tsec/iter: 0.0658\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.172527 (avg: 0.176375) \tsec/iter: 0.0615\n",
      "Test set (epoch 308): Average loss: 0.5354, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.145342 (avg: 0.145342) \tsec/iter: 0.0638\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.229382 (avg: 0.188841) \tsec/iter: 0.0575\n",
      "Test set (epoch 309): Average loss: 0.5538, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.224676 (avg: 0.224676) \tsec/iter: 0.0618\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.105812 (avg: 0.159424) \tsec/iter: 0.0555\n",
      "Test set (epoch 310): Average loss: 0.6189, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.202210 (avg: 0.202210) \tsec/iter: 0.0638\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.149040 (avg: 0.171843) \tsec/iter: 0.0549\n",
      "Test set (epoch 311): Average loss: 0.6652, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.115127 (avg: 0.115127) \tsec/iter: 0.0539\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.260546 (avg: 0.187516) \tsec/iter: 0.0575\n",
      "Test set (epoch 312): Average loss: 0.5630, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.111787 (avg: 0.111787) \tsec/iter: 0.0479\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.274360 (avg: 0.158926) \tsec/iter: 0.0469\n",
      "Test set (epoch 313): Average loss: 0.5978, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.200023 (avg: 0.200023) \tsec/iter: 0.0479\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.198322 (avg: 0.202005) \tsec/iter: 0.0426\n",
      "Test set (epoch 314): Average loss: 0.5294, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.211387 (avg: 0.211387) \tsec/iter: 0.0519\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.186297 (avg: 0.220196) \tsec/iter: 0.0562\n",
      "Test set (epoch 315): Average loss: 0.4462, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.144012 (avg: 0.144012) \tsec/iter: 0.0957\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.199763 (avg: 0.162218) \tsec/iter: 0.0751\n",
      "Test set (epoch 316): Average loss: 0.5856, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.146808 (avg: 0.146808) \tsec/iter: 0.0489\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.118678 (avg: 0.153936) \tsec/iter: 0.0532\n",
      "Test set (epoch 317): Average loss: 0.5434, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.172206 (avg: 0.172206) \tsec/iter: 0.0618\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.155846 (avg: 0.239863) \tsec/iter: 0.0605\n",
      "Test set (epoch 318): Average loss: 0.7416, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.249277 (avg: 0.249277) \tsec/iter: 0.0559\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.181242 (avg: 0.189364) \tsec/iter: 0.0469\n",
      "Test set (epoch 319): Average loss: 0.5605, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.146033 (avg: 0.146033) \tsec/iter: 0.0578\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.140295 (avg: 0.176768) \tsec/iter: 0.0499\n",
      "Test set (epoch 320): Average loss: 0.5012, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.097416 (avg: 0.097416) \tsec/iter: 0.0598\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.285643 (avg: 0.173266) \tsec/iter: 0.0529\n",
      "Test set (epoch 321): Average loss: 0.4558, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.171673 (avg: 0.171673) \tsec/iter: 0.0499\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.282260 (avg: 0.206370) \tsec/iter: 0.0435\n",
      "Test set (epoch 322): Average loss: 0.5131, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.260422 (avg: 0.260422) \tsec/iter: 0.0509\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.230663 (avg: 0.236462) \tsec/iter: 0.0904\n",
      "Test set (epoch 323): Average loss: 0.5480, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.151063 (avg: 0.151063) \tsec/iter: 0.1137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.159872 (avg: 0.192408) \tsec/iter: 0.1124\n",
      "Test set (epoch 324): Average loss: 0.5395, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.181955 (avg: 0.181955) \tsec/iter: 0.1995\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.162548 (avg: 0.177334) \tsec/iter: 0.1180\n",
      "Test set (epoch 325): Average loss: 0.5219, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.179178 (avg: 0.179178) \tsec/iter: 0.0788\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.193473 (avg: 0.185372) \tsec/iter: 0.0721\n",
      "Test set (epoch 326): Average loss: 0.5687, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.211821 (avg: 0.211821) \tsec/iter: 0.1137\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.114894 (avg: 0.200379) \tsec/iter: 0.0928\n",
      "Test set (epoch 327): Average loss: 0.5620, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.093471 (avg: 0.093471) \tsec/iter: 0.0469\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.143864 (avg: 0.175430) \tsec/iter: 0.0455\n",
      "Test set (epoch 328): Average loss: 0.8133, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.213697 (avg: 0.213697) \tsec/iter: 0.0539\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.149035 (avg: 0.168529) \tsec/iter: 0.0519\n",
      "Test set (epoch 329): Average loss: 0.5218, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.121558 (avg: 0.121558) \tsec/iter: 0.0549\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.134369 (avg: 0.151015) \tsec/iter: 0.0469\n",
      "Test set (epoch 330): Average loss: 0.5788, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.208307 (avg: 0.208307) \tsec/iter: 0.0559\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.167250 (avg: 0.204834) \tsec/iter: 0.0449\n",
      "Test set (epoch 331): Average loss: 0.6056, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.183761 (avg: 0.183761) \tsec/iter: 0.0509\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.255442 (avg: 0.203159) \tsec/iter: 0.0449\n",
      "Test set (epoch 332): Average loss: 0.6080, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.193349 (avg: 0.193349) \tsec/iter: 0.0519\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.070389 (avg: 0.165428) \tsec/iter: 0.0605\n",
      "Test set (epoch 333): Average loss: 0.5422, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.189795 (avg: 0.189795) \tsec/iter: 0.0708\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.091039 (avg: 0.149724) \tsec/iter: 0.0592\n",
      "Test set (epoch 334): Average loss: 0.6332, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.126437 (avg: 0.126437) \tsec/iter: 0.0578\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.145289 (avg: 0.169319) \tsec/iter: 0.0668\n",
      "Test set (epoch 335): Average loss: 0.6971, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.117687 (avg: 0.117687) \tsec/iter: 0.0539\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.244461 (avg: 0.212702) \tsec/iter: 0.0529\n",
      "Test set (epoch 336): Average loss: 0.8568, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.171150 (avg: 0.171150) \tsec/iter: 0.0668\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.192603 (avg: 0.204609) \tsec/iter: 0.0618\n",
      "Test set (epoch 337): Average loss: 0.5548, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.234195 (avg: 0.234195) \tsec/iter: 0.0558\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.159245 (avg: 0.178623) \tsec/iter: 0.0472\n",
      "Test set (epoch 338): Average loss: 0.5898, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.151538 (avg: 0.151538) \tsec/iter: 0.0519\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.224848 (avg: 0.219683) \tsec/iter: 0.0449\n",
      "Test set (epoch 339): Average loss: 0.5499, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.145566 (avg: 0.145566) \tsec/iter: 0.0469\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.161591 (avg: 0.163603) \tsec/iter: 0.0465\n",
      "Test set (epoch 340): Average loss: 0.5195, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.184514 (avg: 0.184514) \tsec/iter: 0.0539\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.156240 (avg: 0.178085) \tsec/iter: 0.0499\n",
      "Test set (epoch 341): Average loss: 0.5284, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.103500 (avg: 0.103500) \tsec/iter: 0.0598\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.182783 (avg: 0.147786) \tsec/iter: 0.0562\n",
      "Test set (epoch 342): Average loss: 0.5431, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.196265 (avg: 0.196265) \tsec/iter: 0.0628\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.142608 (avg: 0.169883) \tsec/iter: 0.0578\n",
      "Test set (epoch 343): Average loss: 0.5199, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.185305 (avg: 0.185305) \tsec/iter: 0.0499\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.251052 (avg: 0.209304) \tsec/iter: 0.0432\n",
      "Test set (epoch 344): Average loss: 0.6581, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.133960 (avg: 0.133960) \tsec/iter: 0.0558\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.300431 (avg: 0.175264) \tsec/iter: 0.0489\n",
      "Test set (epoch 345): Average loss: 0.5698, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.099368 (avg: 0.099368) \tsec/iter: 0.0399\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.151784 (avg: 0.215415) \tsec/iter: 0.0409\n",
      "Test set (epoch 346): Average loss: 0.6390, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.186144 (avg: 0.186144) \tsec/iter: 0.0578\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.168322 (avg: 0.159937) \tsec/iter: 0.0529\n",
      "Test set (epoch 347): Average loss: 0.5176, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.221003 (avg: 0.221003) \tsec/iter: 0.0519\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.160848 (avg: 0.186283) \tsec/iter: 0.0462\n",
      "Test set (epoch 348): Average loss: 0.5487, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.113107 (avg: 0.113107) \tsec/iter: 0.0449\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.260351 (avg: 0.163028) \tsec/iter: 0.0422\n",
      "Test set (epoch 349): Average loss: 0.7057, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.250301 (avg: 0.250301) \tsec/iter: 0.0499\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.189107 (avg: 0.187005) \tsec/iter: 0.0465\n",
      "Test set (epoch 350): Average loss: 0.5174, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.288830 (avg: 0.288830) \tsec/iter: 0.0499\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.208027 (avg: 0.220018) \tsec/iter: 0.0472\n",
      "Test set (epoch 351): Average loss: 0.6279, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.141789 (avg: 0.141789) \tsec/iter: 0.0539\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.242083 (avg: 0.166136) \tsec/iter: 0.0475\n",
      "Test set (epoch 352): Average loss: 0.6177, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.271616 (avg: 0.271616) \tsec/iter: 0.0489\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.088424 (avg: 0.199335) \tsec/iter: 0.0462\n",
      "Test set (epoch 353): Average loss: 0.5653, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.068852 (avg: 0.068852) \tsec/iter: 0.0489\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.247767 (avg: 0.171786) \tsec/iter: 0.0455\n",
      "Test set (epoch 354): Average loss: 0.7760, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.175155 (avg: 0.175155) \tsec/iter: 0.0519\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.167480 (avg: 0.168709) \tsec/iter: 0.0459\n",
      "Test set (epoch 355): Average loss: 0.5625, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.210418 (avg: 0.210418) \tsec/iter: 0.0519\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.080132 (avg: 0.166349) \tsec/iter: 0.0479\n",
      "Test set (epoch 356): Average loss: 0.7528, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.151463 (avg: 0.151463) \tsec/iter: 0.0519\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.147235 (avg: 0.157419) \tsec/iter: 0.0479\n",
      "Test set (epoch 357): Average loss: 0.5239, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.225975 (avg: 0.225975) \tsec/iter: 0.0499\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.200690 (avg: 0.189588) \tsec/iter: 0.0449\n",
      "Test set (epoch 358): Average loss: 0.7538, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.191525 (avg: 0.191525) \tsec/iter: 0.0529\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.150624 (avg: 0.165496) \tsec/iter: 0.0469\n",
      "Test set (epoch 359): Average loss: 0.5355, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.055068 (avg: 0.055068) \tsec/iter: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.294648 (avg: 0.150938) \tsec/iter: 0.0575\n",
      "Test set (epoch 360): Average loss: 0.6400, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.167460 (avg: 0.167460) \tsec/iter: 0.0459\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.148636 (avg: 0.163271) \tsec/iter: 0.0462\n",
      "Test set (epoch 361): Average loss: 0.6551, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.275047 (avg: 0.275047) \tsec/iter: 0.0529\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.068664 (avg: 0.197799) \tsec/iter: 0.0489\n",
      "Test set (epoch 362): Average loss: 0.5312, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.172862 (avg: 0.172862) \tsec/iter: 0.0559\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.209643 (avg: 0.151078) \tsec/iter: 0.0459\n",
      "Test set (epoch 363): Average loss: 0.7495, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.151224 (avg: 0.151224) \tsec/iter: 0.0479\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.164342 (avg: 0.153327) \tsec/iter: 0.0452\n",
      "Test set (epoch 364): Average loss: 0.6228, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.138795 (avg: 0.138795) \tsec/iter: 0.0509\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.239274 (avg: 0.154256) \tsec/iter: 0.0442\n",
      "Test set (epoch 365): Average loss: 0.5361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.131050 (avg: 0.131050) \tsec/iter: 0.0419\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.205701 (avg: 0.152538) \tsec/iter: 0.0678\n",
      "Test set (epoch 366): Average loss: 0.6633, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.217169 (avg: 0.217169) \tsec/iter: 0.0997\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.244390 (avg: 0.190094) \tsec/iter: 0.0691\n",
      "Test set (epoch 367): Average loss: 0.4269, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.150803 (avg: 0.150803) \tsec/iter: 0.0539\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.209376 (avg: 0.280620) \tsec/iter: 0.0465\n",
      "Test set (epoch 368): Average loss: 0.7928, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.219489 (avg: 0.219489) \tsec/iter: 0.0459\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.105272 (avg: 0.153209) \tsec/iter: 0.0469\n",
      "Test set (epoch 369): Average loss: 0.5703, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.265166 (avg: 0.265166) \tsec/iter: 0.0449\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.108633 (avg: 0.187699) \tsec/iter: 0.0422\n",
      "Test set (epoch 370): Average loss: 0.6945, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.244303 (avg: 0.244303) \tsec/iter: 0.0539\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.215574 (avg: 0.194325) \tsec/iter: 0.0482\n",
      "Test set (epoch 371): Average loss: 0.4521, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.089740 (avg: 0.089740) \tsec/iter: 0.0578\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.338921 (avg: 0.210553) \tsec/iter: 0.0522\n",
      "Test set (epoch 372): Average loss: 0.5887, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.182457 (avg: 0.182457) \tsec/iter: 0.0578\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.103385 (avg: 0.204610) \tsec/iter: 0.0495\n",
      "Test set (epoch 373): Average loss: 0.3599, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.263260 (avg: 0.263260) \tsec/iter: 0.0499\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.153273 (avg: 0.201431) \tsec/iter: 0.0435\n",
      "Test set (epoch 374): Average loss: 0.5789, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.148220 (avg: 0.148220) \tsec/iter: 0.0529\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.080088 (avg: 0.176885) \tsec/iter: 0.0445\n",
      "Test set (epoch 375): Average loss: 0.3815, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.173498 (avg: 0.173498) \tsec/iter: 0.0469\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.145501 (avg: 0.147947) \tsec/iter: 0.0459\n",
      "Test set (epoch 376): Average loss: 0.6102, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.134123 (avg: 0.134123) \tsec/iter: 0.0628\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.269116 (avg: 0.187817) \tsec/iter: 0.0652\n",
      "Test set (epoch 377): Average loss: 0.7280, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.137986 (avg: 0.137986) \tsec/iter: 0.1057\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.164425 (avg: 0.151412) \tsec/iter: 0.0844\n",
      "Test set (epoch 378): Average loss: 0.6523, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.155599 (avg: 0.155599) \tsec/iter: 0.0529\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.166860 (avg: 0.161626) \tsec/iter: 0.0469\n",
      "Test set (epoch 379): Average loss: 0.4623, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.226365 (avg: 0.226365) \tsec/iter: 0.0489\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.247225 (avg: 0.221116) \tsec/iter: 0.0455\n",
      "Test set (epoch 380): Average loss: 0.5732, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.058712 (avg: 0.058712) \tsec/iter: 0.0489\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.110558 (avg: 0.118333) \tsec/iter: 0.0449\n",
      "Test set (epoch 381): Average loss: 0.4655, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.209883 (avg: 0.209883) \tsec/iter: 0.0479\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.098017 (avg: 0.187048) \tsec/iter: 0.0449\n",
      "Test set (epoch 382): Average loss: 0.5285, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.110670 (avg: 0.110670) \tsec/iter: 0.0578\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.439666 (avg: 0.198774) \tsec/iter: 0.0522\n",
      "Test set (epoch 383): Average loss: 0.6782, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.131349 (avg: 0.131349) \tsec/iter: 0.0698\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.136777 (avg: 0.177076) \tsec/iter: 0.0805\n",
      "Test set (epoch 384): Average loss: 0.5530, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.119306 (avg: 0.119306) \tsec/iter: 0.0578\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.284711 (avg: 0.176377) \tsec/iter: 0.0485\n",
      "Test set (epoch 385): Average loss: 0.7241, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.179040 (avg: 0.179040) \tsec/iter: 0.0529\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.166303 (avg: 0.164465) \tsec/iter: 0.0469\n",
      "Test set (epoch 386): Average loss: 0.5998, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.085759 (avg: 0.085759) \tsec/iter: 0.0499\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.185572 (avg: 0.155584) \tsec/iter: 0.0462\n",
      "Test set (epoch 387): Average loss: 0.5758, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.128861 (avg: 0.128861) \tsec/iter: 0.0598\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.175045 (avg: 0.178929) \tsec/iter: 0.0565\n",
      "Test set (epoch 388): Average loss: 0.6279, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.114337 (avg: 0.114337) \tsec/iter: 0.0539\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.134476 (avg: 0.236358) \tsec/iter: 0.0482\n",
      "Test set (epoch 389): Average loss: 0.7319, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.161909 (avg: 0.161909) \tsec/iter: 0.0618\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.170786 (avg: 0.169713) \tsec/iter: 0.0525\n",
      "Test set (epoch 390): Average loss: 0.4776, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.144618 (avg: 0.144618) \tsec/iter: 0.0449\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.090787 (avg: 0.149852) \tsec/iter: 0.0409\n",
      "Test set (epoch 391): Average loss: 0.7105, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.236362 (avg: 0.236362) \tsec/iter: 0.0429\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.054323 (avg: 0.167410) \tsec/iter: 0.0412\n",
      "Test set (epoch 392): Average loss: 0.5132, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.178714 (avg: 0.178714) \tsec/iter: 0.0479\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.239529 (avg: 0.204325) \tsec/iter: 0.0469\n",
      "Test set (epoch 393): Average loss: 0.6224, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.246749 (avg: 0.246749) \tsec/iter: 0.0489\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.249076 (avg: 0.215946) \tsec/iter: 0.0452\n",
      "Test set (epoch 394): Average loss: 0.6858, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.226652 (avg: 0.226652) \tsec/iter: 0.0439\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.127711 (avg: 0.204395) \tsec/iter: 0.0449\n",
      "Test set (epoch 395): Average loss: 0.6402, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.178248 (avg: 0.178248) \tsec/iter: 0.0429\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.137634 (avg: 0.172081) \tsec/iter: 0.0479\n",
      "Test set (epoch 396): Average loss: 0.5701, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.117681 (avg: 0.117681) \tsec/iter: 0.0519\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.198179 (avg: 0.157505) \tsec/iter: 0.0449\n",
      "Test set (epoch 397): Average loss: 0.6078, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.204539 (avg: 0.204539) \tsec/iter: 0.0449\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.212683 (avg: 0.187846) \tsec/iter: 0.0432\n",
      "Test set (epoch 398): Average loss: 0.4943, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.167703 (avg: 0.167703) \tsec/iter: 0.0469\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.095957 (avg: 0.161148) \tsec/iter: 0.0455\n",
      "Test set (epoch 399): Average loss: 0.5238, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.132941 (avg: 0.132941) \tsec/iter: 0.0549\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.136482 (avg: 0.152669) \tsec/iter: 0.0465\n",
      "Test set (epoch 400): Average loss: 0.4519, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.076944 (avg: 0.076944) \tsec/iter: 0.0479\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.249125 (avg: 0.167835) \tsec/iter: 0.0455\n",
      "Test set (epoch 401): Average loss: 0.5688, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.090282 (avg: 0.090282) \tsec/iter: 0.0419\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.176722 (avg: 0.144292) \tsec/iter: 0.0422\n",
      "Test set (epoch 402): Average loss: 0.4735, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.159688 (avg: 0.159688) \tsec/iter: 0.0509\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.143773 (avg: 0.167765) \tsec/iter: 0.0485\n",
      "Test set (epoch 403): Average loss: 0.4865, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.139280 (avg: 0.139280) \tsec/iter: 0.0519\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.115177 (avg: 0.147226) \tsec/iter: 0.0469\n",
      "Test set (epoch 404): Average loss: 0.6344, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.209838 (avg: 0.209838) \tsec/iter: 0.0588\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.099133 (avg: 0.165387) \tsec/iter: 0.0535\n",
      "Test set (epoch 405): Average loss: 0.5724, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.138716 (avg: 0.138716) \tsec/iter: 0.0608\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.125325 (avg: 0.162475) \tsec/iter: 0.0635\n",
      "Test set (epoch 406): Average loss: 0.7177, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.091367 (avg: 0.091367) \tsec/iter: 0.0479\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.191172 (avg: 0.116510) \tsec/iter: 0.0412\n",
      "Test set (epoch 407): Average loss: 0.7249, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.168963 (avg: 0.168963) \tsec/iter: 0.0449\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.166417 (avg: 0.168813) \tsec/iter: 0.0419\n",
      "Test set (epoch 408): Average loss: 0.3988, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.122471 (avg: 0.122471) \tsec/iter: 0.0519\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.181986 (avg: 0.179474) \tsec/iter: 0.0562\n",
      "Test set (epoch 409): Average loss: 0.7925, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.126749 (avg: 0.126749) \tsec/iter: 0.0888\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.057773 (avg: 0.166195) \tsec/iter: 0.0605\n",
      "Test set (epoch 410): Average loss: 0.6264, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.137973 (avg: 0.137973) \tsec/iter: 0.0519\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.165311 (avg: 0.147993) \tsec/iter: 0.0495\n",
      "Test set (epoch 411): Average loss: 0.5599, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.159086 (avg: 0.159086) \tsec/iter: 0.0529\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.144172 (avg: 0.142028) \tsec/iter: 0.0459\n",
      "Test set (epoch 412): Average loss: 0.6599, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.121311 (avg: 0.121311) \tsec/iter: 0.0559\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.190331 (avg: 0.155548) \tsec/iter: 0.0545\n",
      "Test set (epoch 413): Average loss: 0.5701, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.150273 (avg: 0.150273) \tsec/iter: 0.0449\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.199276 (avg: 0.160105) \tsec/iter: 0.0392\n",
      "Test set (epoch 414): Average loss: 0.6773, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.142838 (avg: 0.142838) \tsec/iter: 0.0439\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.126722 (avg: 0.188967) \tsec/iter: 0.0432\n",
      "Test set (epoch 415): Average loss: 0.8207, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.235724 (avg: 0.235724) \tsec/iter: 0.0499\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.614239 (avg: 0.285573) \tsec/iter: 0.0465\n",
      "Test set (epoch 416): Average loss: 0.7726, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.157313 (avg: 0.157313) \tsec/iter: 0.0439\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.333628 (avg: 0.203031) \tsec/iter: 0.0399\n",
      "Test set (epoch 417): Average loss: 0.5073, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.219937 (avg: 0.219937) \tsec/iter: 0.0409\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.061536 (avg: 0.179090) \tsec/iter: 0.0376\n",
      "Test set (epoch 418): Average loss: 0.6760, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.200436 (avg: 0.200436) \tsec/iter: 0.0389\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.144263 (avg: 0.187945) \tsec/iter: 0.0366\n",
      "Test set (epoch 419): Average loss: 0.6275, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.107656 (avg: 0.107656) \tsec/iter: 0.0389\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.232064 (avg: 0.149564) \tsec/iter: 0.0379\n",
      "Test set (epoch 420): Average loss: 0.6506, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.269057 (avg: 0.269057) \tsec/iter: 0.0439\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.178495 (avg: 0.205125) \tsec/iter: 0.0416\n",
      "Test set (epoch 421): Average loss: 0.6476, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.142564 (avg: 0.142564) \tsec/iter: 0.0479\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.205002 (avg: 0.155834) \tsec/iter: 0.0389\n",
      "Test set (epoch 422): Average loss: 0.4452, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.177159 (avg: 0.177159) \tsec/iter: 0.0479\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.143682 (avg: 0.212222) \tsec/iter: 0.0452\n",
      "Test set (epoch 423): Average loss: 0.6625, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.182369 (avg: 0.182369) \tsec/iter: 0.0668\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.089568 (avg: 0.179384) \tsec/iter: 0.0489\n",
      "Test set (epoch 424): Average loss: 0.5570, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.153427 (avg: 0.153427) \tsec/iter: 0.0349\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.200201 (avg: 0.187400) \tsec/iter: 0.0326\n",
      "Test set (epoch 425): Average loss: 0.6642, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.135153 (avg: 0.135153) \tsec/iter: 0.0349\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.054259 (avg: 0.143455) \tsec/iter: 0.0342\n",
      "Test set (epoch 426): Average loss: 0.5572, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.119506 (avg: 0.119506) \tsec/iter: 0.0359\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.191203 (avg: 0.168897) \tsec/iter: 0.0309\n",
      "Test set (epoch 427): Average loss: 0.6613, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.129009 (avg: 0.129009) \tsec/iter: 0.0339\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.204205 (avg: 0.145885) \tsec/iter: 0.0312\n",
      "Test set (epoch 428): Average loss: 0.6006, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.144332 (avg: 0.144332) \tsec/iter: 0.0299\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.143117 (avg: 0.153383) \tsec/iter: 0.0286\n",
      "Test set (epoch 429): Average loss: 0.6993, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.117093 (avg: 0.117093) \tsec/iter: 0.0299\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.104537 (avg: 0.138101) \tsec/iter: 0.0306\n",
      "Test set (epoch 430): Average loss: 0.5528, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.261481 (avg: 0.261481) \tsec/iter: 0.0339\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.094159 (avg: 0.177909) \tsec/iter: 0.0313\n",
      "Test set (epoch 431): Average loss: 0.6520, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.079272 (avg: 0.079272) \tsec/iter: 0.0339\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.406411 (avg: 0.246728) \tsec/iter: 0.0336\n",
      "Test set (epoch 432): Average loss: 0.6261, Accuracy: 14/18 (77.78%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.154638 (avg: 0.154638) \tsec/iter: 0.0419\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.213202 (avg: 0.190764) \tsec/iter: 0.0362\n",
      "Test set (epoch 433): Average loss: 0.5313, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.245937 (avg: 0.245937) \tsec/iter: 0.0359\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.107513 (avg: 0.186055) \tsec/iter: 0.0306\n",
      "Test set (epoch 434): Average loss: 0.6017, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.179824 (avg: 0.179824) \tsec/iter: 0.0339\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.374856 (avg: 0.213937) \tsec/iter: 0.0312\n",
      "Test set (epoch 435): Average loss: 0.6564, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.136191 (avg: 0.136191) \tsec/iter: 0.0349\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.159636 (avg: 0.160113) \tsec/iter: 0.0312\n",
      "Test set (epoch 436): Average loss: 0.4679, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.102644 (avg: 0.102644) \tsec/iter: 0.0359\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.255671 (avg: 0.157772) \tsec/iter: 0.0346\n",
      "Test set (epoch 437): Average loss: 0.6339, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.205223 (avg: 0.205223) \tsec/iter: 0.0319\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.262417 (avg: 0.180428) \tsec/iter: 0.0303\n",
      "Test set (epoch 438): Average loss: 0.7043, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.200810 (avg: 0.200810) \tsec/iter: 0.0319\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.125894 (avg: 0.155917) \tsec/iter: 0.0306\n",
      "Test set (epoch 439): Average loss: 0.4045, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.100762 (avg: 0.100762) \tsec/iter: 0.0359\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.109803 (avg: 0.200489) \tsec/iter: 0.0319\n",
      "Test set (epoch 440): Average loss: 0.6729, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.130979 (avg: 0.130979) \tsec/iter: 0.0339\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.073425 (avg: 0.128178) \tsec/iter: 0.0312\n",
      "Test set (epoch 441): Average loss: 0.5361, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.074748 (avg: 0.074748) \tsec/iter: 0.0369\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.251298 (avg: 0.147825) \tsec/iter: 0.0352\n",
      "Test set (epoch 442): Average loss: 0.6115, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.159133 (avg: 0.159133) \tsec/iter: 0.0359\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.293730 (avg: 0.184062) \tsec/iter: 0.0309\n",
      "Test set (epoch 443): Average loss: 0.6330, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.212966 (avg: 0.212966) \tsec/iter: 0.0399\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.102022 (avg: 0.153445) \tsec/iter: 0.0326\n",
      "Test set (epoch 444): Average loss: 0.5592, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.155396 (avg: 0.155396) \tsec/iter: 0.0339\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.120068 (avg: 0.169265) \tsec/iter: 0.0303\n",
      "Test set (epoch 445): Average loss: 0.5464, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.171725 (avg: 0.171725) \tsec/iter: 0.0359\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.191436 (avg: 0.154090) \tsec/iter: 0.0306\n",
      "Test set (epoch 446): Average loss: 0.5983, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.125880 (avg: 0.125880) \tsec/iter: 0.0319\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.104710 (avg: 0.151639) \tsec/iter: 0.0326\n",
      "Test set (epoch 447): Average loss: 0.5503, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.186660 (avg: 0.186660) \tsec/iter: 0.0359\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.045682 (avg: 0.129793) \tsec/iter: 0.0322\n",
      "Test set (epoch 448): Average loss: 0.4873, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.136763 (avg: 0.136763) \tsec/iter: 0.0359\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.136222 (avg: 0.171209) \tsec/iter: 0.0319\n",
      "Test set (epoch 449): Average loss: 0.6754, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.114517 (avg: 0.114517) \tsec/iter: 0.0329\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.140943 (avg: 0.151231) \tsec/iter: 0.0319\n",
      "Test set (epoch 450): Average loss: 0.6558, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.112164 (avg: 0.112164) \tsec/iter: 0.0389\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.168489 (avg: 0.147225) \tsec/iter: 0.0372\n",
      "Test set (epoch 451): Average loss: 0.5880, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.119002 (avg: 0.119002) \tsec/iter: 0.0568\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.104587 (avg: 0.125525) \tsec/iter: 0.0475\n",
      "Test set (epoch 452): Average loss: 0.6724, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.170252 (avg: 0.170252) \tsec/iter: 0.0489\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.092922 (avg: 0.112908) \tsec/iter: 0.0445\n",
      "Test set (epoch 453): Average loss: 0.5711, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.127808 (avg: 0.127808) \tsec/iter: 0.0429\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.116184 (avg: 0.147479) \tsec/iter: 0.0339\n",
      "Test set (epoch 454): Average loss: 0.5394, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.080846 (avg: 0.080846) \tsec/iter: 0.0379\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.145959 (avg: 0.153639) \tsec/iter: 0.0316\n",
      "Test set (epoch 455): Average loss: 0.5883, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.171011 (avg: 0.171011) \tsec/iter: 0.0349\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.192037 (avg: 0.162429) \tsec/iter: 0.0339\n",
      "Test set (epoch 456): Average loss: 0.6119, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.147436 (avg: 0.147436) \tsec/iter: 0.0439\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.184768 (avg: 0.161652) \tsec/iter: 0.0396\n",
      "Test set (epoch 457): Average loss: 0.7346, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.252834 (avg: 0.252834) \tsec/iter: 0.0479\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.090298 (avg: 0.164114) \tsec/iter: 0.0386\n",
      "Test set (epoch 458): Average loss: 0.5753, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.152976 (avg: 0.152976) \tsec/iter: 0.0359\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.136843 (avg: 0.196653) \tsec/iter: 0.0359\n",
      "Test set (epoch 459): Average loss: 0.5109, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.188444 (avg: 0.188444) \tsec/iter: 0.0379\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.188012 (avg: 0.176182) \tsec/iter: 0.0342\n",
      "Test set (epoch 460): Average loss: 0.5793, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.246432 (avg: 0.246432) \tsec/iter: 0.0349\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.276309 (avg: 0.211546) \tsec/iter: 0.0316\n",
      "Test set (epoch 461): Average loss: 0.4906, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.227303 (avg: 0.227303) \tsec/iter: 0.0349\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.223619 (avg: 0.164511) \tsec/iter: 0.0352\n",
      "Test set (epoch 462): Average loss: 0.4739, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.158478 (avg: 0.158478) \tsec/iter: 0.0389\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.159841 (avg: 0.165643) \tsec/iter: 0.0342\n",
      "Test set (epoch 463): Average loss: 0.4653, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.190986 (avg: 0.190986) \tsec/iter: 0.0369\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.107837 (avg: 0.155410) \tsec/iter: 0.0322\n",
      "Test set (epoch 464): Average loss: 0.4943, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.151938 (avg: 0.151938) \tsec/iter: 0.0349\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.340727 (avg: 0.192798) \tsec/iter: 0.0312\n",
      "Test set (epoch 465): Average loss: 0.5373, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.325948 (avg: 0.325948) \tsec/iter: 0.0349\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.163139 (avg: 0.180006) \tsec/iter: 0.0309\n",
      "Test set (epoch 466): Average loss: 0.4962, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.170492 (avg: 0.170492) \tsec/iter: 0.0339\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.196411 (avg: 0.180410) \tsec/iter: 0.0366\n",
      "Test set (epoch 467): Average loss: 0.5900, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.138550 (avg: 0.138550) \tsec/iter: 0.0339\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.169006 (avg: 0.180057) \tsec/iter: 0.0346\n",
      "Test set (epoch 468): Average loss: 0.6653, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.141540 (avg: 0.141540) \tsec/iter: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.180035 (avg: 0.153979) \tsec/iter: 0.0386\n",
      "Test set (epoch 469): Average loss: 0.4961, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.098755 (avg: 0.098755) \tsec/iter: 0.0309\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.098568 (avg: 0.131967) \tsec/iter: 0.0346\n",
      "Test set (epoch 470): Average loss: 0.5273, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.174180 (avg: 0.174180) \tsec/iter: 0.0459\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.090784 (avg: 0.135719) \tsec/iter: 0.0422\n",
      "Test set (epoch 471): Average loss: 0.4040, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.178607 (avg: 0.178607) \tsec/iter: 0.0479\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.215793 (avg: 0.197444) \tsec/iter: 0.0409\n",
      "Test set (epoch 472): Average loss: 0.5107, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.118485 (avg: 0.118485) \tsec/iter: 0.0339\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.086711 (avg: 0.118647) \tsec/iter: 0.0329\n",
      "Test set (epoch 473): Average loss: 0.5741, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.138423 (avg: 0.138423) \tsec/iter: 0.0359\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.255940 (avg: 0.183116) \tsec/iter: 0.0332\n",
      "Test set (epoch 474): Average loss: 0.5086, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.149307 (avg: 0.149307) \tsec/iter: 0.0399\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.179253 (avg: 0.148800) \tsec/iter: 0.0339\n",
      "Test set (epoch 475): Average loss: 0.6702, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.187143 (avg: 0.187143) \tsec/iter: 0.0349\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.312498 (avg: 0.211948) \tsec/iter: 0.0309\n",
      "Test set (epoch 476): Average loss: 0.7154, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.223941 (avg: 0.223941) \tsec/iter: 0.0419\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.359079 (avg: 0.260253) \tsec/iter: 0.0386\n",
      "Test set (epoch 477): Average loss: 0.5571, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.109735 (avg: 0.109735) \tsec/iter: 0.0389\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.216672 (avg: 0.161909) \tsec/iter: 0.0332\n",
      "Test set (epoch 478): Average loss: 0.5310, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.303903 (avg: 0.303903) \tsec/iter: 0.0389\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.118656 (avg: 0.177191) \tsec/iter: 0.0336\n",
      "Test set (epoch 479): Average loss: 0.6844, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.113417 (avg: 0.113417) \tsec/iter: 0.0349\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.283971 (avg: 0.188448) \tsec/iter: 0.0303\n",
      "Test set (epoch 480): Average loss: 0.8706, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.222561 (avg: 0.222561) \tsec/iter: 0.0329\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.098299 (avg: 0.150362) \tsec/iter: 0.0329\n",
      "Test set (epoch 481): Average loss: 0.4678, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.196324 (avg: 0.196324) \tsec/iter: 0.0369\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.192906 (avg: 0.170515) \tsec/iter: 0.0319\n",
      "Test set (epoch 482): Average loss: 0.4727, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.209833 (avg: 0.209833) \tsec/iter: 0.0339\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.162915 (avg: 0.166570) \tsec/iter: 0.0312\n",
      "Test set (epoch 483): Average loss: 0.5603, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.200461 (avg: 0.200461) \tsec/iter: 0.0339\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.086909 (avg: 0.187572) \tsec/iter: 0.0316\n",
      "Test set (epoch 484): Average loss: 0.6300, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.155198 (avg: 0.155198) \tsec/iter: 0.0369\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.120564 (avg: 0.136225) \tsec/iter: 0.0319\n",
      "Test set (epoch 485): Average loss: 0.6768, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.203630 (avg: 0.203630) \tsec/iter: 0.0339\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.126992 (avg: 0.155014) \tsec/iter: 0.0336\n",
      "Test set (epoch 486): Average loss: 0.5779, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.148966 (avg: 0.148966) \tsec/iter: 0.0429\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.233344 (avg: 0.158043) \tsec/iter: 0.0386\n",
      "Test set (epoch 487): Average loss: 0.7015, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.273798 (avg: 0.273798) \tsec/iter: 0.0389\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.086441 (avg: 0.191905) \tsec/iter: 0.0342\n",
      "Test set (epoch 488): Average loss: 0.5074, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.121685 (avg: 0.121685) \tsec/iter: 0.0369\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.195980 (avg: 0.135208) \tsec/iter: 0.0329\n",
      "Test set (epoch 489): Average loss: 0.5059, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.098753 (avg: 0.098753) \tsec/iter: 0.0339\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.161539 (avg: 0.134809) \tsec/iter: 0.0316\n",
      "Test set (epoch 490): Average loss: 0.8007, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.260142 (avg: 0.260142) \tsec/iter: 0.0309\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.167377 (avg: 0.176337) \tsec/iter: 0.0303\n",
      "Test set (epoch 491): Average loss: 0.5014, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.159692 (avg: 0.159692) \tsec/iter: 0.0359\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.123460 (avg: 0.147470) \tsec/iter: 0.0329\n",
      "Test set (epoch 492): Average loss: 0.6201, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.221300 (avg: 0.221300) \tsec/iter: 0.0359\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.124873 (avg: 0.193344) \tsec/iter: 0.0316\n",
      "Test set (epoch 493): Average loss: 0.6000, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.156814 (avg: 0.156814) \tsec/iter: 0.0349\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.104566 (avg: 0.140609) \tsec/iter: 0.0322\n",
      "Test set (epoch 494): Average loss: 0.6219, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.071226 (avg: 0.071226) \tsec/iter: 0.0379\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.212226 (avg: 0.154991) \tsec/iter: 0.0362\n",
      "Test set (epoch 495): Average loss: 0.6607, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.091248 (avg: 0.091248) \tsec/iter: 0.0539\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.162237 (avg: 0.153147) \tsec/iter: 0.0479\n",
      "Test set (epoch 496): Average loss: 0.6502, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.138830 (avg: 0.138830) \tsec/iter: 0.0489\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.176000 (avg: 0.145698) \tsec/iter: 0.0465\n",
      "Test set (epoch 497): Average loss: 0.5510, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.136585 (avg: 0.136585) \tsec/iter: 0.0469\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.194900 (avg: 0.129576) \tsec/iter: 0.0426\n",
      "Test set (epoch 498): Average loss: 0.7094, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.169810 (avg: 0.169810) \tsec/iter: 0.0379\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.107005 (avg: 0.185160) \tsec/iter: 0.0372\n",
      "Test set (epoch 499): Average loss: 0.6729, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "\n",
      "FOLD 7\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.072099 (avg: 1.072099) \tsec/iter: 0.0439\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 1.598331 (avg: 2.217561) \tsec/iter: 0.0366\n",
      "Test set (epoch 0): Average loss: 1.4118, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 0.524727 (avg: 0.524727) \tsec/iter: 0.0369\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.851801 (avg: 1.072866) \tsec/iter: 0.0316\n",
      "Test set (epoch 1): Average loss: 0.6405, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.462189 (avg: 0.462189) \tsec/iter: 0.0329\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 0.541549 (avg: 0.563569) \tsec/iter: 0.0296\n",
      "Test set (epoch 2): Average loss: 0.9049, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.561003 (avg: 0.561003) \tsec/iter: 0.0339\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 1.915521 (avg: 1.078297) \tsec/iter: 0.0349\n",
      "Test set (epoch 3): Average loss: 0.5988, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.975242 (avg: 0.975242) \tsec/iter: 0.0419\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.486626 (avg: 0.771189) \tsec/iter: 0.0379\n",
      "Test set (epoch 4): Average loss: 1.2455, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.298796 (avg: 0.298796) \tsec/iter: 0.0369\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.351107 (avg: 0.363337) \tsec/iter: 0.0362\n",
      "Test set (epoch 5): Average loss: 1.6714, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.463782 (avg: 0.463782) \tsec/iter: 0.0469\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.381979 (avg: 0.400307) \tsec/iter: 0.0422\n",
      "Test set (epoch 6): Average loss: 1.4408, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.418975 (avg: 0.418975) \tsec/iter: 0.0439\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.459263 (avg: 0.424198) \tsec/iter: 0.0366\n",
      "Test set (epoch 7): Average loss: 1.1804, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.559546 (avg: 0.559546) \tsec/iter: 0.0329\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.364390 (avg: 0.457228) \tsec/iter: 0.0296\n",
      "Test set (epoch 8): Average loss: 1.4433, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.457812 (avg: 0.457812) \tsec/iter: 0.0329\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.335492 (avg: 0.433662) \tsec/iter: 0.0309\n",
      "Test set (epoch 9): Average loss: 1.4968, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.428200 (avg: 0.428200) \tsec/iter: 0.0369\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.455559 (avg: 0.397024) \tsec/iter: 0.0339\n",
      "Test set (epoch 10): Average loss: 1.7057, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.331112 (avg: 0.331112) \tsec/iter: 0.0369\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.405587 (avg: 0.441523) \tsec/iter: 0.0316\n",
      "Test set (epoch 11): Average loss: 1.3570, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.540446 (avg: 0.540446) \tsec/iter: 0.0429\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.682326 (avg: 0.532678) \tsec/iter: 0.0376\n",
      "Test set (epoch 12): Average loss: 2.0833, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.425444 (avg: 0.425444) \tsec/iter: 0.0389\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.577255 (avg: 0.439275) \tsec/iter: 0.0369\n",
      "Test set (epoch 13): Average loss: 1.4818, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.392841 (avg: 0.392841) \tsec/iter: 0.0349\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.555528 (avg: 0.526354) \tsec/iter: 0.0299\n",
      "Test set (epoch 14): Average loss: 1.2166, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.429765 (avg: 0.429765) \tsec/iter: 0.0329\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.407245 (avg: 0.442901) \tsec/iter: 0.0319\n",
      "Test set (epoch 15): Average loss: 0.8712, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.586271 (avg: 0.586271) \tsec/iter: 0.0349\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.299307 (avg: 0.412082) \tsec/iter: 0.0326\n",
      "Test set (epoch 16): Average loss: 1.3700, Accuracy: 5/18 (27.78%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.372319 (avg: 0.372319) \tsec/iter: 0.0379\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.335394 (avg: 0.369199) \tsec/iter: 0.0312\n",
      "Test set (epoch 17): Average loss: 1.3515, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.427373 (avg: 0.427373) \tsec/iter: 0.0349\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.343413 (avg: 0.413877) \tsec/iter: 0.0306\n",
      "Test set (epoch 18): Average loss: 0.6977, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.445427 (avg: 0.445427) \tsec/iter: 0.0329\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.301039 (avg: 0.383963) \tsec/iter: 0.0293\n",
      "Test set (epoch 19): Average loss: 1.2028, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.316055 (avg: 0.316055) \tsec/iter: 0.0339\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.559144 (avg: 0.398341) \tsec/iter: 0.0296\n",
      "Test set (epoch 20): Average loss: 1.0277, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.252203 (avg: 0.252203) \tsec/iter: 0.0339\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.450690 (avg: 0.377158) \tsec/iter: 0.0332\n",
      "Test set (epoch 21): Average loss: 1.1073, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.363501 (avg: 0.363501) \tsec/iter: 0.0399\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.322311 (avg: 0.361612) \tsec/iter: 0.0366\n",
      "Test set (epoch 22): Average loss: 1.1312, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.341185 (avg: 0.341185) \tsec/iter: 0.0359\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.395051 (avg: 0.342956) \tsec/iter: 0.0312\n",
      "Test set (epoch 23): Average loss: 1.0172, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.410879 (avg: 0.410879) \tsec/iter: 0.0319\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.301378 (avg: 0.354347) \tsec/iter: 0.0316\n",
      "Test set (epoch 24): Average loss: 1.1027, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.420644 (avg: 0.420644) \tsec/iter: 0.0399\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.344141 (avg: 0.373027) \tsec/iter: 0.0356\n",
      "Test set (epoch 25): Average loss: 0.9562, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.345384 (avg: 0.345384) \tsec/iter: 0.0349\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.420000 (avg: 0.368586) \tsec/iter: 0.0332\n",
      "Test set (epoch 26): Average loss: 1.1709, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.264136 (avg: 0.264136) \tsec/iter: 0.0339\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.563471 (avg: 0.371579) \tsec/iter: 0.0306\n",
      "Test set (epoch 27): Average loss: 1.3143, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.455468 (avg: 0.455468) \tsec/iter: 0.0389\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.428818 (avg: 0.384313) \tsec/iter: 0.0316\n",
      "Test set (epoch 28): Average loss: 1.0527, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.334374 (avg: 0.334374) \tsec/iter: 0.0339\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.470921 (avg: 0.363828) \tsec/iter: 0.0299\n",
      "Test set (epoch 29): Average loss: 0.9859, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.328166 (avg: 0.328166) \tsec/iter: 0.0329\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.400423 (avg: 0.361755) \tsec/iter: 0.0316\n",
      "Test set (epoch 30): Average loss: 0.9784, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.383621 (avg: 0.383621) \tsec/iter: 0.0449\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.302672 (avg: 0.326940) \tsec/iter: 0.0389\n",
      "Test set (epoch 31): Average loss: 0.8721, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.347432 (avg: 0.347432) \tsec/iter: 0.0409\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.472416 (avg: 0.370602) \tsec/iter: 0.0346\n",
      "Test set (epoch 32): Average loss: 0.9236, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.373511 (avg: 0.373511) \tsec/iter: 0.0339\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.341210 (avg: 0.331690) \tsec/iter: 0.0336\n",
      "Test set (epoch 33): Average loss: 0.9422, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.369546 (avg: 0.369546) \tsec/iter: 0.0429\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.279948 (avg: 0.361064) \tsec/iter: 0.0419\n",
      "Test set (epoch 34): Average loss: 0.8854, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.305798 (avg: 0.305798) \tsec/iter: 0.0429\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.442401 (avg: 0.354947) \tsec/iter: 0.0406\n",
      "Test set (epoch 35): Average loss: 0.8214, Accuracy: 9/18 (50.00%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.300680 (avg: 0.300680) \tsec/iter: 0.0399\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.293545 (avg: 0.350818) \tsec/iter: 0.0356\n",
      "Test set (epoch 36): Average loss: 0.8897, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.284179 (avg: 0.284179) \tsec/iter: 0.0349\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.274893 (avg: 0.342942) \tsec/iter: 0.0296\n",
      "Test set (epoch 37): Average loss: 0.9078, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.435394 (avg: 0.435394) \tsec/iter: 0.0419\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.413724 (avg: 0.357934) \tsec/iter: 0.0332\n",
      "Test set (epoch 38): Average loss: 0.8130, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.269394 (avg: 0.269394) \tsec/iter: 0.0379\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.336870 (avg: 0.323831) \tsec/iter: 0.0432\n",
      "Test set (epoch 39): Average loss: 0.8338, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.297319 (avg: 0.297319) \tsec/iter: 0.0578\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.279595 (avg: 0.360521) \tsec/iter: 0.0499\n",
      "Test set (epoch 40): Average loss: 0.9323, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.292879 (avg: 0.292879) \tsec/iter: 0.0409\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.452106 (avg: 0.327693) \tsec/iter: 0.0356\n",
      "Test set (epoch 41): Average loss: 0.8655, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.362919 (avg: 0.362919) \tsec/iter: 0.0339\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.486140 (avg: 0.366540) \tsec/iter: 0.0322\n",
      "Test set (epoch 42): Average loss: 0.8972, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.284283 (avg: 0.284283) \tsec/iter: 0.0369\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.456142 (avg: 0.327978) \tsec/iter: 0.0389\n",
      "Test set (epoch 43): Average loss: 0.9051, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.228371 (avg: 0.228371) \tsec/iter: 0.0449\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.273881 (avg: 0.323283) \tsec/iter: 0.0419\n",
      "Test set (epoch 44): Average loss: 0.8864, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.358519 (avg: 0.358519) \tsec/iter: 0.0349\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.296757 (avg: 0.316659) \tsec/iter: 0.0346\n",
      "Test set (epoch 45): Average loss: 0.7992, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.357317 (avg: 0.357317) \tsec/iter: 0.0339\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.383055 (avg: 0.352166) \tsec/iter: 0.0303\n",
      "Test set (epoch 46): Average loss: 0.8395, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.358542 (avg: 0.358542) \tsec/iter: 0.0309\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.339480 (avg: 0.352729) \tsec/iter: 0.0303\n",
      "Test set (epoch 47): Average loss: 0.7497, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.330831 (avg: 0.330831) \tsec/iter: 0.0419\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.343640 (avg: 0.327342) \tsec/iter: 0.0379\n",
      "Test set (epoch 48): Average loss: 0.8339, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.384551 (avg: 0.384551) \tsec/iter: 0.0349\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.201787 (avg: 0.322348) \tsec/iter: 0.0326\n",
      "Test set (epoch 49): Average loss: 0.8027, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.246863 (avg: 0.246863) \tsec/iter: 0.0409\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.440975 (avg: 0.326140) \tsec/iter: 0.0326\n",
      "Test set (epoch 50): Average loss: 0.7772, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.319372 (avg: 0.319372) \tsec/iter: 0.0329\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.297083 (avg: 0.325233) \tsec/iter: 0.0293\n",
      "Test set (epoch 51): Average loss: 0.7553, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.254957 (avg: 0.254957) \tsec/iter: 0.0329\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.280631 (avg: 0.327820) \tsec/iter: 0.0306\n",
      "Test set (epoch 52): Average loss: 0.7769, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.259077 (avg: 0.259077) \tsec/iter: 0.0369\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.454698 (avg: 0.319559) \tsec/iter: 0.0352\n",
      "Test set (epoch 53): Average loss: 0.8194, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.331793 (avg: 0.331793) \tsec/iter: 0.0339\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.259511 (avg: 0.330428) \tsec/iter: 0.0309\n",
      "Test set (epoch 54): Average loss: 0.7965, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.220793 (avg: 0.220793) \tsec/iter: 0.0319\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.252439 (avg: 0.286151) \tsec/iter: 0.0316\n",
      "Test set (epoch 55): Average loss: 0.8343, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.349787 (avg: 0.349787) \tsec/iter: 0.0339\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.342830 (avg: 0.309897) \tsec/iter: 0.0296\n",
      "Test set (epoch 56): Average loss: 0.6836, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.435608 (avg: 0.435608) \tsec/iter: 0.0349\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.254282 (avg: 0.353318) \tsec/iter: 0.0349\n",
      "Test set (epoch 57): Average loss: 0.7815, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.282235 (avg: 0.282235) \tsec/iter: 0.0389\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.291784 (avg: 0.340702) \tsec/iter: 0.0359\n",
      "Test set (epoch 58): Average loss: 0.8574, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.240947 (avg: 0.240947) \tsec/iter: 0.0389\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.415398 (avg: 0.332246) \tsec/iter: 0.0329\n",
      "Test set (epoch 59): Average loss: 0.9030, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.346428 (avg: 0.346428) \tsec/iter: 0.0329\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.442166 (avg: 0.342881) \tsec/iter: 0.0299\n",
      "Test set (epoch 60): Average loss: 0.6470, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.409974 (avg: 0.409974) \tsec/iter: 0.0309\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.271520 (avg: 0.339923) \tsec/iter: 0.0319\n",
      "Test set (epoch 61): Average loss: 0.7803, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.264377 (avg: 0.264377) \tsec/iter: 0.0309\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.303946 (avg: 0.310750) \tsec/iter: 0.0303\n",
      "Test set (epoch 62): Average loss: 0.8507, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.294717 (avg: 0.294717) \tsec/iter: 0.0389\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.500737 (avg: 0.326193) \tsec/iter: 0.0356\n",
      "Test set (epoch 63): Average loss: 0.6939, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.310896 (avg: 0.310896) \tsec/iter: 0.0339\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.170518 (avg: 0.309452) \tsec/iter: 0.0296\n",
      "Test set (epoch 64): Average loss: 0.6393, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.317972 (avg: 0.317972) \tsec/iter: 0.0379\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.231834 (avg: 0.323826) \tsec/iter: 0.0312\n",
      "Test set (epoch 65): Average loss: 0.7135, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.304430 (avg: 0.304430) \tsec/iter: 0.0339\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.309887 (avg: 0.330021) \tsec/iter: 0.0326\n",
      "Test set (epoch 66): Average loss: 0.7189, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.314075 (avg: 0.314075) \tsec/iter: 0.0429\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.383537 (avg: 0.315254) \tsec/iter: 0.0359\n",
      "Test set (epoch 67): Average loss: 0.7174, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.396141 (avg: 0.396141) \tsec/iter: 0.0379\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.360690 (avg: 0.330644) \tsec/iter: 0.0349\n",
      "Test set (epoch 68): Average loss: 0.7087, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.306577 (avg: 0.306577) \tsec/iter: 0.0329\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.407168 (avg: 0.342998) \tsec/iter: 0.0289\n",
      "Test set (epoch 69): Average loss: 0.6723, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.305518 (avg: 0.305518) \tsec/iter: 0.0309\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.170264 (avg: 0.295153) \tsec/iter: 0.0293\n",
      "Test set (epoch 70): Average loss: 0.6803, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.406038 (avg: 0.406038) \tsec/iter: 0.0349\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.198851 (avg: 0.284681) \tsec/iter: 0.0299\n",
      "Test set (epoch 71): Average loss: 0.6931, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.288761 (avg: 0.288761) \tsec/iter: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.391898 (avg: 0.299091) \tsec/iter: 0.0342\n",
      "Test set (epoch 72): Average loss: 0.6689, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.304428 (avg: 0.304428) \tsec/iter: 0.0339\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.327599 (avg: 0.289294) \tsec/iter: 0.0296\n",
      "Test set (epoch 73): Average loss: 0.6979, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.385371 (avg: 0.385371) \tsec/iter: 0.0319\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.362162 (avg: 0.370322) \tsec/iter: 0.0296\n",
      "Test set (epoch 74): Average loss: 0.7811, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.299411 (avg: 0.299411) \tsec/iter: 0.0339\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.263202 (avg: 0.313578) \tsec/iter: 0.0293\n",
      "Test set (epoch 75): Average loss: 0.6906, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.238594 (avg: 0.238594) \tsec/iter: 0.0369\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.356903 (avg: 0.300678) \tsec/iter: 0.0379\n",
      "Test set (epoch 76): Average loss: 0.5539, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.223856 (avg: 0.223856) \tsec/iter: 0.0479\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.307901 (avg: 0.319079) \tsec/iter: 0.0389\n",
      "Test set (epoch 77): Average loss: 0.7767, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.322712 (avg: 0.322712) \tsec/iter: 0.0319\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.239543 (avg: 0.361550) \tsec/iter: 0.0322\n",
      "Test set (epoch 78): Average loss: 0.7709, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.275941 (avg: 0.275941) \tsec/iter: 0.0359\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.320433 (avg: 0.296314) \tsec/iter: 0.0332\n",
      "Test set (epoch 79): Average loss: 0.5268, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.211212 (avg: 0.211212) \tsec/iter: 0.0379\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.221502 (avg: 0.304380) \tsec/iter: 0.0303\n",
      "Test set (epoch 80): Average loss: 0.7648, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.363901 (avg: 0.363901) \tsec/iter: 0.0319\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.244257 (avg: 0.272014) \tsec/iter: 0.0306\n",
      "Test set (epoch 81): Average loss: 0.7412, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.330873 (avg: 0.330873) \tsec/iter: 0.0399\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.301447 (avg: 0.354650) \tsec/iter: 0.0329\n",
      "Test set (epoch 82): Average loss: 0.5264, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.340220 (avg: 0.340220) \tsec/iter: 0.0359\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.286633 (avg: 0.318683) \tsec/iter: 0.0309\n",
      "Test set (epoch 83): Average loss: 0.6375, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.274352 (avg: 0.274352) \tsec/iter: 0.0339\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.351309 (avg: 0.303371) \tsec/iter: 0.0299\n",
      "Test set (epoch 84): Average loss: 0.7682, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.255991 (avg: 0.255991) \tsec/iter: 0.0319\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.354302 (avg: 0.311572) \tsec/iter: 0.0319\n",
      "Test set (epoch 85): Average loss: 0.6423, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.340664 (avg: 0.340664) \tsec/iter: 0.0419\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.221307 (avg: 0.330611) \tsec/iter: 0.0379\n",
      "Test set (epoch 86): Average loss: 0.5605, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.260036 (avg: 0.260036) \tsec/iter: 0.0359\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.333403 (avg: 0.290943) \tsec/iter: 0.0306\n",
      "Test set (epoch 87): Average loss: 0.6769, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.387366 (avg: 0.387366) \tsec/iter: 0.0329\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.271168 (avg: 0.335875) \tsec/iter: 0.0303\n",
      "Test set (epoch 88): Average loss: 0.7793, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.332762 (avg: 0.332762) \tsec/iter: 0.0299\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.382591 (avg: 0.311854) \tsec/iter: 0.0303\n",
      "Test set (epoch 89): Average loss: 0.7431, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.293870 (avg: 0.293870) \tsec/iter: 0.0349\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.383315 (avg: 0.333043) \tsec/iter: 0.0336\n",
      "Test set (epoch 90): Average loss: 0.8579, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.328475 (avg: 0.328475) \tsec/iter: 0.0369\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.210309 (avg: 0.302710) \tsec/iter: 0.0332\n",
      "Test set (epoch 91): Average loss: 0.5649, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.249518 (avg: 0.249518) \tsec/iter: 0.0389\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.447212 (avg: 0.307102) \tsec/iter: 0.0326\n",
      "Test set (epoch 92): Average loss: 0.8046, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.353177 (avg: 0.353177) \tsec/iter: 0.0369\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.246278 (avg: 0.304059) \tsec/iter: 0.0316\n",
      "Test set (epoch 93): Average loss: 0.7102, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.368928 (avg: 0.368928) \tsec/iter: 0.0359\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.277749 (avg: 0.334595) \tsec/iter: 0.0306\n",
      "Test set (epoch 94): Average loss: 0.6116, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.365474 (avg: 0.365474) \tsec/iter: 0.0588\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.369694 (avg: 0.330848) \tsec/iter: 0.0519\n",
      "Test set (epoch 95): Average loss: 0.5149, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.415461 (avg: 0.415461) \tsec/iter: 0.0549\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.443216 (avg: 0.371480) \tsec/iter: 0.0432\n",
      "Test set (epoch 96): Average loss: 0.6530, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.376782 (avg: 0.376782) \tsec/iter: 0.0349\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.364273 (avg: 0.348359) \tsec/iter: 0.0322\n",
      "Test set (epoch 97): Average loss: 0.4788, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.262919 (avg: 0.262919) \tsec/iter: 0.0399\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.440796 (avg: 0.321233) \tsec/iter: 0.0329\n",
      "Test set (epoch 98): Average loss: 0.5843, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.274305 (avg: 0.274305) \tsec/iter: 0.0309\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.242330 (avg: 0.290382) \tsec/iter: 0.0296\n",
      "Test set (epoch 99): Average loss: 0.6926, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.285089 (avg: 0.285089) \tsec/iter: 0.0339\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.278757 (avg: 0.277327) \tsec/iter: 0.0309\n",
      "Test set (epoch 100): Average loss: 0.5627, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.324972 (avg: 0.324972) \tsec/iter: 0.0399\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.206576 (avg: 0.253720) \tsec/iter: 0.0376\n",
      "Test set (epoch 101): Average loss: 0.5199, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.276728 (avg: 0.276728) \tsec/iter: 0.0409\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.165970 (avg: 0.287435) \tsec/iter: 0.0369\n",
      "Test set (epoch 102): Average loss: 0.6771, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.328127 (avg: 0.328127) \tsec/iter: 0.0479\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.319115 (avg: 0.305301) \tsec/iter: 0.0422\n",
      "Test set (epoch 103): Average loss: 0.6404, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.387540 (avg: 0.387540) \tsec/iter: 0.0469\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.194432 (avg: 0.304396) \tsec/iter: 0.0396\n",
      "Test set (epoch 104): Average loss: 0.6232, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.220345 (avg: 0.220345) \tsec/iter: 0.0339\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.419220 (avg: 0.296605) \tsec/iter: 0.0322\n",
      "Test set (epoch 105): Average loss: 0.5670, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.274693 (avg: 0.274693) \tsec/iter: 0.0479\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.496331 (avg: 0.319782) \tsec/iter: 0.0439\n",
      "Test set (epoch 106): Average loss: 0.5885, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.347473 (avg: 0.347473) \tsec/iter: 0.0489\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.275039 (avg: 0.285596) \tsec/iter: 0.0426\n",
      "Test set (epoch 107): Average loss: 0.5302, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.287919 (avg: 0.287919) \tsec/iter: 0.0419\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.237039 (avg: 0.296811) \tsec/iter: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 108): Average loss: 0.5987, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.347768 (avg: 0.347768) \tsec/iter: 0.0369\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.200089 (avg: 0.284200) \tsec/iter: 0.0319\n",
      "Test set (epoch 109): Average loss: 0.5925, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.291980 (avg: 0.291980) \tsec/iter: 0.0309\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.280405 (avg: 0.295700) \tsec/iter: 0.0296\n",
      "Test set (epoch 110): Average loss: 0.6783, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.375116 (avg: 0.375116) \tsec/iter: 0.0349\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.239058 (avg: 0.277962) \tsec/iter: 0.0392\n",
      "Test set (epoch 111): Average loss: 0.6243, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.227995 (avg: 0.227995) \tsec/iter: 0.0489\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.292475 (avg: 0.270796) \tsec/iter: 0.0482\n",
      "Test set (epoch 112): Average loss: 0.7084, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.183649 (avg: 0.183649) \tsec/iter: 0.0449\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.348854 (avg: 0.296164) \tsec/iter: 0.0429\n",
      "Test set (epoch 113): Average loss: 0.7012, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.318372 (avg: 0.318372) \tsec/iter: 0.0449\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.275384 (avg: 0.290575) \tsec/iter: 0.0412\n",
      "Test set (epoch 114): Average loss: 0.5771, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.256537 (avg: 0.256537) \tsec/iter: 0.0429\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.281898 (avg: 0.317464) \tsec/iter: 0.0356\n",
      "Test set (epoch 115): Average loss: 0.5991, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.294890 (avg: 0.294890) \tsec/iter: 0.0349\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.282782 (avg: 0.271022) \tsec/iter: 0.0322\n",
      "Test set (epoch 116): Average loss: 0.5423, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.332609 (avg: 0.332609) \tsec/iter: 0.0349\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.238803 (avg: 0.285070) \tsec/iter: 0.0306\n",
      "Test set (epoch 117): Average loss: 0.5710, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.228642 (avg: 0.228642) \tsec/iter: 0.0349\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.237371 (avg: 0.275085) \tsec/iter: 0.0309\n",
      "Test set (epoch 118): Average loss: 0.5413, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.344530 (avg: 0.344530) \tsec/iter: 0.0349\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.217815 (avg: 0.283146) \tsec/iter: 0.0319\n",
      "Test set (epoch 119): Average loss: 0.6764, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.237642 (avg: 0.237642) \tsec/iter: 0.0409\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.152459 (avg: 0.262787) \tsec/iter: 0.0359\n",
      "Test set (epoch 120): Average loss: 0.6260, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.188160 (avg: 0.188160) \tsec/iter: 0.0379\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.476883 (avg: 0.305571) \tsec/iter: 0.0352\n",
      "Test set (epoch 121): Average loss: 0.4132, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.281828 (avg: 0.281828) \tsec/iter: 0.0349\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.257444 (avg: 0.325012) \tsec/iter: 0.0322\n",
      "Test set (epoch 122): Average loss: 0.6792, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.244722 (avg: 0.244722) \tsec/iter: 0.0329\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.371485 (avg: 0.305736) \tsec/iter: 0.0303\n",
      "Test set (epoch 123): Average loss: 0.4973, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.247478 (avg: 0.247478) \tsec/iter: 0.0429\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.388000 (avg: 0.272309) \tsec/iter: 0.0342\n",
      "Test set (epoch 124): Average loss: 0.5292, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.384330 (avg: 0.384330) \tsec/iter: 0.0369\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.291706 (avg: 0.321509) \tsec/iter: 0.0312\n",
      "Test set (epoch 125): Average loss: 0.4157, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.334225 (avg: 0.334225) \tsec/iter: 0.0359\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.304473 (avg: 0.291189) \tsec/iter: 0.0303\n",
      "Test set (epoch 126): Average loss: 0.5598, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.228118 (avg: 0.228118) \tsec/iter: 0.0359\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.392846 (avg: 0.302786) \tsec/iter: 0.0339\n",
      "Test set (epoch 127): Average loss: 0.5188, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.307278 (avg: 0.307278) \tsec/iter: 0.0319\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.287037 (avg: 0.298209) \tsec/iter: 0.0322\n",
      "Test set (epoch 128): Average loss: 0.5806, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.302884 (avg: 0.302884) \tsec/iter: 0.0419\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.307604 (avg: 0.291801) \tsec/iter: 0.0379\n",
      "Test set (epoch 129): Average loss: 0.5859, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.320518 (avg: 0.320518) \tsec/iter: 0.0389\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.309239 (avg: 0.276067) \tsec/iter: 0.0342\n",
      "Test set (epoch 130): Average loss: 0.5437, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.402521 (avg: 0.402521) \tsec/iter: 0.0299\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.292131 (avg: 0.328377) \tsec/iter: 0.0316\n",
      "Test set (epoch 131): Average loss: 0.5356, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.273007 (avg: 0.273007) \tsec/iter: 0.0339\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.196635 (avg: 0.272148) \tsec/iter: 0.0316\n",
      "Test set (epoch 132): Average loss: 0.5519, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.288587 (avg: 0.288587) \tsec/iter: 0.0389\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.262749 (avg: 0.259991) \tsec/iter: 0.0306\n",
      "Test set (epoch 133): Average loss: 0.5090, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.266017 (avg: 0.266017) \tsec/iter: 0.0339\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.298348 (avg: 0.276672) \tsec/iter: 0.0326\n",
      "Test set (epoch 134): Average loss: 0.5011, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.337024 (avg: 0.337024) \tsec/iter: 0.0339\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.287515 (avg: 0.332096) \tsec/iter: 0.0296\n",
      "Test set (epoch 135): Average loss: 0.4903, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.248127 (avg: 0.248127) \tsec/iter: 0.0299\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.345654 (avg: 0.266693) \tsec/iter: 0.0286\n",
      "Test set (epoch 136): Average loss: 0.6297, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.215493 (avg: 0.215493) \tsec/iter: 0.0359\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.231272 (avg: 0.233141) \tsec/iter: 0.0342\n",
      "Test set (epoch 137): Average loss: 0.5120, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.293181 (avg: 0.293181) \tsec/iter: 0.0349\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.215243 (avg: 0.236193) \tsec/iter: 0.0336\n",
      "Test set (epoch 138): Average loss: 0.6005, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.217730 (avg: 0.217730) \tsec/iter: 0.0409\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.386000 (avg: 0.311251) \tsec/iter: 0.0389\n",
      "Test set (epoch 139): Average loss: 0.6074, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.175899 (avg: 0.175899) \tsec/iter: 0.0329\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.338270 (avg: 0.255320) \tsec/iter: 0.0332\n",
      "Test set (epoch 140): Average loss: 0.8627, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.318742 (avg: 0.318742) \tsec/iter: 0.0329\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.272719 (avg: 0.289697) \tsec/iter: 0.0309\n",
      "Test set (epoch 141): Average loss: 0.4000, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.236134 (avg: 0.236134) \tsec/iter: 0.0319\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.488317 (avg: 0.286795) \tsec/iter: 0.0299\n",
      "Test set (epoch 142): Average loss: 0.5483, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.220890 (avg: 0.220890) \tsec/iter: 0.0349\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.322507 (avg: 0.267895) \tsec/iter: 0.0329\n",
      "Test set (epoch 143): Average loss: 0.5694, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.282001 (avg: 0.282001) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.250269 (avg: 0.240152) \tsec/iter: 0.0303\n",
      "Test set (epoch 144): Average loss: 0.4939, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.212514 (avg: 0.212514) \tsec/iter: 0.0379\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.223033 (avg: 0.245787) \tsec/iter: 0.0339\n",
      "Test set (epoch 145): Average loss: 0.4970, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.249569 (avg: 0.249569) \tsec/iter: 0.0329\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.176057 (avg: 0.252883) \tsec/iter: 0.0299\n",
      "Test set (epoch 146): Average loss: 0.5045, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.334441 (avg: 0.334441) \tsec/iter: 0.0349\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.174436 (avg: 0.256348) \tsec/iter: 0.0289\n",
      "Test set (epoch 147): Average loss: 0.5909, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.255346 (avg: 0.255346) \tsec/iter: 0.0379\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.279812 (avg: 0.244984) \tsec/iter: 0.0366\n",
      "Test set (epoch 148): Average loss: 0.6625, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.239753 (avg: 0.239753) \tsec/iter: 0.0389\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.313029 (avg: 0.240681) \tsec/iter: 0.0339\n",
      "Test set (epoch 149): Average loss: 0.4539, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.310049 (avg: 0.310049) \tsec/iter: 0.0339\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.249079 (avg: 0.302167) \tsec/iter: 0.0346\n",
      "Test set (epoch 150): Average loss: 0.7180, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.241100 (avg: 0.241100) \tsec/iter: 0.0379\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.261931 (avg: 0.250852) \tsec/iter: 0.0326\n",
      "Test set (epoch 151): Average loss: 0.4793, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.316013 (avg: 0.316013) \tsec/iter: 0.0339\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.202368 (avg: 0.279734) \tsec/iter: 0.0326\n",
      "Test set (epoch 152): Average loss: 0.4912, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.273241 (avg: 0.273241) \tsec/iter: 0.0349\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.240712 (avg: 0.249642) \tsec/iter: 0.0322\n",
      "Test set (epoch 153): Average loss: 0.6716, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.240820 (avg: 0.240820) \tsec/iter: 0.0289\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.199171 (avg: 0.233003) \tsec/iter: 0.0303\n",
      "Test set (epoch 154): Average loss: 0.4826, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.269642 (avg: 0.269642) \tsec/iter: 0.0309\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.270843 (avg: 0.276321) \tsec/iter: 0.0289\n",
      "Test set (epoch 155): Average loss: 0.6633, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.289835 (avg: 0.289835) \tsec/iter: 0.0329\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.286727 (avg: 0.264935) \tsec/iter: 0.0296\n",
      "Test set (epoch 156): Average loss: 0.5145, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.236104 (avg: 0.236104) \tsec/iter: 0.0399\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.269807 (avg: 0.243677) \tsec/iter: 0.0402\n",
      "Test set (epoch 157): Average loss: 0.5797, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.264053 (avg: 0.264053) \tsec/iter: 0.0608\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.292727 (avg: 0.250443) \tsec/iter: 0.0512\n",
      "Test set (epoch 158): Average loss: 0.5405, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.352696 (avg: 0.352696) \tsec/iter: 0.0419\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.259209 (avg: 0.289724) \tsec/iter: 0.0409\n",
      "Test set (epoch 159): Average loss: 0.5458, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.281752 (avg: 0.281752) \tsec/iter: 0.0698\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.287525 (avg: 0.269710) \tsec/iter: 0.0568\n",
      "Test set (epoch 160): Average loss: 0.5314, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.162753 (avg: 0.162753) \tsec/iter: 0.0549\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.414021 (avg: 0.254581) \tsec/iter: 0.0485\n",
      "Test set (epoch 161): Average loss: 0.5003, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.269924 (avg: 0.269924) \tsec/iter: 0.0529\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.236007 (avg: 0.247445) \tsec/iter: 0.0442\n",
      "Test set (epoch 162): Average loss: 0.6063, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.269334 (avg: 0.269334) \tsec/iter: 0.0499\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.258561 (avg: 0.262749) \tsec/iter: 0.0436\n",
      "Test set (epoch 163): Average loss: 0.4891, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.339721 (avg: 0.339721) \tsec/iter: 0.0539\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.240337 (avg: 0.310819) \tsec/iter: 0.0495\n",
      "Test set (epoch 164): Average loss: 0.5236, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.299247 (avg: 0.299247) \tsec/iter: 0.0549\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.273339 (avg: 0.255393) \tsec/iter: 0.0465\n",
      "Test set (epoch 165): Average loss: 0.4976, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.298096 (avg: 0.298096) \tsec/iter: 0.0529\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.393912 (avg: 0.298108) \tsec/iter: 0.0475\n",
      "Test set (epoch 166): Average loss: 0.7172, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.244536 (avg: 0.244536) \tsec/iter: 0.0499\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.258489 (avg: 0.278700) \tsec/iter: 0.0452\n",
      "Test set (epoch 167): Average loss: 0.5119, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.303025 (avg: 0.303025) \tsec/iter: 0.0449\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.175846 (avg: 0.265245) \tsec/iter: 0.0426\n",
      "Test set (epoch 168): Average loss: 0.4270, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.260731 (avg: 0.260731) \tsec/iter: 0.0419\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.388866 (avg: 0.281774) \tsec/iter: 0.0416\n",
      "Test set (epoch 169): Average loss: 0.5357, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.262200 (avg: 0.262200) \tsec/iter: 0.0479\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.393737 (avg: 0.270235) \tsec/iter: 0.0449\n",
      "Test set (epoch 170): Average loss: 0.4626, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.211499 (avg: 0.211499) \tsec/iter: 0.0489\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.174463 (avg: 0.212327) \tsec/iter: 0.0509\n",
      "Test set (epoch 171): Average loss: 0.6247, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.197997 (avg: 0.197997) \tsec/iter: 0.0429\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.235259 (avg: 0.216906) \tsec/iter: 0.0459\n",
      "Test set (epoch 172): Average loss: 0.6123, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.246663 (avg: 0.246663) \tsec/iter: 0.0559\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.327053 (avg: 0.239660) \tsec/iter: 0.0475\n",
      "Test set (epoch 173): Average loss: 0.5572, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.200232 (avg: 0.200232) \tsec/iter: 0.0529\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.194171 (avg: 0.251563) \tsec/iter: 0.0442\n",
      "Test set (epoch 174): Average loss: 0.6138, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.333048 (avg: 0.333048) \tsec/iter: 0.0449\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.211430 (avg: 0.292075) \tsec/iter: 0.0462\n",
      "Test set (epoch 175): Average loss: 0.5635, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.223490 (avg: 0.223490) \tsec/iter: 0.0529\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.082781 (avg: 0.212203) \tsec/iter: 0.0489\n",
      "Test set (epoch 176): Average loss: 0.5814, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.255260 (avg: 0.255260) \tsec/iter: 0.0439\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.177485 (avg: 0.230471) \tsec/iter: 0.0459\n",
      "Test set (epoch 177): Average loss: 0.6267, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.246595 (avg: 0.246595) \tsec/iter: 0.0568\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.186532 (avg: 0.235954) \tsec/iter: 0.0509\n",
      "Test set (epoch 178): Average loss: 0.5008, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.242025 (avg: 0.242025) \tsec/iter: 0.0499\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.418013 (avg: 0.262742) \tsec/iter: 0.0469\n",
      "Test set (epoch 179): Average loss: 0.6597, Accuracy: 11/18 (61.11%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.211317 (avg: 0.211317) \tsec/iter: 0.0469\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.149425 (avg: 0.196065) \tsec/iter: 0.0445\n",
      "Test set (epoch 180): Average loss: 0.5037, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.262845 (avg: 0.262845) \tsec/iter: 0.0489\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.201225 (avg: 0.243381) \tsec/iter: 0.0402\n",
      "Test set (epoch 181): Average loss: 0.7204, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.257229 (avg: 0.257229) \tsec/iter: 0.0479\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.285107 (avg: 0.250949) \tsec/iter: 0.0399\n",
      "Test set (epoch 182): Average loss: 0.5213, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.240976 (avg: 0.240976) \tsec/iter: 0.0379\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.170325 (avg: 0.285290) \tsec/iter: 0.0399\n",
      "Test set (epoch 183): Average loss: 0.5458, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.157490 (avg: 0.157490) \tsec/iter: 0.0409\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.233583 (avg: 0.251076) \tsec/iter: 0.0376\n",
      "Test set (epoch 184): Average loss: 0.5519, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.264411 (avg: 0.264411) \tsec/iter: 0.0429\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.183670 (avg: 0.230510) \tsec/iter: 0.0379\n",
      "Test set (epoch 185): Average loss: 0.6076, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.309733 (avg: 0.309733) \tsec/iter: 0.0359\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.315968 (avg: 0.254732) \tsec/iter: 0.0319\n",
      "Test set (epoch 186): Average loss: 0.6191, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.355114 (avg: 0.355114) \tsec/iter: 0.0329\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.157313 (avg: 0.265609) \tsec/iter: 0.0312\n",
      "Test set (epoch 187): Average loss: 0.6456, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.243154 (avg: 0.243154) \tsec/iter: 0.0349\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.146509 (avg: 0.200786) \tsec/iter: 0.0299\n",
      "Test set (epoch 188): Average loss: 0.5011, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.348964 (avg: 0.348964) \tsec/iter: 0.0359\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.215084 (avg: 0.242107) \tsec/iter: 0.0316\n",
      "Test set (epoch 189): Average loss: 0.5021, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.178891 (avg: 0.178891) \tsec/iter: 0.0339\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.272052 (avg: 0.230211) \tsec/iter: 0.0309\n",
      "Test set (epoch 190): Average loss: 0.5467, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.140843 (avg: 0.140843) \tsec/iter: 0.0299\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.232487 (avg: 0.198769) \tsec/iter: 0.0283\n",
      "Test set (epoch 191): Average loss: 0.6355, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.172160 (avg: 0.172160) \tsec/iter: 0.0329\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.224464 (avg: 0.216127) \tsec/iter: 0.0306\n",
      "Test set (epoch 192): Average loss: 0.6485, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.144389 (avg: 0.144389) \tsec/iter: 0.0329\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.341108 (avg: 0.254038) \tsec/iter: 0.0342\n",
      "Test set (epoch 193): Average loss: 0.5983, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.203757 (avg: 0.203757) \tsec/iter: 0.0399\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.202866 (avg: 0.223007) \tsec/iter: 0.0366\n",
      "Test set (epoch 194): Average loss: 0.5159, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.190109 (avg: 0.190109) \tsec/iter: 0.0349\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.244980 (avg: 0.225042) \tsec/iter: 0.0316\n",
      "Test set (epoch 195): Average loss: 0.6184, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.279084 (avg: 0.279084) \tsec/iter: 0.0319\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.180511 (avg: 0.236578) \tsec/iter: 0.0326\n",
      "Test set (epoch 196): Average loss: 0.6052, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.262442 (avg: 0.262442) \tsec/iter: 0.0359\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.353087 (avg: 0.234056) \tsec/iter: 0.0306\n",
      "Test set (epoch 197): Average loss: 0.5658, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.240371 (avg: 0.240371) \tsec/iter: 0.0389\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.249115 (avg: 0.233516) \tsec/iter: 0.0322\n",
      "Test set (epoch 198): Average loss: 0.5782, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.264550 (avg: 0.264550) \tsec/iter: 0.0369\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.266454 (avg: 0.250099) \tsec/iter: 0.0319\n",
      "Test set (epoch 199): Average loss: 0.5363, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.291204 (avg: 0.291204) \tsec/iter: 0.0309\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.219783 (avg: 0.240730) \tsec/iter: 0.0303\n",
      "Test set (epoch 200): Average loss: 0.4577, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.187036 (avg: 0.187036) \tsec/iter: 0.0329\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.325297 (avg: 0.230653) \tsec/iter: 0.0293\n",
      "Test set (epoch 201): Average loss: 0.6733, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.180650 (avg: 0.180650) \tsec/iter: 0.0329\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.408994 (avg: 0.239473) \tsec/iter: 0.0329\n",
      "Test set (epoch 202): Average loss: 0.5728, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.365871 (avg: 0.365871) \tsec/iter: 0.0379\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.188381 (avg: 0.256281) \tsec/iter: 0.0346\n",
      "Test set (epoch 203): Average loss: 0.5384, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.250272 (avg: 0.250272) \tsec/iter: 0.0419\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.301087 (avg: 0.233324) \tsec/iter: 0.0356\n",
      "Test set (epoch 204): Average loss: 0.5837, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.278256 (avg: 0.278256) \tsec/iter: 0.0369\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.249000 (avg: 0.238308) \tsec/iter: 0.0322\n",
      "Test set (epoch 205): Average loss: 0.4982, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.151434 (avg: 0.151434) \tsec/iter: 0.0329\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.179107 (avg: 0.206502) \tsec/iter: 0.0312\n",
      "Test set (epoch 206): Average loss: 0.5192, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.225575 (avg: 0.225575) \tsec/iter: 0.0389\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.229510 (avg: 0.199646) \tsec/iter: 0.0336\n",
      "Test set (epoch 207): Average loss: 0.6101, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.286968 (avg: 0.286968) \tsec/iter: 0.0319\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.247004 (avg: 0.214308) \tsec/iter: 0.0312\n",
      "Test set (epoch 208): Average loss: 0.4949, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.122897 (avg: 0.122897) \tsec/iter: 0.0329\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.209188 (avg: 0.197659) \tsec/iter: 0.0303\n",
      "Test set (epoch 209): Average loss: 0.5446, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.173330 (avg: 0.173330) \tsec/iter: 0.0299\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.244046 (avg: 0.169499) \tsec/iter: 0.0296\n",
      "Test set (epoch 210): Average loss: 0.6255, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.164296 (avg: 0.164296) \tsec/iter: 0.0319\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.244907 (avg: 0.216655) \tsec/iter: 0.0293\n",
      "Test set (epoch 211): Average loss: 0.6531, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.156512 (avg: 0.156512) \tsec/iter: 0.0359\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.287039 (avg: 0.198665) \tsec/iter: 0.0319\n",
      "Test set (epoch 212): Average loss: 0.5670, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.240630 (avg: 0.240630) \tsec/iter: 0.0379\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.242844 (avg: 0.215652) \tsec/iter: 0.0369\n",
      "Test set (epoch 213): Average loss: 0.4713, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.172494 (avg: 0.172494) \tsec/iter: 0.0409\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.197752 (avg: 0.187611) \tsec/iter: 0.0372\n",
      "Test set (epoch 214): Average loss: 0.5051, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.266603 (avg: 0.266603) \tsec/iter: 0.0309\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.202032 (avg: 0.220066) \tsec/iter: 0.0286\n",
      "Test set (epoch 215): Average loss: 0.6174, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.194959 (avg: 0.194959) \tsec/iter: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.238331 (avg: 0.205679) \tsec/iter: 0.0342\n",
      "Test set (epoch 216): Average loss: 0.6548, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.319812 (avg: 0.319812) \tsec/iter: 0.0329\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.217701 (avg: 0.252300) \tsec/iter: 0.0303\n",
      "Test set (epoch 217): Average loss: 0.5278, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.140646 (avg: 0.140646) \tsec/iter: 0.0309\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.228578 (avg: 0.165416) \tsec/iter: 0.0279\n",
      "Test set (epoch 218): Average loss: 0.5680, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.137176 (avg: 0.137176) \tsec/iter: 0.0329\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.232938 (avg: 0.193334) \tsec/iter: 0.0293\n",
      "Test set (epoch 219): Average loss: 0.6264, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.301811 (avg: 0.301811) \tsec/iter: 0.0329\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.144137 (avg: 0.234057) \tsec/iter: 0.0352\n",
      "Test set (epoch 220): Average loss: 0.6347, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.270075 (avg: 0.270075) \tsec/iter: 0.0329\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.137249 (avg: 0.240391) \tsec/iter: 0.0302\n",
      "Test set (epoch 221): Average loss: 0.5296, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.259334 (avg: 0.259334) \tsec/iter: 0.0349\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.194364 (avg: 0.235869) \tsec/iter: 0.0322\n",
      "Test set (epoch 222): Average loss: 0.5715, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.193573 (avg: 0.193573) \tsec/iter: 0.0389\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.214065 (avg: 0.187440) \tsec/iter: 0.0352\n",
      "Test set (epoch 223): Average loss: 0.5239, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.131764 (avg: 0.131764) \tsec/iter: 0.0379\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.274522 (avg: 0.181030) \tsec/iter: 0.0316\n",
      "Test set (epoch 224): Average loss: 0.6349, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.244889 (avg: 0.244889) \tsec/iter: 0.0319\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.241062 (avg: 0.217181) \tsec/iter: 0.0303\n",
      "Test set (epoch 225): Average loss: 0.5680, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.160312 (avg: 0.160312) \tsec/iter: 0.0359\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.239491 (avg: 0.232834) \tsec/iter: 0.0299\n",
      "Test set (epoch 226): Average loss: 0.5606, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.157664 (avg: 0.157664) \tsec/iter: 0.0329\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.283477 (avg: 0.226556) \tsec/iter: 0.0309\n",
      "Test set (epoch 227): Average loss: 0.4692, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.186497 (avg: 0.186497) \tsec/iter: 0.0369\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.398333 (avg: 0.236327) \tsec/iter: 0.0303\n",
      "Test set (epoch 228): Average loss: 0.5654, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.231377 (avg: 0.231377) \tsec/iter: 0.0319\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.200030 (avg: 0.217935) \tsec/iter: 0.0293\n",
      "Test set (epoch 229): Average loss: 0.6521, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.270140 (avg: 0.270140) \tsec/iter: 0.0349\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.226697 (avg: 0.232278) \tsec/iter: 0.0303\n",
      "Test set (epoch 230): Average loss: 0.5122, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.218139 (avg: 0.218139) \tsec/iter: 0.0319\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.253685 (avg: 0.228339) \tsec/iter: 0.0326\n",
      "Test set (epoch 231): Average loss: 0.4450, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.149318 (avg: 0.149318) \tsec/iter: 0.0309\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.277420 (avg: 0.193980) \tsec/iter: 0.0322\n",
      "Test set (epoch 232): Average loss: 0.5879, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.202176 (avg: 0.202176) \tsec/iter: 0.0658\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.192068 (avg: 0.205872) \tsec/iter: 0.0465\n",
      "Test set (epoch 233): Average loss: 0.6018, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.195903 (avg: 0.195903) \tsec/iter: 0.0549\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.240520 (avg: 0.210900) \tsec/iter: 0.0449\n",
      "Test set (epoch 234): Average loss: 0.5751, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.174467 (avg: 0.174467) \tsec/iter: 0.0549\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.233355 (avg: 0.226205) \tsec/iter: 0.0462\n",
      "Test set (epoch 235): Average loss: 0.5679, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.209795 (avg: 0.209795) \tsec/iter: 0.0469\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.251977 (avg: 0.199921) \tsec/iter: 0.0422\n",
      "Test set (epoch 236): Average loss: 0.6153, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.129699 (avg: 0.129699) \tsec/iter: 0.0588\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.171536 (avg: 0.151135) \tsec/iter: 0.0485\n",
      "Test set (epoch 237): Average loss: 0.4639, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.249196 (avg: 0.249196) \tsec/iter: 0.0519\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.222028 (avg: 0.210701) \tsec/iter: 0.0459\n",
      "Test set (epoch 238): Average loss: 0.5027, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.095213 (avg: 0.095213) \tsec/iter: 0.0539\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.227451 (avg: 0.193159) \tsec/iter: 0.0482\n",
      "Test set (epoch 239): Average loss: 0.5184, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.278060 (avg: 0.278060) \tsec/iter: 0.0578\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.194754 (avg: 0.234719) \tsec/iter: 0.0469\n",
      "Test set (epoch 240): Average loss: 0.5661, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.224979 (avg: 0.224979) \tsec/iter: 0.0449\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.141582 (avg: 0.181176) \tsec/iter: 0.0409\n",
      "Test set (epoch 241): Average loss: 0.5278, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.145967 (avg: 0.145967) \tsec/iter: 0.0409\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.248506 (avg: 0.174004) \tsec/iter: 0.0389\n",
      "Test set (epoch 242): Average loss: 0.5421, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.202202 (avg: 0.202202) \tsec/iter: 0.0409\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.224674 (avg: 0.188621) \tsec/iter: 0.0382\n",
      "Test set (epoch 243): Average loss: 0.6191, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.283618 (avg: 0.283618) \tsec/iter: 0.0479\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.260653 (avg: 0.247370) \tsec/iter: 0.0419\n",
      "Test set (epoch 244): Average loss: 0.7402, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.131038 (avg: 0.131038) \tsec/iter: 0.0449\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.177790 (avg: 0.211433) \tsec/iter: 0.0399\n",
      "Test set (epoch 245): Average loss: 0.6088, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.237453 (avg: 0.237453) \tsec/iter: 0.0439\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.151485 (avg: 0.181173) \tsec/iter: 0.0412\n",
      "Test set (epoch 246): Average loss: 0.5857, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.209623 (avg: 0.209623) \tsec/iter: 0.0469\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.114120 (avg: 0.178461) \tsec/iter: 0.0436\n",
      "Test set (epoch 247): Average loss: 0.6519, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.190556 (avg: 0.190556) \tsec/iter: 0.0389\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.203183 (avg: 0.192848) \tsec/iter: 0.0376\n",
      "Test set (epoch 248): Average loss: 0.4960, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.190513 (avg: 0.190513) \tsec/iter: 0.0409\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.143609 (avg: 0.178467) \tsec/iter: 0.0376\n",
      "Test set (epoch 249): Average loss: 0.6450, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.224632 (avg: 0.224632) \tsec/iter: 0.0469\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.138330 (avg: 0.228366) \tsec/iter: 0.0392\n",
      "Test set (epoch 250): Average loss: 0.6283, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.110982 (avg: 0.110982) \tsec/iter: 0.0459\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.223997 (avg: 0.160165) \tsec/iter: 0.0412\n",
      "Test set (epoch 251): Average loss: 0.6849, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.131960 (avg: 0.131960) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.154657 (avg: 0.163716) \tsec/iter: 0.0406\n",
      "Test set (epoch 252): Average loss: 0.4967, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.139255 (avg: 0.139255) \tsec/iter: 0.0459\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.174311 (avg: 0.167991) \tsec/iter: 0.0342\n",
      "Test set (epoch 253): Average loss: 0.6375, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.243723 (avg: 0.243723) \tsec/iter: 0.0329\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.118850 (avg: 0.186096) \tsec/iter: 0.0356\n",
      "Test set (epoch 254): Average loss: 0.5916, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.312693 (avg: 0.312693) \tsec/iter: 0.0449\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.280357 (avg: 0.268187) \tsec/iter: 0.0402\n",
      "Test set (epoch 255): Average loss: 0.7449, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.257749 (avg: 0.257749) \tsec/iter: 0.0349\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.232151 (avg: 0.244043) \tsec/iter: 0.0316\n",
      "Test set (epoch 256): Average loss: 0.4958, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.175847 (avg: 0.175847) \tsec/iter: 0.0349\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.213723 (avg: 0.177997) \tsec/iter: 0.0329\n",
      "Test set (epoch 257): Average loss: 0.5348, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.272625 (avg: 0.272625) \tsec/iter: 0.0329\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.144000 (avg: 0.189365) \tsec/iter: 0.0326\n",
      "Test set (epoch 258): Average loss: 0.5112, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.160580 (avg: 0.160580) \tsec/iter: 0.0339\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.219986 (avg: 0.202786) \tsec/iter: 0.0289\n",
      "Test set (epoch 259): Average loss: 0.5458, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.125335 (avg: 0.125335) \tsec/iter: 0.0309\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.189555 (avg: 0.167151) \tsec/iter: 0.0309\n",
      "Test set (epoch 260): Average loss: 0.5230, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.126218 (avg: 0.126218) \tsec/iter: 0.0319\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.124479 (avg: 0.189551) \tsec/iter: 0.0312\n",
      "Test set (epoch 261): Average loss: 0.6411, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.115591 (avg: 0.115591) \tsec/iter: 0.0319\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.254923 (avg: 0.214931) \tsec/iter: 0.0293\n",
      "Test set (epoch 262): Average loss: 0.4734, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.141901 (avg: 0.141901) \tsec/iter: 0.0339\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.310112 (avg: 0.190396) \tsec/iter: 0.0309\n",
      "Test set (epoch 263): Average loss: 0.6343, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.219277 (avg: 0.219277) \tsec/iter: 0.0369\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.216779 (avg: 0.181495) \tsec/iter: 0.0362\n",
      "Test set (epoch 264): Average loss: 0.7210, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.307135 (avg: 0.307135) \tsec/iter: 0.0379\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.209837 (avg: 0.222632) \tsec/iter: 0.0346\n",
      "Test set (epoch 265): Average loss: 0.5459, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.144684 (avg: 0.144684) \tsec/iter: 0.0319\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.123988 (avg: 0.166553) \tsec/iter: 0.0306\n",
      "Test set (epoch 266): Average loss: 0.6237, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.166610 (avg: 0.166610) \tsec/iter: 0.0309\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.230784 (avg: 0.210971) \tsec/iter: 0.0279\n",
      "Test set (epoch 267): Average loss: 0.6100, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.255873 (avg: 0.255873) \tsec/iter: 0.0329\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.162596 (avg: 0.179853) \tsec/iter: 0.0312\n",
      "Test set (epoch 268): Average loss: 0.5034, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.137948 (avg: 0.137948) \tsec/iter: 0.0429\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.172873 (avg: 0.163236) \tsec/iter: 0.0359\n",
      "Test set (epoch 269): Average loss: 0.6236, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.141706 (avg: 0.141706) \tsec/iter: 0.0329\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.187020 (avg: 0.147359) \tsec/iter: 0.0299\n",
      "Test set (epoch 270): Average loss: 0.5932, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.130048 (avg: 0.130048) \tsec/iter: 0.0339\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.265878 (avg: 0.208652) \tsec/iter: 0.0319\n",
      "Test set (epoch 271): Average loss: 0.6912, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.148745 (avg: 0.148745) \tsec/iter: 0.0299\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.197235 (avg: 0.175283) \tsec/iter: 0.0306\n",
      "Test set (epoch 272): Average loss: 0.6323, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.216789 (avg: 0.216789) \tsec/iter: 0.0329\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.269369 (avg: 0.182134) \tsec/iter: 0.0346\n",
      "Test set (epoch 273): Average loss: 0.5430, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.189282 (avg: 0.189282) \tsec/iter: 0.0389\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.113392 (avg: 0.162997) \tsec/iter: 0.0376\n",
      "Test set (epoch 274): Average loss: 0.6475, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.277238 (avg: 0.277238) \tsec/iter: 0.0359\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.125609 (avg: 0.223169) \tsec/iter: 0.0319\n",
      "Test set (epoch 275): Average loss: 0.5533, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.229732 (avg: 0.229732) \tsec/iter: 0.0339\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.179013 (avg: 0.185305) \tsec/iter: 0.0303\n",
      "Test set (epoch 276): Average loss: 0.6122, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.225184 (avg: 0.225184) \tsec/iter: 0.0349\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.151791 (avg: 0.187650) \tsec/iter: 0.0306\n",
      "Test set (epoch 277): Average loss: 0.6707, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.182036 (avg: 0.182036) \tsec/iter: 0.0319\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.183204 (avg: 0.144346) \tsec/iter: 0.0299\n",
      "Test set (epoch 278): Average loss: 0.5829, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.128903 (avg: 0.128903) \tsec/iter: 0.0369\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.097442 (avg: 0.149930) \tsec/iter: 0.0316\n",
      "Test set (epoch 279): Average loss: 0.7423, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.208228 (avg: 0.208228) \tsec/iter: 0.0299\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.242846 (avg: 0.167075) \tsec/iter: 0.0293\n",
      "Test set (epoch 280): Average loss: 0.5763, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.112803 (avg: 0.112803) \tsec/iter: 0.0439\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.251568 (avg: 0.152401) \tsec/iter: 0.0342\n",
      "Test set (epoch 281): Average loss: 0.5555, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.215216 (avg: 0.215216) \tsec/iter: 0.0309\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.130441 (avg: 0.190016) \tsec/iter: 0.0306\n",
      "Test set (epoch 282): Average loss: 0.6441, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.175872 (avg: 0.175872) \tsec/iter: 0.0389\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.134175 (avg: 0.168320) \tsec/iter: 0.0349\n",
      "Test set (epoch 283): Average loss: 0.6442, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.160304 (avg: 0.160304) \tsec/iter: 0.0419\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.220607 (avg: 0.154899) \tsec/iter: 0.0369\n",
      "Test set (epoch 284): Average loss: 0.4636, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.273866 (avg: 0.273866) \tsec/iter: 0.0369\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.129800 (avg: 0.189894) \tsec/iter: 0.0309\n",
      "Test set (epoch 285): Average loss: 0.5752, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.190191 (avg: 0.190191) \tsec/iter: 0.0289\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.160307 (avg: 0.160982) \tsec/iter: 0.0303\n",
      "Test set (epoch 286): Average loss: 0.7269, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.188653 (avg: 0.188653) \tsec/iter: 0.0319\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.155356 (avg: 0.170185) \tsec/iter: 0.0286\n",
      "Test set (epoch 287): Average loss: 0.7501, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.064693 (avg: 0.064693) \tsec/iter: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.308494 (avg: 0.176673) \tsec/iter: 0.0336\n",
      "Test set (epoch 288): Average loss: 0.5505, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.157189 (avg: 0.157189) \tsec/iter: 0.0359\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.169163 (avg: 0.173139) \tsec/iter: 0.0306\n",
      "Test set (epoch 289): Average loss: 0.6075, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.217987 (avg: 0.217987) \tsec/iter: 0.0319\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.128410 (avg: 0.199050) \tsec/iter: 0.0296\n",
      "Test set (epoch 290): Average loss: 0.6928, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.125168 (avg: 0.125168) \tsec/iter: 0.0309\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.154617 (avg: 0.153623) \tsec/iter: 0.0276\n",
      "Test set (epoch 291): Average loss: 0.6330, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.132141 (avg: 0.132141) \tsec/iter: 0.0329\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.195687 (avg: 0.143707) \tsec/iter: 0.0306\n",
      "Test set (epoch 292): Average loss: 0.9282, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.169811 (avg: 0.169811) \tsec/iter: 0.0389\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.138024 (avg: 0.172513) \tsec/iter: 0.0362\n",
      "Test set (epoch 293): Average loss: 0.7054, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.114614 (avg: 0.114614) \tsec/iter: 0.0349\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.108923 (avg: 0.175192) \tsec/iter: 0.0319\n",
      "Test set (epoch 294): Average loss: 0.8726, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.127590 (avg: 0.127590) \tsec/iter: 0.0319\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.173319 (avg: 0.167039) \tsec/iter: 0.0312\n",
      "Test set (epoch 295): Average loss: 0.5787, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.283562 (avg: 0.283562) \tsec/iter: 0.0349\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.137325 (avg: 0.179109) \tsec/iter: 0.0329\n",
      "Test set (epoch 296): Average loss: 0.5261, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.229095 (avg: 0.229095) \tsec/iter: 0.0309\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.234595 (avg: 0.186121) \tsec/iter: 0.0303\n",
      "Test set (epoch 297): Average loss: 0.5420, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.129037 (avg: 0.129037) \tsec/iter: 0.0389\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.151944 (avg: 0.156875) \tsec/iter: 0.0342\n",
      "Test set (epoch 298): Average loss: 0.5000, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.160262 (avg: 0.160262) \tsec/iter: 0.0369\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.173384 (avg: 0.156726) \tsec/iter: 0.0309\n",
      "Test set (epoch 299): Average loss: 0.6878, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.140954 (avg: 0.140954) \tsec/iter: 0.0309\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.278653 (avg: 0.160482) \tsec/iter: 0.0286\n",
      "Test set (epoch 300): Average loss: 0.6680, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.228178 (avg: 0.228178) \tsec/iter: 0.0339\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.158840 (avg: 0.177590) \tsec/iter: 0.0299\n",
      "Test set (epoch 301): Average loss: 0.6042, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.208344 (avg: 0.208344) \tsec/iter: 0.0359\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.221607 (avg: 0.187268) \tsec/iter: 0.0332\n",
      "Test set (epoch 302): Average loss: 0.5170, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.147333 (avg: 0.147333) \tsec/iter: 0.0429\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.221092 (avg: 0.178652) \tsec/iter: 0.0369\n",
      "Test set (epoch 303): Average loss: 0.7781, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.373510 (avg: 0.373510) \tsec/iter: 0.0359\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.089903 (avg: 0.199395) \tsec/iter: 0.0319\n",
      "Test set (epoch 304): Average loss: 0.5844, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.224459 (avg: 0.224459) \tsec/iter: 0.0309\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.169692 (avg: 0.174787) \tsec/iter: 0.0283\n",
      "Test set (epoch 305): Average loss: 0.6935, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.189845 (avg: 0.189845) \tsec/iter: 0.0319\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.069722 (avg: 0.177776) \tsec/iter: 0.0303\n",
      "Test set (epoch 306): Average loss: 0.8039, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.174146 (avg: 0.174146) \tsec/iter: 0.0349\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.181267 (avg: 0.176668) \tsec/iter: 0.0322\n",
      "Test set (epoch 307): Average loss: 0.7543, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.185579 (avg: 0.185579) \tsec/iter: 0.0359\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.171016 (avg: 0.170409) \tsec/iter: 0.0309\n",
      "Test set (epoch 308): Average loss: 0.7028, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.157737 (avg: 0.157737) \tsec/iter: 0.0369\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.141290 (avg: 0.158977) \tsec/iter: 0.0326\n",
      "Test set (epoch 309): Average loss: 0.5565, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.199609 (avg: 0.199609) \tsec/iter: 0.0409\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.281789 (avg: 0.180677) \tsec/iter: 0.0342\n",
      "Test set (epoch 310): Average loss: 0.6966, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.174939 (avg: 0.174939) \tsec/iter: 0.0309\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.075827 (avg: 0.196736) \tsec/iter: 0.0322\n",
      "Test set (epoch 311): Average loss: 0.8209, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.162035 (avg: 0.162035) \tsec/iter: 0.0419\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.205182 (avg: 0.186588) \tsec/iter: 0.0362\n",
      "Test set (epoch 312): Average loss: 0.7720, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.206560 (avg: 0.206560) \tsec/iter: 0.0389\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.111088 (avg: 0.167527) \tsec/iter: 0.0326\n",
      "Test set (epoch 313): Average loss: 0.7914, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.179657 (avg: 0.179657) \tsec/iter: 0.0309\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.092596 (avg: 0.161054) \tsec/iter: 0.0276\n",
      "Test set (epoch 314): Average loss: 0.7967, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.210247 (avg: 0.210247) \tsec/iter: 0.0319\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.289434 (avg: 0.189839) \tsec/iter: 0.0309\n",
      "Test set (epoch 315): Average loss: 0.6679, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.182032 (avg: 0.182032) \tsec/iter: 0.0339\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.238968 (avg: 0.184935) \tsec/iter: 0.0309\n",
      "Test set (epoch 316): Average loss: 0.7083, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.141729 (avg: 0.141729) \tsec/iter: 0.0329\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.172448 (avg: 0.141358) \tsec/iter: 0.0319\n",
      "Test set (epoch 317): Average loss: 0.7072, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.200371 (avg: 0.200371) \tsec/iter: 0.0339\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.157901 (avg: 0.176111) \tsec/iter: 0.0306\n",
      "Test set (epoch 318): Average loss: 0.6120, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.241554 (avg: 0.241554) \tsec/iter: 0.0339\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.130345 (avg: 0.237786) \tsec/iter: 0.0306\n",
      "Test set (epoch 319): Average loss: 0.7431, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.268810 (avg: 0.268810) \tsec/iter: 0.0299\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.164165 (avg: 0.186947) \tsec/iter: 0.0283\n",
      "Test set (epoch 320): Average loss: 0.5577, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.159244 (avg: 0.159244) \tsec/iter: 0.0359\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.241948 (avg: 0.232140) \tsec/iter: 0.0326\n",
      "Test set (epoch 321): Average loss: 0.6876, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.143397 (avg: 0.143397) \tsec/iter: 0.0419\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.267441 (avg: 0.172128) \tsec/iter: 0.0356\n",
      "Test set (epoch 322): Average loss: 0.7177, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.311762 (avg: 0.311762) \tsec/iter: 0.0389\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.220069 (avg: 0.209390) \tsec/iter: 0.0359\n",
      "Test set (epoch 323): Average loss: 0.8200, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.161429 (avg: 0.161429) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.183790 (avg: 0.150667) \tsec/iter: 0.0306\n",
      "Test set (epoch 324): Average loss: 0.6069, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.217591 (avg: 0.217591) \tsec/iter: 0.0359\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.183702 (avg: 0.169872) \tsec/iter: 0.0312\n",
      "Test set (epoch 325): Average loss: 0.6466, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.126820 (avg: 0.126820) \tsec/iter: 0.0349\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.168096 (avg: 0.172733) \tsec/iter: 0.0316\n",
      "Test set (epoch 326): Average loss: 0.7667, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.198565 (avg: 0.198565) \tsec/iter: 0.0359\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.200319 (avg: 0.183840) \tsec/iter: 0.0316\n",
      "Test set (epoch 327): Average loss: 0.6009, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.234298 (avg: 0.234298) \tsec/iter: 0.0349\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.255765 (avg: 0.211608) \tsec/iter: 0.0283\n",
      "Test set (epoch 328): Average loss: 0.6630, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.186502 (avg: 0.186502) \tsec/iter: 0.0329\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.212914 (avg: 0.173039) \tsec/iter: 0.0296\n",
      "Test set (epoch 329): Average loss: 0.5866, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.129946 (avg: 0.129946) \tsec/iter: 0.0319\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.278107 (avg: 0.172761) \tsec/iter: 0.0286\n",
      "Test set (epoch 330): Average loss: 0.6694, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.151341 (avg: 0.151341) \tsec/iter: 0.0329\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.416365 (avg: 0.235663) \tsec/iter: 0.0312\n",
      "Test set (epoch 331): Average loss: 0.7993, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.075726 (avg: 0.075726) \tsec/iter: 0.0419\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.294789 (avg: 0.134757) \tsec/iter: 0.0379\n",
      "Test set (epoch 332): Average loss: 0.6525, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.226596 (avg: 0.226596) \tsec/iter: 0.0339\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.101529 (avg: 0.175641) \tsec/iter: 0.0303\n",
      "Test set (epoch 333): Average loss: 0.8820, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.181057 (avg: 0.181057) \tsec/iter: 0.0339\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.257205 (avg: 0.211753) \tsec/iter: 0.0296\n",
      "Test set (epoch 334): Average loss: 0.6446, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.112777 (avg: 0.112777) \tsec/iter: 0.0319\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.160494 (avg: 0.160576) \tsec/iter: 0.0293\n",
      "Test set (epoch 335): Average loss: 0.7696, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.177515 (avg: 0.177515) \tsec/iter: 0.0339\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.369126 (avg: 0.206680) \tsec/iter: 0.0312\n",
      "Test set (epoch 336): Average loss: 0.5472, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.211303 (avg: 0.211303) \tsec/iter: 0.0419\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.115445 (avg: 0.163741) \tsec/iter: 0.0366\n",
      "Test set (epoch 337): Average loss: 0.5556, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.086689 (avg: 0.086689) \tsec/iter: 0.0309\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.149055 (avg: 0.168867) \tsec/iter: 0.0303\n",
      "Test set (epoch 338): Average loss: 0.6141, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.196395 (avg: 0.196395) \tsec/iter: 0.0349\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.164900 (avg: 0.207034) \tsec/iter: 0.0303\n",
      "Test set (epoch 339): Average loss: 0.5751, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.214600 (avg: 0.214600) \tsec/iter: 0.0349\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.135892 (avg: 0.221273) \tsec/iter: 0.0289\n",
      "Test set (epoch 340): Average loss: 0.5772, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.122780 (avg: 0.122780) \tsec/iter: 0.0379\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.172898 (avg: 0.162185) \tsec/iter: 0.0352\n",
      "Test set (epoch 341): Average loss: 0.7068, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.185834 (avg: 0.185834) \tsec/iter: 0.0389\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.184690 (avg: 0.168181) \tsec/iter: 0.0346\n",
      "Test set (epoch 342): Average loss: 0.8344, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.169192 (avg: 0.169192) \tsec/iter: 0.0339\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.112829 (avg: 0.149831) \tsec/iter: 0.0296\n",
      "Test set (epoch 343): Average loss: 0.7505, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.143615 (avg: 0.143615) \tsec/iter: 0.0349\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.069387 (avg: 0.146347) \tsec/iter: 0.0322\n",
      "Test set (epoch 344): Average loss: 0.6863, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.114334 (avg: 0.114334) \tsec/iter: 0.0329\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.181301 (avg: 0.157639) \tsec/iter: 0.0306\n",
      "Test set (epoch 345): Average loss: 0.7834, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.149916 (avg: 0.149916) \tsec/iter: 0.0289\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.077742 (avg: 0.145570) \tsec/iter: 0.0279\n",
      "Test set (epoch 346): Average loss: 0.6773, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.151583 (avg: 0.151583) \tsec/iter: 0.0319\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.097495 (avg: 0.138537) \tsec/iter: 0.0299\n",
      "Test set (epoch 347): Average loss: 0.7211, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.254864 (avg: 0.254864) \tsec/iter: 0.0369\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.277311 (avg: 0.194628) \tsec/iter: 0.0316\n",
      "Test set (epoch 348): Average loss: 0.7071, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.188130 (avg: 0.188130) \tsec/iter: 0.0329\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.068606 (avg: 0.149376) \tsec/iter: 0.0293\n",
      "Test set (epoch 349): Average loss: 0.6670, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.155801 (avg: 0.155801) \tsec/iter: 0.0319\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.136021 (avg: 0.154394) \tsec/iter: 0.0299\n",
      "Test set (epoch 350): Average loss: 0.4749, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.142542 (avg: 0.142542) \tsec/iter: 0.0399\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.261450 (avg: 0.168042) \tsec/iter: 0.0376\n",
      "Test set (epoch 351): Average loss: 0.6336, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.148278 (avg: 0.148278) \tsec/iter: 0.0409\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.180855 (avg: 0.169728) \tsec/iter: 0.0349\n",
      "Test set (epoch 352): Average loss: 0.6869, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.131594 (avg: 0.131594) \tsec/iter: 0.0309\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.196323 (avg: 0.140811) \tsec/iter: 0.0303\n",
      "Test set (epoch 353): Average loss: 0.7720, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.213502 (avg: 0.213502) \tsec/iter: 0.0369\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.134034 (avg: 0.166317) \tsec/iter: 0.0309\n",
      "Test set (epoch 354): Average loss: 0.8753, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.129608 (avg: 0.129608) \tsec/iter: 0.0339\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.321101 (avg: 0.165231) \tsec/iter: 0.0319\n",
      "Test set (epoch 355): Average loss: 0.7180, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.216734 (avg: 0.216734) \tsec/iter: 0.0299\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.099724 (avg: 0.156128) \tsec/iter: 0.0283\n",
      "Test set (epoch 356): Average loss: 0.8051, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.117759 (avg: 0.117759) \tsec/iter: 0.0389\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.157053 (avg: 0.169358) \tsec/iter: 0.0306\n",
      "Test set (epoch 357): Average loss: 0.7646, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.226197 (avg: 0.226197) \tsec/iter: 0.0309\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.218113 (avg: 0.181456) \tsec/iter: 0.0299\n",
      "Test set (epoch 358): Average loss: 0.8173, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.181003 (avg: 0.181003) \tsec/iter: 0.0389\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.088428 (avg: 0.134917) \tsec/iter: 0.0316\n",
      "Test set (epoch 359): Average loss: 0.7853, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.122480 (avg: 0.122480) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.231546 (avg: 0.159787) \tsec/iter: 0.0319\n",
      "Test set (epoch 360): Average loss: 0.7016, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.141129 (avg: 0.141129) \tsec/iter: 0.0419\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.161736 (avg: 0.132780) \tsec/iter: 0.0372\n",
      "Test set (epoch 361): Average loss: 0.7631, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.182607 (avg: 0.182607) \tsec/iter: 0.0369\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.223488 (avg: 0.178481) \tsec/iter: 0.0326\n",
      "Test set (epoch 362): Average loss: 0.7897, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.233517 (avg: 0.233517) \tsec/iter: 0.0329\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.124761 (avg: 0.259152) \tsec/iter: 0.0303\n",
      "Test set (epoch 363): Average loss: 0.7127, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.233325 (avg: 0.233325) \tsec/iter: 0.0399\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.213604 (avg: 0.190031) \tsec/iter: 0.0352\n",
      "Test set (epoch 364): Average loss: 0.7449, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.213523 (avg: 0.213523) \tsec/iter: 0.0419\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.316921 (avg: 0.203006) \tsec/iter: 0.0339\n",
      "Test set (epoch 365): Average loss: 0.6533, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.112475 (avg: 0.112475) \tsec/iter: 0.0359\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.147417 (avg: 0.160920) \tsec/iter: 0.0303\n",
      "Test set (epoch 366): Average loss: 0.5665, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.174236 (avg: 0.174236) \tsec/iter: 0.0349\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.255348 (avg: 0.188223) \tsec/iter: 0.0296\n",
      "Test set (epoch 367): Average loss: 0.6065, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.160862 (avg: 0.160862) \tsec/iter: 0.0329\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.102354 (avg: 0.130023) \tsec/iter: 0.0289\n",
      "Test set (epoch 368): Average loss: 0.7639, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.181544 (avg: 0.181544) \tsec/iter: 0.0339\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.180578 (avg: 0.148711) \tsec/iter: 0.0312\n",
      "Test set (epoch 369): Average loss: 0.7116, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.118404 (avg: 0.118404) \tsec/iter: 0.0389\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.165606 (avg: 0.144886) \tsec/iter: 0.0359\n",
      "Test set (epoch 370): Average loss: 0.5854, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.143654 (avg: 0.143654) \tsec/iter: 0.0419\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.170722 (avg: 0.181173) \tsec/iter: 0.0349\n",
      "Test set (epoch 371): Average loss: 0.5944, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.109116 (avg: 0.109116) \tsec/iter: 0.0349\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.132870 (avg: 0.168730) \tsec/iter: 0.0303\n",
      "Test set (epoch 372): Average loss: 0.6410, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.164457 (avg: 0.164457) \tsec/iter: 0.0349\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.142673 (avg: 0.132717) \tsec/iter: 0.0319\n",
      "Test set (epoch 373): Average loss: 0.5930, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.126260 (avg: 0.126260) \tsec/iter: 0.0309\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.109085 (avg: 0.138431) \tsec/iter: 0.0309\n",
      "Test set (epoch 374): Average loss: 0.7164, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.158410 (avg: 0.158410) \tsec/iter: 0.0329\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.112131 (avg: 0.147518) \tsec/iter: 0.0306\n",
      "Test set (epoch 375): Average loss: 0.7122, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.212677 (avg: 0.212677) \tsec/iter: 0.0329\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.086350 (avg: 0.163939) \tsec/iter: 0.0306\n",
      "Test set (epoch 376): Average loss: 0.7736, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.170838 (avg: 0.170838) \tsec/iter: 0.0299\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.140681 (avg: 0.181580) \tsec/iter: 0.0269\n",
      "Test set (epoch 377): Average loss: 0.7442, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.160337 (avg: 0.160337) \tsec/iter: 0.0299\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.199144 (avg: 0.146874) \tsec/iter: 0.0309\n",
      "Test set (epoch 378): Average loss: 0.8026, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.197290 (avg: 0.197290) \tsec/iter: 0.0399\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.283038 (avg: 0.183894) \tsec/iter: 0.0336\n",
      "Test set (epoch 379): Average loss: 0.7236, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.321732 (avg: 0.321732) \tsec/iter: 0.0439\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.095472 (avg: 0.173316) \tsec/iter: 0.0399\n",
      "Test set (epoch 380): Average loss: 0.6663, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.248749 (avg: 0.248749) \tsec/iter: 0.0359\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.109357 (avg: 0.160864) \tsec/iter: 0.0309\n",
      "Test set (epoch 381): Average loss: 0.7901, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.146498 (avg: 0.146498) \tsec/iter: 0.0319\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.146039 (avg: 0.158151) \tsec/iter: 0.0293\n",
      "Test set (epoch 382): Average loss: 0.6721, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.219936 (avg: 0.219936) \tsec/iter: 0.0319\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.090671 (avg: 0.159302) \tsec/iter: 0.0306\n",
      "Test set (epoch 383): Average loss: 0.8513, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.191297 (avg: 0.191297) \tsec/iter: 0.0319\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.276577 (avg: 0.193757) \tsec/iter: 0.0296\n",
      "Test set (epoch 384): Average loss: 0.6251, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.177228 (avg: 0.177228) \tsec/iter: 0.0369\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.067447 (avg: 0.176067) \tsec/iter: 0.0309\n",
      "Test set (epoch 385): Average loss: 0.4980, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.167393 (avg: 0.167393) \tsec/iter: 0.0359\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.281342 (avg: 0.170566) \tsec/iter: 0.0306\n",
      "Test set (epoch 386): Average loss: 0.7119, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.153592 (avg: 0.153592) \tsec/iter: 0.0309\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.210361 (avg: 0.177620) \tsec/iter: 0.0296\n",
      "Test set (epoch 387): Average loss: 0.6443, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.237636 (avg: 0.237636) \tsec/iter: 0.0329\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.219454 (avg: 0.228222) \tsec/iter: 0.0303\n",
      "Test set (epoch 388): Average loss: 0.7296, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.126804 (avg: 0.126804) \tsec/iter: 0.0299\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.145783 (avg: 0.142732) \tsec/iter: 0.0339\n",
      "Test set (epoch 389): Average loss: 0.6809, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.107099 (avg: 0.107099) \tsec/iter: 0.0399\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.084723 (avg: 0.120719) \tsec/iter: 0.0352\n",
      "Test set (epoch 390): Average loss: 0.7831, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.163255 (avg: 0.163255) \tsec/iter: 0.0339\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.164953 (avg: 0.147087) \tsec/iter: 0.0293\n",
      "Test set (epoch 391): Average loss: 0.5581, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.192886 (avg: 0.192886) \tsec/iter: 0.0369\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.285733 (avg: 0.193284) \tsec/iter: 0.0339\n",
      "Test set (epoch 392): Average loss: 0.6370, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.218363 (avg: 0.218363) \tsec/iter: 0.0339\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.109297 (avg: 0.157254) \tsec/iter: 0.0316\n",
      "Test set (epoch 393): Average loss: 0.7566, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.151767 (avg: 0.151767) \tsec/iter: 0.0339\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.149267 (avg: 0.149139) \tsec/iter: 0.0316\n",
      "Test set (epoch 394): Average loss: 0.8139, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.114318 (avg: 0.114318) \tsec/iter: 0.0329\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.203228 (avg: 0.167526) \tsec/iter: 0.0296\n",
      "Test set (epoch 395): Average loss: 0.9282, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.133314 (avg: 0.133314) \tsec/iter: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.239991 (avg: 0.192663) \tsec/iter: 0.0306\n",
      "Test set (epoch 396): Average loss: 0.8432, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.180084 (avg: 0.180084) \tsec/iter: 0.0379\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.118870 (avg: 0.136407) \tsec/iter: 0.0306\n",
      "Test set (epoch 397): Average loss: 0.7425, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.085177 (avg: 0.085177) \tsec/iter: 0.0359\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.290176 (avg: 0.153347) \tsec/iter: 0.0303\n",
      "Test set (epoch 398): Average loss: 0.8646, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.103522 (avg: 0.103522) \tsec/iter: 0.0409\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.220057 (avg: 0.150969) \tsec/iter: 0.0366\n",
      "Test set (epoch 399): Average loss: 0.6867, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.097210 (avg: 0.097210) \tsec/iter: 0.0389\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.157265 (avg: 0.140978) \tsec/iter: 0.0336\n",
      "Test set (epoch 400): Average loss: 0.6498, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.091458 (avg: 0.091458) \tsec/iter: 0.0349\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.279699 (avg: 0.165349) \tsec/iter: 0.0329\n",
      "Test set (epoch 401): Average loss: 0.6639, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.137226 (avg: 0.137226) \tsec/iter: 0.0339\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.172713 (avg: 0.170598) \tsec/iter: 0.0326\n",
      "Test set (epoch 402): Average loss: 0.7279, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.105917 (avg: 0.105917) \tsec/iter: 0.0339\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.279890 (avg: 0.160366) \tsec/iter: 0.0303\n",
      "Test set (epoch 403): Average loss: 0.6535, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.095450 (avg: 0.095450) \tsec/iter: 0.0299\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.209392 (avg: 0.181051) \tsec/iter: 0.0303\n",
      "Test set (epoch 404): Average loss: 0.9672, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.136213 (avg: 0.136213) \tsec/iter: 0.0329\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.204598 (avg: 0.152334) \tsec/iter: 0.0309\n",
      "Test set (epoch 405): Average loss: 0.7466, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.145618 (avg: 0.145618) \tsec/iter: 0.0369\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.108759 (avg: 0.131849) \tsec/iter: 0.0309\n",
      "Test set (epoch 406): Average loss: 0.6474, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.153000 (avg: 0.153000) \tsec/iter: 0.0339\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.161573 (avg: 0.140501) \tsec/iter: 0.0312\n",
      "Test set (epoch 407): Average loss: 0.8915, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.231769 (avg: 0.231769) \tsec/iter: 0.0339\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.104679 (avg: 0.148042) \tsec/iter: 0.0346\n",
      "Test set (epoch 408): Average loss: 0.6978, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.225445 (avg: 0.225445) \tsec/iter: 0.0399\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.183256 (avg: 0.189660) \tsec/iter: 0.0376\n",
      "Test set (epoch 409): Average loss: 0.8819, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.112246 (avg: 0.112246) \tsec/iter: 0.0329\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.113576 (avg: 0.156901) \tsec/iter: 0.0312\n",
      "Test set (epoch 410): Average loss: 0.6949, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.110959 (avg: 0.110959) \tsec/iter: 0.0339\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.187707 (avg: 0.202629) \tsec/iter: 0.0322\n",
      "Test set (epoch 411): Average loss: 0.5178, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.178298 (avg: 0.178298) \tsec/iter: 0.0409\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.166213 (avg: 0.157959) \tsec/iter: 0.0339\n",
      "Test set (epoch 412): Average loss: 0.7070, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.098495 (avg: 0.098495) \tsec/iter: 0.0349\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.216727 (avg: 0.137998) \tsec/iter: 0.0299\n",
      "Test set (epoch 413): Average loss: 0.8664, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.096432 (avg: 0.096432) \tsec/iter: 0.0329\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.178154 (avg: 0.127908) \tsec/iter: 0.0289\n",
      "Test set (epoch 414): Average loss: 0.5917, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.133954 (avg: 0.133954) \tsec/iter: 0.0349\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.240594 (avg: 0.176672) \tsec/iter: 0.0319\n",
      "Test set (epoch 415): Average loss: 0.7311, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.186604 (avg: 0.186604) \tsec/iter: 0.0349\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.130709 (avg: 0.149339) \tsec/iter: 0.0316\n",
      "Test set (epoch 416): Average loss: 0.7530, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.145770 (avg: 0.145770) \tsec/iter: 0.0329\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.180940 (avg: 0.145273) \tsec/iter: 0.0296\n",
      "Test set (epoch 417): Average loss: 0.7357, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.087078 (avg: 0.087078) \tsec/iter: 0.0409\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.101181 (avg: 0.111229) \tsec/iter: 0.0372\n",
      "Test set (epoch 418): Average loss: 0.7615, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.111270 (avg: 0.111270) \tsec/iter: 0.0449\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.248274 (avg: 0.134563) \tsec/iter: 0.0379\n",
      "Test set (epoch 419): Average loss: 1.0143, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.196043 (avg: 0.196043) \tsec/iter: 0.0329\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.122625 (avg: 0.164203) \tsec/iter: 0.0306\n",
      "Test set (epoch 420): Average loss: 0.7989, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.139858 (avg: 0.139858) \tsec/iter: 0.0329\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.134934 (avg: 0.172421) \tsec/iter: 0.0336\n",
      "Test set (epoch 421): Average loss: 0.8005, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.099904 (avg: 0.099904) \tsec/iter: 0.0379\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.217701 (avg: 0.131135) \tsec/iter: 0.0336\n",
      "Test set (epoch 422): Average loss: 0.6614, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.131697 (avg: 0.131697) \tsec/iter: 0.0349\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.224514 (avg: 0.148447) \tsec/iter: 0.0322\n",
      "Test set (epoch 423): Average loss: 0.7178, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.109679 (avg: 0.109679) \tsec/iter: 0.0339\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.250751 (avg: 0.141489) \tsec/iter: 0.0309\n",
      "Test set (epoch 424): Average loss: 0.8263, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.087255 (avg: 0.087255) \tsec/iter: 0.0329\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.178512 (avg: 0.137919) \tsec/iter: 0.0296\n",
      "Test set (epoch 425): Average loss: 0.6918, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.131579 (avg: 0.131579) \tsec/iter: 0.0389\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.129464 (avg: 0.170836) \tsec/iter: 0.0326\n",
      "Test set (epoch 426): Average loss: 0.7707, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.167388 (avg: 0.167388) \tsec/iter: 0.0309\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.206433 (avg: 0.148176) \tsec/iter: 0.0339\n",
      "Test set (epoch 427): Average loss: 0.5863, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.154389 (avg: 0.154389) \tsec/iter: 0.0409\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.168848 (avg: 0.133415) \tsec/iter: 0.0336\n",
      "Test set (epoch 428): Average loss: 0.5952, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.097849 (avg: 0.097849) \tsec/iter: 0.0369\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.323330 (avg: 0.162823) \tsec/iter: 0.0326\n",
      "Test set (epoch 429): Average loss: 0.9303, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.228140 (avg: 0.228140) \tsec/iter: 0.0329\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.121146 (avg: 0.163728) \tsec/iter: 0.0296\n",
      "Test set (epoch 430): Average loss: 0.7045, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.196957 (avg: 0.196957) \tsec/iter: 0.0319\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.177792 (avg: 0.190070) \tsec/iter: 0.0309\n",
      "Test set (epoch 431): Average loss: 0.6032, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.172324 (avg: 0.172324) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.097561 (avg: 0.137605) \tsec/iter: 0.0326\n",
      "Test set (epoch 432): Average loss: 0.5261, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.235374 (avg: 0.235374) \tsec/iter: 0.0389\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.138060 (avg: 0.177145) \tsec/iter: 0.0319\n",
      "Test set (epoch 433): Average loss: 0.6911, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.157284 (avg: 0.157284) \tsec/iter: 0.0329\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.135266 (avg: 0.152592) \tsec/iter: 0.0326\n",
      "Test set (epoch 434): Average loss: 0.4843, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.129667 (avg: 0.129667) \tsec/iter: 0.0309\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.285133 (avg: 0.157561) \tsec/iter: 0.0322\n",
      "Test set (epoch 435): Average loss: 0.7775, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.121810 (avg: 0.121810) \tsec/iter: 0.0319\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.387296 (avg: 0.176503) \tsec/iter: 0.0303\n",
      "Test set (epoch 436): Average loss: 0.7402, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.164968 (avg: 0.164968) \tsec/iter: 0.0409\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.115226 (avg: 0.193878) \tsec/iter: 0.0362\n",
      "Test set (epoch 437): Average loss: 0.9282, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.242315 (avg: 0.242315) \tsec/iter: 0.0369\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.135346 (avg: 0.161749) \tsec/iter: 0.0316\n",
      "Test set (epoch 438): Average loss: 0.8933, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.091763 (avg: 0.091763) \tsec/iter: 0.0349\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.188749 (avg: 0.127939) \tsec/iter: 0.0306\n",
      "Test set (epoch 439): Average loss: 0.4930, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.095296 (avg: 0.095296) \tsec/iter: 0.0379\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.372026 (avg: 0.204213) \tsec/iter: 0.0342\n",
      "Test set (epoch 440): Average loss: 0.6761, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.153298 (avg: 0.153298) \tsec/iter: 0.0359\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.256039 (avg: 0.187329) \tsec/iter: 0.0322\n",
      "Test set (epoch 441): Average loss: 0.6754, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.174309 (avg: 0.174309) \tsec/iter: 0.0359\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.222967 (avg: 0.202264) \tsec/iter: 0.0336\n",
      "Test set (epoch 442): Average loss: 0.5654, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.165984 (avg: 0.165984) \tsec/iter: 0.0369\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.229921 (avg: 0.158506) \tsec/iter: 0.0303\n",
      "Test set (epoch 443): Average loss: 0.7938, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.145979 (avg: 0.145979) \tsec/iter: 0.0309\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.228487 (avg: 0.155147) \tsec/iter: 0.0322\n",
      "Test set (epoch 444): Average loss: 0.8004, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.212382 (avg: 0.212382) \tsec/iter: 0.0349\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.112018 (avg: 0.161582) \tsec/iter: 0.0319\n",
      "Test set (epoch 445): Average loss: 0.5057, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.182976 (avg: 0.182976) \tsec/iter: 0.0349\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.149116 (avg: 0.135591) \tsec/iter: 0.0356\n",
      "Test set (epoch 446): Average loss: 0.7351, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.145710 (avg: 0.145710) \tsec/iter: 0.0449\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.120310 (avg: 0.148980) \tsec/iter: 0.0356\n",
      "Test set (epoch 447): Average loss: 0.5988, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.127126 (avg: 0.127126) \tsec/iter: 0.0309\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.187966 (avg: 0.160904) \tsec/iter: 0.0306\n",
      "Test set (epoch 448): Average loss: 0.5027, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.087820 (avg: 0.087820) \tsec/iter: 0.0359\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.159456 (avg: 0.123093) \tsec/iter: 0.0339\n",
      "Test set (epoch 449): Average loss: 0.6220, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.132123 (avg: 0.132123) \tsec/iter: 0.0329\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.080047 (avg: 0.147427) \tsec/iter: 0.0322\n",
      "Test set (epoch 450): Average loss: 0.7124, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.186700 (avg: 0.186700) \tsec/iter: 0.0399\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.182799 (avg: 0.155935) \tsec/iter: 0.0319\n",
      "Test set (epoch 451): Average loss: 0.6746, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.154657 (avg: 0.154657) \tsec/iter: 0.0329\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.085775 (avg: 0.148963) \tsec/iter: 0.0339\n",
      "Test set (epoch 452): Average loss: 0.6405, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.155600 (avg: 0.155600) \tsec/iter: 0.0379\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.154290 (avg: 0.189389) \tsec/iter: 0.0342\n",
      "Test set (epoch 453): Average loss: 0.7935, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.161992 (avg: 0.161992) \tsec/iter: 0.0329\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.089045 (avg: 0.129341) \tsec/iter: 0.0306\n",
      "Test set (epoch 454): Average loss: 0.6027, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.114084 (avg: 0.114084) \tsec/iter: 0.0329\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.119884 (avg: 0.111934) \tsec/iter: 0.0332\n",
      "Test set (epoch 455): Average loss: 0.9006, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.100591 (avg: 0.100591) \tsec/iter: 0.0429\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.207168 (avg: 0.152884) \tsec/iter: 0.0376\n",
      "Test set (epoch 456): Average loss: 0.6154, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.118510 (avg: 0.118510) \tsec/iter: 0.0329\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.320647 (avg: 0.175229) \tsec/iter: 0.0296\n",
      "Test set (epoch 457): Average loss: 0.7816, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.184290 (avg: 0.184290) \tsec/iter: 0.0349\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.084053 (avg: 0.161185) \tsec/iter: 0.0319\n",
      "Test set (epoch 458): Average loss: 0.9090, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.084762 (avg: 0.084762) \tsec/iter: 0.0319\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.179561 (avg: 0.154242) \tsec/iter: 0.0303\n",
      "Test set (epoch 459): Average loss: 0.6605, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.134808 (avg: 0.134808) \tsec/iter: 0.0329\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.157951 (avg: 0.122073) \tsec/iter: 0.0322\n",
      "Test set (epoch 460): Average loss: 0.7525, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.162880 (avg: 0.162880) \tsec/iter: 0.0369\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.109303 (avg: 0.161048) \tsec/iter: 0.0319\n",
      "Test set (epoch 461): Average loss: 0.4730, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.118298 (avg: 0.118298) \tsec/iter: 0.0349\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.112142 (avg: 0.113588) \tsec/iter: 0.0322\n",
      "Test set (epoch 462): Average loss: 0.7427, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.208981 (avg: 0.208981) \tsec/iter: 0.0309\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.112346 (avg: 0.153160) \tsec/iter: 0.0293\n",
      "Test set (epoch 463): Average loss: 0.7603, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.212113 (avg: 0.212113) \tsec/iter: 0.0329\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.079764 (avg: 0.153584) \tsec/iter: 0.0309\n",
      "Test set (epoch 464): Average loss: 0.8790, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.151918 (avg: 0.151918) \tsec/iter: 0.0419\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.114069 (avg: 0.161416) \tsec/iter: 0.0372\n",
      "Test set (epoch 465): Average loss: 1.1624, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.225944 (avg: 0.225944) \tsec/iter: 0.0479\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.071674 (avg: 0.167995) \tsec/iter: 0.0379\n",
      "Test set (epoch 466): Average loss: 0.5464, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.150598 (avg: 0.150598) \tsec/iter: 0.0329\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.133562 (avg: 0.148165) \tsec/iter: 0.0303\n",
      "Test set (epoch 467): Average loss: 0.6338, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.154713 (avg: 0.154713) \tsec/iter: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.152756 (avg: 0.129193) \tsec/iter: 0.0346\n",
      "Test set (epoch 468): Average loss: 0.6480, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.319384 (avg: 0.319384) \tsec/iter: 0.0389\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.186766 (avg: 0.214622) \tsec/iter: 0.0346\n",
      "Test set (epoch 469): Average loss: 0.7947, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.165795 (avg: 0.165795) \tsec/iter: 0.0379\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.175436 (avg: 0.135153) \tsec/iter: 0.0336\n",
      "Test set (epoch 470): Average loss: 0.6289, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.175237 (avg: 0.175237) \tsec/iter: 0.0339\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.076998 (avg: 0.187986) \tsec/iter: 0.0299\n",
      "Test set (epoch 471): Average loss: 0.6785, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.167779 (avg: 0.167779) \tsec/iter: 0.0359\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.171366 (avg: 0.180174) \tsec/iter: 0.0313\n",
      "Test set (epoch 472): Average loss: 0.8714, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.187330 (avg: 0.187330) \tsec/iter: 0.0359\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.254258 (avg: 0.200124) \tsec/iter: 0.0319\n",
      "Test set (epoch 473): Average loss: 0.8740, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.078828 (avg: 0.078828) \tsec/iter: 0.0429\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.236326 (avg: 0.148931) \tsec/iter: 0.0386\n",
      "Test set (epoch 474): Average loss: 0.7722, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.177732 (avg: 0.177732) \tsec/iter: 0.0439\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.164525 (avg: 0.182142) \tsec/iter: 0.0382\n",
      "Test set (epoch 475): Average loss: 0.6621, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.242724 (avg: 0.242724) \tsec/iter: 0.0349\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.095726 (avg: 0.186769) \tsec/iter: 0.0306\n",
      "Test set (epoch 476): Average loss: 0.5677, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.154804 (avg: 0.154804) \tsec/iter: 0.0329\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.109392 (avg: 0.127752) \tsec/iter: 0.0303\n",
      "Test set (epoch 477): Average loss: 0.7726, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.238805 (avg: 0.238805) \tsec/iter: 0.0329\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.127231 (avg: 0.162417) \tsec/iter: 0.0332\n",
      "Test set (epoch 478): Average loss: 0.5965, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.298891 (avg: 0.298891) \tsec/iter: 0.0399\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.256522 (avg: 0.252849) \tsec/iter: 0.0366\n",
      "Test set (epoch 479): Average loss: 0.6564, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.191158 (avg: 0.191158) \tsec/iter: 0.0379\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.223426 (avg: 0.174958) \tsec/iter: 0.0312\n",
      "Test set (epoch 480): Average loss: 0.6656, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.127188 (avg: 0.127188) \tsec/iter: 0.0349\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.225122 (avg: 0.156605) \tsec/iter: 0.0312\n",
      "Test set (epoch 481): Average loss: 0.7049, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.142414 (avg: 0.142414) \tsec/iter: 0.0369\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.201551 (avg: 0.174969) \tsec/iter: 0.0329\n",
      "Test set (epoch 482): Average loss: 0.5536, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.143419 (avg: 0.143419) \tsec/iter: 0.0449\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.126478 (avg: 0.160794) \tsec/iter: 0.0386\n",
      "Test set (epoch 483): Average loss: 0.6235, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.171810 (avg: 0.171810) \tsec/iter: 0.0419\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.169773 (avg: 0.136040) \tsec/iter: 0.0369\n",
      "Test set (epoch 484): Average loss: 0.6230, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.194547 (avg: 0.194547) \tsec/iter: 0.0349\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.159279 (avg: 0.165168) \tsec/iter: 0.0322\n",
      "Test set (epoch 485): Average loss: 0.6735, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.198806 (avg: 0.198806) \tsec/iter: 0.0319\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.209295 (avg: 0.177934) \tsec/iter: 0.0309\n",
      "Test set (epoch 486): Average loss: 0.7455, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.129516 (avg: 0.129516) \tsec/iter: 0.0329\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.288115 (avg: 0.213003) \tsec/iter: 0.0316\n",
      "Test set (epoch 487): Average loss: 0.8037, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.148830 (avg: 0.148830) \tsec/iter: 0.0359\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.139334 (avg: 0.141212) \tsec/iter: 0.0336\n",
      "Test set (epoch 488): Average loss: 0.6095, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.173203 (avg: 0.173203) \tsec/iter: 0.0369\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.214191 (avg: 0.206657) \tsec/iter: 0.0329\n",
      "Test set (epoch 489): Average loss: 0.8680, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.248516 (avg: 0.248516) \tsec/iter: 0.0389\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.065249 (avg: 0.182011) \tsec/iter: 0.0332\n",
      "Test set (epoch 490): Average loss: 0.6719, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.171591 (avg: 0.171591) \tsec/iter: 0.0329\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.305921 (avg: 0.185232) \tsec/iter: 0.0309\n",
      "Test set (epoch 491): Average loss: 0.6470, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.147775 (avg: 0.147775) \tsec/iter: 0.0419\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.107039 (avg: 0.148564) \tsec/iter: 0.0406\n",
      "Test set (epoch 492): Average loss: 0.5358, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.099433 (avg: 0.099433) \tsec/iter: 0.0419\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.205560 (avg: 0.121166) \tsec/iter: 0.0372\n",
      "Test set (epoch 493): Average loss: 0.7002, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.144715 (avg: 0.144715) \tsec/iter: 0.0369\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.336783 (avg: 0.177875) \tsec/iter: 0.0346\n",
      "Test set (epoch 494): Average loss: 0.5730, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.256157 (avg: 0.256157) \tsec/iter: 0.0369\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.105044 (avg: 0.164496) \tsec/iter: 0.0326\n",
      "Test set (epoch 495): Average loss: 0.5138, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.149715 (avg: 0.149715) \tsec/iter: 0.0399\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.089565 (avg: 0.139225) \tsec/iter: 0.0356\n",
      "Test set (epoch 496): Average loss: 0.7813, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.090953 (avg: 0.090953) \tsec/iter: 0.0399\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.166321 (avg: 0.131816) \tsec/iter: 0.0409\n",
      "Test set (epoch 497): Average loss: 0.6975, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.169505 (avg: 0.169505) \tsec/iter: 0.0449\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.142525 (avg: 0.157037) \tsec/iter: 0.0409\n",
      "Test set (epoch 498): Average loss: 0.6063, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.106422 (avg: 0.106422) \tsec/iter: 0.0489\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.111257 (avg: 0.139299) \tsec/iter: 0.0382\n",
      "Test set (epoch 499): Average loss: 0.5491, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "\n",
      "FOLD 8\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 2.563616 (avg: 2.563616) \tsec/iter: 0.0379\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 0.653452 (avg: 6.376418) \tsec/iter: 0.0362\n",
      "Test set (epoch 0): Average loss: 1.9928, Accuracy: 9/18 (50.00%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 2.312578 (avg: 2.312578) \tsec/iter: 0.0439\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.745913 (avg: 1.459227) \tsec/iter: 0.0369\n",
      "Test set (epoch 1): Average loss: 0.3614, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 0.342689 (avg: 0.342689) \tsec/iter: 0.0349\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 1.092085 (avg: 0.634839) \tsec/iter: 0.0322\n",
      "Test set (epoch 2): Average loss: 0.5403, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.521725 (avg: 0.521725) \tsec/iter: 0.0379\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.516573 (avg: 0.528241) \tsec/iter: 0.0322\n",
      "Test set (epoch 3): Average loss: 0.8617, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.747000 (avg: 0.747000) \tsec/iter: 0.0419\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 1.712127 (avg: 1.136229) \tsec/iter: 0.0359\n",
      "Test set (epoch 4): Average loss: 1.7941, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.542597 (avg: 0.542597) \tsec/iter: 0.0329\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.171471 (avg: 0.554787) \tsec/iter: 0.0296\n",
      "Test set (epoch 5): Average loss: 0.2689, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.570058 (avg: 0.570058) \tsec/iter: 0.0319\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.806711 (avg: 0.571051) \tsec/iter: 0.0326\n",
      "Test set (epoch 6): Average loss: 1.1287, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.466071 (avg: 0.466071) \tsec/iter: 0.0309\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.568183 (avg: 0.494687) \tsec/iter: 0.0326\n",
      "Test set (epoch 7): Average loss: 1.1752, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.471437 (avg: 0.471437) \tsec/iter: 0.0299\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.425842 (avg: 0.458749) \tsec/iter: 0.0293\n",
      "Test set (epoch 8): Average loss: 0.7422, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.447002 (avg: 0.447002) \tsec/iter: 0.0339\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.463058 (avg: 0.406984) \tsec/iter: 0.0316\n",
      "Test set (epoch 9): Average loss: 0.8902, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.330801 (avg: 0.330801) \tsec/iter: 0.0419\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.552403 (avg: 0.467761) \tsec/iter: 0.0386\n",
      "Test set (epoch 10): Average loss: 0.8849, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.408460 (avg: 0.408460) \tsec/iter: 0.0359\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.536907 (avg: 0.418040) \tsec/iter: 0.0336\n",
      "Test set (epoch 11): Average loss: 0.6201, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.657662 (avg: 0.657662) \tsec/iter: 0.0389\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.384377 (avg: 0.545346) \tsec/iter: 0.0322\n",
      "Test set (epoch 12): Average loss: 0.5831, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.720977 (avg: 0.720977) \tsec/iter: 0.0379\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.529606 (avg: 0.644638) \tsec/iter: 0.0329\n",
      "Test set (epoch 13): Average loss: 0.5706, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 0.411417 (avg: 0.411417) \tsec/iter: 0.0339\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.364662 (avg: 0.389009) \tsec/iter: 0.0309\n",
      "Test set (epoch 14): Average loss: 0.7156, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.451774 (avg: 0.451774) \tsec/iter: 0.0379\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.333635 (avg: 0.411258) \tsec/iter: 0.0309\n",
      "Test set (epoch 15): Average loss: 0.6178, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.583205 (avg: 0.583205) \tsec/iter: 0.0409\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.323089 (avg: 0.473797) \tsec/iter: 0.0326\n",
      "Test set (epoch 16): Average loss: 0.5288, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.498749 (avg: 0.498749) \tsec/iter: 0.0319\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.544622 (avg: 0.439370) \tsec/iter: 0.0339\n",
      "Test set (epoch 17): Average loss: 0.4358, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.730385 (avg: 0.730385) \tsec/iter: 0.0349\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.478980 (avg: 0.513360) \tsec/iter: 0.0309\n",
      "Test set (epoch 18): Average loss: 0.6645, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.344013 (avg: 0.344013) \tsec/iter: 0.0379\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.444175 (avg: 0.390315) \tsec/iter: 0.0349\n",
      "Test set (epoch 19): Average loss: 0.5596, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.402796 (avg: 0.402796) \tsec/iter: 0.0439\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.374473 (avg: 0.409693) \tsec/iter: 0.0366\n",
      "Test set (epoch 20): Average loss: 0.6098, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.401105 (avg: 0.401105) \tsec/iter: 0.0469\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.353825 (avg: 0.368025) \tsec/iter: 0.0359\n",
      "Test set (epoch 21): Average loss: 0.5410, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.381457 (avg: 0.381457) \tsec/iter: 0.0309\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.368129 (avg: 0.373125) \tsec/iter: 0.0289\n",
      "Test set (epoch 22): Average loss: 0.6154, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.362417 (avg: 0.362417) \tsec/iter: 0.0329\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.407681 (avg: 0.382703) \tsec/iter: 0.0306\n",
      "Test set (epoch 23): Average loss: 0.6491, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.336074 (avg: 0.336074) \tsec/iter: 0.0349\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.387579 (avg: 0.373799) \tsec/iter: 0.0299\n",
      "Test set (epoch 24): Average loss: 0.6165, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.372141 (avg: 0.372141) \tsec/iter: 0.0349\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.480585 (avg: 0.373729) \tsec/iter: 0.0339\n",
      "Test set (epoch 25): Average loss: 0.6524, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.352048 (avg: 0.352048) \tsec/iter: 0.0359\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.404820 (avg: 0.359082) \tsec/iter: 0.0326\n",
      "Test set (epoch 26): Average loss: 0.7550, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.415865 (avg: 0.415865) \tsec/iter: 0.0499\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.327869 (avg: 0.381710) \tsec/iter: 0.0382\n",
      "Test set (epoch 27): Average loss: 0.6825, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.426359 (avg: 0.426359) \tsec/iter: 0.0379\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.367646 (avg: 0.390914) \tsec/iter: 0.0366\n",
      "Test set (epoch 28): Average loss: 0.7032, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.325097 (avg: 0.325097) \tsec/iter: 0.0409\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.412291 (avg: 0.396405) \tsec/iter: 0.0342\n",
      "Test set (epoch 29): Average loss: 0.6638, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.378039 (avg: 0.378039) \tsec/iter: 0.0409\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.299312 (avg: 0.353384) \tsec/iter: 0.0356\n",
      "Test set (epoch 30): Average loss: 0.6431, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.475932 (avg: 0.475932) \tsec/iter: 0.0379\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.302869 (avg: 0.370695) \tsec/iter: 0.0339\n",
      "Test set (epoch 31): Average loss: 0.5708, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.441122 (avg: 0.441122) \tsec/iter: 0.0339\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.352858 (avg: 0.384349) \tsec/iter: 0.0306\n",
      "Test set (epoch 32): Average loss: 0.6414, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.403175 (avg: 0.403175) \tsec/iter: 0.0359\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.490495 (avg: 0.418900) \tsec/iter: 0.0332\n",
      "Test set (epoch 33): Average loss: 0.5762, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.396837 (avg: 0.396837) \tsec/iter: 0.0379\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.332922 (avg: 0.377724) \tsec/iter: 0.0316\n",
      "Test set (epoch 34): Average loss: 0.6621, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.332915 (avg: 0.332915) \tsec/iter: 0.0379\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.475122 (avg: 0.372136) \tsec/iter: 0.0332\n",
      "Test set (epoch 35): Average loss: 0.6104, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.394365 (avg: 0.394365) \tsec/iter: 0.0349\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.300086 (avg: 0.359939) \tsec/iter: 0.0332\n",
      "Test set (epoch 36): Average loss: 0.5459, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.467799 (avg: 0.467799) \tsec/iter: 0.0309\n",
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.317620 (avg: 0.380601) \tsec/iter: 0.0336\n",
      "Test set (epoch 37): Average loss: 0.5562, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.344898 (avg: 0.344898) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.437421 (avg: 0.426533) \tsec/iter: 0.0369\n",
      "Test set (epoch 38): Average loss: 0.5503, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.360435 (avg: 0.360435) \tsec/iter: 0.0389\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.452585 (avg: 0.386894) \tsec/iter: 0.0326\n",
      "Test set (epoch 39): Average loss: 0.5578, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.420818 (avg: 0.420818) \tsec/iter: 0.0359\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.294707 (avg: 0.366469) \tsec/iter: 0.0309\n",
      "Test set (epoch 40): Average loss: 0.4991, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.331518 (avg: 0.331518) \tsec/iter: 0.0369\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.323216 (avg: 0.357435) \tsec/iter: 0.0336\n",
      "Test set (epoch 41): Average loss: 0.5620, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.290718 (avg: 0.290718) \tsec/iter: 0.0339\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.306498 (avg: 0.378221) \tsec/iter: 0.0312\n",
      "Test set (epoch 42): Average loss: 0.5363, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.438484 (avg: 0.438484) \tsec/iter: 0.0389\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.390515 (avg: 0.384257) \tsec/iter: 0.0356\n",
      "Test set (epoch 43): Average loss: 0.5555, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.300475 (avg: 0.300475) \tsec/iter: 0.0319\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.232190 (avg: 0.377096) \tsec/iter: 0.0303\n",
      "Test set (epoch 44): Average loss: 0.5399, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.449370 (avg: 0.449370) \tsec/iter: 0.0349\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.292232 (avg: 0.358752) \tsec/iter: 0.0309\n",
      "Test set (epoch 45): Average loss: 0.5746, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.389670 (avg: 0.389670) \tsec/iter: 0.0329\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.392048 (avg: 0.374478) \tsec/iter: 0.0319\n",
      "Test set (epoch 46): Average loss: 0.5297, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.254124 (avg: 0.254124) \tsec/iter: 0.0399\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.462215 (avg: 0.345647) \tsec/iter: 0.0359\n",
      "Test set (epoch 47): Average loss: 0.5533, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.282667 (avg: 0.282667) \tsec/iter: 0.0389\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.362062 (avg: 0.361006) \tsec/iter: 0.0349\n",
      "Test set (epoch 48): Average loss: 0.5944, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.325961 (avg: 0.325961) \tsec/iter: 0.0339\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.435816 (avg: 0.392090) \tsec/iter: 0.0299\n",
      "Test set (epoch 49): Average loss: 0.4971, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.385827 (avg: 0.385827) \tsec/iter: 0.0309\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.433602 (avg: 0.373699) \tsec/iter: 0.0289\n",
      "Test set (epoch 50): Average loss: 0.4956, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.330396 (avg: 0.330396) \tsec/iter: 0.0379\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.349038 (avg: 0.356009) \tsec/iter: 0.0326\n",
      "Test set (epoch 51): Average loss: 0.5601, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.357738 (avg: 0.357738) \tsec/iter: 0.0309\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.336791 (avg: 0.361395) \tsec/iter: 0.0296\n",
      "Test set (epoch 52): Average loss: 0.5092, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.337697 (avg: 0.337697) \tsec/iter: 0.0329\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.523176 (avg: 0.378258) \tsec/iter: 0.0299\n",
      "Test set (epoch 53): Average loss: 0.4836, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.416186 (avg: 0.416186) \tsec/iter: 0.0399\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.436098 (avg: 0.362055) \tsec/iter: 0.0346\n",
      "Test set (epoch 54): Average loss: 0.5658, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.268500 (avg: 0.268500) \tsec/iter: 0.0349\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.470423 (avg: 0.357650) \tsec/iter: 0.0309\n",
      "Test set (epoch 55): Average loss: 0.5014, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.338758 (avg: 0.338758) \tsec/iter: 0.0349\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.500429 (avg: 0.383816) \tsec/iter: 0.0352\n",
      "Test set (epoch 56): Average loss: 0.5568, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.263017 (avg: 0.263017) \tsec/iter: 0.0449\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.390677 (avg: 0.373060) \tsec/iter: 0.0372\n",
      "Test set (epoch 57): Average loss: 0.5353, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.350129 (avg: 0.350129) \tsec/iter: 0.0339\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.451646 (avg: 0.355366) \tsec/iter: 0.0316\n",
      "Test set (epoch 58): Average loss: 0.4807, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.386399 (avg: 0.386399) \tsec/iter: 0.0339\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.319139 (avg: 0.351219) \tsec/iter: 0.0306\n",
      "Test set (epoch 59): Average loss: 0.4712, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.298445 (avg: 0.298445) \tsec/iter: 0.0349\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.361029 (avg: 0.368715) \tsec/iter: 0.0303\n",
      "Test set (epoch 60): Average loss: 0.4886, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.334385 (avg: 0.334385) \tsec/iter: 0.0359\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.386736 (avg: 0.352936) \tsec/iter: 0.0312\n",
      "Test set (epoch 61): Average loss: 0.4496, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.446006 (avg: 0.446006) \tsec/iter: 0.0369\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.340325 (avg: 0.352769) \tsec/iter: 0.0312\n",
      "Test set (epoch 62): Average loss: 0.5263, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.270103 (avg: 0.270103) \tsec/iter: 0.0369\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.597861 (avg: 0.363269) \tsec/iter: 0.0306\n",
      "Test set (epoch 63): Average loss: 0.5149, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.357787 (avg: 0.357787) \tsec/iter: 0.0319\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.373641 (avg: 0.364501) \tsec/iter: 0.0293\n",
      "Test set (epoch 64): Average loss: 0.5003, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.388949 (avg: 0.388949) \tsec/iter: 0.0329\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.472336 (avg: 0.382657) \tsec/iter: 0.0299\n",
      "Test set (epoch 65): Average loss: 0.5111, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.335273 (avg: 0.335273) \tsec/iter: 0.0389\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.370268 (avg: 0.374273) \tsec/iter: 0.0379\n",
      "Test set (epoch 66): Average loss: 0.4162, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.477969 (avg: 0.477969) \tsec/iter: 0.0359\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.310154 (avg: 0.347997) \tsec/iter: 0.0332\n",
      "Test set (epoch 67): Average loss: 0.3964, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.370718 (avg: 0.370718) \tsec/iter: 0.0349\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.269023 (avg: 0.356455) \tsec/iter: 0.0296\n",
      "Test set (epoch 68): Average loss: 0.4171, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.251221 (avg: 0.251221) \tsec/iter: 0.0399\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.369498 (avg: 0.350950) \tsec/iter: 0.0342\n",
      "Test set (epoch 69): Average loss: 0.3606, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.267221 (avg: 0.267221) \tsec/iter: 0.0329\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.471700 (avg: 0.336511) \tsec/iter: 0.0339\n",
      "Test set (epoch 70): Average loss: 0.4030, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.336401 (avg: 0.336401) \tsec/iter: 0.0329\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.315155 (avg: 0.324127) \tsec/iter: 0.0316\n",
      "Test set (epoch 71): Average loss: 0.4321, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.443900 (avg: 0.443900) \tsec/iter: 0.0379\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.202366 (avg: 0.350402) \tsec/iter: 0.0316\n",
      "Test set (epoch 72): Average loss: 0.3761, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.438406 (avg: 0.438406) \tsec/iter: 0.0339\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.182586 (avg: 0.339072) \tsec/iter: 0.0312\n",
      "Test set (epoch 73): Average loss: 0.3675, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.289557 (avg: 0.289557) \tsec/iter: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.344516 (avg: 0.328806) \tsec/iter: 0.0299\n",
      "Test set (epoch 74): Average loss: 0.4183, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.346044 (avg: 0.346044) \tsec/iter: 0.0309\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.270234 (avg: 0.351594) \tsec/iter: 0.0349\n",
      "Test set (epoch 75): Average loss: 0.3471, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.314960 (avg: 0.314960) \tsec/iter: 0.0429\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.457757 (avg: 0.359736) \tsec/iter: 0.0376\n",
      "Test set (epoch 76): Average loss: 0.3985, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.304823 (avg: 0.304823) \tsec/iter: 0.0359\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.354000 (avg: 0.341078) \tsec/iter: 0.0306\n",
      "Test set (epoch 77): Average loss: 0.4272, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.357439 (avg: 0.357439) \tsec/iter: 0.0299\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.410029 (avg: 0.349935) \tsec/iter: 0.0289\n",
      "Test set (epoch 78): Average loss: 0.3778, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.342748 (avg: 0.342748) \tsec/iter: 0.0309\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.380073 (avg: 0.362089) \tsec/iter: 0.0303\n",
      "Test set (epoch 79): Average loss: 0.3384, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.347693 (avg: 0.347693) \tsec/iter: 0.0319\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.266350 (avg: 0.301721) \tsec/iter: 0.0299\n",
      "Test set (epoch 80): Average loss: 0.3634, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.319057 (avg: 0.319057) \tsec/iter: 0.0319\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.277788 (avg: 0.342239) \tsec/iter: 0.0309\n",
      "Test set (epoch 81): Average loss: 0.3848, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.257575 (avg: 0.257575) \tsec/iter: 0.0359\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.442232 (avg: 0.324761) \tsec/iter: 0.0342\n",
      "Test set (epoch 82): Average loss: 0.3930, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.378904 (avg: 0.378904) \tsec/iter: 0.0329\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.274658 (avg: 0.336254) \tsec/iter: 0.0299\n",
      "Test set (epoch 83): Average loss: 0.3443, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.380957 (avg: 0.380957) \tsec/iter: 0.0419\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.311166 (avg: 0.336425) \tsec/iter: 0.0379\n",
      "Test set (epoch 84): Average loss: 0.3762, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.278100 (avg: 0.278100) \tsec/iter: 0.0399\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.342333 (avg: 0.335805) \tsec/iter: 0.0362\n",
      "Test set (epoch 85): Average loss: 0.3542, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.302293 (avg: 0.302293) \tsec/iter: 0.0359\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.407429 (avg: 0.345634) \tsec/iter: 0.0339\n",
      "Test set (epoch 86): Average loss: 0.3976, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.345300 (avg: 0.345300) \tsec/iter: 0.0339\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.402503 (avg: 0.310110) \tsec/iter: 0.0322\n",
      "Test set (epoch 87): Average loss: 0.3716, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.275404 (avg: 0.275404) \tsec/iter: 0.0329\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.441777 (avg: 0.349723) \tsec/iter: 0.0303\n",
      "Test set (epoch 88): Average loss: 0.3919, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.242559 (avg: 0.242559) \tsec/iter: 0.0309\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.388181 (avg: 0.309910) \tsec/iter: 0.0299\n",
      "Test set (epoch 89): Average loss: 0.3139, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.402571 (avg: 0.402571) \tsec/iter: 0.0329\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.238078 (avg: 0.332958) \tsec/iter: 0.0309\n",
      "Test set (epoch 90): Average loss: 0.3480, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.427128 (avg: 0.427128) \tsec/iter: 0.0339\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.258473 (avg: 0.347004) \tsec/iter: 0.0322\n",
      "Test set (epoch 91): Average loss: 0.3227, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.381233 (avg: 0.381233) \tsec/iter: 0.0329\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.285974 (avg: 0.332586) \tsec/iter: 0.0289\n",
      "Test set (epoch 92): Average loss: 0.3382, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.392402 (avg: 0.392402) \tsec/iter: 0.0299\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.277258 (avg: 0.313181) \tsec/iter: 0.0312\n",
      "Test set (epoch 93): Average loss: 0.3431, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.395954 (avg: 0.395954) \tsec/iter: 0.0329\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.350583 (avg: 0.324160) \tsec/iter: 0.0339\n",
      "Test set (epoch 94): Average loss: 0.3637, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.354339 (avg: 0.354339) \tsec/iter: 0.0419\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.295977 (avg: 0.327615) \tsec/iter: 0.0369\n",
      "Test set (epoch 95): Average loss: 0.3297, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.345963 (avg: 0.345963) \tsec/iter: 0.0309\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.308588 (avg: 0.334288) \tsec/iter: 0.0309\n",
      "Test set (epoch 96): Average loss: 0.4072, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.260516 (avg: 0.260516) \tsec/iter: 0.0319\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.368828 (avg: 0.310779) \tsec/iter: 0.0329\n",
      "Test set (epoch 97): Average loss: 0.3110, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.391186 (avg: 0.391186) \tsec/iter: 0.0349\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.240184 (avg: 0.323576) \tsec/iter: 0.0336\n",
      "Test set (epoch 98): Average loss: 0.3309, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.312306 (avg: 0.312306) \tsec/iter: 0.0379\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.415847 (avg: 0.351377) \tsec/iter: 0.0332\n",
      "Test set (epoch 99): Average loss: 0.3662, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.299180 (avg: 0.299180) \tsec/iter: 0.0369\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.239926 (avg: 0.339377) \tsec/iter: 0.0329\n",
      "Test set (epoch 100): Average loss: 0.4027, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.316696 (avg: 0.316696) \tsec/iter: 0.0369\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.290851 (avg: 0.333815) \tsec/iter: 0.0336\n",
      "Test set (epoch 101): Average loss: 0.2992, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.318604 (avg: 0.318604) \tsec/iter: 0.0319\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.440946 (avg: 0.345896) \tsec/iter: 0.0283\n",
      "Test set (epoch 102): Average loss: 0.3184, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.336108 (avg: 0.336108) \tsec/iter: 0.0319\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.211110 (avg: 0.300971) \tsec/iter: 0.0482\n",
      "Test set (epoch 103): Average loss: 0.3449, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.378394 (avg: 0.378394) \tsec/iter: 0.0439\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.292735 (avg: 0.314702) \tsec/iter: 0.0379\n",
      "Test set (epoch 104): Average loss: 0.2921, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.266231 (avg: 0.266231) \tsec/iter: 0.0389\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.392474 (avg: 0.301794) \tsec/iter: 0.0339\n",
      "Test set (epoch 105): Average loss: 0.3166, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.325691 (avg: 0.325691) \tsec/iter: 0.0399\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.385549 (avg: 0.333088) \tsec/iter: 0.0339\n",
      "Test set (epoch 106): Average loss: 0.3387, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.329858 (avg: 0.329858) \tsec/iter: 0.0389\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.187886 (avg: 0.327196) \tsec/iter: 0.0322\n",
      "Test set (epoch 107): Average loss: 0.3020, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.273515 (avg: 0.273515) \tsec/iter: 0.0309\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.314235 (avg: 0.313618) \tsec/iter: 0.0293\n",
      "Test set (epoch 108): Average loss: 0.2833, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.323434 (avg: 0.323434) \tsec/iter: 0.0339\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.324581 (avg: 0.322316) \tsec/iter: 0.0299\n",
      "Test set (epoch 109): Average loss: 0.3111, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.318384 (avg: 0.318384) \tsec/iter: 0.0369\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.295581 (avg: 0.319649) \tsec/iter: 0.0319\n",
      "Test set (epoch 110): Average loss: 0.3046, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.209534 (avg: 0.209534) \tsec/iter: 0.0349\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.304049 (avg: 0.303985) \tsec/iter: 0.0303\n",
      "Test set (epoch 111): Average loss: 0.3384, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.342775 (avg: 0.342775) \tsec/iter: 0.0379\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.398633 (avg: 0.318758) \tsec/iter: 0.0349\n",
      "Test set (epoch 112): Average loss: 0.2976, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.316077 (avg: 0.316077) \tsec/iter: 0.0389\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.258379 (avg: 0.311673) \tsec/iter: 0.0362\n",
      "Test set (epoch 113): Average loss: 0.3446, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.260004 (avg: 0.260004) \tsec/iter: 0.0349\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.354962 (avg: 0.327717) \tsec/iter: 0.0322\n",
      "Test set (epoch 114): Average loss: 0.3354, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.348326 (avg: 0.348326) \tsec/iter: 0.0329\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.406538 (avg: 0.340192) \tsec/iter: 0.0286\n",
      "Test set (epoch 115): Average loss: 0.3534, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.348811 (avg: 0.348811) \tsec/iter: 0.0329\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.296415 (avg: 0.337875) \tsec/iter: 0.0306\n",
      "Test set (epoch 116): Average loss: 0.2963, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.315996 (avg: 0.315996) \tsec/iter: 0.0359\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.272707 (avg: 0.329674) \tsec/iter: 0.0339\n",
      "Test set (epoch 117): Average loss: 0.2941, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.364077 (avg: 0.364077) \tsec/iter: 0.0349\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.230633 (avg: 0.292066) \tsec/iter: 0.0326\n",
      "Test set (epoch 118): Average loss: 0.3361, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.345744 (avg: 0.345744) \tsec/iter: 0.0329\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.370275 (avg: 0.339463) \tsec/iter: 0.0286\n",
      "Test set (epoch 119): Average loss: 0.2779, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.292110 (avg: 0.292110) \tsec/iter: 0.0369\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.336381 (avg: 0.311082) \tsec/iter: 0.0339\n",
      "Test set (epoch 120): Average loss: 0.2935, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.251951 (avg: 0.251951) \tsec/iter: 0.0319\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.284696 (avg: 0.300761) \tsec/iter: 0.0299\n",
      "Test set (epoch 121): Average loss: 0.3064, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.343805 (avg: 0.343805) \tsec/iter: 0.0399\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.372093 (avg: 0.308239) \tsec/iter: 0.0372\n",
      "Test set (epoch 122): Average loss: 0.2820, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.281789 (avg: 0.281789) \tsec/iter: 0.0419\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.320093 (avg: 0.293018) \tsec/iter: 0.0342\n",
      "Test set (epoch 123): Average loss: 0.3082, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.366722 (avg: 0.366722) \tsec/iter: 0.0319\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.251371 (avg: 0.324203) \tsec/iter: 0.0309\n",
      "Test set (epoch 124): Average loss: 0.2861, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.275287 (avg: 0.275287) \tsec/iter: 0.0349\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.315861 (avg: 0.321508) \tsec/iter: 0.0296\n",
      "Test set (epoch 125): Average loss: 0.3684, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.312607 (avg: 0.312607) \tsec/iter: 0.0349\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.213881 (avg: 0.279054) \tsec/iter: 0.0322\n",
      "Test set (epoch 126): Average loss: 0.3226, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.309850 (avg: 0.309850) \tsec/iter: 0.0369\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.279191 (avg: 0.277566) \tsec/iter: 0.0336\n",
      "Test set (epoch 127): Average loss: 0.3269, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.383703 (avg: 0.383703) \tsec/iter: 0.0319\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.285724 (avg: 0.329567) \tsec/iter: 0.0312\n",
      "Test set (epoch 128): Average loss: 0.2905, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.317151 (avg: 0.317151) \tsec/iter: 0.0319\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.321806 (avg: 0.288718) \tsec/iter: 0.0299\n",
      "Test set (epoch 129): Average loss: 0.3583, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.408047 (avg: 0.408047) \tsec/iter: 0.0319\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.298580 (avg: 0.343592) \tsec/iter: 0.0296\n",
      "Test set (epoch 130): Average loss: 0.3251, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.327721 (avg: 0.327721) \tsec/iter: 0.0319\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.398102 (avg: 0.315171) \tsec/iter: 0.0312\n",
      "Test set (epoch 131): Average loss: 0.3158, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.338021 (avg: 0.338021) \tsec/iter: 0.0399\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.319687 (avg: 0.301599) \tsec/iter: 0.0366\n",
      "Test set (epoch 132): Average loss: 0.3228, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.230650 (avg: 0.230650) \tsec/iter: 0.0369\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.377196 (avg: 0.314161) \tsec/iter: 0.0326\n",
      "Test set (epoch 133): Average loss: 0.3086, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.364832 (avg: 0.364832) \tsec/iter: 0.0379\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.299502 (avg: 0.310458) \tsec/iter: 0.0336\n",
      "Test set (epoch 134): Average loss: 0.3040, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.305593 (avg: 0.305593) \tsec/iter: 0.0329\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.286070 (avg: 0.300897) \tsec/iter: 0.0306\n",
      "Test set (epoch 135): Average loss: 0.3252, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.285864 (avg: 0.285864) \tsec/iter: 0.0379\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.447403 (avg: 0.337996) \tsec/iter: 0.0322\n",
      "Test set (epoch 136): Average loss: 0.3487, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.374578 (avg: 0.374578) \tsec/iter: 0.0339\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.278169 (avg: 0.304177) \tsec/iter: 0.0326\n",
      "Test set (epoch 137): Average loss: 0.3489, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.209269 (avg: 0.209269) \tsec/iter: 0.0339\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.262004 (avg: 0.280807) \tsec/iter: 0.0309\n",
      "Test set (epoch 138): Average loss: 0.2843, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.305321 (avg: 0.305321) \tsec/iter: 0.0309\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.412689 (avg: 0.293443) \tsec/iter: 0.0286\n",
      "Test set (epoch 139): Average loss: 0.2866, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.244506 (avg: 0.244506) \tsec/iter: 0.0349\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.362195 (avg: 0.324055) \tsec/iter: 0.0303\n",
      "Test set (epoch 140): Average loss: 0.2828, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.349627 (avg: 0.349627) \tsec/iter: 0.0349\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.268924 (avg: 0.331947) \tsec/iter: 0.0352\n",
      "Test set (epoch 141): Average loss: 0.3458, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.338183 (avg: 0.338183) \tsec/iter: 0.0369\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.265240 (avg: 0.295011) \tsec/iter: 0.0342\n",
      "Test set (epoch 142): Average loss: 0.3375, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.238042 (avg: 0.238042) \tsec/iter: 0.0309\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.263058 (avg: 0.269219) \tsec/iter: 0.0316\n",
      "Test set (epoch 143): Average loss: 0.3624, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.321109 (avg: 0.321109) \tsec/iter: 0.0329\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.461337 (avg: 0.315257) \tsec/iter: 0.0299\n",
      "Test set (epoch 144): Average loss: 0.3230, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.266876 (avg: 0.266876) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.462194 (avg: 0.328905) \tsec/iter: 0.0293\n",
      "Test set (epoch 145): Average loss: 0.3171, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.274300 (avg: 0.274300) \tsec/iter: 0.0339\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.236431 (avg: 0.313070) \tsec/iter: 0.0316\n",
      "Test set (epoch 146): Average loss: 0.3088, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.347870 (avg: 0.347870) \tsec/iter: 0.0349\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.270743 (avg: 0.297121) \tsec/iter: 0.0329\n",
      "Test set (epoch 147): Average loss: 0.2659, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.211429 (avg: 0.211429) \tsec/iter: 0.0339\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.344154 (avg: 0.271608) \tsec/iter: 0.0286\n",
      "Test set (epoch 148): Average loss: 0.2591, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.210220 (avg: 0.210220) \tsec/iter: 0.0319\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.484310 (avg: 0.307408) \tsec/iter: 0.0289\n",
      "Test set (epoch 149): Average loss: 0.3148, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.346776 (avg: 0.346776) \tsec/iter: 0.0369\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.210668 (avg: 0.310138) \tsec/iter: 0.0319\n",
      "Test set (epoch 150): Average loss: 0.3554, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.275037 (avg: 0.275037) \tsec/iter: 0.0449\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.314830 (avg: 0.308596) \tsec/iter: 0.0406\n",
      "Test set (epoch 151): Average loss: 0.2776, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.300351 (avg: 0.300351) \tsec/iter: 0.0419\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.291504 (avg: 0.306925) \tsec/iter: 0.0336\n",
      "Test set (epoch 152): Average loss: 0.3405, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.239305 (avg: 0.239305) \tsec/iter: 0.0349\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.286184 (avg: 0.279636) \tsec/iter: 0.0316\n",
      "Test set (epoch 153): Average loss: 0.2657, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.316772 (avg: 0.316772) \tsec/iter: 0.0319\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.144140 (avg: 0.261930) \tsec/iter: 0.0316\n",
      "Test set (epoch 154): Average loss: 0.2894, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.245936 (avg: 0.245936) \tsec/iter: 0.0389\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.284337 (avg: 0.309818) \tsec/iter: 0.0326\n",
      "Test set (epoch 155): Average loss: 0.3404, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.301582 (avg: 0.301582) \tsec/iter: 0.0389\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.297833 (avg: 0.290955) \tsec/iter: 0.0329\n",
      "Test set (epoch 156): Average loss: 0.2500, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.323156 (avg: 0.323156) \tsec/iter: 0.0349\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.280494 (avg: 0.284082) \tsec/iter: 0.0303\n",
      "Test set (epoch 157): Average loss: 0.3149, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.288820 (avg: 0.288820) \tsec/iter: 0.0369\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.406796 (avg: 0.276483) \tsec/iter: 0.0322\n",
      "Test set (epoch 158): Average loss: 0.3358, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.295436 (avg: 0.295436) \tsec/iter: 0.0329\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.167533 (avg: 0.258978) \tsec/iter: 0.0293\n",
      "Test set (epoch 159): Average loss: 0.3245, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.297187 (avg: 0.297187) \tsec/iter: 0.0319\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.284344 (avg: 0.297653) \tsec/iter: 0.0329\n",
      "Test set (epoch 160): Average loss: 0.3125, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.374056 (avg: 0.374056) \tsec/iter: 0.0419\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.245126 (avg: 0.284337) \tsec/iter: 0.0382\n",
      "Test set (epoch 161): Average loss: 0.3015, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.286215 (avg: 0.286215) \tsec/iter: 0.0349\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.378032 (avg: 0.296411) \tsec/iter: 0.0322\n",
      "Test set (epoch 162): Average loss: 0.4389, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.367896 (avg: 0.367896) \tsec/iter: 0.0359\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.277613 (avg: 0.312410) \tsec/iter: 0.0299\n",
      "Test set (epoch 163): Average loss: 0.2465, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.253535 (avg: 0.253535) \tsec/iter: 0.0339\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.324917 (avg: 0.295682) \tsec/iter: 0.0309\n",
      "Test set (epoch 164): Average loss: 0.3537, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.244497 (avg: 0.244497) \tsec/iter: 0.0359\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.352167 (avg: 0.287620) \tsec/iter: 0.0319\n",
      "Test set (epoch 165): Average loss: 0.3424, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.245103 (avg: 0.245103) \tsec/iter: 0.0329\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.282163 (avg: 0.273276) \tsec/iter: 0.0312\n",
      "Test set (epoch 166): Average loss: 0.3108, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.227464 (avg: 0.227464) \tsec/iter: 0.0319\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.411071 (avg: 0.290285) \tsec/iter: 0.0303\n",
      "Test set (epoch 167): Average loss: 0.3161, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.287497 (avg: 0.287497) \tsec/iter: 0.0379\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.238326 (avg: 0.255776) \tsec/iter: 0.0346\n",
      "Test set (epoch 168): Average loss: 0.3250, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.263027 (avg: 0.263027) \tsec/iter: 0.0349\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.209504 (avg: 0.260435) \tsec/iter: 0.0329\n",
      "Test set (epoch 169): Average loss: 0.3554, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.277282 (avg: 0.277282) \tsec/iter: 0.0369\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.293839 (avg: 0.251607) \tsec/iter: 0.0349\n",
      "Test set (epoch 170): Average loss: 0.3467, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.302008 (avg: 0.302008) \tsec/iter: 0.0429\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.254305 (avg: 0.280883) \tsec/iter: 0.0366\n",
      "Test set (epoch 171): Average loss: 0.3412, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.288895 (avg: 0.288895) \tsec/iter: 0.0329\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.296404 (avg: 0.275566) \tsec/iter: 0.0306\n",
      "Test set (epoch 172): Average loss: 0.2953, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.285379 (avg: 0.285379) \tsec/iter: 0.0369\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.431630 (avg: 0.305154) \tsec/iter: 0.0342\n",
      "Test set (epoch 173): Average loss: 0.3538, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.349203 (avg: 0.349203) \tsec/iter: 0.0349\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.269092 (avg: 0.271416) \tsec/iter: 0.0306\n",
      "Test set (epoch 174): Average loss: 0.3767, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.273873 (avg: 0.273873) \tsec/iter: 0.0329\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.177139 (avg: 0.266401) \tsec/iter: 0.0299\n",
      "Test set (epoch 175): Average loss: 0.3596, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.232324 (avg: 0.232324) \tsec/iter: 0.0319\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.273051 (avg: 0.252457) \tsec/iter: 0.0316\n",
      "Test set (epoch 176): Average loss: 0.4025, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.373725 (avg: 0.373725) \tsec/iter: 0.0309\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.329995 (avg: 0.294703) \tsec/iter: 0.0322\n",
      "Test set (epoch 177): Average loss: 0.3117, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.278881 (avg: 0.278881) \tsec/iter: 0.0329\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.327915 (avg: 0.280034) \tsec/iter: 0.0309\n",
      "Test set (epoch 178): Average loss: 0.4116, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.199865 (avg: 0.199865) \tsec/iter: 0.0339\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.349740 (avg: 0.249622) \tsec/iter: 0.0359\n",
      "Test set (epoch 179): Average loss: 0.3125, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.274097 (avg: 0.274097) \tsec/iter: 0.0409\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.302804 (avg: 0.273354) \tsec/iter: 0.0349\n",
      "Test set (epoch 180): Average loss: 0.2592, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.335675 (avg: 0.335675) \tsec/iter: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.323879 (avg: 0.297268) \tsec/iter: 0.0312\n",
      "Test set (epoch 181): Average loss: 0.2408, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.201262 (avg: 0.201262) \tsec/iter: 0.0349\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.137087 (avg: 0.263959) \tsec/iter: 0.0309\n",
      "Test set (epoch 182): Average loss: 0.3314, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.213352 (avg: 0.213352) \tsec/iter: 0.0339\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.364685 (avg: 0.252292) \tsec/iter: 0.0316\n",
      "Test set (epoch 183): Average loss: 0.3874, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.357150 (avg: 0.357150) \tsec/iter: 0.0329\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.154035 (avg: 0.282661) \tsec/iter: 0.0326\n",
      "Test set (epoch 184): Average loss: 0.2893, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.246196 (avg: 0.246196) \tsec/iter: 0.0359\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.289907 (avg: 0.246003) \tsec/iter: 0.0312\n",
      "Test set (epoch 185): Average loss: 0.3632, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.376427 (avg: 0.376427) \tsec/iter: 0.0319\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.181153 (avg: 0.282463) \tsec/iter: 0.0303\n",
      "Test set (epoch 186): Average loss: 0.3384, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.287201 (avg: 0.287201) \tsec/iter: 0.0289\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.245988 (avg: 0.239853) \tsec/iter: 0.0293\n",
      "Test set (epoch 187): Average loss: 0.3335, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.226141 (avg: 0.226141) \tsec/iter: 0.0319\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.299112 (avg: 0.258096) \tsec/iter: 0.0316\n",
      "Test set (epoch 188): Average loss: 0.3678, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.245448 (avg: 0.245448) \tsec/iter: 0.0389\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.381097 (avg: 0.259485) \tsec/iter: 0.0369\n",
      "Test set (epoch 189): Average loss: 0.3200, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.307727 (avg: 0.307727) \tsec/iter: 0.0359\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.248193 (avg: 0.274134) \tsec/iter: 0.0336\n",
      "Test set (epoch 190): Average loss: 0.3004, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.223090 (avg: 0.223090) \tsec/iter: 0.0349\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.256113 (avg: 0.242747) \tsec/iter: 0.0312\n",
      "Test set (epoch 191): Average loss: 0.3039, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.276559 (avg: 0.276559) \tsec/iter: 0.0319\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.266327 (avg: 0.278911) \tsec/iter: 0.0293\n",
      "Test set (epoch 192): Average loss: 0.4036, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.274619 (avg: 0.274619) \tsec/iter: 0.0369\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.303369 (avg: 0.280031) \tsec/iter: 0.0329\n",
      "Test set (epoch 193): Average loss: 0.2980, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.247548 (avg: 0.247548) \tsec/iter: 0.0359\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.235055 (avg: 0.257958) \tsec/iter: 0.0309\n",
      "Test set (epoch 194): Average loss: 0.3023, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.227263 (avg: 0.227263) \tsec/iter: 0.0349\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.350027 (avg: 0.251521) \tsec/iter: 0.0309\n",
      "Test set (epoch 195): Average loss: 0.3882, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.256125 (avg: 0.256125) \tsec/iter: 0.0299\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.182778 (avg: 0.252175) \tsec/iter: 0.0303\n",
      "Test set (epoch 196): Average loss: 0.3197, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.389162 (avg: 0.389162) \tsec/iter: 0.0369\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.099903 (avg: 0.270260) \tsec/iter: 0.0326\n",
      "Test set (epoch 197): Average loss: 0.3618, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.206044 (avg: 0.206044) \tsec/iter: 0.0349\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.209908 (avg: 0.266424) \tsec/iter: 0.0362\n",
      "Test set (epoch 198): Average loss: 0.3483, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.232353 (avg: 0.232353) \tsec/iter: 0.0409\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.190577 (avg: 0.245013) \tsec/iter: 0.0379\n",
      "Test set (epoch 199): Average loss: 0.2652, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.240744 (avg: 0.240744) \tsec/iter: 0.0339\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.281821 (avg: 0.271679) \tsec/iter: 0.0309\n",
      "Test set (epoch 200): Average loss: 0.3275, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.198723 (avg: 0.198723) \tsec/iter: 0.0339\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.361414 (avg: 0.268400) \tsec/iter: 0.0316\n",
      "Test set (epoch 201): Average loss: 0.2915, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.324396 (avg: 0.324396) \tsec/iter: 0.0379\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.284852 (avg: 0.273717) \tsec/iter: 0.0319\n",
      "Test set (epoch 202): Average loss: 0.2717, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.258614 (avg: 0.258614) \tsec/iter: 0.0319\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.200082 (avg: 0.248099) \tsec/iter: 0.0293\n",
      "Test set (epoch 203): Average loss: 0.2973, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.220083 (avg: 0.220083) \tsec/iter: 0.0339\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.404887 (avg: 0.277107) \tsec/iter: 0.0309\n",
      "Test set (epoch 204): Average loss: 0.3347, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.390409 (avg: 0.390409) \tsec/iter: 0.0319\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.152234 (avg: 0.311133) \tsec/iter: 0.0306\n",
      "Test set (epoch 205): Average loss: 0.2777, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.298523 (avg: 0.298523) \tsec/iter: 0.0349\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.201121 (avg: 0.269254) \tsec/iter: 0.0306\n",
      "Test set (epoch 206): Average loss: 0.3122, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.238818 (avg: 0.238818) \tsec/iter: 0.0359\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.232289 (avg: 0.256223) \tsec/iter: 0.0299\n",
      "Test set (epoch 207): Average loss: 0.3051, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.332016 (avg: 0.332016) \tsec/iter: 0.0419\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.175828 (avg: 0.287499) \tsec/iter: 0.0352\n",
      "Test set (epoch 208): Average loss: 0.3532, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.408790 (avg: 0.408790) \tsec/iter: 0.0389\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.235256 (avg: 0.311821) \tsec/iter: 0.0322\n",
      "Test set (epoch 209): Average loss: 0.3253, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.257397 (avg: 0.257397) \tsec/iter: 0.0299\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.212366 (avg: 0.253917) \tsec/iter: 0.0296\n",
      "Test set (epoch 210): Average loss: 0.1980, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.245283 (avg: 0.245283) \tsec/iter: 0.0309\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.249506 (avg: 0.252896) \tsec/iter: 0.0303\n",
      "Test set (epoch 211): Average loss: 0.3072, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.218466 (avg: 0.218466) \tsec/iter: 0.0419\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.200177 (avg: 0.293269) \tsec/iter: 0.0339\n",
      "Test set (epoch 212): Average loss: 0.3226, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.174663 (avg: 0.174663) \tsec/iter: 0.0519\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.420117 (avg: 0.310574) \tsec/iter: 0.0402\n",
      "Test set (epoch 213): Average loss: 0.5269, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.399968 (avg: 0.399968) \tsec/iter: 0.0359\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.330919 (avg: 0.350629) \tsec/iter: 0.0319\n",
      "Test set (epoch 214): Average loss: 0.3417, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.155992 (avg: 0.155992) \tsec/iter: 0.0339\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.309005 (avg: 0.238384) \tsec/iter: 0.0299\n",
      "Test set (epoch 215): Average loss: 0.3140, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.292361 (avg: 0.292361) \tsec/iter: 0.0369\n",
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.335199 (avg: 0.300772) \tsec/iter: 0.0319\n",
      "Test set (epoch 216): Average loss: 0.3340, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.381485 (avg: 0.381485) \tsec/iter: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.234290 (avg: 0.258152) \tsec/iter: 0.0359\n",
      "Test set (epoch 217): Average loss: 0.2802, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.219405 (avg: 0.219405) \tsec/iter: 0.0369\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.300520 (avg: 0.255604) \tsec/iter: 0.0356\n",
      "Test set (epoch 218): Average loss: 0.3209, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.268641 (avg: 0.268641) \tsec/iter: 0.0319\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.294071 (avg: 0.271897) \tsec/iter: 0.0309\n",
      "Test set (epoch 219): Average loss: 0.3002, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.239284 (avg: 0.239284) \tsec/iter: 0.0389\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.263174 (avg: 0.264618) \tsec/iter: 0.0332\n",
      "Test set (epoch 220): Average loss: 0.2292, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.257178 (avg: 0.257178) \tsec/iter: 0.0299\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.234103 (avg: 0.236242) \tsec/iter: 0.0286\n",
      "Test set (epoch 221): Average loss: 0.2321, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.213613 (avg: 0.213613) \tsec/iter: 0.0359\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.123474 (avg: 0.218870) \tsec/iter: 0.0312\n",
      "Test set (epoch 222): Average loss: 0.2887, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.385982 (avg: 0.385982) \tsec/iter: 0.0309\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.255533 (avg: 0.291240) \tsec/iter: 0.0293\n",
      "Test set (epoch 223): Average loss: 0.3358, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.310670 (avg: 0.310670) \tsec/iter: 0.0369\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.172954 (avg: 0.268066) \tsec/iter: 0.0312\n",
      "Test set (epoch 224): Average loss: 0.2832, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.383433 (avg: 0.383433) \tsec/iter: 0.0349\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.241163 (avg: 0.273236) \tsec/iter: 0.0346\n",
      "Test set (epoch 225): Average loss: 0.3822, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.268295 (avg: 0.268295) \tsec/iter: 0.0319\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.294396 (avg: 0.232867) \tsec/iter: 0.0296\n",
      "Test set (epoch 226): Average loss: 0.3632, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.246795 (avg: 0.246795) \tsec/iter: 0.0399\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.199329 (avg: 0.262790) \tsec/iter: 0.0369\n",
      "Test set (epoch 227): Average loss: 0.3190, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.391100 (avg: 0.391100) \tsec/iter: 0.0389\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.222396 (avg: 0.272902) \tsec/iter: 0.0322\n",
      "Test set (epoch 228): Average loss: 0.3208, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.204306 (avg: 0.204306) \tsec/iter: 0.0319\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.190526 (avg: 0.225640) \tsec/iter: 0.0306\n",
      "Test set (epoch 229): Average loss: 0.3311, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.267584 (avg: 0.267584) \tsec/iter: 0.0349\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.206870 (avg: 0.254822) \tsec/iter: 0.0326\n",
      "Test set (epoch 230): Average loss: 0.2756, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.240617 (avg: 0.240617) \tsec/iter: 0.0329\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.191442 (avg: 0.239856) \tsec/iter: 0.0306\n",
      "Test set (epoch 231): Average loss: 0.2383, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.217007 (avg: 0.217007) \tsec/iter: 0.0369\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.364345 (avg: 0.217680) \tsec/iter: 0.0319\n",
      "Test set (epoch 232): Average loss: 0.3260, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.210719 (avg: 0.210719) \tsec/iter: 0.0369\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.216869 (avg: 0.240778) \tsec/iter: 0.0332\n",
      "Test set (epoch 233): Average loss: 0.2905, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.244370 (avg: 0.244370) \tsec/iter: 0.0339\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.362308 (avg: 0.243579) \tsec/iter: 0.0303\n",
      "Test set (epoch 234): Average loss: 0.2328, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.205004 (avg: 0.205004) \tsec/iter: 0.0319\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.292255 (avg: 0.245722) \tsec/iter: 0.0326\n",
      "Test set (epoch 235): Average loss: 0.2291, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.214080 (avg: 0.214080) \tsec/iter: 0.0359\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.278997 (avg: 0.238297) \tsec/iter: 0.0332\n",
      "Test set (epoch 236): Average loss: 0.2576, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.335963 (avg: 0.335963) \tsec/iter: 0.0389\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.250552 (avg: 0.271088) \tsec/iter: 0.0356\n",
      "Test set (epoch 237): Average loss: 0.2283, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.211969 (avg: 0.211969) \tsec/iter: 0.0369\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.413769 (avg: 0.245899) \tsec/iter: 0.0306\n",
      "Test set (epoch 238): Average loss: 0.2734, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.289549 (avg: 0.289549) \tsec/iter: 0.0369\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.135102 (avg: 0.229109) \tsec/iter: 0.0309\n",
      "Test set (epoch 239): Average loss: 0.3128, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.304956 (avg: 0.304956) \tsec/iter: 0.0339\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.210260 (avg: 0.247905) \tsec/iter: 0.0306\n",
      "Test set (epoch 240): Average loss: 0.3585, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.202489 (avg: 0.202489) \tsec/iter: 0.0299\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.251382 (avg: 0.226100) \tsec/iter: 0.0276\n",
      "Test set (epoch 241): Average loss: 0.2626, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.204078 (avg: 0.204078) \tsec/iter: 0.0309\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.405477 (avg: 0.260641) \tsec/iter: 0.0309\n",
      "Test set (epoch 242): Average loss: 0.3931, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.144231 (avg: 0.144231) \tsec/iter: 0.0349\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.217639 (avg: 0.250219) \tsec/iter: 0.0293\n",
      "Test set (epoch 243): Average loss: 0.3861, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.307375 (avg: 0.307375) \tsec/iter: 0.0319\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.301294 (avg: 0.244785) \tsec/iter: 0.0319\n",
      "Test set (epoch 244): Average loss: 0.3050, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.252012 (avg: 0.252012) \tsec/iter: 0.0319\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.241450 (avg: 0.222042) \tsec/iter: 0.0299\n",
      "Test set (epoch 245): Average loss: 0.3412, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.287340 (avg: 0.287340) \tsec/iter: 0.0409\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.124099 (avg: 0.212940) \tsec/iter: 0.0356\n",
      "Test set (epoch 246): Average loss: 0.4030, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.178325 (avg: 0.178325) \tsec/iter: 0.0399\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.397929 (avg: 0.230710) \tsec/iter: 0.0356\n",
      "Test set (epoch 247): Average loss: 0.2880, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.260708 (avg: 0.260708) \tsec/iter: 0.0339\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.218348 (avg: 0.248873) \tsec/iter: 0.0309\n",
      "Test set (epoch 248): Average loss: 0.3171, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.340325 (avg: 0.340325) \tsec/iter: 0.0289\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.208336 (avg: 0.306276) \tsec/iter: 0.0279\n",
      "Test set (epoch 249): Average loss: 0.2830, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.238054 (avg: 0.238054) \tsec/iter: 0.0299\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.235200 (avg: 0.249884) \tsec/iter: 0.0296\n",
      "Test set (epoch 250): Average loss: 0.3685, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.239779 (avg: 0.239779) \tsec/iter: 0.0309\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.296358 (avg: 0.237561) \tsec/iter: 0.0286\n",
      "Test set (epoch 251): Average loss: 0.3557, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.392234 (avg: 0.392234) \tsec/iter: 0.0349\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.144696 (avg: 0.260145) \tsec/iter: 0.0312\n",
      "Test set (epoch 252): Average loss: 0.3434, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.270226 (avg: 0.270226) \tsec/iter: 0.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.295803 (avg: 0.244618) \tsec/iter: 0.0309\n",
      "Test set (epoch 253): Average loss: 0.3605, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.277596 (avg: 0.277596) \tsec/iter: 0.0309\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.150389 (avg: 0.231615) \tsec/iter: 0.0293\n",
      "Test set (epoch 254): Average loss: 0.2631, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.140099 (avg: 0.140099) \tsec/iter: 0.0319\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.321421 (avg: 0.246641) \tsec/iter: 0.0303\n",
      "Test set (epoch 255): Average loss: 0.2482, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.264551 (avg: 0.264551) \tsec/iter: 0.0379\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.400127 (avg: 0.272201) \tsec/iter: 0.0352\n",
      "Test set (epoch 256): Average loss: 0.3228, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.215848 (avg: 0.215848) \tsec/iter: 0.0419\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.289748 (avg: 0.266016) \tsec/iter: 0.0346\n",
      "Test set (epoch 257): Average loss: 0.3965, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.212012 (avg: 0.212012) \tsec/iter: 0.0339\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.222774 (avg: 0.236083) \tsec/iter: 0.0303\n",
      "Test set (epoch 258): Average loss: 0.3032, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.263060 (avg: 0.263060) \tsec/iter: 0.0299\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.131753 (avg: 0.230001) \tsec/iter: 0.0316\n",
      "Test set (epoch 259): Average loss: 0.2742, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.294531 (avg: 0.294531) \tsec/iter: 0.0369\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.222955 (avg: 0.226712) \tsec/iter: 0.0306\n",
      "Test set (epoch 260): Average loss: 0.3260, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.262253 (avg: 0.262253) \tsec/iter: 0.0349\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.199658 (avg: 0.251828) \tsec/iter: 0.0309\n",
      "Test set (epoch 261): Average loss: 0.2903, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.293740 (avg: 0.293740) \tsec/iter: 0.0329\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.223006 (avg: 0.231262) \tsec/iter: 0.0303\n",
      "Test set (epoch 262): Average loss: 0.2447, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.240075 (avg: 0.240075) \tsec/iter: 0.0339\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.213002 (avg: 0.214805) \tsec/iter: 0.0336\n",
      "Test set (epoch 263): Average loss: 0.3088, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.312916 (avg: 0.312916) \tsec/iter: 0.0369\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.262331 (avg: 0.261157) \tsec/iter: 0.0329\n",
      "Test set (epoch 264): Average loss: 0.2365, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.216915 (avg: 0.216915) \tsec/iter: 0.0399\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.123982 (avg: 0.216601) \tsec/iter: 0.0429\n",
      "Test set (epoch 265): Average loss: 0.2576, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.270223 (avg: 0.270223) \tsec/iter: 0.0489\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.244906 (avg: 0.234527) \tsec/iter: 0.0412\n",
      "Test set (epoch 266): Average loss: 0.3009, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.152018 (avg: 0.152018) \tsec/iter: 0.0349\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.161453 (avg: 0.245431) \tsec/iter: 0.0362\n",
      "Test set (epoch 267): Average loss: 0.2385, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.162861 (avg: 0.162861) \tsec/iter: 0.0379\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.321776 (avg: 0.261528) \tsec/iter: 0.0329\n",
      "Test set (epoch 268): Average loss: 0.2074, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.182122 (avg: 0.182122) \tsec/iter: 0.0329\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.206757 (avg: 0.233977) \tsec/iter: 0.0672\n",
      "Test set (epoch 269): Average loss: 0.2756, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.256139 (avg: 0.256139) \tsec/iter: 0.0559\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.224881 (avg: 0.256825) \tsec/iter: 0.0612\n",
      "Test set (epoch 270): Average loss: 0.2995, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.243538 (avg: 0.243538) \tsec/iter: 0.0778\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.151082 (avg: 0.232985) \tsec/iter: 0.0495\n",
      "Test set (epoch 271): Average loss: 0.3215, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.096753 (avg: 0.096753) \tsec/iter: 0.0519\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.527970 (avg: 0.258379) \tsec/iter: 0.0429\n",
      "Test set (epoch 272): Average loss: 0.3309, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.342290 (avg: 0.342290) \tsec/iter: 0.0409\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.254746 (avg: 0.270278) \tsec/iter: 0.0332\n",
      "Test set (epoch 273): Average loss: 0.4370, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.151935 (avg: 0.151935) \tsec/iter: 0.0429\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.296886 (avg: 0.215367) \tsec/iter: 0.0359\n",
      "Test set (epoch 274): Average loss: 0.2962, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.190229 (avg: 0.190229) \tsec/iter: 0.0389\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.368309 (avg: 0.238956) \tsec/iter: 0.0329\n",
      "Test set (epoch 275): Average loss: 0.3203, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.224620 (avg: 0.224620) \tsec/iter: 0.0369\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.212216 (avg: 0.227848) \tsec/iter: 0.0346\n",
      "Test set (epoch 276): Average loss: 0.2458, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.182786 (avg: 0.182786) \tsec/iter: 0.0359\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.369114 (avg: 0.232795) \tsec/iter: 0.0322\n",
      "Test set (epoch 277): Average loss: 0.3572, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.240723 (avg: 0.240723) \tsec/iter: 0.0329\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.242455 (avg: 0.219806) \tsec/iter: 0.0309\n",
      "Test set (epoch 278): Average loss: 0.2970, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.283729 (avg: 0.283729) \tsec/iter: 0.0369\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.200404 (avg: 0.228816) \tsec/iter: 0.0326\n",
      "Test set (epoch 279): Average loss: 0.2991, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.330595 (avg: 0.330595) \tsec/iter: 0.0379\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.160859 (avg: 0.251050) \tsec/iter: 0.0402\n",
      "Test set (epoch 280): Average loss: 0.2703, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.154936 (avg: 0.154936) \tsec/iter: 0.0449\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.207840 (avg: 0.233247) \tsec/iter: 0.0409\n",
      "Test set (epoch 281): Average loss: 0.3228, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.223124 (avg: 0.223124) \tsec/iter: 0.0329\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.291261 (avg: 0.256316) \tsec/iter: 0.0309\n",
      "Test set (epoch 282): Average loss: 0.2044, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.279757 (avg: 0.279757) \tsec/iter: 0.0369\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.202044 (avg: 0.227319) \tsec/iter: 0.0362\n",
      "Test set (epoch 283): Average loss: 0.2919, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.282681 (avg: 0.282681) \tsec/iter: 0.0419\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.119801 (avg: 0.223039) \tsec/iter: 0.0399\n",
      "Test set (epoch 284): Average loss: 0.2504, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.241457 (avg: 0.241457) \tsec/iter: 0.0379\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.305506 (avg: 0.249013) \tsec/iter: 0.0362\n",
      "Test set (epoch 285): Average loss: 0.3449, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.323821 (avg: 0.323821) \tsec/iter: 0.0359\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.227733 (avg: 0.235637) \tsec/iter: 0.0322\n",
      "Test set (epoch 286): Average loss: 0.2817, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.160538 (avg: 0.160538) \tsec/iter: 0.0359\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.279160 (avg: 0.241175) \tsec/iter: 0.0319\n",
      "Test set (epoch 287): Average loss: 0.3433, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.199269 (avg: 0.199269) \tsec/iter: 0.0319\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.266187 (avg: 0.223678) \tsec/iter: 0.0319\n",
      "Test set (epoch 288): Average loss: 0.3419, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.228116 (avg: 0.228116) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.122730 (avg: 0.231283) \tsec/iter: 0.0352\n",
      "Test set (epoch 289): Average loss: 0.3154, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.227601 (avg: 0.227601) \tsec/iter: 0.0688\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.308484 (avg: 0.216400) \tsec/iter: 0.0502\n",
      "Test set (epoch 290): Average loss: 0.3105, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.133651 (avg: 0.133651) \tsec/iter: 0.0469\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.263546 (avg: 0.200963) \tsec/iter: 0.0429\n",
      "Test set (epoch 291): Average loss: 0.3281, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.221655 (avg: 0.221655) \tsec/iter: 0.0389\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.172423 (avg: 0.227439) \tsec/iter: 0.0495\n",
      "Test set (epoch 292): Average loss: 0.3173, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.279278 (avg: 0.279278) \tsec/iter: 0.0519\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.209293 (avg: 0.243559) \tsec/iter: 0.0422\n",
      "Test set (epoch 293): Average loss: 0.3515, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.373060 (avg: 0.373060) \tsec/iter: 0.0459\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.134918 (avg: 0.266518) \tsec/iter: 0.0426\n",
      "Test set (epoch 294): Average loss: 0.3644, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.254994 (avg: 0.254994) \tsec/iter: 0.0519\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.202099 (avg: 0.238439) \tsec/iter: 0.0532\n",
      "Test set (epoch 295): Average loss: 0.3493, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.227740 (avg: 0.227740) \tsec/iter: 0.0529\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.322166 (avg: 0.233646) \tsec/iter: 0.0502\n",
      "Test set (epoch 296): Average loss: 0.3055, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.165790 (avg: 0.165790) \tsec/iter: 0.0628\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.213956 (avg: 0.215412) \tsec/iter: 0.0509\n",
      "Test set (epoch 297): Average loss: 0.3797, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.265674 (avg: 0.265674) \tsec/iter: 0.0419\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.203140 (avg: 0.225249) \tsec/iter: 0.0442\n",
      "Test set (epoch 298): Average loss: 0.2759, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.208621 (avg: 0.208621) \tsec/iter: 0.0529\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.229008 (avg: 0.224278) \tsec/iter: 0.0462\n",
      "Test set (epoch 299): Average loss: 0.3306, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.216156 (avg: 0.216156) \tsec/iter: 0.0559\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.240111 (avg: 0.213817) \tsec/iter: 0.0489\n",
      "Test set (epoch 300): Average loss: 0.2296, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.194425 (avg: 0.194425) \tsec/iter: 0.0539\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.336420 (avg: 0.239489) \tsec/iter: 0.0495\n",
      "Test set (epoch 301): Average loss: 0.4519, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.324559 (avg: 0.324559) \tsec/iter: 0.0489\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.239467 (avg: 0.226704) \tsec/iter: 0.0462\n",
      "Test set (epoch 302): Average loss: 0.3765, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.281420 (avg: 0.281420) \tsec/iter: 0.0658\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.278338 (avg: 0.270616) \tsec/iter: 0.0529\n",
      "Test set (epoch 303): Average loss: 0.2214, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.233339 (avg: 0.233339) \tsec/iter: 0.0469\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.197782 (avg: 0.209641) \tsec/iter: 0.0489\n",
      "Test set (epoch 304): Average loss: 0.3206, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.161816 (avg: 0.161816) \tsec/iter: 0.0578\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.247518 (avg: 0.181024) \tsec/iter: 0.0549\n",
      "Test set (epoch 305): Average loss: 0.4034, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.220696 (avg: 0.220696) \tsec/iter: 0.0638\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.271463 (avg: 0.295148) \tsec/iter: 0.0568\n",
      "Test set (epoch 306): Average loss: 0.4864, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.269385 (avg: 0.269385) \tsec/iter: 0.0638\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.200387 (avg: 0.273422) \tsec/iter: 0.0592\n",
      "Test set (epoch 307): Average loss: 0.2898, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.199890 (avg: 0.199890) \tsec/iter: 0.0529\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.300540 (avg: 0.219917) \tsec/iter: 0.0495\n",
      "Test set (epoch 308): Average loss: 0.2579, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.250535 (avg: 0.250535) \tsec/iter: 0.0668\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.233064 (avg: 0.231329) \tsec/iter: 0.0529\n",
      "Test set (epoch 309): Average loss: 0.3712, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.140833 (avg: 0.140833) \tsec/iter: 0.0459\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.270619 (avg: 0.229179) \tsec/iter: 0.0482\n",
      "Test set (epoch 310): Average loss: 0.2396, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.235798 (avg: 0.235798) \tsec/iter: 0.0529\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.185207 (avg: 0.210485) \tsec/iter: 0.0485\n",
      "Test set (epoch 311): Average loss: 0.2803, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.162999 (avg: 0.162999) \tsec/iter: 0.0499\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.371786 (avg: 0.224958) \tsec/iter: 0.0465\n",
      "Test set (epoch 312): Average loss: 0.4052, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.283820 (avg: 0.283820) \tsec/iter: 0.0469\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.374965 (avg: 0.264452) \tsec/iter: 0.0459\n",
      "Test set (epoch 313): Average loss: 0.2572, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.151631 (avg: 0.151631) \tsec/iter: 0.0419\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.309151 (avg: 0.243843) \tsec/iter: 0.0462\n",
      "Test set (epoch 314): Average loss: 0.2574, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.196776 (avg: 0.196776) \tsec/iter: 0.0948\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.204230 (avg: 0.222695) \tsec/iter: 0.0761\n",
      "Test set (epoch 315): Average loss: 0.3331, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.170104 (avg: 0.170104) \tsec/iter: 0.0459\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.202389 (avg: 0.181744) \tsec/iter: 0.0555\n",
      "Test set (epoch 316): Average loss: 0.3135, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.266445 (avg: 0.266445) \tsec/iter: 0.0658\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.134523 (avg: 0.205828) \tsec/iter: 0.0608\n",
      "Test set (epoch 317): Average loss: 0.3746, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.281778 (avg: 0.281778) \tsec/iter: 0.0708\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.110828 (avg: 0.198519) \tsec/iter: 0.0562\n",
      "Test set (epoch 318): Average loss: 0.3275, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.178619 (avg: 0.178619) \tsec/iter: 0.0449\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.175121 (avg: 0.247536) \tsec/iter: 0.0429\n",
      "Test set (epoch 319): Average loss: 0.2622, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.147363 (avg: 0.147363) \tsec/iter: 0.0698\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.203471 (avg: 0.184244) \tsec/iter: 0.0735\n",
      "Test set (epoch 320): Average loss: 0.3036, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.186723 (avg: 0.186723) \tsec/iter: 0.0688\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.204534 (avg: 0.215419) \tsec/iter: 0.0628\n",
      "Test set (epoch 321): Average loss: 0.3123, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.195687 (avg: 0.195687) \tsec/iter: 0.0509\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.312544 (avg: 0.204917) \tsec/iter: 0.0462\n",
      "Test set (epoch 322): Average loss: 0.2687, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.141740 (avg: 0.141740) \tsec/iter: 0.0638\n",
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.351133 (avg: 0.200686) \tsec/iter: 0.0582\n",
      "Test set (epoch 323): Average loss: 0.1957, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.184652 (avg: 0.184652) \tsec/iter: 0.0718\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.221525 (avg: 0.205239) \tsec/iter: 0.0618\n",
      "Test set (epoch 324): Average loss: 0.3560, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.281907 (avg: 0.281907) \tsec/iter: 0.0459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.220856 (avg: 0.272647) \tsec/iter: 0.0535\n",
      "Test set (epoch 325): Average loss: 0.2649, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.224407 (avg: 0.224407) \tsec/iter: 0.0778\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.237834 (avg: 0.227533) \tsec/iter: 0.0725\n",
      "Test set (epoch 326): Average loss: 0.2808, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.227679 (avg: 0.227679) \tsec/iter: 0.0658\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.210025 (avg: 0.207479) \tsec/iter: 0.0575\n",
      "Test set (epoch 327): Average loss: 0.4641, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.164350 (avg: 0.164350) \tsec/iter: 0.0479\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.189674 (avg: 0.188347) \tsec/iter: 0.0459\n",
      "Test set (epoch 328): Average loss: 0.4258, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.286682 (avg: 0.286682) \tsec/iter: 0.0568\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.188640 (avg: 0.234620) \tsec/iter: 0.0559\n",
      "Test set (epoch 329): Average loss: 0.6567, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.264533 (avg: 0.264533) \tsec/iter: 0.0698\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.305489 (avg: 0.245801) \tsec/iter: 0.0691\n",
      "Test set (epoch 330): Average loss: 0.3118, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.119613 (avg: 0.119613) \tsec/iter: 0.0568\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.243070 (avg: 0.232657) \tsec/iter: 0.0519\n",
      "Test set (epoch 331): Average loss: 0.2583, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.247560 (avg: 0.247560) \tsec/iter: 0.0509\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.158412 (avg: 0.210652) \tsec/iter: 0.0459\n",
      "Test set (epoch 332): Average loss: 0.3420, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.123417 (avg: 0.123417) \tsec/iter: 0.0409\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.455366 (avg: 0.228096) \tsec/iter: 0.0432\n",
      "Test set (epoch 333): Average loss: 0.2870, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.332340 (avg: 0.332340) \tsec/iter: 0.0389\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.213694 (avg: 0.231210) \tsec/iter: 0.0445\n",
      "Test set (epoch 334): Average loss: 0.3536, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.415195 (avg: 0.415195) \tsec/iter: 0.0529\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.190334 (avg: 0.275032) \tsec/iter: 0.0482\n",
      "Test set (epoch 335): Average loss: 0.3170, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.208395 (avg: 0.208395) \tsec/iter: 0.0529\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.340236 (avg: 0.207051) \tsec/iter: 0.0465\n",
      "Test set (epoch 336): Average loss: 0.2713, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.232231 (avg: 0.232231) \tsec/iter: 0.0479\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.195088 (avg: 0.207004) \tsec/iter: 0.0445\n",
      "Test set (epoch 337): Average loss: 0.3270, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.253103 (avg: 0.253103) \tsec/iter: 0.0499\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.281680 (avg: 0.227920) \tsec/iter: 0.0455\n",
      "Test set (epoch 338): Average loss: 0.3056, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.250330 (avg: 0.250330) \tsec/iter: 0.0479\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.219938 (avg: 0.226675) \tsec/iter: 0.0455\n",
      "Test set (epoch 339): Average loss: 0.3971, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.302021 (avg: 0.302021) \tsec/iter: 0.0578\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.239298 (avg: 0.247007) \tsec/iter: 0.0529\n",
      "Test set (epoch 340): Average loss: 0.3736, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.250472 (avg: 0.250472) \tsec/iter: 0.0708\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.098292 (avg: 0.220693) \tsec/iter: 0.0628\n",
      "Test set (epoch 341): Average loss: 0.2476, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.238367 (avg: 0.238367) \tsec/iter: 0.0578\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.160619 (avg: 0.199927) \tsec/iter: 0.0492\n",
      "Test set (epoch 342): Average loss: 0.5539, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.264398 (avg: 0.264398) \tsec/iter: 0.0499\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.117318 (avg: 0.217622) \tsec/iter: 0.0502\n",
      "Test set (epoch 343): Average loss: 0.3433, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.101182 (avg: 0.101182) \tsec/iter: 0.0539\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.211098 (avg: 0.208610) \tsec/iter: 0.0479\n",
      "Test set (epoch 344): Average loss: 0.4073, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.342736 (avg: 0.342736) \tsec/iter: 0.0578\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.195158 (avg: 0.244572) \tsec/iter: 0.0462\n",
      "Test set (epoch 345): Average loss: 0.2635, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.153216 (avg: 0.153216) \tsec/iter: 0.0469\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.279970 (avg: 0.194634) \tsec/iter: 0.0462\n",
      "Test set (epoch 346): Average loss: 0.3483, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.178457 (avg: 0.178457) \tsec/iter: 0.0419\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.388630 (avg: 0.237440) \tsec/iter: 0.0499\n",
      "Test set (epoch 347): Average loss: 0.2959, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.158030 (avg: 0.158030) \tsec/iter: 0.0618\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.127525 (avg: 0.188149) \tsec/iter: 0.0542\n",
      "Test set (epoch 348): Average loss: 0.3230, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.235049 (avg: 0.235049) \tsec/iter: 0.0578\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.177568 (avg: 0.208303) \tsec/iter: 0.0475\n",
      "Test set (epoch 349): Average loss: 0.4011, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.297679 (avg: 0.297679) \tsec/iter: 0.0499\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.164509 (avg: 0.209722) \tsec/iter: 0.0475\n",
      "Test set (epoch 350): Average loss: 0.2645, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.274223 (avg: 0.274223) \tsec/iter: 0.0519\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.115464 (avg: 0.234890) \tsec/iter: 0.0495\n",
      "Test set (epoch 351): Average loss: 0.4579, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.178150 (avg: 0.178150) \tsec/iter: 0.0638\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.217889 (avg: 0.214654) \tsec/iter: 0.0529\n",
      "Test set (epoch 352): Average loss: 0.4015, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.247017 (avg: 0.247017) \tsec/iter: 0.0479\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.184966 (avg: 0.224343) \tsec/iter: 0.0472\n",
      "Test set (epoch 353): Average loss: 0.3416, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.153050 (avg: 0.153050) \tsec/iter: 0.0429\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.197720 (avg: 0.223489) \tsec/iter: 0.0452\n",
      "Test set (epoch 354): Average loss: 0.3016, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.284943 (avg: 0.284943) \tsec/iter: 0.0549\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.302756 (avg: 0.249474) \tsec/iter: 0.0469\n",
      "Test set (epoch 355): Average loss: 0.4794, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.301203 (avg: 0.301203) \tsec/iter: 0.0519\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.157029 (avg: 0.218545) \tsec/iter: 0.0529\n",
      "Test set (epoch 356): Average loss: 0.3140, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.281114 (avg: 0.281114) \tsec/iter: 0.0529\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.158644 (avg: 0.237595) \tsec/iter: 0.0445\n",
      "Test set (epoch 357): Average loss: 0.4674, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.143140 (avg: 0.143140) \tsec/iter: 0.0489\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.162590 (avg: 0.267297) \tsec/iter: 0.0442\n",
      "Test set (epoch 358): Average loss: 0.2238, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.265390 (avg: 0.265390) \tsec/iter: 0.0409\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.133548 (avg: 0.209556) \tsec/iter: 0.0436\n",
      "Test set (epoch 359): Average loss: 0.4608, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.151146 (avg: 0.151146) \tsec/iter: 0.0519\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.218342 (avg: 0.180623) \tsec/iter: 0.0455\n",
      "Test set (epoch 360): Average loss: 0.3755, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.216110 (avg: 0.216110) \tsec/iter: 0.0479\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.135130 (avg: 0.197415) \tsec/iter: 0.0442\n",
      "Test set (epoch 361): Average loss: 0.4938, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.140030 (avg: 0.140030) \tsec/iter: 0.0419\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.239396 (avg: 0.223426) \tsec/iter: 0.0462\n",
      "Test set (epoch 362): Average loss: 0.2721, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.285306 (avg: 0.285306) \tsec/iter: 0.0658\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.314072 (avg: 0.246397) \tsec/iter: 0.0522\n",
      "Test set (epoch 363): Average loss: 0.6907, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.347320 (avg: 0.347320) \tsec/iter: 0.0469\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.153181 (avg: 0.240982) \tsec/iter: 0.0449\n",
      "Test set (epoch 364): Average loss: 0.4418, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.151673 (avg: 0.151673) \tsec/iter: 0.0539\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.167364 (avg: 0.187213) \tsec/iter: 0.0475\n",
      "Test set (epoch 365): Average loss: 0.3377, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.222671 (avg: 0.222671) \tsec/iter: 0.0519\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.168362 (avg: 0.200877) \tsec/iter: 0.0465\n",
      "Test set (epoch 366): Average loss: 0.2827, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.120460 (avg: 0.120460) \tsec/iter: 0.0449\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.457968 (avg: 0.230511) \tsec/iter: 0.0432\n",
      "Test set (epoch 367): Average loss: 0.3032, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.200375 (avg: 0.200375) \tsec/iter: 0.0539\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.219386 (avg: 0.232456) \tsec/iter: 0.0475\n",
      "Test set (epoch 368): Average loss: 0.3406, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.130657 (avg: 0.130657) \tsec/iter: 0.0519\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.273793 (avg: 0.227533) \tsec/iter: 0.0482\n",
      "Test set (epoch 369): Average loss: 0.5798, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.170863 (avg: 0.170863) \tsec/iter: 0.0549\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.226869 (avg: 0.196374) \tsec/iter: 0.0469\n",
      "Test set (epoch 370): Average loss: 0.3843, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.195135 (avg: 0.195135) \tsec/iter: 0.0519\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.239860 (avg: 0.222913) \tsec/iter: 0.0485\n",
      "Test set (epoch 371): Average loss: 0.4991, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.224679 (avg: 0.224679) \tsec/iter: 0.0499\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.206500 (avg: 0.213345) \tsec/iter: 0.0469\n",
      "Test set (epoch 372): Average loss: 0.4470, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.228315 (avg: 0.228315) \tsec/iter: 0.0439\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.154264 (avg: 0.216073) \tsec/iter: 0.0432\n",
      "Test set (epoch 373): Average loss: 0.2845, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.171674 (avg: 0.171674) \tsec/iter: 0.0379\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.295378 (avg: 0.237259) \tsec/iter: 0.0409\n",
      "Test set (epoch 374): Average loss: 0.3854, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.176353 (avg: 0.176353) \tsec/iter: 0.0489\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.303823 (avg: 0.203097) \tsec/iter: 0.0429\n",
      "Test set (epoch 375): Average loss: 0.4404, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.176402 (avg: 0.176402) \tsec/iter: 0.0499\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.280593 (avg: 0.191869) \tsec/iter: 0.0472\n",
      "Test set (epoch 376): Average loss: 0.3776, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.214704 (avg: 0.214704) \tsec/iter: 0.0459\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.140761 (avg: 0.202306) \tsec/iter: 0.0445\n",
      "Test set (epoch 377): Average loss: 0.4738, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.198141 (avg: 0.198141) \tsec/iter: 0.0429\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.242494 (avg: 0.210529) \tsec/iter: 0.0449\n",
      "Test set (epoch 378): Average loss: 0.2819, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.272879 (avg: 0.272879) \tsec/iter: 0.0519\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.276397 (avg: 0.261466) \tsec/iter: 0.0549\n",
      "Test set (epoch 379): Average loss: 0.4643, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.131753 (avg: 0.131753) \tsec/iter: 0.0638\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.326326 (avg: 0.217634) \tsec/iter: 0.0612\n",
      "Test set (epoch 380): Average loss: 0.5091, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.247770 (avg: 0.247770) \tsec/iter: 0.0558\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.283092 (avg: 0.217306) \tsec/iter: 0.0562\n",
      "Test set (epoch 381): Average loss: 0.3117, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.202856 (avg: 0.202856) \tsec/iter: 0.0479\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.302884 (avg: 0.206677) \tsec/iter: 0.0542\n",
      "Test set (epoch 382): Average loss: 0.3529, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.140836 (avg: 0.140836) \tsec/iter: 0.0628\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.215194 (avg: 0.219648) \tsec/iter: 0.0585\n",
      "Test set (epoch 383): Average loss: 0.2830, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.243228 (avg: 0.243228) \tsec/iter: 0.0638\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.185177 (avg: 0.186039) \tsec/iter: 0.0588\n",
      "Test set (epoch 384): Average loss: 0.3931, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.175450 (avg: 0.175450) \tsec/iter: 0.0489\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.386926 (avg: 0.241071) \tsec/iter: 0.0472\n",
      "Test set (epoch 385): Average loss: 0.4065, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.177669 (avg: 0.177669) \tsec/iter: 0.0449\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.241967 (avg: 0.196140) \tsec/iter: 0.0452\n",
      "Test set (epoch 386): Average loss: 0.4327, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.131193 (avg: 0.131193) \tsec/iter: 0.0529\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.278863 (avg: 0.194211) \tsec/iter: 0.0505\n",
      "Test set (epoch 387): Average loss: 0.5340, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.217119 (avg: 0.217119) \tsec/iter: 0.0489\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.213587 (avg: 0.212459) \tsec/iter: 0.0452\n",
      "Test set (epoch 388): Average loss: 0.4757, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.192586 (avg: 0.192586) \tsec/iter: 0.0519\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.186839 (avg: 0.183138) \tsec/iter: 0.0445\n",
      "Test set (epoch 389): Average loss: 0.4848, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.212229 (avg: 0.212229) \tsec/iter: 0.0439\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.326834 (avg: 0.219546) \tsec/iter: 0.0455\n",
      "Test set (epoch 390): Average loss: 0.3478, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.166107 (avg: 0.166107) \tsec/iter: 0.0489\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.118894 (avg: 0.234726) \tsec/iter: 0.0439\n",
      "Test set (epoch 391): Average loss: 0.5804, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.207889 (avg: 0.207889) \tsec/iter: 0.0409\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.249499 (avg: 0.241488) \tsec/iter: 0.0419\n",
      "Test set (epoch 392): Average loss: 0.4407, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.229911 (avg: 0.229911) \tsec/iter: 0.0529\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.296180 (avg: 0.222906) \tsec/iter: 0.0452\n",
      "Test set (epoch 393): Average loss: 0.3506, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.157423 (avg: 0.157423) \tsec/iter: 0.0509\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.317647 (avg: 0.281788) \tsec/iter: 0.0472\n",
      "Test set (epoch 394): Average loss: 0.5054, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.241021 (avg: 0.241021) \tsec/iter: 0.0628\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.214797 (avg: 0.215455) \tsec/iter: 0.0509\n",
      "Test set (epoch 395): Average loss: 0.4657, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.196541 (avg: 0.196541) \tsec/iter: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.148261 (avg: 0.196942) \tsec/iter: 0.0439\n",
      "Test set (epoch 396): Average loss: 0.5255, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.300804 (avg: 0.300804) \tsec/iter: 0.0409\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.253596 (avg: 0.232209) \tsec/iter: 0.0432\n",
      "Test set (epoch 397): Average loss: 0.4037, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.208906 (avg: 0.208906) \tsec/iter: 0.0489\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.079550 (avg: 0.257743) \tsec/iter: 0.0422\n",
      "Test set (epoch 398): Average loss: 0.3627, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.260094 (avg: 0.260094) \tsec/iter: 0.0598\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.252729 (avg: 0.220723) \tsec/iter: 0.0568\n",
      "Test set (epoch 399): Average loss: 0.5079, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.211241 (avg: 0.211241) \tsec/iter: 0.0728\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.394965 (avg: 0.222424) \tsec/iter: 0.0608\n",
      "Test set (epoch 400): Average loss: 0.3880, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.201745 (avg: 0.201745) \tsec/iter: 0.0499\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.112503 (avg: 0.183236) \tsec/iter: 0.0459\n",
      "Test set (epoch 401): Average loss: 0.4931, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.247538 (avg: 0.247538) \tsec/iter: 0.0489\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.111133 (avg: 0.180357) \tsec/iter: 0.0482\n",
      "Test set (epoch 402): Average loss: 0.4780, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.222196 (avg: 0.222196) \tsec/iter: 0.0409\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.219537 (avg: 0.179226) \tsec/iter: 0.0452\n",
      "Test set (epoch 403): Average loss: 0.6250, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.198179 (avg: 0.198179) \tsec/iter: 0.0559\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.322150 (avg: 0.203203) \tsec/iter: 0.0462\n",
      "Test set (epoch 404): Average loss: 0.6086, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.169895 (avg: 0.169895) \tsec/iter: 0.0399\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.322336 (avg: 0.190298) \tsec/iter: 0.0426\n",
      "Test set (epoch 405): Average loss: 0.5516, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.108125 (avg: 0.108125) \tsec/iter: 0.0439\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.170748 (avg: 0.189017) \tsec/iter: 0.0452\n",
      "Test set (epoch 406): Average loss: 0.5522, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.244543 (avg: 0.244543) \tsec/iter: 0.0429\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.112281 (avg: 0.194514) \tsec/iter: 0.0439\n",
      "Test set (epoch 407): Average loss: 0.7808, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.172649 (avg: 0.172649) \tsec/iter: 0.0549\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.318788 (avg: 0.204124) \tsec/iter: 0.0485\n",
      "Test set (epoch 408): Average loss: 0.5091, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.154114 (avg: 0.154114) \tsec/iter: 0.0499\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.153775 (avg: 0.180459) \tsec/iter: 0.0475\n",
      "Test set (epoch 409): Average loss: 0.4951, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.203641 (avg: 0.203641) \tsec/iter: 0.0409\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.097762 (avg: 0.187359) \tsec/iter: 0.0412\n",
      "Test set (epoch 410): Average loss: 0.4485, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.258709 (avg: 0.258709) \tsec/iter: 0.0429\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.182215 (avg: 0.208057) \tsec/iter: 0.0442\n",
      "Test set (epoch 411): Average loss: 0.8202, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.272078 (avg: 0.272078) \tsec/iter: 0.0449\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.139340 (avg: 0.198449) \tsec/iter: 0.0462\n",
      "Test set (epoch 412): Average loss: 0.4060, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.244756 (avg: 0.244756) \tsec/iter: 0.0419\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.154555 (avg: 0.217906) \tsec/iter: 0.0462\n",
      "Test set (epoch 413): Average loss: 0.5219, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.203556 (avg: 0.203556) \tsec/iter: 0.0848\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.322155 (avg: 0.234615) \tsec/iter: 0.0731\n",
      "Test set (epoch 414): Average loss: 0.4412, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.234973 (avg: 0.234973) \tsec/iter: 0.0409\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.183795 (avg: 0.211020) \tsec/iter: 0.0445\n",
      "Test set (epoch 415): Average loss: 0.4786, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.298760 (avg: 0.298760) \tsec/iter: 0.0439\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.196764 (avg: 0.250537) \tsec/iter: 0.0455\n",
      "Test set (epoch 416): Average loss: 0.5721, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.187862 (avg: 0.187862) \tsec/iter: 0.0489\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.176591 (avg: 0.186243) \tsec/iter: 0.0479\n",
      "Test set (epoch 417): Average loss: 0.6556, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.170159 (avg: 0.170159) \tsec/iter: 0.0469\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.277219 (avg: 0.224898) \tsec/iter: 0.0452\n",
      "Test set (epoch 418): Average loss: 0.5019, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.159464 (avg: 0.159464) \tsec/iter: 0.0459\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.255911 (avg: 0.172896) \tsec/iter: 0.0445\n",
      "Test set (epoch 419): Average loss: 0.5027, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.205220 (avg: 0.205220) \tsec/iter: 0.0509\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.334837 (avg: 0.247155) \tsec/iter: 0.0479\n",
      "Test set (epoch 420): Average loss: 0.4599, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.184457 (avg: 0.184457) \tsec/iter: 0.0648\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.213524 (avg: 0.195758) \tsec/iter: 0.0509\n",
      "Test set (epoch 421): Average loss: 0.4099, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.150103 (avg: 0.150103) \tsec/iter: 0.0439\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.267452 (avg: 0.188494) \tsec/iter: 0.0422\n",
      "Test set (epoch 422): Average loss: 0.5498, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.239968 (avg: 0.239968) \tsec/iter: 0.0559\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.186042 (avg: 0.210156) \tsec/iter: 0.0475\n",
      "Test set (epoch 423): Average loss: 0.5945, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.157761 (avg: 0.157761) \tsec/iter: 0.0509\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.258814 (avg: 0.216207) \tsec/iter: 0.0429\n",
      "Test set (epoch 424): Average loss: 0.4811, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.184315 (avg: 0.184315) \tsec/iter: 0.0519\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.246345 (avg: 0.208069) \tsec/iter: 0.0479\n",
      "Test set (epoch 425): Average loss: 0.7390, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.228093 (avg: 0.228093) \tsec/iter: 0.0519\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.234996 (avg: 0.260699) \tsec/iter: 0.0462\n",
      "Test set (epoch 426): Average loss: 0.5533, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.187902 (avg: 0.187902) \tsec/iter: 0.0479\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.176228 (avg: 0.224128) \tsec/iter: 0.0465\n",
      "Test set (epoch 427): Average loss: 0.5832, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.148643 (avg: 0.148643) \tsec/iter: 0.0568\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.186585 (avg: 0.223757) \tsec/iter: 0.0495\n",
      "Test set (epoch 428): Average loss: 0.4620, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.199704 (avg: 0.199704) \tsec/iter: 0.0409\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.137568 (avg: 0.181891) \tsec/iter: 0.0439\n",
      "Test set (epoch 429): Average loss: 0.6575, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.214309 (avg: 0.214309) \tsec/iter: 0.0489\n",
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.093907 (avg: 0.204698) \tsec/iter: 0.0445\n",
      "Test set (epoch 430): Average loss: 0.4931, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.206095 (avg: 0.206095) \tsec/iter: 0.0529\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.090425 (avg: 0.155125) \tsec/iter: 0.0472\n",
      "Test set (epoch 431): Average loss: 0.6864, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.205317 (avg: 0.205317) \tsec/iter: 0.0419\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.136381 (avg: 0.167242) \tsec/iter: 0.0426\n",
      "Test set (epoch 432): Average loss: 0.5064, Accuracy: 15/18 (83.33%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.258783 (avg: 0.258783) \tsec/iter: 0.0439\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.277741 (avg: 0.210628) \tsec/iter: 0.0459\n",
      "Test set (epoch 433): Average loss: 0.7034, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.195767 (avg: 0.195767) \tsec/iter: 0.0568\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.127722 (avg: 0.238161) \tsec/iter: 0.0515\n",
      "Test set (epoch 434): Average loss: 0.8198, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.172232 (avg: 0.172232) \tsec/iter: 0.0559\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.284240 (avg: 0.198367) \tsec/iter: 0.0499\n",
      "Test set (epoch 435): Average loss: 0.5167, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.329636 (avg: 0.329636) \tsec/iter: 0.0539\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.248047 (avg: 0.236619) \tsec/iter: 0.0479\n",
      "Test set (epoch 436): Average loss: 0.4764, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.165255 (avg: 0.165255) \tsec/iter: 0.0499\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.157958 (avg: 0.153678) \tsec/iter: 0.0475\n",
      "Test set (epoch 437): Average loss: 0.6208, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.161591 (avg: 0.161591) \tsec/iter: 0.0419\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.132538 (avg: 0.211193) \tsec/iter: 0.0439\n",
      "Test set (epoch 438): Average loss: 0.5449, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.318345 (avg: 0.318345) \tsec/iter: 0.0568\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.136754 (avg: 0.231113) \tsec/iter: 0.0509\n",
      "Test set (epoch 439): Average loss: 0.6414, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.216189 (avg: 0.216189) \tsec/iter: 0.0628\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.082729 (avg: 0.179396) \tsec/iter: 0.0535\n",
      "Test set (epoch 440): Average loss: 0.6868, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.167714 (avg: 0.167714) \tsec/iter: 0.0449\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.379087 (avg: 0.226800) \tsec/iter: 0.0465\n",
      "Test set (epoch 441): Average loss: 0.5274, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.288074 (avg: 0.288074) \tsec/iter: 0.0389\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.174620 (avg: 0.208405) \tsec/iter: 0.0426\n",
      "Test set (epoch 442): Average loss: 0.5064, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.184239 (avg: 0.184239) \tsec/iter: 0.0549\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.135646 (avg: 0.173239) \tsec/iter: 0.0492\n",
      "Test set (epoch 443): Average loss: 0.4810, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.138013 (avg: 0.138013) \tsec/iter: 0.0469\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.156601 (avg: 0.167573) \tsec/iter: 0.0472\n",
      "Test set (epoch 444): Average loss: 0.4550, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.298000 (avg: 0.298000) \tsec/iter: 0.0409\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.111891 (avg: 0.191748) \tsec/iter: 0.0442\n",
      "Test set (epoch 445): Average loss: 0.5996, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.208820 (avg: 0.208820) \tsec/iter: 0.0509\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.065750 (avg: 0.153006) \tsec/iter: 0.0555\n",
      "Test set (epoch 446): Average loss: 0.6001, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.125273 (avg: 0.125273) \tsec/iter: 0.0519\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.224689 (avg: 0.188534) \tsec/iter: 0.0452\n",
      "Test set (epoch 447): Average loss: 0.4976, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.210131 (avg: 0.210131) \tsec/iter: 0.0598\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.154914 (avg: 0.163340) \tsec/iter: 0.0579\n",
      "Test set (epoch 448): Average loss: 1.3429, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.272618 (avg: 0.272618) \tsec/iter: 0.0568\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.126778 (avg: 0.224577) \tsec/iter: 0.0469\n",
      "Test set (epoch 449): Average loss: 0.6217, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.120790 (avg: 0.120790) \tsec/iter: 0.0459\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.136506 (avg: 0.208791) \tsec/iter: 0.0559\n",
      "Test set (epoch 450): Average loss: 0.6119, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.138191 (avg: 0.138191) \tsec/iter: 0.0628\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.324694 (avg: 0.196590) \tsec/iter: 0.0575\n",
      "Test set (epoch 451): Average loss: 0.8558, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.159976 (avg: 0.159976) \tsec/iter: 0.0529\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.203837 (avg: 0.215868) \tsec/iter: 0.0608\n",
      "Test set (epoch 452): Average loss: 0.5960, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.162067 (avg: 0.162067) \tsec/iter: 0.0698\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.243690 (avg: 0.190248) \tsec/iter: 0.0572\n",
      "Test set (epoch 453): Average loss: 0.4608, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.276812 (avg: 0.276812) \tsec/iter: 0.0529\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.165264 (avg: 0.192997) \tsec/iter: 0.0475\n",
      "Test set (epoch 454): Average loss: 0.5958, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.106327 (avg: 0.106327) \tsec/iter: 0.0519\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.200635 (avg: 0.166517) \tsec/iter: 0.0462\n",
      "Test set (epoch 455): Average loss: 0.6998, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.212607 (avg: 0.212607) \tsec/iter: 0.0459\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.112644 (avg: 0.189063) \tsec/iter: 0.0426\n",
      "Test set (epoch 456): Average loss: 0.4804, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.200966 (avg: 0.200966) \tsec/iter: 0.0439\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.100179 (avg: 0.188075) \tsec/iter: 0.0409\n",
      "Test set (epoch 457): Average loss: 0.7440, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.333571 (avg: 0.333571) \tsec/iter: 0.0439\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.184952 (avg: 0.228046) \tsec/iter: 0.0432\n",
      "Test set (epoch 458): Average loss: 0.5635, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.131549 (avg: 0.131549) \tsec/iter: 0.0509\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.216671 (avg: 0.188958) \tsec/iter: 0.0482\n",
      "Test set (epoch 459): Average loss: 0.5964, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.139816 (avg: 0.139816) \tsec/iter: 0.0469\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.258143 (avg: 0.184766) \tsec/iter: 0.0512\n",
      "Test set (epoch 460): Average loss: 0.7244, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.309980 (avg: 0.309980) \tsec/iter: 0.0648\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.214647 (avg: 0.249533) \tsec/iter: 0.0605\n",
      "Test set (epoch 461): Average loss: 0.5424, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.187312 (avg: 0.187312) \tsec/iter: 0.0598\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.209746 (avg: 0.192451) \tsec/iter: 0.0492\n",
      "Test set (epoch 462): Average loss: 0.5797, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.137818 (avg: 0.137818) \tsec/iter: 0.0509\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.140611 (avg: 0.198169) \tsec/iter: 0.0482\n",
      "Test set (epoch 463): Average loss: 0.6244, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.186364 (avg: 0.186364) \tsec/iter: 0.0539\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.348968 (avg: 0.208391) \tsec/iter: 0.0502\n",
      "Test set (epoch 464): Average loss: 0.6207, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.266449 (avg: 0.266449) \tsec/iter: 0.0529\n",
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.084293 (avg: 0.173427) \tsec/iter: 0.0612\n",
      "Test set (epoch 465): Average loss: 0.4405, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.157849 (avg: 0.157849) \tsec/iter: 0.0618\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.145087 (avg: 0.207873) \tsec/iter: 0.0542\n",
      "Test set (epoch 466): Average loss: 0.5709, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.175001 (avg: 0.175001) \tsec/iter: 0.0489\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.150103 (avg: 0.140609) \tsec/iter: 0.0436\n",
      "Test set (epoch 467): Average loss: 0.5610, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.255706 (avg: 0.255706) \tsec/iter: 0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.384486 (avg: 0.282362) \tsec/iter: 0.0449\n",
      "Test set (epoch 468): Average loss: 0.5684, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.214737 (avg: 0.214737) \tsec/iter: 0.0509\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.123150 (avg: 0.223626) \tsec/iter: 0.0455\n",
      "Test set (epoch 469): Average loss: 0.8614, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.178206 (avg: 0.178206) \tsec/iter: 0.0469\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.171517 (avg: 0.189206) \tsec/iter: 0.0465\n",
      "Test set (epoch 470): Average loss: 0.5013, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.147737 (avg: 0.147737) \tsec/iter: 0.0828\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.197469 (avg: 0.163855) \tsec/iter: 0.0731\n",
      "Test set (epoch 471): Average loss: 0.8257, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.183359 (avg: 0.183359) \tsec/iter: 0.0628\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.335463 (avg: 0.245949) \tsec/iter: 0.0575\n",
      "Test set (epoch 472): Average loss: 0.4583, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.149182 (avg: 0.149182) \tsec/iter: 0.0489\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.077262 (avg: 0.164082) \tsec/iter: 0.0455\n",
      "Test set (epoch 473): Average loss: 0.6197, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.127750 (avg: 0.127750) \tsec/iter: 0.0598\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.129401 (avg: 0.160867) \tsec/iter: 0.0585\n",
      "Test set (epoch 474): Average loss: 0.6390, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.237676 (avg: 0.237676) \tsec/iter: 0.0688\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.117012 (avg: 0.180928) \tsec/iter: 0.0519\n",
      "Test set (epoch 475): Average loss: 0.6294, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.173040 (avg: 0.173040) \tsec/iter: 0.0539\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.148382 (avg: 0.174174) \tsec/iter: 0.0489\n",
      "Test set (epoch 476): Average loss: 0.6695, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.151726 (avg: 0.151726) \tsec/iter: 0.0608\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.427334 (avg: 0.202706) \tsec/iter: 0.0482\n",
      "Test set (epoch 477): Average loss: 0.5393, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.123742 (avg: 0.123742) \tsec/iter: 0.0479\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.259562 (avg: 0.199369) \tsec/iter: 0.0459\n",
      "Test set (epoch 478): Average loss: 0.5760, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.070692 (avg: 0.070692) \tsec/iter: 0.0469\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.232303 (avg: 0.207715) \tsec/iter: 0.0449\n",
      "Test set (epoch 479): Average loss: 0.5868, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.132051 (avg: 0.132051) \tsec/iter: 0.0459\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.155999 (avg: 0.178911) \tsec/iter: 0.0452\n",
      "Test set (epoch 480): Average loss: 0.6305, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.200154 (avg: 0.200154) \tsec/iter: 0.0489\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.097759 (avg: 0.216735) \tsec/iter: 0.0445\n",
      "Test set (epoch 481): Average loss: 0.4972, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.179081 (avg: 0.179081) \tsec/iter: 0.0529\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.091812 (avg: 0.180357) \tsec/iter: 0.0479\n",
      "Test set (epoch 482): Average loss: 0.7438, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.119633 (avg: 0.119633) \tsec/iter: 0.0479\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.287232 (avg: 0.214299) \tsec/iter: 0.0452\n",
      "Test set (epoch 483): Average loss: 0.7793, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.197659 (avg: 0.197659) \tsec/iter: 0.0489\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.174834 (avg: 0.191185) \tsec/iter: 0.0442\n",
      "Test set (epoch 484): Average loss: 0.8003, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.187205 (avg: 0.187205) \tsec/iter: 0.0459\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.114885 (avg: 0.169911) \tsec/iter: 0.0445\n",
      "Test set (epoch 485): Average loss: 0.8137, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.131677 (avg: 0.131677) \tsec/iter: 0.0429\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.125161 (avg: 0.156472) \tsec/iter: 0.0465\n",
      "Test set (epoch 486): Average loss: 0.6057, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.145946 (avg: 0.145946) \tsec/iter: 0.0638\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.106762 (avg: 0.157026) \tsec/iter: 0.0608\n",
      "Test set (epoch 487): Average loss: 0.5800, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.168952 (avg: 0.168952) \tsec/iter: 0.0628\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.192171 (avg: 0.191153) \tsec/iter: 0.0509\n",
      "Test set (epoch 488): Average loss: 0.4803, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.218989 (avg: 0.218989) \tsec/iter: 0.0588\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.105836 (avg: 0.188646) \tsec/iter: 0.0519\n",
      "Test set (epoch 489): Average loss: 0.9781, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.174304 (avg: 0.174304) \tsec/iter: 0.0638\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.224858 (avg: 0.243019) \tsec/iter: 0.0532\n",
      "Test set (epoch 490): Average loss: 0.7637, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.313099 (avg: 0.313099) \tsec/iter: 0.0479\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.079006 (avg: 0.182105) \tsec/iter: 0.0432\n",
      "Test set (epoch 491): Average loss: 0.7656, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.165033 (avg: 0.165033) \tsec/iter: 0.0519\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.244441 (avg: 0.179941) \tsec/iter: 0.0442\n",
      "Test set (epoch 492): Average loss: 0.7029, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.128050 (avg: 0.128050) \tsec/iter: 0.0529\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.190783 (avg: 0.182037) \tsec/iter: 0.0479\n",
      "Test set (epoch 493): Average loss: 0.7107, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.222817 (avg: 0.222817) \tsec/iter: 0.0399\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.129746 (avg: 0.183644) \tsec/iter: 0.0409\n",
      "Test set (epoch 494): Average loss: 0.7218, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.228730 (avg: 0.228730) \tsec/iter: 0.0529\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.130987 (avg: 0.197810) \tsec/iter: 0.0472\n",
      "Test set (epoch 495): Average loss: 0.8888, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.266295 (avg: 0.266295) \tsec/iter: 0.0489\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.149159 (avg: 0.181829) \tsec/iter: 0.0595\n",
      "Test set (epoch 496): Average loss: 0.7449, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.217145 (avg: 0.217145) \tsec/iter: 0.0638\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.113600 (avg: 0.166852) \tsec/iter: 0.0605\n",
      "Test set (epoch 497): Average loss: 0.6830, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.284881 (avg: 0.284881) \tsec/iter: 0.0678\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.122552 (avg: 0.211037) \tsec/iter: 0.0525\n",
      "Test set (epoch 498): Average loss: 0.7321, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.190881 (avg: 0.190881) \tsec/iter: 0.0519\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.184771 (avg: 0.184463) \tsec/iter: 0.0505\n",
      "Test set (epoch 499): Average loss: 0.4813, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "\n",
      "FOLD 9\n",
      "TRAIN: 170/188\n",
      "TEST: 18/188\n",
      "\n",
      "Initialize model\n",
      "GNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=7, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): GraphSN(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): Dropout(p=0.6, inplace=False)\n",
      "        (2): ReLU()\n",
      "        (3): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): Dropout(p=0.6, inplace=False)\n",
      "        (6): ReLU()\n",
      "        (7): BatchNorm1d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): Linear(in_features=135, out_features=2, bias=True)\n",
      ")\n",
      "N trainable parameters: 21810\n",
      "Train Epoch: 0 [64/170 (33%)]\tLoss: 1.566628 (avg: 1.566628) \tsec/iter: 0.0529\n",
      "Train Epoch: 0 [170/170 (100%)]\tLoss: 4.397295 (avg: 5.098905) \tsec/iter: 0.0492\n",
      "Test set (epoch 0): Average loss: 0.5059, Accuracy: 13/18 (72.22%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 1 [64/170 (33%)]\tLoss: 0.414808 (avg: 0.414808) \tsec/iter: 0.0519\n",
      "Train Epoch: 1 [170/170 (100%)]\tLoss: 0.717904 (avg: 1.486549) \tsec/iter: 0.0469\n",
      "Test set (epoch 1): Average loss: 0.4153, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 2 [64/170 (33%)]\tLoss: 1.930666 (avg: 1.930666) \tsec/iter: 0.0479\n",
      "Train Epoch: 2 [170/170 (100%)]\tLoss: 1.029875 (avg: 1.207430) \tsec/iter: 0.0472\n",
      "Test set (epoch 2): Average loss: 1.7417, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 3 [64/170 (33%)]\tLoss: 0.553564 (avg: 0.553564) \tsec/iter: 0.0529\n",
      "Train Epoch: 3 [170/170 (100%)]\tLoss: 0.332295 (avg: 0.489978) \tsec/iter: 0.0462\n",
      "Test set (epoch 3): Average loss: 1.3876, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 4 [64/170 (33%)]\tLoss: 0.472999 (avg: 0.472999) \tsec/iter: 0.0429\n",
      "Train Epoch: 4 [170/170 (100%)]\tLoss: 0.357921 (avg: 0.474945) \tsec/iter: 0.0442\n",
      "Test set (epoch 4): Average loss: 1.2982, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 5 [64/170 (33%)]\tLoss: 0.473160 (avg: 0.473160) \tsec/iter: 0.0499\n",
      "Train Epoch: 5 [170/170 (100%)]\tLoss: 0.423065 (avg: 0.436795) \tsec/iter: 0.0436\n",
      "Test set (epoch 5): Average loss: 2.7171, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 6 [64/170 (33%)]\tLoss: 0.893660 (avg: 0.893660) \tsec/iter: 0.0559\n",
      "Train Epoch: 6 [170/170 (100%)]\tLoss: 0.767055 (avg: 0.704673) \tsec/iter: 0.0489\n",
      "Test set (epoch 6): Average loss: 2.6835, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 7 [64/170 (33%)]\tLoss: 0.478518 (avg: 0.478518) \tsec/iter: 0.0439\n",
      "Train Epoch: 7 [170/170 (100%)]\tLoss: 0.325254 (avg: 0.407955) \tsec/iter: 0.0429\n",
      "Test set (epoch 7): Average loss: 1.9034, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 8 [64/170 (33%)]\tLoss: 0.401948 (avg: 0.401948) \tsec/iter: 0.0668\n",
      "Train Epoch: 8 [170/170 (100%)]\tLoss: 0.601090 (avg: 0.460908) \tsec/iter: 0.0555\n",
      "Test set (epoch 8): Average loss: 1.3976, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 9 [64/170 (33%)]\tLoss: 0.484035 (avg: 0.484035) \tsec/iter: 0.0598\n",
      "Train Epoch: 9 [170/170 (100%)]\tLoss: 0.536136 (avg: 0.485452) \tsec/iter: 0.0542\n",
      "Test set (epoch 9): Average loss: 1.5875, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 10 [64/170 (33%)]\tLoss: 0.369031 (avg: 0.369031) \tsec/iter: 0.0529\n",
      "Train Epoch: 10 [170/170 (100%)]\tLoss: 0.468376 (avg: 0.432742) \tsec/iter: 0.0492\n",
      "Test set (epoch 10): Average loss: 1.3446, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 11 [64/170 (33%)]\tLoss: 0.438725 (avg: 0.438725) \tsec/iter: 0.0558\n",
      "Train Epoch: 11 [170/170 (100%)]\tLoss: 0.356659 (avg: 0.370785) \tsec/iter: 0.0472\n",
      "Test set (epoch 11): Average loss: 1.3472, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 12 [64/170 (33%)]\tLoss: 0.476132 (avg: 0.476132) \tsec/iter: 0.0489\n",
      "Train Epoch: 12 [170/170 (100%)]\tLoss: 0.542408 (avg: 0.430062) \tsec/iter: 0.0449\n",
      "Test set (epoch 12): Average loss: 1.9226, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 13 [64/170 (33%)]\tLoss: 0.537878 (avg: 0.537878) \tsec/iter: 0.0568\n",
      "Train Epoch: 13 [170/170 (100%)]\tLoss: 0.245355 (avg: 0.573743) \tsec/iter: 0.0502\n",
      "Test set (epoch 13): Average loss: 0.6493, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 14 [64/170 (33%)]\tLoss: 1.051349 (avg: 1.051349) \tsec/iter: 0.0578\n",
      "Train Epoch: 14 [170/170 (100%)]\tLoss: 0.292232 (avg: 0.640331) \tsec/iter: 0.0575\n",
      "Test set (epoch 14): Average loss: 1.8834, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 15 [64/170 (33%)]\tLoss: 0.477873 (avg: 0.477873) \tsec/iter: 0.0648\n",
      "Train Epoch: 15 [170/170 (100%)]\tLoss: 0.394979 (avg: 0.445731) \tsec/iter: 0.0565\n",
      "Test set (epoch 15): Average loss: 1.3761, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 16 [64/170 (33%)]\tLoss: 0.363195 (avg: 0.363195) \tsec/iter: 0.0509\n",
      "Train Epoch: 16 [170/170 (100%)]\tLoss: 0.476463 (avg: 0.370394) \tsec/iter: 0.0482\n",
      "Test set (epoch 16): Average loss: 1.3475, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 17 [64/170 (33%)]\tLoss: 0.386291 (avg: 0.386291) \tsec/iter: 0.0479\n",
      "Train Epoch: 17 [170/170 (100%)]\tLoss: 0.441619 (avg: 0.415824) \tsec/iter: 0.0645\n",
      "Test set (epoch 17): Average loss: 1.6966, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 18 [64/170 (33%)]\tLoss: 0.454232 (avg: 0.454232) \tsec/iter: 0.0489\n",
      "Train Epoch: 18 [170/170 (100%)]\tLoss: 0.591649 (avg: 0.476635) \tsec/iter: 0.0452\n",
      "Test set (epoch 18): Average loss: 1.2037, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 19 [64/170 (33%)]\tLoss: 0.411742 (avg: 0.411742) \tsec/iter: 0.0469\n",
      "Train Epoch: 19 [170/170 (100%)]\tLoss: 0.431527 (avg: 0.401009) \tsec/iter: 0.0452\n",
      "Test set (epoch 19): Average loss: 1.0093, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 20 [64/170 (33%)]\tLoss: 0.390949 (avg: 0.390949) \tsec/iter: 0.0818\n",
      "Train Epoch: 20 [170/170 (100%)]\tLoss: 0.491977 (avg: 0.401462) \tsec/iter: 0.0652\n",
      "Test set (epoch 20): Average loss: 1.0688, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 21 [64/170 (33%)]\tLoss: 0.358924 (avg: 0.358924) \tsec/iter: 0.0568\n",
      "Train Epoch: 21 [170/170 (100%)]\tLoss: 0.347208 (avg: 0.377791) \tsec/iter: 0.0499\n",
      "Test set (epoch 21): Average loss: 1.2785, Accuracy: 6/18 (33.33%)\n",
      "\n",
      "Train Epoch: 22 [64/170 (33%)]\tLoss: 0.333340 (avg: 0.333340) \tsec/iter: 0.0439\n",
      "Train Epoch: 22 [170/170 (100%)]\tLoss: 0.373055 (avg: 0.379449) \tsec/iter: 0.0436\n",
      "Test set (epoch 22): Average loss: 1.0688, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 23 [64/170 (33%)]\tLoss: 0.420858 (avg: 0.420858) \tsec/iter: 0.0479\n",
      "Train Epoch: 23 [170/170 (100%)]\tLoss: 0.610943 (avg: 0.431754) \tsec/iter: 0.0422\n",
      "Test set (epoch 23): Average loss: 1.1418, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 24 [64/170 (33%)]\tLoss: 0.481777 (avg: 0.481777) \tsec/iter: 0.0539\n",
      "Train Epoch: 24 [170/170 (100%)]\tLoss: 0.355949 (avg: 0.436073) \tsec/iter: 0.0449\n",
      "Test set (epoch 24): Average loss: 1.0876, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 25 [64/170 (33%)]\tLoss: 0.309763 (avg: 0.309763) \tsec/iter: 0.0389\n",
      "Train Epoch: 25 [170/170 (100%)]\tLoss: 0.512527 (avg: 0.392387) \tsec/iter: 0.0406\n",
      "Test set (epoch 25): Average loss: 0.8390, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 26 [64/170 (33%)]\tLoss: 0.379715 (avg: 0.379715) \tsec/iter: 0.0469\n",
      "Train Epoch: 26 [170/170 (100%)]\tLoss: 0.451138 (avg: 0.381325) \tsec/iter: 0.0445\n",
      "Test set (epoch 26): Average loss: 1.0596, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 27 [64/170 (33%)]\tLoss: 0.425201 (avg: 0.425201) \tsec/iter: 0.0997\n",
      "Train Epoch: 27 [170/170 (100%)]\tLoss: 0.414658 (avg: 0.404456) \tsec/iter: 0.0775\n",
      "Test set (epoch 27): Average loss: 0.8511, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 28 [64/170 (33%)]\tLoss: 0.335276 (avg: 0.335276) \tsec/iter: 0.0598\n",
      "Train Epoch: 28 [170/170 (100%)]\tLoss: 0.373099 (avg: 0.347291) \tsec/iter: 0.0472\n",
      "Test set (epoch 28): Average loss: 0.9127, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 29 [64/170 (33%)]\tLoss: 0.383213 (avg: 0.383213) \tsec/iter: 0.0499\n",
      "Train Epoch: 29 [170/170 (100%)]\tLoss: 0.379995 (avg: 0.354281) \tsec/iter: 0.0462\n",
      "Test set (epoch 29): Average loss: 0.9594, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 30 [64/170 (33%)]\tLoss: 0.438717 (avg: 0.438717) \tsec/iter: 0.0449\n",
      "Train Epoch: 30 [170/170 (100%)]\tLoss: 0.227913 (avg: 0.376091) \tsec/iter: 0.0506\n",
      "Test set (epoch 30): Average loss: 0.9309, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 31 [64/170 (33%)]\tLoss: 0.345530 (avg: 0.345530) \tsec/iter: 0.0658\n",
      "Train Epoch: 31 [170/170 (100%)]\tLoss: 0.354896 (avg: 0.364672) \tsec/iter: 0.0582\n",
      "Test set (epoch 31): Average loss: 0.9832, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 32 [64/170 (33%)]\tLoss: 0.360759 (avg: 0.360759) \tsec/iter: 0.0509\n",
      "Train Epoch: 32 [170/170 (100%)]\tLoss: 0.535197 (avg: 0.403293) \tsec/iter: 0.0445\n",
      "Test set (epoch 32): Average loss: 1.0158, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 33 [64/170 (33%)]\tLoss: 0.282293 (avg: 0.282293) \tsec/iter: 0.0489\n",
      "Train Epoch: 33 [170/170 (100%)]\tLoss: 0.497136 (avg: 0.375955) \tsec/iter: 0.0439\n",
      "Test set (epoch 33): Average loss: 1.0203, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 34 [64/170 (33%)]\tLoss: 0.406657 (avg: 0.406657) \tsec/iter: 0.0439\n",
      "Train Epoch: 34 [170/170 (100%)]\tLoss: 0.353880 (avg: 0.365276) \tsec/iter: 0.0426\n",
      "Test set (epoch 34): Average loss: 0.9947, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 35 [64/170 (33%)]\tLoss: 0.433934 (avg: 0.433934) \tsec/iter: 0.0499\n",
      "Train Epoch: 35 [170/170 (100%)]\tLoss: 0.280546 (avg: 0.369721) \tsec/iter: 0.0449\n",
      "Test set (epoch 35): Average loss: 0.9452, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 36 [64/170 (33%)]\tLoss: 0.429012 (avg: 0.429012) \tsec/iter: 0.0499\n",
      "Train Epoch: 36 [170/170 (100%)]\tLoss: 0.328747 (avg: 0.368349) \tsec/iter: 0.0479\n",
      "Test set (epoch 36): Average loss: 0.8743, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 37 [64/170 (33%)]\tLoss: 0.465805 (avg: 0.465805) \tsec/iter: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [170/170 (100%)]\tLoss: 0.333721 (avg: 0.365916) \tsec/iter: 0.0482\n",
      "Test set (epoch 37): Average loss: 0.8909, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 38 [64/170 (33%)]\tLoss: 0.347299 (avg: 0.347299) \tsec/iter: 0.0529\n",
      "Train Epoch: 38 [170/170 (100%)]\tLoss: 0.431974 (avg: 0.352049) \tsec/iter: 0.0429\n",
      "Test set (epoch 38): Average loss: 0.9649, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 39 [64/170 (33%)]\tLoss: 0.361689 (avg: 0.361689) \tsec/iter: 0.0509\n",
      "Train Epoch: 39 [170/170 (100%)]\tLoss: 0.312391 (avg: 0.355854) \tsec/iter: 0.0462\n",
      "Test set (epoch 39): Average loss: 0.8749, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 40 [64/170 (33%)]\tLoss: 0.395108 (avg: 0.395108) \tsec/iter: 0.0578\n",
      "Train Epoch: 40 [170/170 (100%)]\tLoss: 0.272429 (avg: 0.341592) \tsec/iter: 0.0469\n",
      "Test set (epoch 40): Average loss: 0.8488, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 41 [64/170 (33%)]\tLoss: 0.278162 (avg: 0.278162) \tsec/iter: 0.0469\n",
      "Train Epoch: 41 [170/170 (100%)]\tLoss: 0.310272 (avg: 0.372958) \tsec/iter: 0.0472\n",
      "Test set (epoch 41): Average loss: 0.8262, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 42 [64/170 (33%)]\tLoss: 0.276388 (avg: 0.276388) \tsec/iter: 0.0539\n",
      "Train Epoch: 42 [170/170 (100%)]\tLoss: 0.624611 (avg: 0.404667) \tsec/iter: 0.0482\n",
      "Test set (epoch 42): Average loss: 0.9227, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 43 [64/170 (33%)]\tLoss: 0.302367 (avg: 0.302367) \tsec/iter: 0.0509\n",
      "Train Epoch: 43 [170/170 (100%)]\tLoss: 0.468344 (avg: 0.389800) \tsec/iter: 0.0442\n",
      "Test set (epoch 43): Average loss: 0.8995, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 44 [64/170 (33%)]\tLoss: 0.303673 (avg: 0.303673) \tsec/iter: 0.0449\n",
      "Train Epoch: 44 [170/170 (100%)]\tLoss: 0.471327 (avg: 0.354413) \tsec/iter: 0.0402\n",
      "Test set (epoch 44): Average loss: 0.7999, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 45 [64/170 (33%)]\tLoss: 0.285128 (avg: 0.285128) \tsec/iter: 0.0489\n",
      "Train Epoch: 45 [170/170 (100%)]\tLoss: 0.365119 (avg: 0.354613) \tsec/iter: 0.0442\n",
      "Test set (epoch 45): Average loss: 0.8559, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 46 [64/170 (33%)]\tLoss: 0.436382 (avg: 0.436382) \tsec/iter: 0.0688\n",
      "Train Epoch: 46 [170/170 (100%)]\tLoss: 0.295768 (avg: 0.375200) \tsec/iter: 0.0555\n",
      "Test set (epoch 46): Average loss: 0.8037, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 47 [64/170 (33%)]\tLoss: 0.311000 (avg: 0.311000) \tsec/iter: 0.0409\n",
      "Train Epoch: 47 [170/170 (100%)]\tLoss: 0.474215 (avg: 0.384350) \tsec/iter: 0.0445\n",
      "Test set (epoch 47): Average loss: 0.9060, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 48 [64/170 (33%)]\tLoss: 0.347397 (avg: 0.347397) \tsec/iter: 0.0529\n",
      "Train Epoch: 48 [170/170 (100%)]\tLoss: 0.255956 (avg: 0.344955) \tsec/iter: 0.0445\n",
      "Test set (epoch 48): Average loss: 0.8115, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 49 [64/170 (33%)]\tLoss: 0.344442 (avg: 0.344442) \tsec/iter: 0.0439\n",
      "Train Epoch: 49 [170/170 (100%)]\tLoss: 0.418973 (avg: 0.354865) \tsec/iter: 0.0422\n",
      "Test set (epoch 49): Average loss: 0.8020, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 50 [64/170 (33%)]\tLoss: 0.357513 (avg: 0.357513) \tsec/iter: 0.0539\n",
      "Train Epoch: 50 [170/170 (100%)]\tLoss: 0.357559 (avg: 0.351752) \tsec/iter: 0.0442\n",
      "Test set (epoch 50): Average loss: 0.8680, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 51 [64/170 (33%)]\tLoss: 0.388968 (avg: 0.388968) \tsec/iter: 0.0529\n",
      "Train Epoch: 51 [170/170 (100%)]\tLoss: 0.364819 (avg: 0.399562) \tsec/iter: 0.0462\n",
      "Test set (epoch 51): Average loss: 0.8436, Accuracy: 7/18 (38.89%)\n",
      "\n",
      "Train Epoch: 52 [64/170 (33%)]\tLoss: 0.418499 (avg: 0.418499) \tsec/iter: 0.0519\n",
      "Train Epoch: 52 [170/170 (100%)]\tLoss: 0.286141 (avg: 0.355434) \tsec/iter: 0.0439\n",
      "Test set (epoch 52): Average loss: 0.7387, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 53 [64/170 (33%)]\tLoss: 0.399835 (avg: 0.399835) \tsec/iter: 0.0479\n",
      "Train Epoch: 53 [170/170 (100%)]\tLoss: 0.401740 (avg: 0.376533) \tsec/iter: 0.0442\n",
      "Test set (epoch 53): Average loss: 0.7268, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 54 [64/170 (33%)]\tLoss: 0.417111 (avg: 0.417111) \tsec/iter: 0.0439\n",
      "Train Epoch: 54 [170/170 (100%)]\tLoss: 0.375243 (avg: 0.364034) \tsec/iter: 0.0475\n",
      "Test set (epoch 54): Average loss: 0.7387, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 55 [64/170 (33%)]\tLoss: 0.247108 (avg: 0.247108) \tsec/iter: 0.0668\n",
      "Train Epoch: 55 [170/170 (100%)]\tLoss: 0.311567 (avg: 0.304474) \tsec/iter: 0.0642\n",
      "Test set (epoch 55): Average loss: 0.7810, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 56 [64/170 (33%)]\tLoss: 0.260700 (avg: 0.260700) \tsec/iter: 0.0718\n",
      "Train Epoch: 56 [170/170 (100%)]\tLoss: 0.532375 (avg: 0.369628) \tsec/iter: 0.0572\n",
      "Test set (epoch 56): Average loss: 0.8035, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 57 [64/170 (33%)]\tLoss: 0.375643 (avg: 0.375643) \tsec/iter: 0.0519\n",
      "Train Epoch: 57 [170/170 (100%)]\tLoss: 0.404849 (avg: 0.335667) \tsec/iter: 0.0475\n",
      "Test set (epoch 57): Average loss: 0.7566, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 58 [64/170 (33%)]\tLoss: 0.326537 (avg: 0.326537) \tsec/iter: 0.0509\n",
      "Train Epoch: 58 [170/170 (100%)]\tLoss: 0.362364 (avg: 0.347064) \tsec/iter: 0.0469\n",
      "Test set (epoch 58): Average loss: 0.7324, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 59 [64/170 (33%)]\tLoss: 0.337995 (avg: 0.337995) \tsec/iter: 0.0568\n",
      "Train Epoch: 59 [170/170 (100%)]\tLoss: 0.447671 (avg: 0.366204) \tsec/iter: 0.0519\n",
      "Test set (epoch 59): Average loss: 0.7136, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 60 [64/170 (33%)]\tLoss: 0.278837 (avg: 0.278837) \tsec/iter: 0.0549\n",
      "Train Epoch: 60 [170/170 (100%)]\tLoss: 0.439985 (avg: 0.344940) \tsec/iter: 0.0505\n",
      "Test set (epoch 60): Average loss: 0.7785, Accuracy: 9/18 (50.00%)\n",
      "\n",
      "Train Epoch: 61 [64/170 (33%)]\tLoss: 0.317139 (avg: 0.317139) \tsec/iter: 0.0459\n",
      "Train Epoch: 61 [170/170 (100%)]\tLoss: 0.264147 (avg: 0.345687) \tsec/iter: 0.0455\n",
      "Test set (epoch 61): Average loss: 0.7004, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 62 [64/170 (33%)]\tLoss: 0.296677 (avg: 0.296677) \tsec/iter: 0.0449\n",
      "Train Epoch: 62 [170/170 (100%)]\tLoss: 0.347515 (avg: 0.362362) \tsec/iter: 0.0416\n",
      "Test set (epoch 62): Average loss: 0.7272, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 63 [64/170 (33%)]\tLoss: 0.323859 (avg: 0.323859) \tsec/iter: 0.0469\n",
      "Train Epoch: 63 [170/170 (100%)]\tLoss: 0.374311 (avg: 0.368023) \tsec/iter: 0.0455\n",
      "Test set (epoch 63): Average loss: 0.7079, Accuracy: 10/18 (55.56%)\n",
      "\n",
      "Train Epoch: 64 [64/170 (33%)]\tLoss: 0.331659 (avg: 0.331659) \tsec/iter: 0.0499\n",
      "Train Epoch: 64 [170/170 (100%)]\tLoss: 0.473943 (avg: 0.377241) \tsec/iter: 0.0435\n",
      "Test set (epoch 64): Average loss: 0.6421, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 65 [64/170 (33%)]\tLoss: 0.281247 (avg: 0.281247) \tsec/iter: 0.0628\n",
      "Train Epoch: 65 [170/170 (100%)]\tLoss: 0.303857 (avg: 0.349029) \tsec/iter: 0.0499\n",
      "Test set (epoch 65): Average loss: 0.6436, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 66 [64/170 (33%)]\tLoss: 0.329164 (avg: 0.329164) \tsec/iter: 0.0519\n",
      "Train Epoch: 66 [170/170 (100%)]\tLoss: 0.305462 (avg: 0.366415) \tsec/iter: 0.0472\n",
      "Test set (epoch 66): Average loss: 0.7213, Accuracy: 8/18 (44.44%)\n",
      "\n",
      "Train Epoch: 67 [64/170 (33%)]\tLoss: 0.454610 (avg: 0.454610) \tsec/iter: 0.0539\n",
      "Train Epoch: 67 [170/170 (100%)]\tLoss: 0.310039 (avg: 0.360075) \tsec/iter: 0.0475\n",
      "Test set (epoch 67): Average loss: 0.6982, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 68 [64/170 (33%)]\tLoss: 0.389664 (avg: 0.389664) \tsec/iter: 0.0509\n",
      "Train Epoch: 68 [170/170 (100%)]\tLoss: 0.274579 (avg: 0.394431) \tsec/iter: 0.0482\n",
      "Test set (epoch 68): Average loss: 0.6380, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 69 [64/170 (33%)]\tLoss: 0.328644 (avg: 0.328644) \tsec/iter: 0.0489\n",
      "Train Epoch: 69 [170/170 (100%)]\tLoss: 0.309182 (avg: 0.340422) \tsec/iter: 0.0522\n",
      "Test set (epoch 69): Average loss: 0.6332, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 70 [64/170 (33%)]\tLoss: 0.417803 (avg: 0.417803) \tsec/iter: 0.0698\n",
      "Train Epoch: 70 [170/170 (100%)]\tLoss: 0.297259 (avg: 0.344836) \tsec/iter: 0.0592\n",
      "Test set (epoch 70): Average loss: 0.6270, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 71 [64/170 (33%)]\tLoss: 0.268286 (avg: 0.268286) \tsec/iter: 0.0838\n",
      "Train Epoch: 71 [170/170 (100%)]\tLoss: 0.516294 (avg: 0.331581) \tsec/iter: 0.0888\n",
      "Test set (epoch 71): Average loss: 0.6468, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 72 [64/170 (33%)]\tLoss: 0.300038 (avg: 0.300038) \tsec/iter: 0.1596\n",
      "Train Epoch: 72 [170/170 (100%)]\tLoss: 0.347032 (avg: 0.347701) \tsec/iter: 0.0947\n",
      "Test set (epoch 72): Average loss: 0.6668, Accuracy: 12/18 (66.67%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [64/170 (33%)]\tLoss: 0.311822 (avg: 0.311822) \tsec/iter: 0.0728\n",
      "Train Epoch: 73 [170/170 (100%)]\tLoss: 0.433259 (avg: 0.347022) \tsec/iter: 0.0568\n",
      "Test set (epoch 73): Average loss: 0.5813, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 74 [64/170 (33%)]\tLoss: 0.282493 (avg: 0.282493) \tsec/iter: 0.0539\n",
      "Train Epoch: 74 [170/170 (100%)]\tLoss: 0.353147 (avg: 0.327172) \tsec/iter: 0.0482\n",
      "Test set (epoch 74): Average loss: 0.6367, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 75 [64/170 (33%)]\tLoss: 0.314686 (avg: 0.314686) \tsec/iter: 0.0469\n",
      "Train Epoch: 75 [170/170 (100%)]\tLoss: 0.376447 (avg: 0.334652) \tsec/iter: 0.0512\n",
      "Test set (epoch 75): Average loss: 0.6048, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 76 [64/170 (33%)]\tLoss: 0.330592 (avg: 0.330592) \tsec/iter: 0.0947\n",
      "Train Epoch: 76 [170/170 (100%)]\tLoss: 0.272292 (avg: 0.341665) \tsec/iter: 0.0691\n",
      "Test set (epoch 76): Average loss: 0.5700, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 77 [64/170 (33%)]\tLoss: 0.401629 (avg: 0.401629) \tsec/iter: 0.0469\n",
      "Train Epoch: 77 [170/170 (100%)]\tLoss: 0.292964 (avg: 0.380609) \tsec/iter: 0.0465\n",
      "Test set (epoch 77): Average loss: 0.5626, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 78 [64/170 (33%)]\tLoss: 0.334080 (avg: 0.334080) \tsec/iter: 0.0559\n",
      "Train Epoch: 78 [170/170 (100%)]\tLoss: 0.332632 (avg: 0.345695) \tsec/iter: 0.0455\n",
      "Test set (epoch 78): Average loss: 0.5592, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 79 [64/170 (33%)]\tLoss: 0.354394 (avg: 0.354394) \tsec/iter: 0.0489\n",
      "Train Epoch: 79 [170/170 (100%)]\tLoss: 0.394522 (avg: 0.363551) \tsec/iter: 0.0429\n",
      "Test set (epoch 79): Average loss: 0.6228, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 80 [64/170 (33%)]\tLoss: 0.341030 (avg: 0.341030) \tsec/iter: 0.0529\n",
      "Train Epoch: 80 [170/170 (100%)]\tLoss: 0.392405 (avg: 0.335526) \tsec/iter: 0.0542\n",
      "Test set (epoch 80): Average loss: 0.5704, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 81 [64/170 (33%)]\tLoss: 0.323429 (avg: 0.323429) \tsec/iter: 0.0598\n",
      "Train Epoch: 81 [170/170 (100%)]\tLoss: 0.387111 (avg: 0.343786) \tsec/iter: 0.0512\n",
      "Test set (epoch 81): Average loss: 0.6332, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 82 [64/170 (33%)]\tLoss: 0.346062 (avg: 0.346062) \tsec/iter: 0.0558\n",
      "Train Epoch: 82 [170/170 (100%)]\tLoss: 0.331461 (avg: 0.340825) \tsec/iter: 0.0552\n",
      "Test set (epoch 82): Average loss: 0.5962, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 83 [64/170 (33%)]\tLoss: 0.443528 (avg: 0.443528) \tsec/iter: 0.0578\n",
      "Train Epoch: 83 [170/170 (100%)]\tLoss: 0.360672 (avg: 0.372153) \tsec/iter: 0.0519\n",
      "Test set (epoch 83): Average loss: 0.5747, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 84 [64/170 (33%)]\tLoss: 0.391000 (avg: 0.391000) \tsec/iter: 0.0519\n",
      "Train Epoch: 84 [170/170 (100%)]\tLoss: 0.283825 (avg: 0.338536) \tsec/iter: 0.0482\n",
      "Test set (epoch 84): Average loss: 0.6190, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 85 [64/170 (33%)]\tLoss: 0.337968 (avg: 0.337968) \tsec/iter: 0.1067\n",
      "Train Epoch: 85 [170/170 (100%)]\tLoss: 0.372015 (avg: 0.363025) \tsec/iter: 0.0725\n",
      "Test set (epoch 85): Average loss: 0.6185, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 86 [64/170 (33%)]\tLoss: 0.363110 (avg: 0.363110) \tsec/iter: 0.0598\n",
      "Train Epoch: 86 [170/170 (100%)]\tLoss: 0.341645 (avg: 0.361029) \tsec/iter: 0.0682\n",
      "Test set (epoch 86): Average loss: 0.6199, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 87 [64/170 (33%)]\tLoss: 0.332749 (avg: 0.332749) \tsec/iter: 0.0688\n",
      "Train Epoch: 87 [170/170 (100%)]\tLoss: 0.393450 (avg: 0.344615) \tsec/iter: 0.0602\n",
      "Test set (epoch 87): Average loss: 0.6403, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 88 [64/170 (33%)]\tLoss: 0.325486 (avg: 0.325486) \tsec/iter: 0.0539\n",
      "Train Epoch: 88 [170/170 (100%)]\tLoss: 0.286384 (avg: 0.368957) \tsec/iter: 0.0482\n",
      "Test set (epoch 88): Average loss: 0.5467, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 89 [64/170 (33%)]\tLoss: 0.342588 (avg: 0.342588) \tsec/iter: 0.0499\n",
      "Train Epoch: 89 [170/170 (100%)]\tLoss: 0.296624 (avg: 0.363470) \tsec/iter: 0.0449\n",
      "Test set (epoch 89): Average loss: 0.5309, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 90 [64/170 (33%)]\tLoss: 0.212917 (avg: 0.212917) \tsec/iter: 0.0489\n",
      "Train Epoch: 90 [170/170 (100%)]\tLoss: 0.295899 (avg: 0.356429) \tsec/iter: 0.0449\n",
      "Test set (epoch 90): Average loss: 0.5825, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 91 [64/170 (33%)]\tLoss: 0.388687 (avg: 0.388687) \tsec/iter: 0.0469\n",
      "Train Epoch: 91 [170/170 (100%)]\tLoss: 0.373960 (avg: 0.348520) \tsec/iter: 0.0436\n",
      "Test set (epoch 91): Average loss: 0.5731, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 92 [64/170 (33%)]\tLoss: 0.310672 (avg: 0.310672) \tsec/iter: 0.0479\n",
      "Train Epoch: 92 [170/170 (100%)]\tLoss: 0.448004 (avg: 0.363765) \tsec/iter: 0.0469\n",
      "Test set (epoch 92): Average loss: 0.6229, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 93 [64/170 (33%)]\tLoss: 0.326670 (avg: 0.326670) \tsec/iter: 0.0439\n",
      "Train Epoch: 93 [170/170 (100%)]\tLoss: 0.531962 (avg: 0.374332) \tsec/iter: 0.0459\n",
      "Test set (epoch 93): Average loss: 0.6084, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 94 [64/170 (33%)]\tLoss: 0.382224 (avg: 0.382224) \tsec/iter: 0.0568\n",
      "Train Epoch: 94 [170/170 (100%)]\tLoss: 0.380757 (avg: 0.339182) \tsec/iter: 0.0472\n",
      "Test set (epoch 94): Average loss: 0.4959, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 95 [64/170 (33%)]\tLoss: 0.332571 (avg: 0.332571) \tsec/iter: 0.0549\n",
      "Train Epoch: 95 [170/170 (100%)]\tLoss: 0.412548 (avg: 0.355658) \tsec/iter: 0.0489\n",
      "Test set (epoch 95): Average loss: 0.5619, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 96 [64/170 (33%)]\tLoss: 0.315765 (avg: 0.315765) \tsec/iter: 0.0529\n",
      "Train Epoch: 96 [170/170 (100%)]\tLoss: 0.324634 (avg: 0.333139) \tsec/iter: 0.0452\n",
      "Test set (epoch 96): Average loss: 0.6065, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 97 [64/170 (33%)]\tLoss: 0.292913 (avg: 0.292913) \tsec/iter: 0.0499\n",
      "Train Epoch: 97 [170/170 (100%)]\tLoss: 0.393950 (avg: 0.334028) \tsec/iter: 0.0442\n",
      "Test set (epoch 97): Average loss: 0.5804, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 98 [64/170 (33%)]\tLoss: 0.332705 (avg: 0.332705) \tsec/iter: 0.0449\n",
      "Train Epoch: 98 [170/170 (100%)]\tLoss: 0.352263 (avg: 0.359512) \tsec/iter: 0.0449\n",
      "Test set (epoch 98): Average loss: 0.5668, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 99 [64/170 (33%)]\tLoss: 0.261626 (avg: 0.261626) \tsec/iter: 0.0499\n",
      "Train Epoch: 99 [170/170 (100%)]\tLoss: 0.444923 (avg: 0.358012) \tsec/iter: 0.0452\n",
      "Test set (epoch 99): Average loss: 0.5865, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 100 [64/170 (33%)]\tLoss: 0.358446 (avg: 0.358446) \tsec/iter: 0.0469\n",
      "Train Epoch: 100 [170/170 (100%)]\tLoss: 0.320847 (avg: 0.346620) \tsec/iter: 0.0465\n",
      "Test set (epoch 100): Average loss: 0.4953, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 101 [64/170 (33%)]\tLoss: 0.352744 (avg: 0.352744) \tsec/iter: 0.0549\n",
      "Train Epoch: 101 [170/170 (100%)]\tLoss: 0.388266 (avg: 0.364269) \tsec/iter: 0.0475\n",
      "Test set (epoch 101): Average loss: 0.5459, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 102 [64/170 (33%)]\tLoss: 0.347096 (avg: 0.347096) \tsec/iter: 0.0459\n",
      "Train Epoch: 102 [170/170 (100%)]\tLoss: 0.245567 (avg: 0.341277) \tsec/iter: 0.0445\n",
      "Test set (epoch 102): Average loss: 0.5245, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 103 [64/170 (33%)]\tLoss: 0.364732 (avg: 0.364732) \tsec/iter: 0.0549\n",
      "Train Epoch: 103 [170/170 (100%)]\tLoss: 0.388574 (avg: 0.350348) \tsec/iter: 0.0502\n",
      "Test set (epoch 103): Average loss: 0.5207, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 104 [64/170 (33%)]\tLoss: 0.305119 (avg: 0.305119) \tsec/iter: 0.0529\n",
      "Train Epoch: 104 [170/170 (100%)]\tLoss: 0.317272 (avg: 0.303073) \tsec/iter: 0.0475\n",
      "Test set (epoch 104): Average loss: 0.5068, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 105 [64/170 (33%)]\tLoss: 0.416216 (avg: 0.416216) \tsec/iter: 0.0499\n",
      "Train Epoch: 105 [170/170 (100%)]\tLoss: 0.283401 (avg: 0.346819) \tsec/iter: 0.0449\n",
      "Test set (epoch 105): Average loss: 0.4995, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 106 [64/170 (33%)]\tLoss: 0.252723 (avg: 0.252723) \tsec/iter: 0.0439\n",
      "Train Epoch: 106 [170/170 (100%)]\tLoss: 0.385768 (avg: 0.331676) \tsec/iter: 0.0419\n",
      "Test set (epoch 106): Average loss: 0.5042, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 107 [64/170 (33%)]\tLoss: 0.423631 (avg: 0.423631) \tsec/iter: 0.0509\n",
      "Train Epoch: 107 [170/170 (100%)]\tLoss: 0.327247 (avg: 0.361939) \tsec/iter: 0.0462\n",
      "Test set (epoch 107): Average loss: 0.5667, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 108 [64/170 (33%)]\tLoss: 0.356955 (avg: 0.356955) \tsec/iter: 0.0598\n",
      "Train Epoch: 108 [170/170 (100%)]\tLoss: 0.290476 (avg: 0.350241) \tsec/iter: 0.0512\n",
      "Test set (epoch 108): Average loss: 0.6029, Accuracy: 12/18 (66.67%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [64/170 (33%)]\tLoss: 0.308206 (avg: 0.308206) \tsec/iter: 0.0479\n",
      "Train Epoch: 109 [170/170 (100%)]\tLoss: 0.286897 (avg: 0.337867) \tsec/iter: 0.0449\n",
      "Test set (epoch 109): Average loss: 0.5045, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 110 [64/170 (33%)]\tLoss: 0.253404 (avg: 0.253404) \tsec/iter: 0.0519\n",
      "Train Epoch: 110 [170/170 (100%)]\tLoss: 0.336758 (avg: 0.351745) \tsec/iter: 0.0419\n",
      "Test set (epoch 110): Average loss: 0.4760, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 111 [64/170 (33%)]\tLoss: 0.276054 (avg: 0.276054) \tsec/iter: 0.0499\n",
      "Train Epoch: 111 [170/170 (100%)]\tLoss: 0.369852 (avg: 0.336951) \tsec/iter: 0.0459\n",
      "Test set (epoch 111): Average loss: 0.5582, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 112 [64/170 (33%)]\tLoss: 0.399046 (avg: 0.399046) \tsec/iter: 0.0559\n",
      "Train Epoch: 112 [170/170 (100%)]\tLoss: 0.225517 (avg: 0.332617) \tsec/iter: 0.0489\n",
      "Test set (epoch 112): Average loss: 0.4975, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 113 [64/170 (33%)]\tLoss: 0.418670 (avg: 0.418670) \tsec/iter: 0.0559\n",
      "Train Epoch: 113 [170/170 (100%)]\tLoss: 0.376763 (avg: 0.351376) \tsec/iter: 0.0492\n",
      "Test set (epoch 113): Average loss: 0.4715, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 114 [64/170 (33%)]\tLoss: 0.317677 (avg: 0.317677) \tsec/iter: 0.0479\n",
      "Train Epoch: 114 [170/170 (100%)]\tLoss: 0.343248 (avg: 0.328421) \tsec/iter: 0.0442\n",
      "Test set (epoch 114): Average loss: 0.4635, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 115 [64/170 (33%)]\tLoss: 0.338286 (avg: 0.338286) \tsec/iter: 0.0539\n",
      "Train Epoch: 115 [170/170 (100%)]\tLoss: 0.366302 (avg: 0.342196) \tsec/iter: 0.0429\n",
      "Test set (epoch 115): Average loss: 0.4435, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 116 [64/170 (33%)]\tLoss: 0.371568 (avg: 0.371568) \tsec/iter: 0.0509\n",
      "Train Epoch: 116 [170/170 (100%)]\tLoss: 0.309321 (avg: 0.335254) \tsec/iter: 0.0449\n",
      "Test set (epoch 116): Average loss: 0.3934, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 117 [64/170 (33%)]\tLoss: 0.313854 (avg: 0.313854) \tsec/iter: 0.0479\n",
      "Train Epoch: 117 [170/170 (100%)]\tLoss: 0.306746 (avg: 0.341284) \tsec/iter: 0.0475\n",
      "Test set (epoch 117): Average loss: 0.4482, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 118 [64/170 (33%)]\tLoss: 0.324258 (avg: 0.324258) \tsec/iter: 0.0558\n",
      "Train Epoch: 118 [170/170 (100%)]\tLoss: 0.222202 (avg: 0.325306) \tsec/iter: 0.0465\n",
      "Test set (epoch 118): Average loss: 0.4790, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 119 [64/170 (33%)]\tLoss: 0.354149 (avg: 0.354149) \tsec/iter: 0.0469\n",
      "Train Epoch: 119 [170/170 (100%)]\tLoss: 0.336951 (avg: 0.359904) \tsec/iter: 0.0426\n",
      "Test set (epoch 119): Average loss: 0.4002, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 120 [64/170 (33%)]\tLoss: 0.324453 (avg: 0.324453) \tsec/iter: 0.0429\n",
      "Train Epoch: 120 [170/170 (100%)]\tLoss: 0.382897 (avg: 0.359487) \tsec/iter: 0.0426\n",
      "Test set (epoch 120): Average loss: 0.5194, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 121 [64/170 (33%)]\tLoss: 0.227255 (avg: 0.227255) \tsec/iter: 0.0489\n",
      "Train Epoch: 121 [170/170 (100%)]\tLoss: 0.382728 (avg: 0.288641) \tsec/iter: 0.0419\n",
      "Test set (epoch 121): Average loss: 0.4789, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 122 [64/170 (33%)]\tLoss: 0.238610 (avg: 0.238610) \tsec/iter: 0.0539\n",
      "Train Epoch: 122 [170/170 (100%)]\tLoss: 0.311595 (avg: 0.269972) \tsec/iter: 0.0479\n",
      "Test set (epoch 122): Average loss: 0.3513, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 123 [64/170 (33%)]\tLoss: 0.358657 (avg: 0.358657) \tsec/iter: 0.0509\n",
      "Train Epoch: 123 [170/170 (100%)]\tLoss: 0.345103 (avg: 0.332346) \tsec/iter: 0.0445\n",
      "Test set (epoch 123): Average loss: 0.5447, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 124 [64/170 (33%)]\tLoss: 0.316191 (avg: 0.316191) \tsec/iter: 0.0459\n",
      "Train Epoch: 124 [170/170 (100%)]\tLoss: 0.375486 (avg: 0.351910) \tsec/iter: 0.0465\n",
      "Test set (epoch 124): Average loss: 0.3767, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 125 [64/170 (33%)]\tLoss: 0.362288 (avg: 0.362288) \tsec/iter: 0.0519\n",
      "Train Epoch: 125 [170/170 (100%)]\tLoss: 0.378839 (avg: 0.334235) \tsec/iter: 0.0475\n",
      "Test set (epoch 125): Average loss: 0.4297, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 126 [64/170 (33%)]\tLoss: 0.244137 (avg: 0.244137) \tsec/iter: 0.0499\n",
      "Train Epoch: 126 [170/170 (100%)]\tLoss: 0.452398 (avg: 0.320146) \tsec/iter: 0.0462\n",
      "Test set (epoch 126): Average loss: 0.5294, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 127 [64/170 (33%)]\tLoss: 0.303320 (avg: 0.303320) \tsec/iter: 0.0489\n",
      "Train Epoch: 127 [170/170 (100%)]\tLoss: 0.309773 (avg: 0.322027) \tsec/iter: 0.0452\n",
      "Test set (epoch 127): Average loss: 0.4234, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 128 [64/170 (33%)]\tLoss: 0.256205 (avg: 0.256205) \tsec/iter: 0.0499\n",
      "Train Epoch: 128 [170/170 (100%)]\tLoss: 0.495318 (avg: 0.303954) \tsec/iter: 0.0469\n",
      "Test set (epoch 128): Average loss: 0.4253, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 129 [64/170 (33%)]\tLoss: 0.353554 (avg: 0.353554) \tsec/iter: 0.0499\n",
      "Train Epoch: 129 [170/170 (100%)]\tLoss: 0.293946 (avg: 0.326576) \tsec/iter: 0.0449\n",
      "Test set (epoch 129): Average loss: 0.3900, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 130 [64/170 (33%)]\tLoss: 0.270818 (avg: 0.270818) \tsec/iter: 0.0459\n",
      "Train Epoch: 130 [170/170 (100%)]\tLoss: 0.446005 (avg: 0.337846) \tsec/iter: 0.0429\n",
      "Test set (epoch 130): Average loss: 0.4401, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 131 [64/170 (33%)]\tLoss: 0.345412 (avg: 0.345412) \tsec/iter: 0.0529\n",
      "Train Epoch: 131 [170/170 (100%)]\tLoss: 0.280687 (avg: 0.329915) \tsec/iter: 0.0465\n",
      "Test set (epoch 131): Average loss: 0.4028, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 132 [64/170 (33%)]\tLoss: 0.373051 (avg: 0.373051) \tsec/iter: 0.0519\n",
      "Train Epoch: 132 [170/170 (100%)]\tLoss: 0.358859 (avg: 0.339638) \tsec/iter: 0.0445\n",
      "Test set (epoch 132): Average loss: 0.3376, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 133 [64/170 (33%)]\tLoss: 0.272746 (avg: 0.272746) \tsec/iter: 0.0519\n",
      "Train Epoch: 133 [170/170 (100%)]\tLoss: 0.252827 (avg: 0.319877) \tsec/iter: 0.0445\n",
      "Test set (epoch 133): Average loss: 0.3936, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 134 [64/170 (33%)]\tLoss: 0.274434 (avg: 0.274434) \tsec/iter: 0.0469\n",
      "Train Epoch: 134 [170/170 (100%)]\tLoss: 0.379850 (avg: 0.329108) \tsec/iter: 0.0452\n",
      "Test set (epoch 134): Average loss: 0.3395, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 135 [64/170 (33%)]\tLoss: 0.359555 (avg: 0.359555) \tsec/iter: 0.0519\n",
      "Train Epoch: 135 [170/170 (100%)]\tLoss: 0.358625 (avg: 0.346037) \tsec/iter: 0.0472\n",
      "Test set (epoch 135): Average loss: 0.3650, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 136 [64/170 (33%)]\tLoss: 0.236685 (avg: 0.236685) \tsec/iter: 0.0469\n",
      "Train Epoch: 136 [170/170 (100%)]\tLoss: 0.432681 (avg: 0.328121) \tsec/iter: 0.0449\n",
      "Test set (epoch 136): Average loss: 0.4101, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 137 [64/170 (33%)]\tLoss: 0.277133 (avg: 0.277133) \tsec/iter: 0.0429\n",
      "Train Epoch: 137 [170/170 (100%)]\tLoss: 0.345364 (avg: 0.337449) \tsec/iter: 0.0432\n",
      "Test set (epoch 137): Average loss: 0.3629, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 138 [64/170 (33%)]\tLoss: 0.264545 (avg: 0.264545) \tsec/iter: 0.0499\n",
      "Train Epoch: 138 [170/170 (100%)]\tLoss: 0.332162 (avg: 0.307422) \tsec/iter: 0.0445\n",
      "Test set (epoch 138): Average loss: 0.3952, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 139 [64/170 (33%)]\tLoss: 0.247970 (avg: 0.247970) \tsec/iter: 0.0409\n",
      "Train Epoch: 139 [170/170 (100%)]\tLoss: 0.322754 (avg: 0.300282) \tsec/iter: 0.0422\n",
      "Test set (epoch 139): Average loss: 0.4272, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 140 [64/170 (33%)]\tLoss: 0.425595 (avg: 0.425595) \tsec/iter: 0.0479\n",
      "Train Epoch: 140 [170/170 (100%)]\tLoss: 0.324138 (avg: 0.339570) \tsec/iter: 0.0492\n",
      "Test set (epoch 140): Average loss: 0.3748, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 141 [64/170 (33%)]\tLoss: 0.236277 (avg: 0.236277) \tsec/iter: 0.0559\n",
      "Train Epoch: 141 [170/170 (100%)]\tLoss: 0.306630 (avg: 0.326466) \tsec/iter: 0.0495\n",
      "Test set (epoch 141): Average loss: 0.4718, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 142 [64/170 (33%)]\tLoss: 0.337014 (avg: 0.337014) \tsec/iter: 0.0519\n",
      "Train Epoch: 142 [170/170 (100%)]\tLoss: 0.176922 (avg: 0.321192) \tsec/iter: 0.0482\n",
      "Test set (epoch 142): Average loss: 0.4135, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 143 [64/170 (33%)]\tLoss: 0.264997 (avg: 0.264997) \tsec/iter: 0.0489\n",
      "Train Epoch: 143 [170/170 (100%)]\tLoss: 0.248999 (avg: 0.282032) \tsec/iter: 0.0419\n",
      "Test set (epoch 143): Average loss: 0.4106, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 144 [64/170 (33%)]\tLoss: 0.400531 (avg: 0.400531) \tsec/iter: 0.0519\n",
      "Train Epoch: 144 [170/170 (100%)]\tLoss: 0.291129 (avg: 0.326923) \tsec/iter: 0.0449\n",
      "Test set (epoch 144): Average loss: 0.3822, Accuracy: 12/18 (66.67%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145 [64/170 (33%)]\tLoss: 0.211638 (avg: 0.211638) \tsec/iter: 0.0459\n",
      "Train Epoch: 145 [170/170 (100%)]\tLoss: 0.350442 (avg: 0.317034) \tsec/iter: 0.0459\n",
      "Test set (epoch 145): Average loss: 0.3545, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 146 [64/170 (33%)]\tLoss: 0.286022 (avg: 0.286022) \tsec/iter: 0.0429\n",
      "Train Epoch: 146 [170/170 (100%)]\tLoss: 0.309209 (avg: 0.305072) \tsec/iter: 0.0439\n",
      "Test set (epoch 146): Average loss: 0.3644, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 147 [64/170 (33%)]\tLoss: 0.367697 (avg: 0.367697) \tsec/iter: 0.0519\n",
      "Train Epoch: 147 [170/170 (100%)]\tLoss: 0.262768 (avg: 0.353422) \tsec/iter: 0.0442\n",
      "Test set (epoch 147): Average loss: 0.4082, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 148 [64/170 (33%)]\tLoss: 0.262765 (avg: 0.262765) \tsec/iter: 0.0489\n",
      "Train Epoch: 148 [170/170 (100%)]\tLoss: 0.484874 (avg: 0.342115) \tsec/iter: 0.0462\n",
      "Test set (epoch 148): Average loss: 0.4193, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 149 [64/170 (33%)]\tLoss: 0.287395 (avg: 0.287395) \tsec/iter: 0.0558\n",
      "Train Epoch: 149 [170/170 (100%)]\tLoss: 0.337088 (avg: 0.347321) \tsec/iter: 0.0489\n",
      "Test set (epoch 149): Average loss: 0.3909, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 150 [64/170 (33%)]\tLoss: 0.343249 (avg: 0.343249) \tsec/iter: 0.0549\n",
      "Train Epoch: 150 [170/170 (100%)]\tLoss: 0.258907 (avg: 0.330981) \tsec/iter: 0.0485\n",
      "Test set (epoch 150): Average loss: 0.3711, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 151 [64/170 (33%)]\tLoss: 0.319537 (avg: 0.319537) \tsec/iter: 0.0439\n",
      "Train Epoch: 151 [170/170 (100%)]\tLoss: 0.285985 (avg: 0.297848) \tsec/iter: 0.0449\n",
      "Test set (epoch 151): Average loss: 0.4215, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 152 [64/170 (33%)]\tLoss: 0.291903 (avg: 0.291903) \tsec/iter: 0.0419\n",
      "Train Epoch: 152 [170/170 (100%)]\tLoss: 0.352307 (avg: 0.310204) \tsec/iter: 0.0382\n",
      "Test set (epoch 152): Average loss: 0.3844, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 153 [64/170 (33%)]\tLoss: 0.279839 (avg: 0.279839) \tsec/iter: 0.0509\n",
      "Train Epoch: 153 [170/170 (100%)]\tLoss: 0.206520 (avg: 0.309944) \tsec/iter: 0.0432\n",
      "Test set (epoch 153): Average loss: 0.3964, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 154 [64/170 (33%)]\tLoss: 0.303159 (avg: 0.303159) \tsec/iter: 0.0568\n",
      "Train Epoch: 154 [170/170 (100%)]\tLoss: 0.578104 (avg: 0.341681) \tsec/iter: 0.0519\n",
      "Test set (epoch 154): Average loss: 0.4301, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 155 [64/170 (33%)]\tLoss: 0.249123 (avg: 0.249123) \tsec/iter: 0.0598\n",
      "Train Epoch: 155 [170/170 (100%)]\tLoss: 0.399005 (avg: 0.332807) \tsec/iter: 0.0502\n",
      "Test set (epoch 155): Average loss: 0.4198, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 156 [64/170 (33%)]\tLoss: 0.375989 (avg: 0.375989) \tsec/iter: 0.0598\n",
      "Train Epoch: 156 [170/170 (100%)]\tLoss: 0.264650 (avg: 0.306151) \tsec/iter: 0.0555\n",
      "Test set (epoch 156): Average loss: 0.3871, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 157 [64/170 (33%)]\tLoss: 0.305642 (avg: 0.305642) \tsec/iter: 0.0658\n",
      "Train Epoch: 157 [170/170 (100%)]\tLoss: 0.222380 (avg: 0.308930) \tsec/iter: 0.0595\n",
      "Test set (epoch 157): Average loss: 0.3440, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 158 [64/170 (33%)]\tLoss: 0.320440 (avg: 0.320440) \tsec/iter: 0.0578\n",
      "Train Epoch: 158 [170/170 (100%)]\tLoss: 0.411020 (avg: 0.325842) \tsec/iter: 0.0482\n",
      "Test set (epoch 158): Average loss: 0.3697, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 159 [64/170 (33%)]\tLoss: 0.289240 (avg: 0.289240) \tsec/iter: 0.0568\n",
      "Train Epoch: 159 [170/170 (100%)]\tLoss: 0.264677 (avg: 0.324714) \tsec/iter: 0.0472\n",
      "Test set (epoch 159): Average loss: 0.3495, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 160 [64/170 (33%)]\tLoss: 0.272614 (avg: 0.272614) \tsec/iter: 0.0559\n",
      "Train Epoch: 160 [170/170 (100%)]\tLoss: 0.297744 (avg: 0.297241) \tsec/iter: 0.0512\n",
      "Test set (epoch 160): Average loss: 0.3270, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 161 [64/170 (33%)]\tLoss: 0.299154 (avg: 0.299154) \tsec/iter: 0.0519\n",
      "Train Epoch: 161 [170/170 (100%)]\tLoss: 0.405530 (avg: 0.330576) \tsec/iter: 0.0479\n",
      "Test set (epoch 161): Average loss: 0.4947, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 162 [64/170 (33%)]\tLoss: 0.403609 (avg: 0.403609) \tsec/iter: 0.0539\n",
      "Train Epoch: 162 [170/170 (100%)]\tLoss: 0.251115 (avg: 0.350257) \tsec/iter: 0.0452\n",
      "Test set (epoch 162): Average loss: 0.3589, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 163 [64/170 (33%)]\tLoss: 0.407235 (avg: 0.407235) \tsec/iter: 0.0509\n",
      "Train Epoch: 163 [170/170 (100%)]\tLoss: 0.331168 (avg: 0.323534) \tsec/iter: 0.0519\n",
      "Test set (epoch 163): Average loss: 0.3568, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 164 [64/170 (33%)]\tLoss: 0.376040 (avg: 0.376040) \tsec/iter: 0.0628\n",
      "Train Epoch: 164 [170/170 (100%)]\tLoss: 0.430196 (avg: 0.338567) \tsec/iter: 0.0545\n",
      "Test set (epoch 164): Average loss: 0.3873, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 165 [64/170 (33%)]\tLoss: 0.320631 (avg: 0.320631) \tsec/iter: 0.0499\n",
      "Train Epoch: 165 [170/170 (100%)]\tLoss: 0.352241 (avg: 0.298847) \tsec/iter: 0.0426\n",
      "Test set (epoch 165): Average loss: 0.4304, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 166 [64/170 (33%)]\tLoss: 0.376041 (avg: 0.376041) \tsec/iter: 0.0429\n",
      "Train Epoch: 166 [170/170 (100%)]\tLoss: 0.265133 (avg: 0.301247) \tsec/iter: 0.0638\n",
      "Test set (epoch 166): Average loss: 0.3373, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 167 [64/170 (33%)]\tLoss: 0.326972 (avg: 0.326972) \tsec/iter: 0.0658\n",
      "Train Epoch: 167 [170/170 (100%)]\tLoss: 0.292997 (avg: 0.313741) \tsec/iter: 0.0525\n",
      "Test set (epoch 167): Average loss: 0.3622, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 168 [64/170 (33%)]\tLoss: 0.414935 (avg: 0.414935) \tsec/iter: 0.0499\n",
      "Train Epoch: 168 [170/170 (100%)]\tLoss: 0.294221 (avg: 0.319702) \tsec/iter: 0.0465\n",
      "Test set (epoch 168): Average loss: 0.2988, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 169 [64/170 (33%)]\tLoss: 0.370027 (avg: 0.370027) \tsec/iter: 0.0608\n",
      "Train Epoch: 169 [170/170 (100%)]\tLoss: 0.341753 (avg: 0.314368) \tsec/iter: 0.0542\n",
      "Test set (epoch 169): Average loss: 0.3047, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 170 [64/170 (33%)]\tLoss: 0.303668 (avg: 0.303668) \tsec/iter: 0.0588\n",
      "Train Epoch: 170 [170/170 (100%)]\tLoss: 0.279991 (avg: 0.328637) \tsec/iter: 0.0592\n",
      "Test set (epoch 170): Average loss: 0.3368, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 171 [64/170 (33%)]\tLoss: 0.294335 (avg: 0.294335) \tsec/iter: 0.0559\n",
      "Train Epoch: 171 [170/170 (100%)]\tLoss: 0.371231 (avg: 0.313849) \tsec/iter: 0.0482\n",
      "Test set (epoch 171): Average loss: 0.3895, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 172 [64/170 (33%)]\tLoss: 0.317512 (avg: 0.317512) \tsec/iter: 0.0888\n",
      "Train Epoch: 172 [170/170 (100%)]\tLoss: 0.192033 (avg: 0.301357) \tsec/iter: 0.0698\n",
      "Test set (epoch 172): Average loss: 0.4689, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 173 [64/170 (33%)]\tLoss: 0.227999 (avg: 0.227999) \tsec/iter: 0.0429\n",
      "Train Epoch: 173 [170/170 (100%)]\tLoss: 0.221765 (avg: 0.269992) \tsec/iter: 0.0459\n",
      "Test set (epoch 173): Average loss: 0.3677, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 174 [64/170 (33%)]\tLoss: 0.209641 (avg: 0.209641) \tsec/iter: 0.0539\n",
      "Train Epoch: 174 [170/170 (100%)]\tLoss: 0.376146 (avg: 0.320272) \tsec/iter: 0.0469\n",
      "Test set (epoch 174): Average loss: 0.3105, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 175 [64/170 (33%)]\tLoss: 0.375008 (avg: 0.375008) \tsec/iter: 0.0449\n",
      "Train Epoch: 175 [170/170 (100%)]\tLoss: 0.302427 (avg: 0.339776) \tsec/iter: 0.0416\n",
      "Test set (epoch 175): Average loss: 0.3550, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 176 [64/170 (33%)]\tLoss: 0.265985 (avg: 0.265985) \tsec/iter: 0.0509\n",
      "Train Epoch: 176 [170/170 (100%)]\tLoss: 0.261957 (avg: 0.302421) \tsec/iter: 0.0469\n",
      "Test set (epoch 176): Average loss: 0.4511, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 177 [64/170 (33%)]\tLoss: 0.373002 (avg: 0.373002) \tsec/iter: 0.0399\n",
      "Train Epoch: 177 [170/170 (100%)]\tLoss: 0.275237 (avg: 0.303646) \tsec/iter: 0.0429\n",
      "Test set (epoch 177): Average loss: 0.3233, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 178 [64/170 (33%)]\tLoss: 0.335326 (avg: 0.335326) \tsec/iter: 0.0459\n",
      "Train Epoch: 178 [170/170 (100%)]\tLoss: 0.348505 (avg: 0.297678) \tsec/iter: 0.0435\n",
      "Test set (epoch 178): Average loss: 0.3784, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 179 [64/170 (33%)]\tLoss: 0.332346 (avg: 0.332346) \tsec/iter: 0.0519\n",
      "Train Epoch: 179 [170/170 (100%)]\tLoss: 0.189410 (avg: 0.296705) \tsec/iter: 0.0525\n",
      "Test set (epoch 179): Average loss: 0.3727, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 180 [64/170 (33%)]\tLoss: 0.256400 (avg: 0.256400) \tsec/iter: 0.0469\n",
      "Train Epoch: 180 [170/170 (100%)]\tLoss: 0.377118 (avg: 0.284821) \tsec/iter: 0.0436\n",
      "Test set (epoch 180): Average loss: 0.5142, Accuracy: 13/18 (72.22%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181 [64/170 (33%)]\tLoss: 0.253270 (avg: 0.253270) \tsec/iter: 0.0429\n",
      "Train Epoch: 181 [170/170 (100%)]\tLoss: 0.330837 (avg: 0.300292) \tsec/iter: 0.0442\n",
      "Test set (epoch 181): Average loss: 0.3242, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 182 [64/170 (33%)]\tLoss: 0.270311 (avg: 0.270311) \tsec/iter: 0.0459\n",
      "Train Epoch: 182 [170/170 (100%)]\tLoss: 0.332340 (avg: 0.268155) \tsec/iter: 0.0426\n",
      "Test set (epoch 182): Average loss: 0.3974, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 183 [64/170 (33%)]\tLoss: 0.359240 (avg: 0.359240) \tsec/iter: 0.0539\n",
      "Train Epoch: 183 [170/170 (100%)]\tLoss: 0.349951 (avg: 0.288097) \tsec/iter: 0.0485\n",
      "Test set (epoch 183): Average loss: 0.3392, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 184 [64/170 (33%)]\tLoss: 0.280369 (avg: 0.280369) \tsec/iter: 0.0509\n",
      "Train Epoch: 184 [170/170 (100%)]\tLoss: 0.453562 (avg: 0.346126) \tsec/iter: 0.0469\n",
      "Test set (epoch 184): Average loss: 0.4047, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 185 [64/170 (33%)]\tLoss: 0.407232 (avg: 0.407232) \tsec/iter: 0.0549\n",
      "Train Epoch: 185 [170/170 (100%)]\tLoss: 0.320205 (avg: 0.326818) \tsec/iter: 0.0522\n",
      "Test set (epoch 185): Average loss: 0.4031, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 186 [64/170 (33%)]\tLoss: 0.330301 (avg: 0.330301) \tsec/iter: 0.0499\n",
      "Train Epoch: 186 [170/170 (100%)]\tLoss: 0.232812 (avg: 0.268695) \tsec/iter: 0.0459\n",
      "Test set (epoch 186): Average loss: 0.3102, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 187 [64/170 (33%)]\tLoss: 0.383672 (avg: 0.383672) \tsec/iter: 0.0529\n",
      "Train Epoch: 187 [170/170 (100%)]\tLoss: 0.183183 (avg: 0.293304) \tsec/iter: 0.0475\n",
      "Test set (epoch 187): Average loss: 0.3442, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 188 [64/170 (33%)]\tLoss: 0.319740 (avg: 0.319740) \tsec/iter: 0.0449\n",
      "Train Epoch: 188 [170/170 (100%)]\tLoss: 0.370633 (avg: 0.288196) \tsec/iter: 0.0422\n",
      "Test set (epoch 188): Average loss: 0.4375, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 189 [64/170 (33%)]\tLoss: 0.238528 (avg: 0.238528) \tsec/iter: 0.0539\n",
      "Train Epoch: 189 [170/170 (100%)]\tLoss: 0.426402 (avg: 0.273145) \tsec/iter: 0.0485\n",
      "Test set (epoch 189): Average loss: 0.3407, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 190 [64/170 (33%)]\tLoss: 0.235698 (avg: 0.235698) \tsec/iter: 0.0568\n",
      "Train Epoch: 190 [170/170 (100%)]\tLoss: 0.251580 (avg: 0.253519) \tsec/iter: 0.0492\n",
      "Test set (epoch 190): Average loss: 0.4496, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 191 [64/170 (33%)]\tLoss: 0.250619 (avg: 0.250619) \tsec/iter: 0.0429\n",
      "Train Epoch: 191 [170/170 (100%)]\tLoss: 0.158246 (avg: 0.274331) \tsec/iter: 0.0436\n",
      "Test set (epoch 191): Average loss: 0.3536, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 192 [64/170 (33%)]\tLoss: 0.249463 (avg: 0.249463) \tsec/iter: 0.0489\n",
      "Train Epoch: 192 [170/170 (100%)]\tLoss: 0.431520 (avg: 0.307321) \tsec/iter: 0.0449\n",
      "Test set (epoch 192): Average loss: 0.7040, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 193 [64/170 (33%)]\tLoss: 0.253783 (avg: 0.253783) \tsec/iter: 0.0459\n",
      "Train Epoch: 193 [170/170 (100%)]\tLoss: 0.237646 (avg: 0.290810) \tsec/iter: 0.0422\n",
      "Test set (epoch 193): Average loss: 0.2764, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 194 [64/170 (33%)]\tLoss: 0.546272 (avg: 0.546272) \tsec/iter: 0.0519\n",
      "Train Epoch: 194 [170/170 (100%)]\tLoss: 0.277937 (avg: 0.363186) \tsec/iter: 0.0459\n",
      "Test set (epoch 194): Average loss: 0.2997, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 195 [64/170 (33%)]\tLoss: 0.373198 (avg: 0.373198) \tsec/iter: 0.0449\n",
      "Train Epoch: 195 [170/170 (100%)]\tLoss: 0.272429 (avg: 0.303101) \tsec/iter: 0.0452\n",
      "Test set (epoch 195): Average loss: 0.3151, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 196 [64/170 (33%)]\tLoss: 0.351721 (avg: 0.351721) \tsec/iter: 0.0529\n",
      "Train Epoch: 196 [170/170 (100%)]\tLoss: 0.227467 (avg: 0.294447) \tsec/iter: 0.0459\n",
      "Test set (epoch 196): Average loss: 0.4548, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 197 [64/170 (33%)]\tLoss: 0.257507 (avg: 0.257507) \tsec/iter: 0.0399\n",
      "Train Epoch: 197 [170/170 (100%)]\tLoss: 0.267001 (avg: 0.284004) \tsec/iter: 0.0422\n",
      "Test set (epoch 197): Average loss: 0.4017, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 198 [64/170 (33%)]\tLoss: 0.238800 (avg: 0.238800) \tsec/iter: 0.0479\n",
      "Train Epoch: 198 [170/170 (100%)]\tLoss: 0.356068 (avg: 0.302717) \tsec/iter: 0.0479\n",
      "Test set (epoch 198): Average loss: 0.4633, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 199 [64/170 (33%)]\tLoss: 0.272892 (avg: 0.272892) \tsec/iter: 0.0638\n",
      "Train Epoch: 199 [170/170 (100%)]\tLoss: 0.167509 (avg: 0.252599) \tsec/iter: 0.0515\n",
      "Test set (epoch 199): Average loss: 0.4003, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 200 [64/170 (33%)]\tLoss: 0.286708 (avg: 0.286708) \tsec/iter: 0.0489\n",
      "Train Epoch: 200 [170/170 (100%)]\tLoss: 0.287744 (avg: 0.260836) \tsec/iter: 0.0445\n",
      "Test set (epoch 200): Average loss: 0.2965, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 201 [64/170 (33%)]\tLoss: 0.146998 (avg: 0.146998) \tsec/iter: 0.0439\n",
      "Train Epoch: 201 [170/170 (100%)]\tLoss: 0.306757 (avg: 0.280845) \tsec/iter: 0.0455\n",
      "Test set (epoch 201): Average loss: 0.4359, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 202 [64/170 (33%)]\tLoss: 0.265274 (avg: 0.265274) \tsec/iter: 0.0429\n",
      "Train Epoch: 202 [170/170 (100%)]\tLoss: 0.243535 (avg: 0.301980) \tsec/iter: 0.0419\n",
      "Test set (epoch 202): Average loss: 0.3854, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 203 [64/170 (33%)]\tLoss: 0.257063 (avg: 0.257063) \tsec/iter: 0.0439\n",
      "Train Epoch: 203 [170/170 (100%)]\tLoss: 0.240964 (avg: 0.294696) \tsec/iter: 0.0472\n",
      "Test set (epoch 203): Average loss: 0.3412, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 204 [64/170 (33%)]\tLoss: 0.263756 (avg: 0.263756) \tsec/iter: 0.0429\n",
      "Train Epoch: 204 [170/170 (100%)]\tLoss: 0.348056 (avg: 0.287785) \tsec/iter: 0.0412\n",
      "Test set (epoch 204): Average loss: 0.4975, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 205 [64/170 (33%)]\tLoss: 0.302026 (avg: 0.302026) \tsec/iter: 0.0529\n",
      "Train Epoch: 205 [170/170 (100%)]\tLoss: 0.266054 (avg: 0.284921) \tsec/iter: 0.0482\n",
      "Test set (epoch 205): Average loss: 0.3676, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 206 [64/170 (33%)]\tLoss: 0.286602 (avg: 0.286602) \tsec/iter: 0.0499\n",
      "Train Epoch: 206 [170/170 (100%)]\tLoss: 0.224735 (avg: 0.268090) \tsec/iter: 0.0485\n",
      "Test set (epoch 206): Average loss: 0.4659, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 207 [64/170 (33%)]\tLoss: 0.246773 (avg: 0.246773) \tsec/iter: 0.0559\n",
      "Train Epoch: 207 [170/170 (100%)]\tLoss: 0.302058 (avg: 0.259112) \tsec/iter: 0.0502\n",
      "Test set (epoch 207): Average loss: 0.3479, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 208 [64/170 (33%)]\tLoss: 0.272558 (avg: 0.272558) \tsec/iter: 0.0519\n",
      "Train Epoch: 208 [170/170 (100%)]\tLoss: 0.258402 (avg: 0.265758) \tsec/iter: 0.0452\n",
      "Test set (epoch 208): Average loss: 0.5252, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 209 [64/170 (33%)]\tLoss: 0.301233 (avg: 0.301233) \tsec/iter: 0.0409\n",
      "Train Epoch: 209 [170/170 (100%)]\tLoss: 0.301801 (avg: 0.285518) \tsec/iter: 0.0442\n",
      "Test set (epoch 209): Average loss: 0.3129, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 210 [64/170 (33%)]\tLoss: 0.229014 (avg: 0.229014) \tsec/iter: 0.0419\n",
      "Train Epoch: 210 [170/170 (100%)]\tLoss: 0.251027 (avg: 0.257743) \tsec/iter: 0.0419\n",
      "Test set (epoch 210): Average loss: 0.4155, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 211 [64/170 (33%)]\tLoss: 0.344189 (avg: 0.344189) \tsec/iter: 0.0499\n",
      "Train Epoch: 211 [170/170 (100%)]\tLoss: 0.399915 (avg: 0.319375) \tsec/iter: 0.0449\n",
      "Test set (epoch 211): Average loss: 0.3339, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 212 [64/170 (33%)]\tLoss: 0.325608 (avg: 0.325608) \tsec/iter: 0.0508\n",
      "Train Epoch: 212 [170/170 (100%)]\tLoss: 0.308745 (avg: 0.299362) \tsec/iter: 0.0462\n",
      "Test set (epoch 212): Average loss: 0.2970, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 213 [64/170 (33%)]\tLoss: 0.193356 (avg: 0.193356) \tsec/iter: 0.0489\n",
      "Train Epoch: 213 [170/170 (100%)]\tLoss: 0.246859 (avg: 0.277603) \tsec/iter: 0.0449\n",
      "Test set (epoch 213): Average loss: 0.4545, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 214 [64/170 (33%)]\tLoss: 0.300769 (avg: 0.300769) \tsec/iter: 0.0459\n",
      "Train Epoch: 214 [170/170 (100%)]\tLoss: 0.158637 (avg: 0.252731) \tsec/iter: 0.0429\n",
      "Test set (epoch 214): Average loss: 0.2525, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 215 [64/170 (33%)]\tLoss: 0.215906 (avg: 0.215906) \tsec/iter: 0.0509\n",
      "Train Epoch: 215 [170/170 (100%)]\tLoss: 0.354816 (avg: 0.257050) \tsec/iter: 0.0439\n",
      "Test set (epoch 215): Average loss: 0.4742, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 216 [64/170 (33%)]\tLoss: 0.304618 (avg: 0.304618) \tsec/iter: 0.0499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [170/170 (100%)]\tLoss: 0.253228 (avg: 0.297756) \tsec/iter: 0.0465\n",
      "Test set (epoch 216): Average loss: 0.4472, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 217 [64/170 (33%)]\tLoss: 0.198482 (avg: 0.198482) \tsec/iter: 0.0529\n",
      "Train Epoch: 217 [170/170 (100%)]\tLoss: 0.256619 (avg: 0.245487) \tsec/iter: 0.0482\n",
      "Test set (epoch 217): Average loss: 0.3126, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 218 [64/170 (33%)]\tLoss: 0.194330 (avg: 0.194330) \tsec/iter: 0.0529\n",
      "Train Epoch: 218 [170/170 (100%)]\tLoss: 0.348659 (avg: 0.267737) \tsec/iter: 0.0519\n",
      "Test set (epoch 218): Average loss: 0.3915, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 219 [64/170 (33%)]\tLoss: 0.253165 (avg: 0.253165) \tsec/iter: 0.0549\n",
      "Train Epoch: 219 [170/170 (100%)]\tLoss: 0.195661 (avg: 0.246382) \tsec/iter: 0.0492\n",
      "Test set (epoch 219): Average loss: 0.3174, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 220 [64/170 (33%)]\tLoss: 0.301469 (avg: 0.301469) \tsec/iter: 0.0439\n",
      "Train Epoch: 220 [170/170 (100%)]\tLoss: 0.285356 (avg: 0.278149) \tsec/iter: 0.0422\n",
      "Test set (epoch 220): Average loss: 0.3199, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 221 [64/170 (33%)]\tLoss: 0.245221 (avg: 0.245221) \tsec/iter: 0.0449\n",
      "Train Epoch: 221 [170/170 (100%)]\tLoss: 0.251551 (avg: 0.246460) \tsec/iter: 0.0426\n",
      "Test set (epoch 221): Average loss: 0.3432, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 222 [64/170 (33%)]\tLoss: 0.256603 (avg: 0.256603) \tsec/iter: 0.0469\n",
      "Train Epoch: 222 [170/170 (100%)]\tLoss: 0.172356 (avg: 0.273887) \tsec/iter: 0.0439\n",
      "Test set (epoch 222): Average loss: 0.4513, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 223 [64/170 (33%)]\tLoss: 0.233841 (avg: 0.233841) \tsec/iter: 0.0409\n",
      "Train Epoch: 223 [170/170 (100%)]\tLoss: 0.245895 (avg: 0.238592) \tsec/iter: 0.0406\n",
      "Test set (epoch 223): Average loss: 0.2969, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 224 [64/170 (33%)]\tLoss: 0.255314 (avg: 0.255314) \tsec/iter: 0.0469\n",
      "Train Epoch: 224 [170/170 (100%)]\tLoss: 0.267922 (avg: 0.261882) \tsec/iter: 0.0432\n",
      "Test set (epoch 224): Average loss: 0.4343, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 225 [64/170 (33%)]\tLoss: 0.157540 (avg: 0.157540) \tsec/iter: 0.0499\n",
      "Train Epoch: 225 [170/170 (100%)]\tLoss: 0.201593 (avg: 0.223277) \tsec/iter: 0.0449\n",
      "Test set (epoch 225): Average loss: 0.3737, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 226 [64/170 (33%)]\tLoss: 0.209733 (avg: 0.209733) \tsec/iter: 0.0499\n",
      "Train Epoch: 226 [170/170 (100%)]\tLoss: 0.303502 (avg: 0.250649) \tsec/iter: 0.0462\n",
      "Test set (epoch 226): Average loss: 0.4340, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 227 [64/170 (33%)]\tLoss: 0.213585 (avg: 0.213585) \tsec/iter: 0.0529\n",
      "Train Epoch: 227 [170/170 (100%)]\tLoss: 0.492178 (avg: 0.279858) \tsec/iter: 0.0489\n",
      "Test set (epoch 227): Average loss: 0.4825, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 228 [64/170 (33%)]\tLoss: 0.305103 (avg: 0.305103) \tsec/iter: 0.0549\n",
      "Train Epoch: 228 [170/170 (100%)]\tLoss: 0.218782 (avg: 0.260773) \tsec/iter: 0.0469\n",
      "Test set (epoch 228): Average loss: 0.2818, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 229 [64/170 (33%)]\tLoss: 0.271643 (avg: 0.271643) \tsec/iter: 0.0529\n",
      "Train Epoch: 229 [170/170 (100%)]\tLoss: 0.234444 (avg: 0.284236) \tsec/iter: 0.0475\n",
      "Test set (epoch 229): Average loss: 0.3804, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 230 [64/170 (33%)]\tLoss: 0.300262 (avg: 0.300262) \tsec/iter: 0.0509\n",
      "Train Epoch: 230 [170/170 (100%)]\tLoss: 0.283862 (avg: 0.273313) \tsec/iter: 0.0479\n",
      "Test set (epoch 230): Average loss: 0.2719, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 231 [64/170 (33%)]\tLoss: 0.256401 (avg: 0.256401) \tsec/iter: 0.0539\n",
      "Train Epoch: 231 [170/170 (100%)]\tLoss: 0.182078 (avg: 0.266787) \tsec/iter: 0.0495\n",
      "Test set (epoch 231): Average loss: 0.2974, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 232 [64/170 (33%)]\tLoss: 0.223546 (avg: 0.223546) \tsec/iter: 0.0718\n",
      "Train Epoch: 232 [170/170 (100%)]\tLoss: 0.222508 (avg: 0.250149) \tsec/iter: 0.0642\n",
      "Test set (epoch 232): Average loss: 0.4974, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 233 [64/170 (33%)]\tLoss: 0.338288 (avg: 0.338288) \tsec/iter: 0.0568\n",
      "Train Epoch: 233 [170/170 (100%)]\tLoss: 0.198575 (avg: 0.299591) \tsec/iter: 0.0559\n",
      "Test set (epoch 233): Average loss: 0.4422, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 234 [64/170 (33%)]\tLoss: 0.294641 (avg: 0.294641) \tsec/iter: 0.0539\n",
      "Train Epoch: 234 [170/170 (100%)]\tLoss: 0.273909 (avg: 0.271677) \tsec/iter: 0.0469\n",
      "Test set (epoch 234): Average loss: 0.2612, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 235 [64/170 (33%)]\tLoss: 0.284612 (avg: 0.284612) \tsec/iter: 0.0519\n",
      "Train Epoch: 235 [170/170 (100%)]\tLoss: 0.288298 (avg: 0.283318) \tsec/iter: 0.0489\n",
      "Test set (epoch 235): Average loss: 0.6664, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 236 [64/170 (33%)]\tLoss: 0.353421 (avg: 0.353421) \tsec/iter: 0.0549\n",
      "Train Epoch: 236 [170/170 (100%)]\tLoss: 0.187172 (avg: 0.278756) \tsec/iter: 0.0509\n",
      "Test set (epoch 236): Average loss: 0.2846, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 237 [64/170 (33%)]\tLoss: 0.208870 (avg: 0.208870) \tsec/iter: 0.0568\n",
      "Train Epoch: 237 [170/170 (100%)]\tLoss: 0.258247 (avg: 0.306667) \tsec/iter: 0.0482\n",
      "Test set (epoch 237): Average loss: 0.4167, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 238 [64/170 (33%)]\tLoss: 0.281286 (avg: 0.281286) \tsec/iter: 0.0549\n",
      "Train Epoch: 238 [170/170 (100%)]\tLoss: 0.253858 (avg: 0.265791) \tsec/iter: 0.0519\n",
      "Test set (epoch 238): Average loss: 0.3900, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 239 [64/170 (33%)]\tLoss: 0.240788 (avg: 0.240788) \tsec/iter: 0.0529\n",
      "Train Epoch: 239 [170/170 (100%)]\tLoss: 0.378810 (avg: 0.254438) \tsec/iter: 0.0495\n",
      "Test set (epoch 239): Average loss: 0.3184, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 240 [64/170 (33%)]\tLoss: 0.232826 (avg: 0.232826) \tsec/iter: 0.0409\n",
      "Train Epoch: 240 [170/170 (100%)]\tLoss: 0.475588 (avg: 0.272117) \tsec/iter: 0.0432\n",
      "Test set (epoch 240): Average loss: 0.3276, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 241 [64/170 (33%)]\tLoss: 0.183052 (avg: 0.183052) \tsec/iter: 0.0479\n",
      "Train Epoch: 241 [170/170 (100%)]\tLoss: 0.187805 (avg: 0.236884) \tsec/iter: 0.0426\n",
      "Test set (epoch 241): Average loss: 0.3359, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 242 [64/170 (33%)]\tLoss: 0.268678 (avg: 0.268678) \tsec/iter: 0.0509\n",
      "Train Epoch: 242 [170/170 (100%)]\tLoss: 0.246904 (avg: 0.263622) \tsec/iter: 0.0462\n",
      "Test set (epoch 242): Average loss: 0.3013, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 243 [64/170 (33%)]\tLoss: 0.285180 (avg: 0.285180) \tsec/iter: 0.0489\n",
      "Train Epoch: 243 [170/170 (100%)]\tLoss: 0.287866 (avg: 0.290304) \tsec/iter: 0.0429\n",
      "Test set (epoch 243): Average loss: 0.6025, Accuracy: 11/18 (61.11%)\n",
      "\n",
      "Train Epoch: 244 [64/170 (33%)]\tLoss: 0.226511 (avg: 0.226511) \tsec/iter: 0.0529\n",
      "Train Epoch: 244 [170/170 (100%)]\tLoss: 0.410420 (avg: 0.267567) \tsec/iter: 0.0475\n",
      "Test set (epoch 244): Average loss: 0.3105, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 245 [64/170 (33%)]\tLoss: 0.226976 (avg: 0.226976) \tsec/iter: 0.0479\n",
      "Train Epoch: 245 [170/170 (100%)]\tLoss: 0.191700 (avg: 0.251410) \tsec/iter: 0.0439\n",
      "Test set (epoch 245): Average loss: 0.4645, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 246 [64/170 (33%)]\tLoss: 0.157931 (avg: 0.157931) \tsec/iter: 0.0479\n",
      "Train Epoch: 246 [170/170 (100%)]\tLoss: 0.461158 (avg: 0.244718) \tsec/iter: 0.0469\n",
      "Test set (epoch 246): Average loss: 0.3562, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 247 [64/170 (33%)]\tLoss: 0.164717 (avg: 0.164717) \tsec/iter: 0.0568\n",
      "Train Epoch: 247 [170/170 (100%)]\tLoss: 0.201513 (avg: 0.232283) \tsec/iter: 0.0472\n",
      "Test set (epoch 247): Average loss: 0.4211, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 248 [64/170 (33%)]\tLoss: 0.296648 (avg: 0.296648) \tsec/iter: 0.0499\n",
      "Train Epoch: 248 [170/170 (100%)]\tLoss: 0.247866 (avg: 0.249363) \tsec/iter: 0.0472\n",
      "Test set (epoch 248): Average loss: 0.3707, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 249 [64/170 (33%)]\tLoss: 0.265103 (avg: 0.265103) \tsec/iter: 0.0539\n",
      "Train Epoch: 249 [170/170 (100%)]\tLoss: 0.234237 (avg: 0.238074) \tsec/iter: 0.0462\n",
      "Test set (epoch 249): Average loss: 0.2607, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 250 [64/170 (33%)]\tLoss: 0.280302 (avg: 0.280302) \tsec/iter: 0.0439\n",
      "Train Epoch: 250 [170/170 (100%)]\tLoss: 0.281049 (avg: 0.267669) \tsec/iter: 0.0455\n",
      "Test set (epoch 250): Average loss: 0.2116, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 251 [64/170 (33%)]\tLoss: 0.249496 (avg: 0.249496) \tsec/iter: 0.0479\n",
      "Train Epoch: 251 [170/170 (100%)]\tLoss: 0.241290 (avg: 0.252444) \tsec/iter: 0.0439\n",
      "Test set (epoch 251): Average loss: 0.4615, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 252 [64/170 (33%)]\tLoss: 0.261992 (avg: 0.261992) \tsec/iter: 0.0479\n",
      "Train Epoch: 252 [170/170 (100%)]\tLoss: 0.260948 (avg: 0.252599) \tsec/iter: 0.0429\n",
      "Test set (epoch 252): Average loss: 0.2593, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 253 [64/170 (33%)]\tLoss: 0.207712 (avg: 0.207712) \tsec/iter: 0.0449\n",
      "Train Epoch: 253 [170/170 (100%)]\tLoss: 0.166093 (avg: 0.248094) \tsec/iter: 0.0432\n",
      "Test set (epoch 253): Average loss: 0.2683, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 254 [64/170 (33%)]\tLoss: 0.185284 (avg: 0.185284) \tsec/iter: 0.0529\n",
      "Train Epoch: 254 [170/170 (100%)]\tLoss: 0.389430 (avg: 0.238715) \tsec/iter: 0.0479\n",
      "Test set (epoch 254): Average loss: 0.2848, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 255 [64/170 (33%)]\tLoss: 0.232839 (avg: 0.232839) \tsec/iter: 0.0529\n",
      "Train Epoch: 255 [170/170 (100%)]\tLoss: 0.317775 (avg: 0.261773) \tsec/iter: 0.0442\n",
      "Test set (epoch 255): Average loss: 0.3012, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 256 [64/170 (33%)]\tLoss: 0.277626 (avg: 0.277626) \tsec/iter: 0.0558\n",
      "Train Epoch: 256 [170/170 (100%)]\tLoss: 0.339952 (avg: 0.289561) \tsec/iter: 0.0499\n",
      "Test set (epoch 256): Average loss: 0.2722, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 257 [64/170 (33%)]\tLoss: 0.193961 (avg: 0.193961) \tsec/iter: 0.0419\n",
      "Train Epoch: 257 [170/170 (100%)]\tLoss: 0.144217 (avg: 0.208844) \tsec/iter: 0.0439\n",
      "Test set (epoch 257): Average loss: 0.3794, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 258 [64/170 (33%)]\tLoss: 0.179410 (avg: 0.179410) \tsec/iter: 0.0578\n",
      "Train Epoch: 258 [170/170 (100%)]\tLoss: 0.269076 (avg: 0.252453) \tsec/iter: 0.0505\n",
      "Test set (epoch 258): Average loss: 0.3754, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 259 [64/170 (33%)]\tLoss: 0.234827 (avg: 0.234827) \tsec/iter: 0.0509\n",
      "Train Epoch: 259 [170/170 (100%)]\tLoss: 0.252711 (avg: 0.242481) \tsec/iter: 0.0426\n",
      "Test set (epoch 259): Average loss: 0.3456, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 260 [64/170 (33%)]\tLoss: 0.174302 (avg: 0.174302) \tsec/iter: 0.0529\n",
      "Train Epoch: 260 [170/170 (100%)]\tLoss: 0.187521 (avg: 0.209688) \tsec/iter: 0.0479\n",
      "Test set (epoch 260): Average loss: 0.4119, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 261 [64/170 (33%)]\tLoss: 0.283756 (avg: 0.283756) \tsec/iter: 0.0419\n",
      "Train Epoch: 261 [170/170 (100%)]\tLoss: 0.324954 (avg: 0.271753) \tsec/iter: 0.0406\n",
      "Test set (epoch 261): Average loss: 0.3391, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 262 [64/170 (33%)]\tLoss: 0.282346 (avg: 0.282346) \tsec/iter: 0.0439\n",
      "Train Epoch: 262 [170/170 (100%)]\tLoss: 0.251465 (avg: 0.268155) \tsec/iter: 0.0455\n",
      "Test set (epoch 262): Average loss: 0.3016, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 263 [64/170 (33%)]\tLoss: 0.304389 (avg: 0.304389) \tsec/iter: 0.0539\n",
      "Train Epoch: 263 [170/170 (100%)]\tLoss: 0.342446 (avg: 0.264807) \tsec/iter: 0.0436\n",
      "Test set (epoch 263): Average loss: 0.4460, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 264 [64/170 (33%)]\tLoss: 0.195715 (avg: 0.195715) \tsec/iter: 0.0499\n",
      "Train Epoch: 264 [170/170 (100%)]\tLoss: 0.362217 (avg: 0.295068) \tsec/iter: 0.0462\n",
      "Test set (epoch 264): Average loss: 0.2498, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 265 [64/170 (33%)]\tLoss: 0.201987 (avg: 0.201987) \tsec/iter: 0.0469\n",
      "Train Epoch: 265 [170/170 (100%)]\tLoss: 0.344513 (avg: 0.254913) \tsec/iter: 0.0479\n",
      "Test set (epoch 265): Average loss: 0.4214, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 266 [64/170 (33%)]\tLoss: 0.276456 (avg: 0.276456) \tsec/iter: 0.0529\n",
      "Train Epoch: 266 [170/170 (100%)]\tLoss: 0.290601 (avg: 0.248026) \tsec/iter: 0.0435\n",
      "Test set (epoch 266): Average loss: 0.4902, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 267 [64/170 (33%)]\tLoss: 0.314539 (avg: 0.314539) \tsec/iter: 0.0519\n",
      "Train Epoch: 267 [170/170 (100%)]\tLoss: 0.241607 (avg: 0.260204) \tsec/iter: 0.0482\n",
      "Test set (epoch 267): Average loss: 0.4905, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 268 [64/170 (33%)]\tLoss: 0.160574 (avg: 0.160574) \tsec/iter: 0.0459\n",
      "Train Epoch: 268 [170/170 (100%)]\tLoss: 0.398282 (avg: 0.241807) \tsec/iter: 0.0442\n",
      "Test set (epoch 268): Average loss: 0.2136, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 269 [64/170 (33%)]\tLoss: 0.228501 (avg: 0.228501) \tsec/iter: 0.0459\n",
      "Train Epoch: 269 [170/170 (100%)]\tLoss: 0.250417 (avg: 0.284470) \tsec/iter: 0.0449\n",
      "Test set (epoch 269): Average loss: 0.3035, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 270 [64/170 (33%)]\tLoss: 0.231242 (avg: 0.231242) \tsec/iter: 0.0429\n",
      "Train Epoch: 270 [170/170 (100%)]\tLoss: 0.312083 (avg: 0.214039) \tsec/iter: 0.0429\n",
      "Test set (epoch 270): Average loss: 0.2905, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 271 [64/170 (33%)]\tLoss: 0.237106 (avg: 0.237106) \tsec/iter: 0.0499\n",
      "Train Epoch: 271 [170/170 (100%)]\tLoss: 0.323154 (avg: 0.262917) \tsec/iter: 0.0452\n",
      "Test set (epoch 271): Average loss: 0.3136, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 272 [64/170 (33%)]\tLoss: 0.187969 (avg: 0.187969) \tsec/iter: 0.0489\n",
      "Train Epoch: 272 [170/170 (100%)]\tLoss: 0.451565 (avg: 0.254122) \tsec/iter: 0.0452\n",
      "Test set (epoch 272): Average loss: 0.4009, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 273 [64/170 (33%)]\tLoss: 0.248740 (avg: 0.248740) \tsec/iter: 0.0479\n",
      "Train Epoch: 273 [170/170 (100%)]\tLoss: 0.263407 (avg: 0.253468) \tsec/iter: 0.0436\n",
      "Test set (epoch 273): Average loss: 0.2326, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 274 [64/170 (33%)]\tLoss: 0.226313 (avg: 0.226313) \tsec/iter: 0.0529\n",
      "Train Epoch: 274 [170/170 (100%)]\tLoss: 0.181686 (avg: 0.231655) \tsec/iter: 0.0459\n",
      "Test set (epoch 274): Average loss: 0.4361, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 275 [64/170 (33%)]\tLoss: 0.316206 (avg: 0.316206) \tsec/iter: 0.0429\n",
      "Train Epoch: 275 [170/170 (100%)]\tLoss: 0.235712 (avg: 0.249225) \tsec/iter: 0.0436\n",
      "Test set (epoch 275): Average loss: 0.2865, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 276 [64/170 (33%)]\tLoss: 0.195102 (avg: 0.195102) \tsec/iter: 0.0489\n",
      "Train Epoch: 276 [170/170 (100%)]\tLoss: 0.106553 (avg: 0.220233) \tsec/iter: 0.0426\n",
      "Test set (epoch 276): Average loss: 0.2816, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 277 [64/170 (33%)]\tLoss: 0.241112 (avg: 0.241112) \tsec/iter: 0.0479\n",
      "Train Epoch: 277 [170/170 (100%)]\tLoss: 0.187862 (avg: 0.216740) \tsec/iter: 0.0465\n",
      "Test set (epoch 277): Average loss: 0.3376, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 278 [64/170 (33%)]\tLoss: 0.335852 (avg: 0.335852) \tsec/iter: 0.0539\n",
      "Train Epoch: 278 [170/170 (100%)]\tLoss: 0.270982 (avg: 0.238549) \tsec/iter: 0.0505\n",
      "Test set (epoch 278): Average loss: 0.3603, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 279 [64/170 (33%)]\tLoss: 0.246523 (avg: 0.246523) \tsec/iter: 0.0628\n",
      "Train Epoch: 279 [170/170 (100%)]\tLoss: 0.185455 (avg: 0.226826) \tsec/iter: 0.0515\n",
      "Test set (epoch 279): Average loss: 0.3435, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 280 [64/170 (33%)]\tLoss: 0.323738 (avg: 0.323738) \tsec/iter: 0.0429\n",
      "Train Epoch: 280 [170/170 (100%)]\tLoss: 0.133246 (avg: 0.288807) \tsec/iter: 0.0436\n",
      "Test set (epoch 280): Average loss: 0.1996, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 281 [64/170 (33%)]\tLoss: 0.314938 (avg: 0.314938) \tsec/iter: 0.0479\n",
      "Train Epoch: 281 [170/170 (100%)]\tLoss: 0.290585 (avg: 0.281221) \tsec/iter: 0.0439\n",
      "Test set (epoch 281): Average loss: 0.2641, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 282 [64/170 (33%)]\tLoss: 0.188693 (avg: 0.188693) \tsec/iter: 0.0509\n",
      "Train Epoch: 282 [170/170 (100%)]\tLoss: 0.224996 (avg: 0.227448) \tsec/iter: 0.0455\n",
      "Test set (epoch 282): Average loss: 0.4294, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 283 [64/170 (33%)]\tLoss: 0.282202 (avg: 0.282202) \tsec/iter: 0.0419\n",
      "Train Epoch: 283 [170/170 (100%)]\tLoss: 0.224088 (avg: 0.242115) \tsec/iter: 0.0449\n",
      "Test set (epoch 283): Average loss: 0.3138, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 284 [64/170 (33%)]\tLoss: 0.252023 (avg: 0.252023) \tsec/iter: 0.0439\n",
      "Train Epoch: 284 [170/170 (100%)]\tLoss: 0.454184 (avg: 0.274142) \tsec/iter: 0.0442\n",
      "Test set (epoch 284): Average loss: 0.4600, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 285 [64/170 (33%)]\tLoss: 0.250176 (avg: 0.250176) \tsec/iter: 0.0459\n",
      "Train Epoch: 285 [170/170 (100%)]\tLoss: 0.163038 (avg: 0.233636) \tsec/iter: 0.0535\n",
      "Test set (epoch 285): Average loss: 0.3163, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 286 [64/170 (33%)]\tLoss: 0.222350 (avg: 0.222350) \tsec/iter: 0.0499\n",
      "Train Epoch: 286 [170/170 (100%)]\tLoss: 0.253718 (avg: 0.257866) \tsec/iter: 0.0475\n",
      "Test set (epoch 286): Average loss: 0.2422, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 287 [64/170 (33%)]\tLoss: 0.112709 (avg: 0.112709) \tsec/iter: 0.0419\n",
      "Train Epoch: 287 [170/170 (100%)]\tLoss: 0.323296 (avg: 0.227576) \tsec/iter: 0.0396\n",
      "Test set (epoch 287): Average loss: 0.2694, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 288 [64/170 (33%)]\tLoss: 0.269437 (avg: 0.269437) \tsec/iter: 0.0469\n",
      "Train Epoch: 288 [170/170 (100%)]\tLoss: 0.291277 (avg: 0.231689) \tsec/iter: 0.0445\n",
      "Test set (epoch 288): Average loss: 0.2055, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 289 [64/170 (33%)]\tLoss: 0.274359 (avg: 0.274359) \tsec/iter: 0.0449\n",
      "Train Epoch: 289 [170/170 (100%)]\tLoss: 0.283427 (avg: 0.253962) \tsec/iter: 0.0449\n",
      "Test set (epoch 289): Average loss: 0.2076, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 290 [64/170 (33%)]\tLoss: 0.261573 (avg: 0.261573) \tsec/iter: 0.0389\n",
      "Train Epoch: 290 [170/170 (100%)]\tLoss: 0.274517 (avg: 0.249496) \tsec/iter: 0.0396\n",
      "Test set (epoch 290): Average loss: 0.3954, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 291 [64/170 (33%)]\tLoss: 0.219887 (avg: 0.219887) \tsec/iter: 0.0419\n",
      "Train Epoch: 291 [170/170 (100%)]\tLoss: 0.142799 (avg: 0.210889) \tsec/iter: 0.0416\n",
      "Test set (epoch 291): Average loss: 0.1775, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 292 [64/170 (33%)]\tLoss: 0.248180 (avg: 0.248180) \tsec/iter: 0.0479\n",
      "Train Epoch: 292 [170/170 (100%)]\tLoss: 0.205017 (avg: 0.232661) \tsec/iter: 0.0449\n",
      "Test set (epoch 292): Average loss: 0.3522, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 293 [64/170 (33%)]\tLoss: 0.243711 (avg: 0.243711) \tsec/iter: 0.0489\n",
      "Train Epoch: 293 [170/170 (100%)]\tLoss: 0.360506 (avg: 0.262235) \tsec/iter: 0.0525\n",
      "Test set (epoch 293): Average loss: 0.6133, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 294 [64/170 (33%)]\tLoss: 0.383456 (avg: 0.383456) \tsec/iter: 0.0628\n",
      "Train Epoch: 294 [170/170 (100%)]\tLoss: 0.313793 (avg: 0.320699) \tsec/iter: 0.0552\n",
      "Test set (epoch 294): Average loss: 0.2697, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 295 [64/170 (33%)]\tLoss: 0.147336 (avg: 0.147336) \tsec/iter: 0.0728\n",
      "Train Epoch: 295 [170/170 (100%)]\tLoss: 0.228898 (avg: 0.241626) \tsec/iter: 0.0565\n",
      "Test set (epoch 295): Average loss: 0.4343, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 296 [64/170 (33%)]\tLoss: 0.267021 (avg: 0.267021) \tsec/iter: 0.0439\n",
      "Train Epoch: 296 [170/170 (100%)]\tLoss: 0.227566 (avg: 0.238061) \tsec/iter: 0.0449\n",
      "Test set (epoch 296): Average loss: 0.2409, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 297 [64/170 (33%)]\tLoss: 0.170535 (avg: 0.170535) \tsec/iter: 0.0489\n",
      "Train Epoch: 297 [170/170 (100%)]\tLoss: 0.401614 (avg: 0.293829) \tsec/iter: 0.0426\n",
      "Test set (epoch 297): Average loss: 0.4722, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 298 [64/170 (33%)]\tLoss: 0.218795 (avg: 0.218795) \tsec/iter: 0.0578\n",
      "Train Epoch: 298 [170/170 (100%)]\tLoss: 0.347712 (avg: 0.250637) \tsec/iter: 0.0505\n",
      "Test set (epoch 298): Average loss: 0.2042, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 299 [64/170 (33%)]\tLoss: 0.164782 (avg: 0.164782) \tsec/iter: 0.0529\n",
      "Train Epoch: 299 [170/170 (100%)]\tLoss: 0.335575 (avg: 0.274174) \tsec/iter: 0.0542\n",
      "Test set (epoch 299): Average loss: 0.5131, Accuracy: 12/18 (66.67%)\n",
      "\n",
      "Train Epoch: 300 [64/170 (33%)]\tLoss: 0.254219 (avg: 0.254219) \tsec/iter: 0.0618\n",
      "Train Epoch: 300 [170/170 (100%)]\tLoss: 0.377946 (avg: 0.263427) \tsec/iter: 0.0499\n",
      "Test set (epoch 300): Average loss: 0.2603, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 301 [64/170 (33%)]\tLoss: 0.181670 (avg: 0.181670) \tsec/iter: 0.0529\n",
      "Train Epoch: 301 [170/170 (100%)]\tLoss: 0.180795 (avg: 0.198409) \tsec/iter: 0.0475\n",
      "Test set (epoch 301): Average loss: 0.1866, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 302 [64/170 (33%)]\tLoss: 0.315124 (avg: 0.315124) \tsec/iter: 0.0469\n",
      "Train Epoch: 302 [170/170 (100%)]\tLoss: 0.109754 (avg: 0.266591) \tsec/iter: 0.0519\n",
      "Test set (epoch 302): Average loss: 0.3114, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 303 [64/170 (33%)]\tLoss: 0.297823 (avg: 0.297823) \tsec/iter: 0.0638\n",
      "Train Epoch: 303 [170/170 (100%)]\tLoss: 0.225779 (avg: 0.263954) \tsec/iter: 0.0575\n",
      "Test set (epoch 303): Average loss: 0.2596, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 304 [64/170 (33%)]\tLoss: 0.323903 (avg: 0.323903) \tsec/iter: 0.0808\n",
      "Train Epoch: 304 [170/170 (100%)]\tLoss: 0.185532 (avg: 0.272347) \tsec/iter: 0.0595\n",
      "Test set (epoch 304): Average loss: 0.2212, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 305 [64/170 (33%)]\tLoss: 0.246231 (avg: 0.246231) \tsec/iter: 0.0529\n",
      "Train Epoch: 305 [170/170 (100%)]\tLoss: 0.295921 (avg: 0.249097) \tsec/iter: 0.0472\n",
      "Test set (epoch 305): Average loss: 0.2719, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 306 [64/170 (33%)]\tLoss: 0.255645 (avg: 0.255645) \tsec/iter: 0.0459\n",
      "Train Epoch: 306 [170/170 (100%)]\tLoss: 0.184854 (avg: 0.220152) \tsec/iter: 0.0412\n",
      "Test set (epoch 306): Average loss: 0.2430, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 307 [64/170 (33%)]\tLoss: 0.192370 (avg: 0.192370) \tsec/iter: 0.0499\n",
      "Train Epoch: 307 [170/170 (100%)]\tLoss: 0.372770 (avg: 0.211031) \tsec/iter: 0.0439\n",
      "Test set (epoch 307): Average loss: 0.3940, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 308 [64/170 (33%)]\tLoss: 0.272352 (avg: 0.272352) \tsec/iter: 0.0429\n",
      "Train Epoch: 308 [170/170 (100%)]\tLoss: 0.134348 (avg: 0.213833) \tsec/iter: 0.0429\n",
      "Test set (epoch 308): Average loss: 0.1876, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 309 [64/170 (33%)]\tLoss: 0.215874 (avg: 0.215874) \tsec/iter: 0.0499\n",
      "Train Epoch: 309 [170/170 (100%)]\tLoss: 0.208345 (avg: 0.241178) \tsec/iter: 0.0436\n",
      "Test set (epoch 309): Average loss: 0.2528, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 310 [64/170 (33%)]\tLoss: 0.182709 (avg: 0.182709) \tsec/iter: 0.0559\n",
      "Train Epoch: 310 [170/170 (100%)]\tLoss: 0.306675 (avg: 0.224363) \tsec/iter: 0.0445\n",
      "Test set (epoch 310): Average loss: 0.2500, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 311 [64/170 (33%)]\tLoss: 0.196004 (avg: 0.196004) \tsec/iter: 0.0509\n",
      "Train Epoch: 311 [170/170 (100%)]\tLoss: 0.404815 (avg: 0.252709) \tsec/iter: 0.0449\n",
      "Test set (epoch 311): Average loss: 0.3198, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 312 [64/170 (33%)]\tLoss: 0.219850 (avg: 0.219850) \tsec/iter: 0.0469\n",
      "Train Epoch: 312 [170/170 (100%)]\tLoss: 0.176981 (avg: 0.223119) \tsec/iter: 0.0445\n",
      "Test set (epoch 312): Average loss: 0.3194, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 313 [64/170 (33%)]\tLoss: 0.195219 (avg: 0.195219) \tsec/iter: 0.0469\n",
      "Train Epoch: 313 [170/170 (100%)]\tLoss: 0.143180 (avg: 0.203064) \tsec/iter: 0.0445\n",
      "Test set (epoch 313): Average loss: 0.2829, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 314 [64/170 (33%)]\tLoss: 0.194971 (avg: 0.194971) \tsec/iter: 0.0499\n",
      "Train Epoch: 314 [170/170 (100%)]\tLoss: 0.325981 (avg: 0.221358) \tsec/iter: 0.0442\n",
      "Test set (epoch 314): Average loss: 0.2874, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 315 [64/170 (33%)]\tLoss: 0.163133 (avg: 0.163133) \tsec/iter: 0.0439\n",
      "Train Epoch: 315 [170/170 (100%)]\tLoss: 0.296695 (avg: 0.205631) \tsec/iter: 0.0419\n",
      "Test set (epoch 315): Average loss: 0.3659, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 316 [64/170 (33%)]\tLoss: 0.234888 (avg: 0.234888) \tsec/iter: 0.0509\n",
      "Train Epoch: 316 [170/170 (100%)]\tLoss: 0.188025 (avg: 0.234803) \tsec/iter: 0.0429\n",
      "Test set (epoch 316): Average loss: 0.3012, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 317 [64/170 (33%)]\tLoss: 0.184143 (avg: 0.184143) \tsec/iter: 0.0539\n",
      "Train Epoch: 317 [170/170 (100%)]\tLoss: 0.109768 (avg: 0.181625) \tsec/iter: 0.0499\n",
      "Test set (epoch 317): Average loss: 0.2983, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 318 [64/170 (33%)]\tLoss: 0.246283 (avg: 0.246283) \tsec/iter: 0.0578\n",
      "Train Epoch: 318 [170/170 (100%)]\tLoss: 0.249375 (avg: 0.215916) \tsec/iter: 0.0479\n",
      "Test set (epoch 318): Average loss: 0.2860, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 319 [64/170 (33%)]\tLoss: 0.177027 (avg: 0.177027) \tsec/iter: 0.0439\n",
      "Train Epoch: 319 [170/170 (100%)]\tLoss: 0.397510 (avg: 0.237614) \tsec/iter: 0.0449\n",
      "Test set (epoch 319): Average loss: 0.3147, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 320 [64/170 (33%)]\tLoss: 0.225005 (avg: 0.225005) \tsec/iter: 0.0499\n",
      "Train Epoch: 320 [170/170 (100%)]\tLoss: 0.286774 (avg: 0.226177) \tsec/iter: 0.0475\n",
      "Test set (epoch 320): Average loss: 0.2284, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 321 [64/170 (33%)]\tLoss: 0.238191 (avg: 0.238191) \tsec/iter: 0.0419\n",
      "Train Epoch: 321 [170/170 (100%)]\tLoss: 0.215892 (avg: 0.240061) \tsec/iter: 0.0386\n",
      "Test set (epoch 321): Average loss: 0.2367, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 322 [64/170 (33%)]\tLoss: 0.266029 (avg: 0.266029) \tsec/iter: 0.0439\n",
      "Train Epoch: 322 [170/170 (100%)]\tLoss: 0.344482 (avg: 0.274355) \tsec/iter: 0.0436\n",
      "Test set (epoch 322): Average loss: 0.1796, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 323 [64/170 (33%)]\tLoss: 0.219485 (avg: 0.219485) \tsec/iter: 0.0489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 323 [170/170 (100%)]\tLoss: 0.227595 (avg: 0.259682) \tsec/iter: 0.0439\n",
      "Test set (epoch 323): Average loss: 0.4550, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 324 [64/170 (33%)]\tLoss: 0.198969 (avg: 0.198969) \tsec/iter: 0.0519\n",
      "Train Epoch: 324 [170/170 (100%)]\tLoss: 0.147123 (avg: 0.198555) \tsec/iter: 0.0449\n",
      "Test set (epoch 324): Average loss: 0.2172, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 325 [64/170 (33%)]\tLoss: 0.272722 (avg: 0.272722) \tsec/iter: 0.0479\n",
      "Train Epoch: 325 [170/170 (100%)]\tLoss: 0.249163 (avg: 0.227602) \tsec/iter: 0.0439\n",
      "Test set (epoch 325): Average loss: 0.3365, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 326 [64/170 (33%)]\tLoss: 0.169791 (avg: 0.169791) \tsec/iter: 0.0539\n",
      "Train Epoch: 326 [170/170 (100%)]\tLoss: 0.179144 (avg: 0.214407) \tsec/iter: 0.0479\n",
      "Test set (epoch 326): Average loss: 0.2141, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 327 [64/170 (33%)]\tLoss: 0.212793 (avg: 0.212793) \tsec/iter: 0.0568\n",
      "Train Epoch: 327 [170/170 (100%)]\tLoss: 0.157638 (avg: 0.230450) \tsec/iter: 0.0502\n",
      "Test set (epoch 327): Average loss: 0.3389, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 328 [64/170 (33%)]\tLoss: 0.170886 (avg: 0.170886) \tsec/iter: 0.0439\n",
      "Train Epoch: 328 [170/170 (100%)]\tLoss: 0.232774 (avg: 0.195575) \tsec/iter: 0.0439\n",
      "Test set (epoch 328): Average loss: 0.2249, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 329 [64/170 (33%)]\tLoss: 0.222592 (avg: 0.222592) \tsec/iter: 0.0499\n",
      "Train Epoch: 329 [170/170 (100%)]\tLoss: 0.193823 (avg: 0.209532) \tsec/iter: 0.0422\n",
      "Test set (epoch 329): Average loss: 0.3808, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 330 [64/170 (33%)]\tLoss: 0.251477 (avg: 0.251477) \tsec/iter: 0.0479\n",
      "Train Epoch: 330 [170/170 (100%)]\tLoss: 0.305328 (avg: 0.261263) \tsec/iter: 0.0426\n",
      "Test set (epoch 330): Average loss: 0.3409, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 331 [64/170 (33%)]\tLoss: 0.238885 (avg: 0.238885) \tsec/iter: 0.0499\n",
      "Train Epoch: 331 [170/170 (100%)]\tLoss: 0.127084 (avg: 0.198211) \tsec/iter: 0.0445\n",
      "Test set (epoch 331): Average loss: 0.1978, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 332 [64/170 (33%)]\tLoss: 0.221963 (avg: 0.221963) \tsec/iter: 0.0479\n",
      "Train Epoch: 332 [170/170 (100%)]\tLoss: 0.159558 (avg: 0.189975) \tsec/iter: 0.0465\n",
      "Test set (epoch 332): Average loss: 0.2713, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 333 [64/170 (33%)]\tLoss: 0.234625 (avg: 0.234625) \tsec/iter: 0.0479\n",
      "Train Epoch: 333 [170/170 (100%)]\tLoss: 0.173822 (avg: 0.227237) \tsec/iter: 0.0475\n",
      "Test set (epoch 333): Average loss: 0.3270, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 334 [64/170 (33%)]\tLoss: 0.304258 (avg: 0.304258) \tsec/iter: 0.0549\n",
      "Train Epoch: 334 [170/170 (100%)]\tLoss: 0.213558 (avg: 0.234015) \tsec/iter: 0.0472\n",
      "Test set (epoch 334): Average loss: 0.3579, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 335 [64/170 (33%)]\tLoss: 0.278217 (avg: 0.278217) \tsec/iter: 0.0529\n",
      "Train Epoch: 335 [170/170 (100%)]\tLoss: 0.185112 (avg: 0.219691) \tsec/iter: 0.0459\n",
      "Test set (epoch 335): Average loss: 0.3637, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 336 [64/170 (33%)]\tLoss: 0.203086 (avg: 0.203086) \tsec/iter: 0.0509\n",
      "Train Epoch: 336 [170/170 (100%)]\tLoss: 0.219278 (avg: 0.243852) \tsec/iter: 0.0445\n",
      "Test set (epoch 336): Average loss: 0.2236, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 337 [64/170 (33%)]\tLoss: 0.142878 (avg: 0.142878) \tsec/iter: 0.0469\n",
      "Train Epoch: 337 [170/170 (100%)]\tLoss: 0.285166 (avg: 0.198967) \tsec/iter: 0.0445\n",
      "Test set (epoch 337): Average loss: 0.2210, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 338 [64/170 (33%)]\tLoss: 0.247223 (avg: 0.247223) \tsec/iter: 0.0539\n",
      "Train Epoch: 338 [170/170 (100%)]\tLoss: 0.194667 (avg: 0.236007) \tsec/iter: 0.0495\n",
      "Test set (epoch 338): Average loss: 0.4629, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 339 [64/170 (33%)]\tLoss: 0.211628 (avg: 0.211628) \tsec/iter: 0.0439\n",
      "Train Epoch: 339 [170/170 (100%)]\tLoss: 0.210165 (avg: 0.243192) \tsec/iter: 0.0422\n",
      "Test set (epoch 339): Average loss: 0.1178, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 340 [64/170 (33%)]\tLoss: 0.337562 (avg: 0.337562) \tsec/iter: 0.0489\n",
      "Train Epoch: 340 [170/170 (100%)]\tLoss: 0.148508 (avg: 0.246289) \tsec/iter: 0.0449\n",
      "Test set (epoch 340): Average loss: 0.2130, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 341 [64/170 (33%)]\tLoss: 0.197430 (avg: 0.197430) \tsec/iter: 0.0489\n",
      "Train Epoch: 341 [170/170 (100%)]\tLoss: 0.240211 (avg: 0.190203) \tsec/iter: 0.0402\n",
      "Test set (epoch 341): Average loss: 0.3070, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 342 [64/170 (33%)]\tLoss: 0.321859 (avg: 0.321859) \tsec/iter: 0.0509\n",
      "Train Epoch: 342 [170/170 (100%)]\tLoss: 0.202829 (avg: 0.244671) \tsec/iter: 0.0445\n",
      "Test set (epoch 342): Average loss: 0.1419, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 343 [64/170 (33%)]\tLoss: 0.107526 (avg: 0.107526) \tsec/iter: 0.0469\n",
      "Train Epoch: 343 [170/170 (100%)]\tLoss: 0.498255 (avg: 0.259330) \tsec/iter: 0.0465\n",
      "Test set (epoch 343): Average loss: 0.3063, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 344 [64/170 (33%)]\tLoss: 0.267336 (avg: 0.267336) \tsec/iter: 0.0519\n",
      "Train Epoch: 344 [170/170 (100%)]\tLoss: 0.368264 (avg: 0.247539) \tsec/iter: 0.0436\n",
      "Test set (epoch 344): Average loss: 0.1872, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 345 [64/170 (33%)]\tLoss: 0.154757 (avg: 0.154757) \tsec/iter: 0.0559\n",
      "Train Epoch: 345 [170/170 (100%)]\tLoss: 0.189999 (avg: 0.200468) \tsec/iter: 0.0505\n",
      "Test set (epoch 345): Average loss: 0.2903, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 346 [64/170 (33%)]\tLoss: 0.223435 (avg: 0.223435) \tsec/iter: 0.0529\n",
      "Train Epoch: 346 [170/170 (100%)]\tLoss: 0.205587 (avg: 0.184915) \tsec/iter: 0.0482\n",
      "Test set (epoch 346): Average loss: 0.1998, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 347 [64/170 (33%)]\tLoss: 0.222395 (avg: 0.222395) \tsec/iter: 0.0439\n",
      "Train Epoch: 347 [170/170 (100%)]\tLoss: 0.223797 (avg: 0.188615) \tsec/iter: 0.0442\n",
      "Test set (epoch 347): Average loss: 0.2677, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 348 [64/170 (33%)]\tLoss: 0.175372 (avg: 0.175372) \tsec/iter: 0.0459\n",
      "Train Epoch: 348 [170/170 (100%)]\tLoss: 0.177289 (avg: 0.192247) \tsec/iter: 0.0469\n",
      "Test set (epoch 348): Average loss: 0.2738, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 349 [64/170 (33%)]\tLoss: 0.193869 (avg: 0.193869) \tsec/iter: 0.0529\n",
      "Train Epoch: 349 [170/170 (100%)]\tLoss: 0.197291 (avg: 0.192785) \tsec/iter: 0.0472\n",
      "Test set (epoch 349): Average loss: 0.2167, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 350 [64/170 (33%)]\tLoss: 0.223648 (avg: 0.223648) \tsec/iter: 0.0479\n",
      "Train Epoch: 350 [170/170 (100%)]\tLoss: 0.189321 (avg: 0.214251) \tsec/iter: 0.0482\n",
      "Test set (epoch 350): Average loss: 0.2746, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 351 [64/170 (33%)]\tLoss: 0.159099 (avg: 0.159099) \tsec/iter: 0.0648\n",
      "Train Epoch: 351 [170/170 (100%)]\tLoss: 0.283774 (avg: 0.244006) \tsec/iter: 0.0622\n",
      "Test set (epoch 351): Average loss: 0.4635, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 352 [64/170 (33%)]\tLoss: 0.238362 (avg: 0.238362) \tsec/iter: 0.0539\n",
      "Train Epoch: 352 [170/170 (100%)]\tLoss: 0.191473 (avg: 0.239036) \tsec/iter: 0.0455\n",
      "Test set (epoch 352): Average loss: 0.1875, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 353 [64/170 (33%)]\tLoss: 0.170100 (avg: 0.170100) \tsec/iter: 0.0479\n",
      "Train Epoch: 353 [170/170 (100%)]\tLoss: 0.122437 (avg: 0.190870) \tsec/iter: 0.0439\n",
      "Test set (epoch 353): Average loss: 0.2347, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 354 [64/170 (33%)]\tLoss: 0.192989 (avg: 0.192989) \tsec/iter: 0.0409\n",
      "Train Epoch: 354 [170/170 (100%)]\tLoss: 0.300255 (avg: 0.203447) \tsec/iter: 0.0442\n",
      "Test set (epoch 354): Average loss: 0.4118, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 355 [64/170 (33%)]\tLoss: 0.188564 (avg: 0.188564) \tsec/iter: 0.0429\n",
      "Train Epoch: 355 [170/170 (100%)]\tLoss: 0.289705 (avg: 0.240967) \tsec/iter: 0.0432\n",
      "Test set (epoch 355): Average loss: 0.2189, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 356 [64/170 (33%)]\tLoss: 0.240355 (avg: 0.240355) \tsec/iter: 0.0419\n",
      "Train Epoch: 356 [170/170 (100%)]\tLoss: 0.103112 (avg: 0.170103) \tsec/iter: 0.0402\n",
      "Test set (epoch 356): Average loss: 0.2524, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 357 [64/170 (33%)]\tLoss: 0.168508 (avg: 0.168508) \tsec/iter: 0.0499\n",
      "Train Epoch: 357 [170/170 (100%)]\tLoss: 0.238893 (avg: 0.192862) \tsec/iter: 0.0459\n",
      "Test set (epoch 357): Average loss: 0.2241, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 358 [64/170 (33%)]\tLoss: 0.153551 (avg: 0.153551) \tsec/iter: 0.0529\n",
      "Train Epoch: 358 [170/170 (100%)]\tLoss: 0.221830 (avg: 0.194192) \tsec/iter: 0.0482\n",
      "Test set (epoch 358): Average loss: 0.2433, Accuracy: 16/18 (88.89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 359 [64/170 (33%)]\tLoss: 0.223318 (avg: 0.223318) \tsec/iter: 0.0529\n",
      "Train Epoch: 359 [170/170 (100%)]\tLoss: 0.072892 (avg: 0.199453) \tsec/iter: 0.0459\n",
      "Test set (epoch 359): Average loss: 0.1784, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 360 [64/170 (33%)]\tLoss: 0.174765 (avg: 0.174765) \tsec/iter: 0.0509\n",
      "Train Epoch: 360 [170/170 (100%)]\tLoss: 0.311596 (avg: 0.190149) \tsec/iter: 0.0509\n",
      "Test set (epoch 360): Average loss: 0.3106, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 361 [64/170 (33%)]\tLoss: 0.181331 (avg: 0.181331) \tsec/iter: 0.0429\n",
      "Train Epoch: 361 [170/170 (100%)]\tLoss: 0.246483 (avg: 0.249162) \tsec/iter: 0.0482\n",
      "Test set (epoch 361): Average loss: 0.2479, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 362 [64/170 (33%)]\tLoss: 0.150329 (avg: 0.150329) \tsec/iter: 0.0638\n",
      "Train Epoch: 362 [170/170 (100%)]\tLoss: 0.259337 (avg: 0.182736) \tsec/iter: 0.0502\n",
      "Test set (epoch 362): Average loss: 0.1843, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 363 [64/170 (33%)]\tLoss: 0.270490 (avg: 0.270490) \tsec/iter: 0.0459\n",
      "Train Epoch: 363 [170/170 (100%)]\tLoss: 0.108393 (avg: 0.199588) \tsec/iter: 0.0432\n",
      "Test set (epoch 363): Average loss: 0.2163, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 364 [64/170 (33%)]\tLoss: 0.176045 (avg: 0.176045) \tsec/iter: 0.0459\n",
      "Train Epoch: 364 [170/170 (100%)]\tLoss: 0.179089 (avg: 0.195729) \tsec/iter: 0.0445\n",
      "Test set (epoch 364): Average loss: 0.1286, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 365 [64/170 (33%)]\tLoss: 0.174076 (avg: 0.174076) \tsec/iter: 0.0519\n",
      "Train Epoch: 365 [170/170 (100%)]\tLoss: 0.239368 (avg: 0.198362) \tsec/iter: 0.0502\n",
      "Test set (epoch 365): Average loss: 0.3115, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 366 [64/170 (33%)]\tLoss: 0.180141 (avg: 0.180141) \tsec/iter: 0.0529\n",
      "Train Epoch: 366 [170/170 (100%)]\tLoss: 0.155470 (avg: 0.191109) \tsec/iter: 0.0482\n",
      "Test set (epoch 366): Average loss: 0.1550, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 367 [64/170 (33%)]\tLoss: 0.219835 (avg: 0.219835) \tsec/iter: 0.0499\n",
      "Train Epoch: 367 [170/170 (100%)]\tLoss: 0.136612 (avg: 0.215589) \tsec/iter: 0.0442\n",
      "Test set (epoch 367): Average loss: 0.2271, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 368 [64/170 (33%)]\tLoss: 0.127084 (avg: 0.127084) \tsec/iter: 0.0459\n",
      "Train Epoch: 368 [170/170 (100%)]\tLoss: 0.191799 (avg: 0.209056) \tsec/iter: 0.0449\n",
      "Test set (epoch 368): Average loss: 0.2284, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 369 [64/170 (33%)]\tLoss: 0.354564 (avg: 0.354564) \tsec/iter: 0.0529\n",
      "Train Epoch: 369 [170/170 (100%)]\tLoss: 0.188165 (avg: 0.259166) \tsec/iter: 0.0475\n",
      "Test set (epoch 369): Average loss: 0.2102, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 370 [64/170 (33%)]\tLoss: 0.221155 (avg: 0.221155) \tsec/iter: 0.0509\n",
      "Train Epoch: 370 [170/170 (100%)]\tLoss: 0.371997 (avg: 0.247643) \tsec/iter: 0.0462\n",
      "Test set (epoch 370): Average loss: 0.1791, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 371 [64/170 (33%)]\tLoss: 0.122123 (avg: 0.122123) \tsec/iter: 0.0588\n",
      "Train Epoch: 371 [170/170 (100%)]\tLoss: 0.296494 (avg: 0.229001) \tsec/iter: 0.0522\n",
      "Test set (epoch 371): Average loss: 0.3875, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 372 [64/170 (33%)]\tLoss: 0.272772 (avg: 0.272772) \tsec/iter: 0.0588\n",
      "Train Epoch: 372 [170/170 (100%)]\tLoss: 0.241314 (avg: 0.224346) \tsec/iter: 0.0515\n",
      "Test set (epoch 372): Average loss: 0.2047, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 373 [64/170 (33%)]\tLoss: 0.177076 (avg: 0.177076) \tsec/iter: 0.0499\n",
      "Train Epoch: 373 [170/170 (100%)]\tLoss: 0.157084 (avg: 0.242672) \tsec/iter: 0.0505\n",
      "Test set (epoch 373): Average loss: 0.2196, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 374 [64/170 (33%)]\tLoss: 0.191232 (avg: 0.191232) \tsec/iter: 0.0509\n",
      "Train Epoch: 374 [170/170 (100%)]\tLoss: 0.172987 (avg: 0.205290) \tsec/iter: 0.0465\n",
      "Test set (epoch 374): Average loss: 0.2059, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 375 [64/170 (33%)]\tLoss: 0.196995 (avg: 0.196995) \tsec/iter: 0.0479\n",
      "Train Epoch: 375 [170/170 (100%)]\tLoss: 0.259857 (avg: 0.201250) \tsec/iter: 0.0422\n",
      "Test set (epoch 375): Average loss: 0.2081, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 376 [64/170 (33%)]\tLoss: 0.108685 (avg: 0.108685) \tsec/iter: 0.0449\n",
      "Train Epoch: 376 [170/170 (100%)]\tLoss: 0.359866 (avg: 0.193805) \tsec/iter: 0.0442\n",
      "Test set (epoch 376): Average loss: 0.2436, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 377 [64/170 (33%)]\tLoss: 0.214777 (avg: 0.214777) \tsec/iter: 0.0578\n",
      "Train Epoch: 377 [170/170 (100%)]\tLoss: 0.275061 (avg: 0.216187) \tsec/iter: 0.0509\n",
      "Test set (epoch 377): Average loss: 0.1796, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 378 [64/170 (33%)]\tLoss: 0.206911 (avg: 0.206911) \tsec/iter: 0.0568\n",
      "Train Epoch: 378 [170/170 (100%)]\tLoss: 0.232505 (avg: 0.209364) \tsec/iter: 0.0525\n",
      "Test set (epoch 378): Average loss: 0.1370, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 379 [64/170 (33%)]\tLoss: 0.135065 (avg: 0.135065) \tsec/iter: 0.0549\n",
      "Train Epoch: 379 [170/170 (100%)]\tLoss: 0.232056 (avg: 0.212812) \tsec/iter: 0.0479\n",
      "Test set (epoch 379): Average loss: 0.2807, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 380 [64/170 (33%)]\tLoss: 0.198426 (avg: 0.198426) \tsec/iter: 0.0459\n",
      "Train Epoch: 380 [170/170 (100%)]\tLoss: 0.216593 (avg: 0.172475) \tsec/iter: 0.0409\n",
      "Test set (epoch 380): Average loss: 0.1631, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 381 [64/170 (33%)]\tLoss: 0.299810 (avg: 0.299810) \tsec/iter: 0.0529\n",
      "Train Epoch: 381 [170/170 (100%)]\tLoss: 0.161348 (avg: 0.224914) \tsec/iter: 0.0489\n",
      "Test set (epoch 381): Average loss: 0.2798, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 382 [64/170 (33%)]\tLoss: 0.173661 (avg: 0.173661) \tsec/iter: 0.0459\n",
      "Train Epoch: 382 [170/170 (100%)]\tLoss: 0.412741 (avg: 0.235805) \tsec/iter: 0.0462\n",
      "Test set (epoch 382): Average loss: 0.2025, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 383 [64/170 (33%)]\tLoss: 0.199622 (avg: 0.199622) \tsec/iter: 0.0568\n",
      "Train Epoch: 383 [170/170 (100%)]\tLoss: 0.175018 (avg: 0.190897) \tsec/iter: 0.0485\n",
      "Test set (epoch 383): Average loss: 0.1219, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 384 [64/170 (33%)]\tLoss: 0.214288 (avg: 0.214288) \tsec/iter: 0.0529\n",
      "Train Epoch: 384 [170/170 (100%)]\tLoss: 0.330687 (avg: 0.223243) \tsec/iter: 0.0515\n",
      "Test set (epoch 384): Average loss: 0.3921, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 385 [64/170 (33%)]\tLoss: 0.207037 (avg: 0.207037) \tsec/iter: 0.0489\n",
      "Train Epoch: 385 [170/170 (100%)]\tLoss: 0.320635 (avg: 0.239003) \tsec/iter: 0.0452\n",
      "Test set (epoch 385): Average loss: 0.1285, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 386 [64/170 (33%)]\tLoss: 0.174446 (avg: 0.174446) \tsec/iter: 0.0768\n",
      "Train Epoch: 386 [170/170 (100%)]\tLoss: 0.276334 (avg: 0.227737) \tsec/iter: 0.0598\n",
      "Test set (epoch 386): Average loss: 0.3013, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 387 [64/170 (33%)]\tLoss: 0.201896 (avg: 0.201896) \tsec/iter: 0.0509\n",
      "Train Epoch: 387 [170/170 (100%)]\tLoss: 0.189187 (avg: 0.185170) \tsec/iter: 0.0469\n",
      "Test set (epoch 387): Average loss: 0.2738, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 388 [64/170 (33%)]\tLoss: 0.243051 (avg: 0.243051) \tsec/iter: 0.0578\n",
      "Train Epoch: 388 [170/170 (100%)]\tLoss: 0.212593 (avg: 0.205327) \tsec/iter: 0.0502\n",
      "Test set (epoch 388): Average loss: 0.2032, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 389 [64/170 (33%)]\tLoss: 0.182808 (avg: 0.182808) \tsec/iter: 0.0509\n",
      "Train Epoch: 389 [170/170 (100%)]\tLoss: 0.153832 (avg: 0.191709) \tsec/iter: 0.0465\n",
      "Test set (epoch 389): Average loss: 0.2808, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 390 [64/170 (33%)]\tLoss: 0.105956 (avg: 0.105956) \tsec/iter: 0.0549\n",
      "Train Epoch: 390 [170/170 (100%)]\tLoss: 0.201043 (avg: 0.159411) \tsec/iter: 0.0515\n",
      "Test set (epoch 390): Average loss: 0.3265, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 391 [64/170 (33%)]\tLoss: 0.265982 (avg: 0.265982) \tsec/iter: 0.0519\n",
      "Train Epoch: 391 [170/170 (100%)]\tLoss: 0.363142 (avg: 0.243179) \tsec/iter: 0.0472\n",
      "Test set (epoch 391): Average loss: 0.3413, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 392 [64/170 (33%)]\tLoss: 0.137386 (avg: 0.137386) \tsec/iter: 0.0529\n",
      "Train Epoch: 392 [170/170 (100%)]\tLoss: 0.206567 (avg: 0.189244) \tsec/iter: 0.0459\n",
      "Test set (epoch 392): Average loss: 0.2836, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 393 [64/170 (33%)]\tLoss: 0.174197 (avg: 0.174197) \tsec/iter: 0.0499\n",
      "Train Epoch: 393 [170/170 (100%)]\tLoss: 0.128046 (avg: 0.173423) \tsec/iter: 0.0455\n",
      "Test set (epoch 393): Average loss: 0.1970, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 394 [64/170 (33%)]\tLoss: 0.168831 (avg: 0.168831) \tsec/iter: 0.0459\n",
      "Train Epoch: 394 [170/170 (100%)]\tLoss: 0.132584 (avg: 0.204630) \tsec/iter: 0.0452\n",
      "Test set (epoch 394): Average loss: 0.1427, Accuracy: 17/18 (94.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 395 [64/170 (33%)]\tLoss: 0.166024 (avg: 0.166024) \tsec/iter: 0.0568\n",
      "Train Epoch: 395 [170/170 (100%)]\tLoss: 0.173300 (avg: 0.202159) \tsec/iter: 0.0485\n",
      "Test set (epoch 395): Average loss: 0.2895, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 396 [64/170 (33%)]\tLoss: 0.179462 (avg: 0.179462) \tsec/iter: 0.0449\n",
      "Train Epoch: 396 [170/170 (100%)]\tLoss: 0.303174 (avg: 0.215148) \tsec/iter: 0.0436\n",
      "Test set (epoch 396): Average loss: 0.2078, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 397 [64/170 (33%)]\tLoss: 0.186000 (avg: 0.186000) \tsec/iter: 0.0489\n",
      "Train Epoch: 397 [170/170 (100%)]\tLoss: 0.513294 (avg: 0.254399) \tsec/iter: 0.0502\n",
      "Test set (epoch 397): Average loss: 0.2973, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 398 [64/170 (33%)]\tLoss: 0.196290 (avg: 0.196290) \tsec/iter: 0.0529\n",
      "Train Epoch: 398 [170/170 (100%)]\tLoss: 0.323718 (avg: 0.228972) \tsec/iter: 0.0459\n",
      "Test set (epoch 398): Average loss: 0.3076, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 399 [64/170 (33%)]\tLoss: 0.225290 (avg: 0.225290) \tsec/iter: 0.0549\n",
      "Train Epoch: 399 [170/170 (100%)]\tLoss: 0.207631 (avg: 0.209648) \tsec/iter: 0.0436\n",
      "Test set (epoch 399): Average loss: 0.2125, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 400 [64/170 (33%)]\tLoss: 0.174222 (avg: 0.174222) \tsec/iter: 0.0489\n",
      "Train Epoch: 400 [170/170 (100%)]\tLoss: 0.156778 (avg: 0.159587) \tsec/iter: 0.0469\n",
      "Test set (epoch 400): Average loss: 0.2448, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 401 [64/170 (33%)]\tLoss: 0.183985 (avg: 0.183985) \tsec/iter: 0.0539\n",
      "Train Epoch: 401 [170/170 (100%)]\tLoss: 0.242194 (avg: 0.198129) \tsec/iter: 0.0475\n",
      "Test set (epoch 401): Average loss: 0.2638, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 402 [64/170 (33%)]\tLoss: 0.179054 (avg: 0.179054) \tsec/iter: 0.0469\n",
      "Train Epoch: 402 [170/170 (100%)]\tLoss: 0.201753 (avg: 0.204774) \tsec/iter: 0.0462\n",
      "Test set (epoch 402): Average loss: 0.1963, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 403 [64/170 (33%)]\tLoss: 0.129335 (avg: 0.129335) \tsec/iter: 0.0479\n",
      "Train Epoch: 403 [170/170 (100%)]\tLoss: 0.219027 (avg: 0.184181) \tsec/iter: 0.0449\n",
      "Test set (epoch 403): Average loss: 0.2170, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 404 [64/170 (33%)]\tLoss: 0.212721 (avg: 0.212721) \tsec/iter: 0.0509\n",
      "Train Epoch: 404 [170/170 (100%)]\tLoss: 0.226827 (avg: 0.199508) \tsec/iter: 0.0465\n",
      "Test set (epoch 404): Average loss: 0.2284, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 405 [64/170 (33%)]\tLoss: 0.156146 (avg: 0.156146) \tsec/iter: 0.0469\n",
      "Train Epoch: 405 [170/170 (100%)]\tLoss: 0.165188 (avg: 0.152515) \tsec/iter: 0.0475\n",
      "Test set (epoch 405): Average loss: 0.1726, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 406 [64/170 (33%)]\tLoss: 0.265501 (avg: 0.265501) \tsec/iter: 0.0419\n",
      "Train Epoch: 406 [170/170 (100%)]\tLoss: 0.132726 (avg: 0.229032) \tsec/iter: 0.0439\n",
      "Test set (epoch 406): Average loss: 0.1355, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 407 [64/170 (33%)]\tLoss: 0.312204 (avg: 0.312204) \tsec/iter: 0.0499\n",
      "Train Epoch: 407 [170/170 (100%)]\tLoss: 0.158858 (avg: 0.208506) \tsec/iter: 0.0445\n",
      "Test set (epoch 407): Average loss: 0.2028, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 408 [64/170 (33%)]\tLoss: 0.137500 (avg: 0.137500) \tsec/iter: 0.0509\n",
      "Train Epoch: 408 [170/170 (100%)]\tLoss: 0.249919 (avg: 0.176363) \tsec/iter: 0.0439\n",
      "Test set (epoch 408): Average loss: 0.3515, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 409 [64/170 (33%)]\tLoss: 0.188223 (avg: 0.188223) \tsec/iter: 0.0439\n",
      "Train Epoch: 409 [170/170 (100%)]\tLoss: 0.168057 (avg: 0.191828) \tsec/iter: 0.0422\n",
      "Test set (epoch 409): Average loss: 0.2052, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 410 [64/170 (33%)]\tLoss: 0.270262 (avg: 0.270262) \tsec/iter: 0.0559\n",
      "Train Epoch: 410 [170/170 (100%)]\tLoss: 0.178433 (avg: 0.197907) \tsec/iter: 0.0505\n",
      "Test set (epoch 410): Average loss: 0.1380, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 411 [64/170 (33%)]\tLoss: 0.153755 (avg: 0.153755) \tsec/iter: 0.0549\n",
      "Train Epoch: 411 [170/170 (100%)]\tLoss: 0.151300 (avg: 0.189256) \tsec/iter: 0.0495\n",
      "Test set (epoch 411): Average loss: 0.2170, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 412 [64/170 (33%)]\tLoss: 0.161843 (avg: 0.161843) \tsec/iter: 0.0479\n",
      "Train Epoch: 412 [170/170 (100%)]\tLoss: 0.153962 (avg: 0.169162) \tsec/iter: 0.0429\n",
      "Test set (epoch 412): Average loss: 0.2444, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 413 [64/170 (33%)]\tLoss: 0.109228 (avg: 0.109228) \tsec/iter: 0.0429\n",
      "Train Epoch: 413 [170/170 (100%)]\tLoss: 0.115337 (avg: 0.124385) \tsec/iter: 0.0402\n",
      "Test set (epoch 413): Average loss: 0.1844, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 414 [64/170 (33%)]\tLoss: 0.318668 (avg: 0.318668) \tsec/iter: 0.0429\n",
      "Train Epoch: 414 [170/170 (100%)]\tLoss: 0.181617 (avg: 0.219794) \tsec/iter: 0.0432\n",
      "Test set (epoch 414): Average loss: 0.1396, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 415 [64/170 (33%)]\tLoss: 0.199371 (avg: 0.199371) \tsec/iter: 0.0479\n",
      "Train Epoch: 415 [170/170 (100%)]\tLoss: 0.125931 (avg: 0.175171) \tsec/iter: 0.0416\n",
      "Test set (epoch 415): Average loss: 0.1674, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 416 [64/170 (33%)]\tLoss: 0.201842 (avg: 0.201842) \tsec/iter: 0.0439\n",
      "Train Epoch: 416 [170/170 (100%)]\tLoss: 0.174240 (avg: 0.199982) \tsec/iter: 0.0392\n",
      "Test set (epoch 416): Average loss: 0.2046, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 417 [64/170 (33%)]\tLoss: 0.193830 (avg: 0.193830) \tsec/iter: 0.0678\n",
      "Train Epoch: 417 [170/170 (100%)]\tLoss: 0.133657 (avg: 0.225410) \tsec/iter: 0.0529\n",
      "Test set (epoch 417): Average loss: 0.3333, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 418 [64/170 (33%)]\tLoss: 0.193521 (avg: 0.193521) \tsec/iter: 0.0449\n",
      "Train Epoch: 418 [170/170 (100%)]\tLoss: 0.282179 (avg: 0.178796) \tsec/iter: 0.0459\n",
      "Test set (epoch 418): Average loss: 0.2692, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 419 [64/170 (33%)]\tLoss: 0.225925 (avg: 0.225925) \tsec/iter: 0.0449\n",
      "Train Epoch: 419 [170/170 (100%)]\tLoss: 0.129206 (avg: 0.176570) \tsec/iter: 0.0412\n",
      "Test set (epoch 419): Average loss: 0.3642, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 420 [64/170 (33%)]\tLoss: 0.113068 (avg: 0.113068) \tsec/iter: 0.0419\n",
      "Train Epoch: 420 [170/170 (100%)]\tLoss: 0.139217 (avg: 0.206613) \tsec/iter: 0.0412\n",
      "Test set (epoch 420): Average loss: 0.2397, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 421 [64/170 (33%)]\tLoss: 0.110976 (avg: 0.110976) \tsec/iter: 0.0469\n",
      "Train Epoch: 421 [170/170 (100%)]\tLoss: 0.155005 (avg: 0.141766) \tsec/iter: 0.0399\n",
      "Test set (epoch 421): Average loss: 0.4177, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 422 [64/170 (33%)]\tLoss: 0.201283 (avg: 0.201283) \tsec/iter: 0.0429\n",
      "Train Epoch: 422 [170/170 (100%)]\tLoss: 0.258427 (avg: 0.200681) \tsec/iter: 0.0392\n",
      "Test set (epoch 422): Average loss: 0.2008, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 423 [64/170 (33%)]\tLoss: 0.207172 (avg: 0.207172) \tsec/iter: 0.0399\n",
      "Train Epoch: 423 [170/170 (100%)]\tLoss: 0.248345 (avg: 0.212630) \tsec/iter: 0.0386\n",
      "Test set (epoch 423): Average loss: 0.3891, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 424 [64/170 (33%)]\tLoss: 0.145775 (avg: 0.145775) \tsec/iter: 0.0469\n",
      "Train Epoch: 424 [170/170 (100%)]\tLoss: 0.225904 (avg: 0.187934) \tsec/iter: 0.0462\n",
      "Test set (epoch 424): Average loss: 0.1837, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 425 [64/170 (33%)]\tLoss: 0.173607 (avg: 0.173607) \tsec/iter: 0.0499\n",
      "Train Epoch: 425 [170/170 (100%)]\tLoss: 0.138679 (avg: 0.191481) \tsec/iter: 0.0436\n",
      "Test set (epoch 425): Average loss: 0.2362, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 426 [64/170 (33%)]\tLoss: 0.133234 (avg: 0.133234) \tsec/iter: 0.0449\n",
      "Train Epoch: 426 [170/170 (100%)]\tLoss: 0.118468 (avg: 0.187241) \tsec/iter: 0.0396\n",
      "Test set (epoch 426): Average loss: 0.1493, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 427 [64/170 (33%)]\tLoss: 0.165562 (avg: 0.165562) \tsec/iter: 0.0419\n",
      "Train Epoch: 427 [170/170 (100%)]\tLoss: 0.201582 (avg: 0.202054) \tsec/iter: 0.0419\n",
      "Test set (epoch 427): Average loss: 0.2441, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 428 [64/170 (33%)]\tLoss: 0.138451 (avg: 0.138451) \tsec/iter: 0.0429\n",
      "Train Epoch: 428 [170/170 (100%)]\tLoss: 0.165537 (avg: 0.158179) \tsec/iter: 0.0392\n",
      "Test set (epoch 428): Average loss: 0.1607, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 429 [64/170 (33%)]\tLoss: 0.245560 (avg: 0.245560) \tsec/iter: 0.0469\n",
      "Train Epoch: 429 [170/170 (100%)]\tLoss: 0.230055 (avg: 0.217706) \tsec/iter: 0.0409\n",
      "Test set (epoch 429): Average loss: 0.2787, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 430 [64/170 (33%)]\tLoss: 0.275410 (avg: 0.275410) \tsec/iter: 0.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 430 [170/170 (100%)]\tLoss: 0.125176 (avg: 0.199339) \tsec/iter: 0.0426\n",
      "Test set (epoch 430): Average loss: 0.1445, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 431 [64/170 (33%)]\tLoss: 0.164239 (avg: 0.164239) \tsec/iter: 0.0469\n",
      "Train Epoch: 431 [170/170 (100%)]\tLoss: 0.204332 (avg: 0.218586) \tsec/iter: 0.0495\n",
      "Test set (epoch 431): Average loss: 0.2167, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 432 [64/170 (33%)]\tLoss: 0.151188 (avg: 0.151188) \tsec/iter: 0.0439\n",
      "Train Epoch: 432 [170/170 (100%)]\tLoss: 0.158827 (avg: 0.175255) \tsec/iter: 0.0362\n",
      "Test set (epoch 432): Average loss: 0.2481, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 433 [64/170 (33%)]\tLoss: 0.175779 (avg: 0.175779) \tsec/iter: 0.0339\n",
      "Train Epoch: 433 [170/170 (100%)]\tLoss: 0.140614 (avg: 0.173071) \tsec/iter: 0.0306\n",
      "Test set (epoch 433): Average loss: 0.1777, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 434 [64/170 (33%)]\tLoss: 0.217953 (avg: 0.217953) \tsec/iter: 0.0349\n",
      "Train Epoch: 434 [170/170 (100%)]\tLoss: 0.146721 (avg: 0.183204) \tsec/iter: 0.0332\n",
      "Test set (epoch 434): Average loss: 0.4025, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 435 [64/170 (33%)]\tLoss: 0.190329 (avg: 0.190329) \tsec/iter: 0.0359\n",
      "Train Epoch: 435 [170/170 (100%)]\tLoss: 0.126386 (avg: 0.175413) \tsec/iter: 0.0316\n",
      "Test set (epoch 435): Average loss: 0.2520, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 436 [64/170 (33%)]\tLoss: 0.230220 (avg: 0.230220) \tsec/iter: 0.0419\n",
      "Train Epoch: 436 [170/170 (100%)]\tLoss: 0.251131 (avg: 0.202674) \tsec/iter: 0.0352\n",
      "Test set (epoch 436): Average loss: 0.3663, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 437 [64/170 (33%)]\tLoss: 0.217932 (avg: 0.217932) \tsec/iter: 0.0349\n",
      "Train Epoch: 437 [170/170 (100%)]\tLoss: 0.350415 (avg: 0.227890) \tsec/iter: 0.0319\n",
      "Test set (epoch 437): Average loss: 0.2714, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 438 [64/170 (33%)]\tLoss: 0.200537 (avg: 0.200537) \tsec/iter: 0.0319\n",
      "Train Epoch: 438 [170/170 (100%)]\tLoss: 0.136020 (avg: 0.168114) \tsec/iter: 0.0303\n",
      "Test set (epoch 438): Average loss: 0.1717, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 439 [64/170 (33%)]\tLoss: 0.152461 (avg: 0.152461) \tsec/iter: 0.0379\n",
      "Train Epoch: 439 [170/170 (100%)]\tLoss: 0.176133 (avg: 0.162206) \tsec/iter: 0.0322\n",
      "Test set (epoch 439): Average loss: 0.2377, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 440 [64/170 (33%)]\tLoss: 0.170358 (avg: 0.170358) \tsec/iter: 0.0369\n",
      "Train Epoch: 440 [170/170 (100%)]\tLoss: 0.205791 (avg: 0.162402) \tsec/iter: 0.0356\n",
      "Test set (epoch 440): Average loss: 0.1849, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 441 [64/170 (33%)]\tLoss: 0.186590 (avg: 0.186590) \tsec/iter: 0.0409\n",
      "Train Epoch: 441 [170/170 (100%)]\tLoss: 0.298486 (avg: 0.223956) \tsec/iter: 0.0352\n",
      "Test set (epoch 441): Average loss: 0.1748, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 442 [64/170 (33%)]\tLoss: 0.213715 (avg: 0.213715) \tsec/iter: 0.0349\n",
      "Train Epoch: 442 [170/170 (100%)]\tLoss: 0.192158 (avg: 0.178639) \tsec/iter: 0.0299\n",
      "Test set (epoch 442): Average loss: 0.2318, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 443 [64/170 (33%)]\tLoss: 0.148808 (avg: 0.148808) \tsec/iter: 0.0319\n",
      "Train Epoch: 443 [170/170 (100%)]\tLoss: 0.336134 (avg: 0.199322) \tsec/iter: 0.0296\n",
      "Test set (epoch 443): Average loss: 0.4271, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 444 [64/170 (33%)]\tLoss: 0.127605 (avg: 0.127605) \tsec/iter: 0.0339\n",
      "Train Epoch: 444 [170/170 (100%)]\tLoss: 0.172480 (avg: 0.158437) \tsec/iter: 0.0309\n",
      "Test set (epoch 444): Average loss: 0.2033, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 445 [64/170 (33%)]\tLoss: 0.142723 (avg: 0.142723) \tsec/iter: 0.0369\n",
      "Train Epoch: 445 [170/170 (100%)]\tLoss: 0.160412 (avg: 0.144305) \tsec/iter: 0.0332\n",
      "Test set (epoch 445): Average loss: 0.3990, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 446 [64/170 (33%)]\tLoss: 0.218887 (avg: 0.218887) \tsec/iter: 0.0359\n",
      "Train Epoch: 446 [170/170 (100%)]\tLoss: 0.232391 (avg: 0.205677) \tsec/iter: 0.0319\n",
      "Test set (epoch 446): Average loss: 0.3675, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 447 [64/170 (33%)]\tLoss: 0.129924 (avg: 0.129924) \tsec/iter: 0.0369\n",
      "Train Epoch: 447 [170/170 (100%)]\tLoss: 0.251664 (avg: 0.172601) \tsec/iter: 0.0322\n",
      "Test set (epoch 447): Average loss: 0.2226, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 448 [64/170 (33%)]\tLoss: 0.241691 (avg: 0.241691) \tsec/iter: 0.0339\n",
      "Train Epoch: 448 [170/170 (100%)]\tLoss: 0.197520 (avg: 0.212908) \tsec/iter: 0.0312\n",
      "Test set (epoch 448): Average loss: 0.2509, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 449 [64/170 (33%)]\tLoss: 0.137651 (avg: 0.137651) \tsec/iter: 0.0379\n",
      "Train Epoch: 449 [170/170 (100%)]\tLoss: 0.171095 (avg: 0.162128) \tsec/iter: 0.0366\n",
      "Test set (epoch 449): Average loss: 0.1234, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 450 [64/170 (33%)]\tLoss: 0.263742 (avg: 0.263742) \tsec/iter: 0.0409\n",
      "Train Epoch: 450 [170/170 (100%)]\tLoss: 0.119101 (avg: 0.177937) \tsec/iter: 0.0356\n",
      "Test set (epoch 450): Average loss: 0.1202, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 451 [64/170 (33%)]\tLoss: 0.157824 (avg: 0.157824) \tsec/iter: 0.0349\n",
      "Train Epoch: 451 [170/170 (100%)]\tLoss: 0.106231 (avg: 0.160663) \tsec/iter: 0.0312\n",
      "Test set (epoch 451): Average loss: 0.1178, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 452 [64/170 (33%)]\tLoss: 0.164895 (avg: 0.164895) \tsec/iter: 0.0349\n",
      "Train Epoch: 452 [170/170 (100%)]\tLoss: 0.190428 (avg: 0.220581) \tsec/iter: 0.0319\n",
      "Test set (epoch 452): Average loss: 0.2389, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 453 [64/170 (33%)]\tLoss: 0.107389 (avg: 0.107389) \tsec/iter: 0.0339\n",
      "Train Epoch: 453 [170/170 (100%)]\tLoss: 0.218066 (avg: 0.178304) \tsec/iter: 0.0306\n",
      "Test set (epoch 453): Average loss: 0.2819, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 454 [64/170 (33%)]\tLoss: 0.172051 (avg: 0.172051) \tsec/iter: 0.0339\n",
      "Train Epoch: 454 [170/170 (100%)]\tLoss: 0.212971 (avg: 0.158983) \tsec/iter: 0.0326\n",
      "Test set (epoch 454): Average loss: 0.2909, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 455 [64/170 (33%)]\tLoss: 0.186256 (avg: 0.186256) \tsec/iter: 0.0379\n",
      "Train Epoch: 455 [170/170 (100%)]\tLoss: 0.180660 (avg: 0.191771) \tsec/iter: 0.0332\n",
      "Test set (epoch 455): Average loss: 0.3723, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 456 [64/170 (33%)]\tLoss: 0.220284 (avg: 0.220284) \tsec/iter: 0.0339\n",
      "Train Epoch: 456 [170/170 (100%)]\tLoss: 0.311846 (avg: 0.222087) \tsec/iter: 0.0312\n",
      "Test set (epoch 456): Average loss: 0.2200, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 457 [64/170 (33%)]\tLoss: 0.293508 (avg: 0.293508) \tsec/iter: 0.0329\n",
      "Train Epoch: 457 [170/170 (100%)]\tLoss: 0.254321 (avg: 0.225436) \tsec/iter: 0.0286\n",
      "Test set (epoch 457): Average loss: 0.3347, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 458 [64/170 (33%)]\tLoss: 0.145741 (avg: 0.145741) \tsec/iter: 0.0369\n",
      "Train Epoch: 458 [170/170 (100%)]\tLoss: 0.203228 (avg: 0.168619) \tsec/iter: 0.0332\n",
      "Test set (epoch 458): Average loss: 0.2727, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 459 [64/170 (33%)]\tLoss: 0.187923 (avg: 0.187923) \tsec/iter: 0.0379\n",
      "Train Epoch: 459 [170/170 (100%)]\tLoss: 0.372404 (avg: 0.200765) \tsec/iter: 0.0369\n",
      "Test set (epoch 459): Average loss: 0.1775, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 460 [64/170 (33%)]\tLoss: 0.276745 (avg: 0.276745) \tsec/iter: 0.0419\n",
      "Train Epoch: 460 [170/170 (100%)]\tLoss: 0.110691 (avg: 0.228236) \tsec/iter: 0.0369\n",
      "Test set (epoch 460): Average loss: 0.1686, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 461 [64/170 (33%)]\tLoss: 0.135379 (avg: 0.135379) \tsec/iter: 0.0299\n",
      "Train Epoch: 461 [170/170 (100%)]\tLoss: 0.206368 (avg: 0.192076) \tsec/iter: 0.0306\n",
      "Test set (epoch 461): Average loss: 0.3356, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 462 [64/170 (33%)]\tLoss: 0.218386 (avg: 0.218386) \tsec/iter: 0.0329\n",
      "Train Epoch: 462 [170/170 (100%)]\tLoss: 0.173371 (avg: 0.178390) \tsec/iter: 0.0322\n",
      "Test set (epoch 462): Average loss: 0.1061, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 463 [64/170 (33%)]\tLoss: 0.199942 (avg: 0.199942) \tsec/iter: 0.0399\n",
      "Train Epoch: 463 [170/170 (100%)]\tLoss: 0.110528 (avg: 0.173381) \tsec/iter: 0.0336\n",
      "Test set (epoch 463): Average loss: 0.2236, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 464 [64/170 (33%)]\tLoss: 0.133568 (avg: 0.133568) \tsec/iter: 0.0359\n",
      "Train Epoch: 464 [170/170 (100%)]\tLoss: 0.220069 (avg: 0.200322) \tsec/iter: 0.0322\n",
      "Test set (epoch 464): Average loss: 0.2044, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 465 [64/170 (33%)]\tLoss: 0.093397 (avg: 0.093397) \tsec/iter: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 465 [170/170 (100%)]\tLoss: 0.245001 (avg: 0.222615) \tsec/iter: 0.0296\n",
      "Test set (epoch 465): Average loss: 0.2968, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 466 [64/170 (33%)]\tLoss: 0.184172 (avg: 0.184172) \tsec/iter: 0.0369\n",
      "Train Epoch: 466 [170/170 (100%)]\tLoss: 0.168420 (avg: 0.165406) \tsec/iter: 0.0309\n",
      "Test set (epoch 466): Average loss: 0.3299, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 467 [64/170 (33%)]\tLoss: 0.195854 (avg: 0.195854) \tsec/iter: 0.0299\n",
      "Train Epoch: 467 [170/170 (100%)]\tLoss: 0.175828 (avg: 0.160509) \tsec/iter: 0.0306\n",
      "Test set (epoch 467): Average loss: 0.3502, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 468 [64/170 (33%)]\tLoss: 0.167944 (avg: 0.167944) \tsec/iter: 0.0379\n",
      "Train Epoch: 468 [170/170 (100%)]\tLoss: 0.170114 (avg: 0.167559) \tsec/iter: 0.0346\n",
      "Test set (epoch 468): Average loss: 0.2324, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 469 [64/170 (33%)]\tLoss: 0.202964 (avg: 0.202964) \tsec/iter: 0.0399\n",
      "Train Epoch: 469 [170/170 (100%)]\tLoss: 0.128799 (avg: 0.147654) \tsec/iter: 0.0359\n",
      "Test set (epoch 469): Average loss: 0.2505, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 470 [64/170 (33%)]\tLoss: 0.176369 (avg: 0.176369) \tsec/iter: 0.0389\n",
      "Train Epoch: 470 [170/170 (100%)]\tLoss: 0.181390 (avg: 0.191600) \tsec/iter: 0.0326\n",
      "Test set (epoch 470): Average loss: 0.2583, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 471 [64/170 (33%)]\tLoss: 0.212850 (avg: 0.212850) \tsec/iter: 0.0349\n",
      "Train Epoch: 471 [170/170 (100%)]\tLoss: 0.131596 (avg: 0.193680) \tsec/iter: 0.0306\n",
      "Test set (epoch 471): Average loss: 0.2920, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 472 [64/170 (33%)]\tLoss: 0.125710 (avg: 0.125710) \tsec/iter: 0.0309\n",
      "Train Epoch: 472 [170/170 (100%)]\tLoss: 0.206863 (avg: 0.151225) \tsec/iter: 0.0303\n",
      "Test set (epoch 472): Average loss: 0.2334, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 473 [64/170 (33%)]\tLoss: 0.225403 (avg: 0.225403) \tsec/iter: 0.0329\n",
      "Train Epoch: 473 [170/170 (100%)]\tLoss: 0.170701 (avg: 0.187625) \tsec/iter: 0.0289\n",
      "Test set (epoch 473): Average loss: 0.1677, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 474 [64/170 (33%)]\tLoss: 0.228229 (avg: 0.228229) \tsec/iter: 0.0329\n",
      "Train Epoch: 474 [170/170 (100%)]\tLoss: 0.194177 (avg: 0.192885) \tsec/iter: 0.0316\n",
      "Test set (epoch 474): Average loss: 0.1173, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 475 [64/170 (33%)]\tLoss: 0.222319 (avg: 0.222319) \tsec/iter: 0.0379\n",
      "Train Epoch: 475 [170/170 (100%)]\tLoss: 0.148081 (avg: 0.176874) \tsec/iter: 0.0359\n",
      "Test set (epoch 475): Average loss: 0.2428, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 476 [64/170 (33%)]\tLoss: 0.232666 (avg: 0.232666) \tsec/iter: 0.0469\n",
      "Train Epoch: 476 [170/170 (100%)]\tLoss: 0.235734 (avg: 0.202157) \tsec/iter: 0.0366\n",
      "Test set (epoch 476): Average loss: 0.2223, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 477 [64/170 (33%)]\tLoss: 0.139919 (avg: 0.139919) \tsec/iter: 0.0359\n",
      "Train Epoch: 477 [170/170 (100%)]\tLoss: 0.142812 (avg: 0.163160) \tsec/iter: 0.0339\n",
      "Test set (epoch 477): Average loss: 0.2193, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 478 [64/170 (33%)]\tLoss: 0.147815 (avg: 0.147815) \tsec/iter: 0.0419\n",
      "Train Epoch: 478 [170/170 (100%)]\tLoss: 0.248328 (avg: 0.202568) \tsec/iter: 0.0389\n",
      "Test set (epoch 478): Average loss: 0.2803, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 479 [64/170 (33%)]\tLoss: 0.174526 (avg: 0.174526) \tsec/iter: 0.0389\n",
      "Train Epoch: 479 [170/170 (100%)]\tLoss: 0.148200 (avg: 0.203881) \tsec/iter: 0.0346\n",
      "Test set (epoch 479): Average loss: 0.2794, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 480 [64/170 (33%)]\tLoss: 0.190312 (avg: 0.190312) \tsec/iter: 0.0349\n",
      "Train Epoch: 480 [170/170 (100%)]\tLoss: 0.191173 (avg: 0.198785) \tsec/iter: 0.0336\n",
      "Test set (epoch 480): Average loss: 0.2350, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 481 [64/170 (33%)]\tLoss: 0.103114 (avg: 0.103114) \tsec/iter: 0.0329\n",
      "Train Epoch: 481 [170/170 (100%)]\tLoss: 0.148992 (avg: 0.137399) \tsec/iter: 0.0306\n",
      "Test set (epoch 481): Average loss: 0.1084, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 482 [64/170 (33%)]\tLoss: 0.205684 (avg: 0.205684) \tsec/iter: 0.0319\n",
      "Train Epoch: 482 [170/170 (100%)]\tLoss: 0.151033 (avg: 0.189062) \tsec/iter: 0.0303\n",
      "Test set (epoch 482): Average loss: 0.4516, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 483 [64/170 (33%)]\tLoss: 0.148107 (avg: 0.148107) \tsec/iter: 0.0349\n",
      "Train Epoch: 483 [170/170 (100%)]\tLoss: 0.103817 (avg: 0.179293) \tsec/iter: 0.0326\n",
      "Test set (epoch 483): Average loss: 0.2158, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 484 [64/170 (33%)]\tLoss: 0.130177 (avg: 0.130177) \tsec/iter: 0.0359\n",
      "Train Epoch: 484 [170/170 (100%)]\tLoss: 0.277262 (avg: 0.188201) \tsec/iter: 0.0326\n",
      "Test set (epoch 484): Average loss: 0.3888, Accuracy: 13/18 (72.22%)\n",
      "\n",
      "Train Epoch: 485 [64/170 (33%)]\tLoss: 0.121910 (avg: 0.121910) \tsec/iter: 0.0359\n",
      "Train Epoch: 485 [170/170 (100%)]\tLoss: 0.173812 (avg: 0.183404) \tsec/iter: 0.0326\n",
      "Test set (epoch 485): Average loss: 0.1620, Accuracy: 18/18 (100.00%)\n",
      "\n",
      "Train Epoch: 486 [64/170 (33%)]\tLoss: 0.311978 (avg: 0.311978) \tsec/iter: 0.0369\n",
      "Train Epoch: 486 [170/170 (100%)]\tLoss: 0.187778 (avg: 0.202601) \tsec/iter: 0.0312\n",
      "Test set (epoch 486): Average loss: 0.2803, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 487 [64/170 (33%)]\tLoss: 0.236643 (avg: 0.236643) \tsec/iter: 0.0409\n",
      "Train Epoch: 487 [170/170 (100%)]\tLoss: 0.186186 (avg: 0.184451) \tsec/iter: 0.0376\n",
      "Test set (epoch 487): Average loss: 0.1823, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 488 [64/170 (33%)]\tLoss: 0.177495 (avg: 0.177495) \tsec/iter: 0.0379\n",
      "Train Epoch: 488 [170/170 (100%)]\tLoss: 0.132134 (avg: 0.160121) \tsec/iter: 0.0339\n",
      "Test set (epoch 488): Average loss: 0.2954, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 489 [64/170 (33%)]\tLoss: 0.158153 (avg: 0.158153) \tsec/iter: 0.0329\n",
      "Train Epoch: 489 [170/170 (100%)]\tLoss: 0.265533 (avg: 0.249656) \tsec/iter: 0.0326\n",
      "Test set (epoch 489): Average loss: 0.2587, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 490 [64/170 (33%)]\tLoss: 0.186911 (avg: 0.186911) \tsec/iter: 0.0389\n",
      "Train Epoch: 490 [170/170 (100%)]\tLoss: 0.275648 (avg: 0.185205) \tsec/iter: 0.0352\n",
      "Test set (epoch 490): Average loss: 0.2004, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 491 [64/170 (33%)]\tLoss: 0.166253 (avg: 0.166253) \tsec/iter: 0.0369\n",
      "Train Epoch: 491 [170/170 (100%)]\tLoss: 0.241793 (avg: 0.170504) \tsec/iter: 0.0319\n",
      "Test set (epoch 491): Average loss: 0.2874, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 492 [64/170 (33%)]\tLoss: 0.167201 (avg: 0.167201) \tsec/iter: 0.0329\n",
      "Train Epoch: 492 [170/170 (100%)]\tLoss: 0.192179 (avg: 0.195223) \tsec/iter: 0.0322\n",
      "Test set (epoch 492): Average loss: 0.5096, Accuracy: 14/18 (77.78%)\n",
      "\n",
      "Train Epoch: 493 [64/170 (33%)]\tLoss: 0.210435 (avg: 0.210435) \tsec/iter: 0.0329\n",
      "Train Epoch: 493 [170/170 (100%)]\tLoss: 0.158868 (avg: 0.163257) \tsec/iter: 0.0296\n",
      "Test set (epoch 493): Average loss: 0.1918, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "Train Epoch: 494 [64/170 (33%)]\tLoss: 0.122672 (avg: 0.122672) \tsec/iter: 0.0399\n",
      "Train Epoch: 494 [170/170 (100%)]\tLoss: 0.126558 (avg: 0.130747) \tsec/iter: 0.0349\n",
      "Test set (epoch 494): Average loss: 0.2327, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 495 [64/170 (33%)]\tLoss: 0.318521 (avg: 0.318521) \tsec/iter: 0.0359\n",
      "Train Epoch: 495 [170/170 (100%)]\tLoss: 0.383936 (avg: 0.243485) \tsec/iter: 0.0322\n",
      "Test set (epoch 495): Average loss: 0.3776, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 496 [64/170 (33%)]\tLoss: 0.331752 (avg: 0.331752) \tsec/iter: 0.0389\n",
      "Train Epoch: 496 [170/170 (100%)]\tLoss: 0.144590 (avg: 0.248428) \tsec/iter: 0.0366\n",
      "Test set (epoch 496): Average loss: 0.1989, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 497 [64/170 (33%)]\tLoss: 0.226262 (avg: 0.226262) \tsec/iter: 0.0389\n",
      "Train Epoch: 497 [170/170 (100%)]\tLoss: 0.196301 (avg: 0.216638) \tsec/iter: 0.0342\n",
      "Test set (epoch 497): Average loss: 0.2080, Accuracy: 16/18 (88.89%)\n",
      "\n",
      "Train Epoch: 498 [64/170 (33%)]\tLoss: 0.212731 (avg: 0.212731) \tsec/iter: 0.0339\n",
      "Train Epoch: 498 [170/170 (100%)]\tLoss: 0.177707 (avg: 0.175775) \tsec/iter: 0.0322\n",
      "Test set (epoch 498): Average loss: 0.2118, Accuracy: 15/18 (83.33%)\n",
      "\n",
      "Train Epoch: 499 [64/170 (33%)]\tLoss: 0.269637 (avg: 0.269637) \tsec/iter: 0.0409\n",
      "Train Epoch: 499 [170/170 (100%)]\tLoss: 0.129574 (avg: 0.256014) \tsec/iter: 0.0336\n",
      "Test set (epoch 499): Average loss: 0.1735, Accuracy: 17/18 (94.44%)\n",
      "\n",
      "[94.44444444444444, 100.0, 94.44444444444444, 94.44444444444444, 94.44444444444444, 94.44444444444444, 94.44444444444444, 88.88888888888889, 100.0, 100.0]\n",
      "10-fold cross validation avg acc (+- std): 95.55555555555556 (3.3333333333333344)\n"
     ]
    }
   ],
   "source": [
    "acc_folds = []\n",
    "accuracy_arr = np.zeros((10, args.epochs), dtype=float)\n",
    "for fold_id in range(args.n_folds):\n",
    "    print('\\nFOLD', fold_id)\n",
    "    loaders = []\n",
    "    for split in ['train', 'test']:\n",
    "        gdata = GraphData(fold_id=fold_id,\n",
    "                             datareader=datareader,\n",
    "                             split=split)\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(gdata, \n",
    "                                             batch_size=args.batch_size,\n",
    "                                             shuffle=split.find('train') >= 0,\n",
    "                                             num_workers=args.threads)\n",
    "        loaders.append(loader)\n",
    "    \n",
    "    model = GNN(input_dim=loaders[0].dataset.features_dim,\n",
    "                hidden_dim=args.hidden_dim,\n",
    "                output_dim=loaders[0].dataset.n_classes,\n",
    "                n_layers=args.n_layers,\n",
    "                batchnorm_dim=args.batchnorm_dim, \n",
    "                dropout_1=args.dropout_1, \n",
    "                dropout_2=args.dropout_2).to(args.device)\n",
    "\n",
    "    print('\\nInitialize model')\n",
    "    print(model)\n",
    "    c = 0\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        c += p.numel()\n",
    "    print('N trainable parameters:', c)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=args.lr,\n",
    "                weight_decay=args.wdecay,\n",
    "                betas=(0.5, 0.999))\n",
    "    \n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, [20, 30], gamma=0.5)\n",
    "\n",
    "    def train(train_loader):\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        train_loss, n_samples = 0, 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            time_iter = time.time() - start\n",
    "            train_loss += loss.item() * len(output)\n",
    "            n_samples += len(output)\n",
    "            if batch_idx % args.log_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} (avg: {:.6f}) \\tsec/iter: {:.4f}'.format(\n",
    "                    epoch, n_samples, len(train_loader.dataset),\n",
    "                    100. * (batch_idx + 1) / len(train_loader), loss.item(), train_loss / n_samples, time_iter / (batch_idx + 1) ))\n",
    "\n",
    "    def test(test_loader):\n",
    "        model.eval()\n",
    "        start = time.time()\n",
    "        test_loss, correct, n_samples = 0, 0, 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(args.device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4], reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            n_samples += len(output)\n",
    "            pred = output.detach().cpu().max(1, keepdim=True)[1]\n",
    "\n",
    "            correct += pred.eq(data[4].detach().cpu().view_as(pred)).sum().item()\n",
    "\n",
    "        time_iter = time.time() - start\n",
    "\n",
    "        test_loss /= n_samples\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print('Test set (epoch {}): Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch, \n",
    "                                                                                              test_loss, \n",
    "                                                                                              correct, \n",
    "                                                                                              n_samples, acc))\n",
    "        return acc\n",
    "\n",
    "    loss_fn = F.cross_entropy\n",
    "    max_acc = 0.0\n",
    "    for epoch in range(args.epochs):\n",
    "        train(loaders[0])\n",
    "        acc = test(loaders[1])\n",
    "        accuracy_arr[fold_id][epoch] = acc\n",
    "        max_acc = max(max_acc, acc)\n",
    "    acc_folds.append(max_acc)\n",
    "\n",
    "print(acc_folds)\n",
    "print('{}-fold cross validation avg acc (+- std): {} ({})'.format(args.n_folds, np.mean(acc_folds), np.std(acc_folds)))\n",
    "\n",
    "mean_validation = accuracy_arr.mean(axis=0)\n",
    "maximum_epoch = np.argmax(mean_validation)\n",
    "average = np.mean(accuracy_arr[:, maximum_epoch])\n",
    "standard_dev = np.std(accuracy_arr[:, maximum_epoch])\n",
    "print('{}-fold cross validation avg acc (+- std): {} ({})'.format(args.n_folds, average, standard_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
